{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/LevSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install biopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from levseq.seqfit import process_plate_files, gen_seqfitvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the seq and fit to merge the two files\n",
    "processed_plate_df, seqfit_path = process_plate_files(product=[\"pdt\"], input_csv=\"/Users/arianemora/Documents/code/MinION/example/HMC0225_HMC0226.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_seqfitvis(seqfit_path=seqfit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get them w.r.t to a mutation\n",
    "from scipy.stats import mannwhitneyu\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "parent = '#PARENT#'\n",
    "value_column = 'pdt'\n",
    "normalise = 'standard' # one of parent, standard, minmax, none\n",
    "stats_method = 'mannwhitneyu'\n",
    "\n",
    "parent_values = processed_plate_df[processed_plate_df['Mutations'] == parent][value_column].values\n",
    "parent_mean = np.mean(parent_values)\n",
    "parent_sd = np.std(parent_values)\n",
    "\n",
    "# if nomrliase normalize with standard normalisation\n",
    "if normalise:\n",
    "    processed_plate_df[f'{value_column} standard norm'] = (processed_plate_df[value_column].values - parent_mean)/parent_sd\n",
    "    value_column = f'{value_column} standard norm'\n",
    "    \n",
    "parent_values = list(processed_plate_df[processed_plate_df['Mutations'] == parent][value_column].values)\n",
    "parent_mean = np.mean(parent_values)\n",
    "parent_sd = np.std(parent_values)\n",
    "sd_cutoff = 1.5 # The number of standard deviations we want above the parent values\n",
    "# Now for all the other mutations we want to look if they are significant, first we'll look at combinations and then individually\n",
    "grouped_by_mutations = processed_plate_df.groupby('Mutations')\n",
    "\n",
    "rows = []\n",
    "for mutation, grp in tqdm(grouped_by_mutations):\n",
    "    # Get the values and then do a ranksum test\n",
    "    if mutation != parent:\n",
    "        vals = list(grp[value_column].values)\n",
    "        U1, p = None, None\n",
    "        # Now check if there are 3 otherwise we just do > X S.D over - won't be sig anyway.\n",
    "        if len(grp) > 2:\n",
    "            # Do stats\n",
    "            U1, p = mannwhitneyu(parent_values, vals, method=\"exact\")\n",
    "        mean_vals = np.mean(vals)\n",
    "        std_vals = np.std(vals)\n",
    "        median_vals = np.median(vals)\n",
    "        sig = mean_vals > ((sd_cutoff*parent_sd) + parent_mean)\n",
    "        rows.append([mutation, len(grp), mean_vals, std_vals, median_vals, mean_vals - parent_mean, sig, U1, p])\n",
    "stats_df = pd.DataFrame(rows, columns=['mutation', 'number of wells with mutation', 'mean', 'std', 'median', 'amount greater than parent mean', f'greater than > {sd_cutoff} parent', 'man whitney U stat', 'p-value'])\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = stats_df.sort_values(by='p-value')\n",
    "stats_df.to_csv('stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "mutation_dict = defaultdict(list)\n",
    "for mutation in stats_df['mutation'].values:\n",
    "    mutations = mutation.split('_')\n",
    "    for m in mutations:\n",
    "        mutation_dict[m].append(mutation)\n",
    "\n",
    "rows = []\n",
    "with pd.ExcelWriter('mutations.xlsx', engine='xlsxwriter') as writer:\n",
    "    for mutation, mutations in mutation_dict.items():\n",
    "        # Here we want to now get the values for each of these i.e. the stats values for each one and summarize it maybe for now we'll just make a excel file\n",
    "        df1 = stats_df[stats_df['mutation'].isin(mutations)]\n",
    "        mutation = mutation.replace('*', '.')\n",
    "        df1.to_excel(writer, sheet_name=mutation)\n",
    "        # Also just take the mean of the mean lol and the sum of the number of the wells\n",
    "        rows.append([mutation, np.sum(df1['number of wells with mutation'].values), '|'.join(set(list(mutations))), np.mean(df1['mean'].values), \n",
    "                     np.median(df1['median'].values), np.mean(df1['amount greater than parent mean'].values), \n",
    "                     np.max(df1['amount greater than parent mean'].values)])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=['mutation', 'number of wells with mutation', \n",
    "                                 'other-mutations', 'mean', 'median', \n",
    "                                 'mean amount greater than parent', 'max amount greater than parent'])\n",
    "df.sort_values(by='mean amount greater than parent', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acid_to_codon = {\n",
    "    'A': 'GCT', 'R': 'CGT', 'N': 'AAT', 'D': 'GAT', 'C': 'TGT',\n",
    "    'Q': 'CAA', 'E': 'GAA', 'G': 'GGT', 'H': 'CAT', 'I': 'ATT',\n",
    "    'L': 'CTT', 'K': 'AAA', 'M': 'ATG', 'F': 'TTT', 'P': 'CCT',\n",
    "    'S': 'TCT', 'T': 'ACT', 'W': 'TGG', 'Y': 'TAT', 'V': 'GTT',\n",
    "    '*': 'TAA'\n",
    "}\n",
    "\n",
    "aas = list(amino_acid_to_codon.keys())\n",
    "from levseq.utils import *\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "seqs = []\n",
    "one_hots_nc = []\n",
    "one_hots_aa = []\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(np.array(['A', 'T', 'G', 'C', '-', '*']).reshape(-1, 1))\n",
    "\n",
    "encoder_aa = OneHotEncoder()\n",
    "encoder_aa.fit(np.array(aas).reshape(-1, 1))\n",
    "\n",
    "for nc in processed_plate_df['nc_variant'].values:\n",
    "    if nc  != 'Deletion':\n",
    "        seq = translate(nc)\n",
    "        one_hot_encoded = encoder.transform(np.array(list(nc)).reshape(-1, 1))\n",
    "        one_hot_encoded_array = one_hot_encoded.toarray().flatten()\n",
    "        one_hots_nc.append(one_hot_encoded_array)\n",
    "    \n",
    "        one_hot_encoded = encoder_aa.transform(np.array(list(seq)).reshape(-1, 1))\n",
    "        one_hot_encoded_array = one_hot_encoded.toarray().flatten()\n",
    "        one_hots_aa.append(one_hot_encoded_array)\n",
    "    else:\n",
    "        print('Deletion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pca = PCA(n_components=20)\n",
    "X = np.array(one_hots_nc)\n",
    "pca = pca.fit(X)\n",
    "pcs = pca.transform(X)\n",
    "\n",
    "non_deletions_df = processed_plate_df[processed_plate_df['nc_variant'] != 'Deletion']\n",
    "non_deletions_df['PC 1'] = pcs[:, 0]\n",
    "non_deletions_df['PC 2'] = pcs[:, 1]\n",
    "\n",
    "sns.scatterplot(non_deletions_df, x='PC 1', y='PC 2', hue='pdt standard norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_values = np.arange(pca.n_components_) + 1\n",
    "plt.plot(PC_values, (pca.explained_variance_ratio_*100), 'o-', linewidth=2, color='blue')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
