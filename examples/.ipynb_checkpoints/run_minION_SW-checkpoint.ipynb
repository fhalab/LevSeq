{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Every Variant Sequencing with Oxford Nanopore Technologies\n",
    "\n",
    "This script is being used after sequencing. The raw pod5 files can be basecalled or the already basecalled files can be used directly (fastq.gz)\n",
    "\n",
    "## Workflow\n",
    "\n",
    "### 1. Basecalling (Optional)\n",
    "\n",
    "- The raw reads are stored in the main folder of ONT (e.g /var/lib/minknow/data). Enter the experiment name as input. \n",
    "- Sequences are basecalled based on the model of choice. If enough computational power is available, we recommend \"sup\" method\n",
    "\n",
    "### 2. Demultiplexing \n",
    "- Each reead is assigned to a well/plate combination. \n",
    "\n",
    "### 3. Variant Calling\n",
    "- Minimap2 for creating Multiple Sequence Alignment (MSA)\n",
    "- Base Frequency Caller is being used for variant calling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import all packages\n",
    "\n",
    "import sys\n",
    "\n",
    "from minION import IO_processor\n",
    "from minION import Basecaller\n",
    "\n",
    "from minION.variantcaller import *\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import importlib\n",
    "importlib.reload(IO_processor)\n",
    "\n",
    "import pickle\n",
    "from Bio import SeqIO\n",
    "import gzip\n",
    "import subprocess\n",
    "import mappy as mp\n",
    "import holoviews as hv\n",
    "import re\n",
    "\n",
    "import ninetysix as ns\n",
    "import colorcet as cc\n",
    "import warnings\n",
    "\n",
    "import bokeh.io\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "hv.extension('bokeh')\n",
    "bokeh.io.output_notebook()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "source": [
    "def _make_platemap(df, title, cmap=None):\n",
    "    \"\"\"Generates a plate heatmap from evSeq data using Holoviews with\n",
    "    bokeh backend.\n",
    "\n",
    "    Called via `generate_platemaps`; see docs there.\n",
    "    \"\"\"\n",
    "    # Convert SeqDepth to log for easier visualization.\n",
    "    df['logseqdepth'] = np.log(\n",
    "        df['Alignment Count'],\n",
    "        out=np.zeros_like(df['Alignment Count'], dtype=float),\n",
    "        where=(df['Alignment Count'] != 0)\n",
    "    )\n",
    "    \n",
    "    # Create necessary Row and Column values and sort\n",
    "    df = df.sort_values(['Column', 'Row'])\n",
    "    df['Column'] = df['Column'].astype('str')\n",
    "\n",
    "    # Set some base opts\n",
    "    opts = dict(invert_yaxis=True, title=title, show_legend=True)\n",
    "    \n",
    "    # logseqdepth heatmap\n",
    "    seq_depth_cmap = list(reversed(cc.CET_D9))\n",
    "    \n",
    "    # Set the center\n",
    "    center = np.log(10)\n",
    "\n",
    "    add_min = False\n",
    "    if df['logseqdepth'].min() >= center:\n",
    "        add_min = True\n",
    "\n",
    "    # Adjust if it is greater than max of data (avoids ValueError)\n",
    "    if df['logseqdepth'].max() <= center:\n",
    "        # Adjust the center\n",
    "        center = df['logseqdepth'].median()\n",
    "\n",
    "    # center colormap\n",
    "    if not add_min:\n",
    "        color_levels = ns.viz._center_colormap(df['logseqdepth'], center)\n",
    "    else:\n",
    "        color_levels = ns.viz._center_colormap(\n",
    "            list(df['logseqdepth']) + [np.log(1)],\n",
    "            center\n",
    "        )\n",
    "\n",
    "    \n",
    "    # Get heights\n",
    "    n_rows = len(df['Row'].unique())\n",
    "    n_cols = len(df['Column'].unique())\n",
    "    height = int(50* n_rows)\n",
    "    width = height * n_cols // n_rows\n",
    "\n",
    "    # add tooltips\n",
    "    tooltips = [\n",
    "        ('Mutations', '@Mutations'),\n",
    "        ('Alignment Count', '@Alignment Count'),\n",
    "        ('Alignment Probability', '@Alignment Probability')\n",
    "    ]\n",
    "\n",
    "    def hook(plot, element):\n",
    "        plot.handles['y_range'].factors = list('HGFEDCBA')\n",
    "        plot.handles['x_range'].factors = [str(value) for value in range(1,13)]\n",
    "\n",
    "    # generate the heatmap\n",
    "    hm = hv.HeatMap(\n",
    "        df,\n",
    "        kdims=['Column', 'Row'],\n",
    "        vdims=[\n",
    "            'logseqdepth',\n",
    "            'Mutations',\n",
    "            'Alignment Count',\n",
    "            'Alignment Probability',\n",
    "        ],\n",
    "    ).redim.values(\n",
    "        row=np.unique(df[\"Row\"]),\n",
    "        Column=np.unique(df[\"Column\"])\n",
    "    ).opts(\n",
    "        **opts,\n",
    "        colorbar=True,\n",
    "        cmap=seq_depth_cmap,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        line_width=4,\n",
    "        clipping_colors={'NaN': '#DCDCDC'},\n",
    "        color_levels=color_levels,\n",
    "        tools=['hover'],\n",
    "        colorbar_opts=dict(\n",
    "            title='LogSeqDepth',\n",
    "            background_fill_alpha=0\n",
    "        ),\n",
    "        hooks=[hook]\n",
    "    )\n",
    " # function to bin the alignment frequencies into more relevant groupings\n",
    "    def bin_align_freq(value):\n",
    "        if value > 0.95:\n",
    "            bin_vals = '0.95+'\n",
    "        if value <= 0.95 and value > 0.9:\n",
    "            bin_vals = '0.90-0.95'\n",
    "        if value <= 0.9 and value > 0.8:\n",
    "            bin_vals = '0.80-0.90'\n",
    "        # anything below 0.8 should really be discarded\n",
    "        if value < 0.8:\n",
    "            bin_vals = '<0.80'\n",
    "        if value == 0.0:\n",
    "            bin_vals = '<0.80'\n",
    "        return bin_vals\n",
    "    \n",
    "    # Bin alignment frequencies for easier viz\n",
    "    bins = ['0.95+', '0.90-0.95', '0.80-0.90','<0.80']\n",
    "    if cmap is None:\n",
    "        cmap = [cc.bmy[int((1.1-i)*len(cc.bmy))]\n",
    "                for i in [0.95, 0.9, 0.8, 0.4]]\n",
    "    if 'stoplight' in cmap:\n",
    "        cmap = ['#337D1F', '#94CD35', '#FFC300', '#C62C20']\n",
    "    else:\n",
    "        # Validate colormap\n",
    "        if not isinstance(cmap, (list, tuple)):\n",
    "            raise ValueError('cmap argument must be a list or tuple')\n",
    "        if len(cmap) > 4:\n",
    "            raise ValueError(\n",
    "                'cmap argument has too many entries; only 4 should be passed'\n",
    "            )\n",
    "    cmap = {bin: color for bin, color in zip(bins, cmap)}\n",
    "\n",
    "    # apply binning function to the AlignmentFrequency\n",
    "    df['AlignmentProbabilityBinned'] = df['Alignment Probability'].apply(\n",
    "        bin_align_freq)\n",
    "\n",
    "    # Set up size of the outline boxes\n",
    "    box_size = height // n_rows*1.2\n",
    "\n",
    "    # alignment frequency heatmap for edges around wells\n",
    "    boxes = hv.Points(\n",
    "        df.sort_values(['Alignment Probability'], ascending=False),\n",
    "        ['Column', 'Row'],\n",
    "        'AlignmentProbabilityBinned'\n",
    "    ).opts(\n",
    "        **opts,\n",
    "        marker='square',\n",
    "        line_color='AlignmentProbabilityBinned',\n",
    "        line_join='miter',\n",
    "        cmap=cmap,\n",
    "        line_width=6,\n",
    "        fill_alpha=0,\n",
    "        line_alpha=1,\n",
    "        legend_position='top',\n",
    "        size=box_size,\n",
    "    )\n",
    "    \n",
    "    # Use in apply statement for residue labels\n",
    "    def split_variant_labels(mutation_string):\n",
    "        \n",
    "        num_mutations = len(mutation_string.split('_'))\n",
    "\n",
    "        if  num_mutations > 4:\n",
    "            return str(num_mutations)+' muts'\n",
    "\n",
    "        mutation_string = mutation_string.replace('?','')\n",
    "        new_line_mutations = mutation_string.replace('_','\\n')\n",
    "        \n",
    "        return new_line_mutations\n",
    "    \n",
    "    _df = df.copy()\n",
    "    _df['Labels'] = _df['Mutations'].apply(split_variant_labels)\n",
    "\n",
    "    # Set the font size based on if #PARENT# is in a well and num of mutations\n",
    "    max_num_mutations = _df['Labels'].apply(lambda x: len(x.split('\\n'))).max()\n",
    "    has_parent = ('#PARENT#' in _df['Labels'])\n",
    "    \n",
    "    if max_num_mutations > 3 or has_parent:\n",
    "        label_fontsize = '8pt'\n",
    "    else:\n",
    "        label_fontsize = '8pt'\n",
    "\n",
    "    labels = hv.Labels(\n",
    "        _df,\n",
    "        ['Column', 'Row'],\n",
    "        'Labels',\n",
    "    ).opts(\n",
    "        text_font_size=label_fontsize,\n",
    "        **opts,\n",
    "        text_color = '#000000'\n",
    "    )\n",
    "    # return formatted final plot\n",
    "    return (hm*boxes*labels).opts(frame_height=550,\n",
    "                                  frame_width=550 * 3 // 2,\n",
    "                                  border=50,\n",
    "                                  show_legend=True)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Heatmap ####\n",
    "def generate_platemaps(\n",
    "    max_combo_data,\n",
    "    cmap=None,\n",
    "    widget_location='top_left',\n",
    "):\n",
    "    \"\"\"Saves a plate heatmap html generated from from evSeq data.\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    max_combo_data: path (str) or DartaFrame\n",
    "        Path to 'Combos_Coupled_Max.csv' from an evSeq experiment or\n",
    "        a pandas DataFrame of that file.\n",
    "    cmap: list-like or str, default None\n",
    "        The colormap to use for the well outline indicating alignment\n",
    "        frequency. If None, defaults to a Plasma-like (colorcet.bmy)\n",
    "        colormap. If 'stoplight', uses a green-yellow-red colormap (not \n",
    "        the most colorblind friendly, but highly intuitive). Otherwise\n",
    "        you may pass any list -like object containing four colors (e.g.,\n",
    "        ['#337D1F', '#94CD35', '#FFC300', '#C62C20'] for 'stoplight').\n",
    "    widget_location: string, default 'top_left'\n",
    "        Location of the widget for navigating plots. Must be one of:\n",
    "        ['left', 'bottom', 'right', 'top', 'top_left', 'top_right',\n",
    "        'bottom_left', 'bottom_right', 'left_top', 'left_bottom', \n",
    "        'right_top', 'right_bottom'].\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hm_holomap: an interactive Platemap\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to dataframe if necessary\n",
    "    if isinstance(max_combo_data, str):\n",
    "        max_combo_df = pd.read_csv(max_combo_data)\n",
    "    else:\n",
    "        max_combo_df = max_combo_data.copy()\n",
    "    \n",
    "    # Identify unique plates\n",
    "    unique_plates = max_combo_df.Plate.unique()\n",
    "    \n",
    "    # dictionary for storing plots\n",
    "    hm_dict = {}\n",
    "   \n",
    "    # make logseqdepth column\n",
    "    max_combo_df['logseqdepth'] = np.log(\n",
    "        max_combo_df['Alignment Count'], \n",
    "        out=np.zeros_like(\n",
    "            max_combo_df['Alignment Count'], \n",
    "            dtype=float\n",
    "        ),\n",
    "        where=max_combo_df['Alignment Count'] != 0\n",
    "    )\n",
    "\n",
    "    # Set the center\n",
    "    center = np.log(10)\n",
    "\n",
    "    add_min = False\n",
    "    if max_combo_df['logseqdepth'].min() >= center:\n",
    "        add_min = True\n",
    "\n",
    "    # Adjust if it is greater than max of data (avoids ValueError)\n",
    "    if max_combo_df['logseqdepth'].max() <= center:\n",
    "        # Adjust the center\n",
    "        center = max_combo_df['logseqdepth'].median()\n",
    "\n",
    "    # center colormap\n",
    "    if not add_min:\n",
    "        color_levels = ns.viz._center_colormap(\n",
    "            max_combo_df['logseqdepth'], center\n",
    "        )\n",
    "    else:\n",
    "        color_levels = ns.viz._center_colormap(\n",
    "            list(max_combo_df['logseqdepth']) + [np.log(1)],\n",
    "            center\n",
    "        )\n",
    "\n",
    "    # Uniform color levels\n",
    "    for _hm in hm_dict.values():\n",
    "        _hm.opts({'HeatMap': {'color_levels': color_levels}})\n",
    "    \n",
    "    # Generate plots for each plate\n",
    "    for plate in unique_plates:\n",
    "        \n",
    "        # Split to just the information of interest\n",
    "        df = max_combo_df.loc[max_combo_df.Plate == plate].copy()\n",
    "    \n",
    "        # generate a holoviews plot\n",
    "        hm_dict[plate] = _make_platemap(df, title=plate, cmap=cmap)  \n",
    " \n",
    "    # plot from the dictionary\n",
    "    hm_holomap = hv.HoloMap(\n",
    "        hm_dict, \n",
    "        kdims=['Plate']\n",
    "    )\n",
    "\n",
    "    # Update widget location\n",
    "    hv.output(widget_location=widget_location)\n",
    "\n",
    "    return hm_holomap"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "source": [
    "def save_platemap_to_file(heatmaps, outputdir, name):\n",
    "    if not os.path.exists(os.path.join(outputdir, \"Platemaps\")):\n",
    "        os.makedirs(os.path.join(outputdir, \"Platemaps\"))\n",
    "    file_path = os.path.join(outputdir, \"Platemaps\", name)\n",
    "    hv.renderer('bokeh').save(heatmaps, file_path)\n",
    "\n",
    "def save_csv(df,outputdir,name):\n",
    "    if not os.path.exists(os.path.join(outputdir, \"Results\")):\n",
    "        os.makedirs(os.path.join(outputdir, \"Results\"))\n",
    "    file_path = os.path.join(outputdir, \"Results\", name + \".csv\")\n",
    "    df.to_csv(file_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Data \n",
    "\n",
    "- Provide the following arguments:\n",
    "\n",
    "- Result Path: Path where the minion result folder will be created. All experiment results are then stored within the folder\n",
    "- Experiment Name: The experiment name is assigned when running the sequencer. Use the same name for identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "source": [
    "result_path = Path(\"/Users/ariane/Documents/code/MinION/data/\")\n",
    "experiment_name = \"RL-8-70\"\n",
    "basecall_model_type = \"sup\"\n",
    "result_folder = IO_processor.create_folder( experiment_name,\n",
    "                                            basecall_model_type, \n",
    "                                            target_path=result_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create Barcode fasta file \n",
    "barcode_path = \"../minION/barcoding/minion_barcodes.fasta\" # Path to standard barcode file\n",
    "front_prefix = \"NB\"\n",
    "back_prefix = \"RB\"\n",
    "bp = IO_processor.BarcodeProcessor(barcode_path, front_prefix, back_prefix)\n",
    "barcode_path = result_folder / \"minion_barcodes_filtered.fasta\"\n",
    "\n",
    "# Barcode indexes\n",
    "front_min = 1\n",
    "front_max = 96\n",
    "back_min = 9\n",
    "back_max = 12\n",
    "\n",
    "# Expected fragment sizes\n",
    "min_size = 800\n",
    "max_size = 5000\n",
    "\n",
    "bp.filter_barcodes(barcode_path, (front_min,front_max), (back_min,back_max))\n",
    "\n",
    "\n",
    "file_to_experiment= f\"/Users/ariane/Documents/code/MinION/data/{experiment_name}\"\n",
    "template_fasta = \"/Users/ariane/Documents/code/MinION/data/pga9-4.fasta\"\n",
    "\n",
    "# Basecalling\n",
    "basecall_folder = result_folder / \"basecalled\"\n",
    "basecall_folder.mkdir(parents=True, exist_ok=True)\n",
    "experiment_folder = IO_processor.find_experiment_folder(experiment_name, '/Users/ariane/Documents/code/MinION/data') # Folder where pod5 files are located\n",
    "\n",
    "# Demultiplexing\n",
    "experiment_name = experiment_name + \"_\" + basecall_model_type\n",
    "result_folder_path = IO_processor.find_folder(result_path, experiment_name)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "source": [
    "# Add conditions to avoid running the script accidentally\n",
    "skip_basecalling = True\n",
    "skip_demultiplex = False\n",
    "skip_variant_calling = False"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 (Optional): Basecall reads\n",
    "\n",
    "- Basecall can usually be done while sequencing (if GPU available?)\n",
    "- Otherwise, basecall afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "source": [
    "if not skip_basecalling:\n",
    "\n",
    "\n",
    "    pod5_files = IO_processor.find_folder(experiment_folder, \"pod5\")\n",
    "    bc = Basecaller(basecall_model_type, pod5_files, basecall_folder, fastq = True)\n",
    "    bc.run_basecaller()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "source": [
    "# Find fastq files\n",
    "file_to_fastq = IO_processor.find_folder(experiment_folder, \"fastq_pass\")\n",
    "print(file_to_fastq)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Demultiplex with SW\n",
    "- Demultiplex with SW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "source": [
    "if not skip_demultiplex:\n",
    "    path_to_code = \"/Users/ariane/Documents/code/MinION/data/demultiplex\"\n",
    "    prompt = f\"{path_to_code} -f {file_to_fastq} -d {result_folder} -b {barcode_path} -w {100} -r {100} -m {min_size} -x {max_size}\"\n",
    "    subprocess.run(prompt, shell=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "source": [
    "demultiplex_folder = result_folder \n",
    "print(demultiplex_folder)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Call Variant with PileUP Analysis\n",
    "\n",
    "- Call Variant with min freq of 0.4 & depth min 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Summary file (Optional):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "demultiplex_folder_name = result_folder"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "source": [
    "experiment_folder"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "source": [
    "if not skip_variant_calling:\n",
    "    vc = VariantCaller(experiment_folder, \n",
    "                   template_fasta, \n",
    "                   demultiplex_folder_name=demultiplex_folder_name, \n",
    "                   padding_start=0, \n",
    "                   padding_end=0)\n",
    "    \n",
    "    variant_df = vc.get_variant_df(qualities=True, \n",
    "                                threshold=0.2,\n",
    "                                min_depth=5)\n",
    "    seq_gen = IO_processor.SequenceGenerator(variant_df, template_fasta)\n",
    "    variant_df = seq_gen.get_sequences()\n",
    "    #TODO: Save the variant_df to a file after running. Currently it is not saved."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "#20 - 30\n",
    "variant_df.to_csv(result_folder / \"variant_df.csv\", index=False)  "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "source": [
    "variant_df.iloc[1,2]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "source": [
    "variant_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "source": [
    "df_variants_ = variant_df.copy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "source": [
    "for seq_record in SeqIO.parse(open(template_fasta),'fasta'):\n",
    "    temp_seq = str(seq_record.seq).upper()\n",
    "df_variants_.insert(0, 'template', temp_seq)\n",
    "df_variants_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "source": [
    "df_variants_['Variant'].tolist()\n",
    "df_variants_['Variant'].fillna('',inplace = True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loop through dataframe and replace mutations\n",
    "mut_ls = []\n",
    "for i in df_variants_.index:\n",
    "    if isinstance(df_variants_['Variant'][i], np.ndarray):\n",
    "        df_variants_['Variant'][i] =  df_variants_['Variant'][i].tolist()\n",
    "        \n",
    "    if df_variants_['Variant'][i] == '':\n",
    "        mut_ls.append('NA')\n",
    "    elif pd.isnull(df_variants_['Variant'][i]):\n",
    "        mut_ls.append('NA')\n",
    "    elif df_variants_['Variant'][i] == '#PARENT#':\n",
    "        mut_ls.append(df_variants_['template'][i])\n",
    "    elif 'DEL' in df_variants_['Variant'][i]:\n",
    "        mut_ls.append('Deletion')\n",
    "    \n",
    "    else:\n",
    "        val_new = [x[-1] for x in df_variants_['Variant'][i].split('_')]\n",
    "        index = [int(s) for s in re.findall(r'\\d+', df_variants_['Variant'][i])]\n",
    "        index_bp = []\n",
    "        var_seq = temp_seq\n",
    "        for m in range(len(index)):\n",
    "            index_bp.append(index[m]-1)\n",
    "            var_seq = var_seq[:index_bp[m]] + val_new[m]+ var_seq[index_bp[m] + 1:]\n",
    "        mut_ls.append(var_seq)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "source": [
    "# Translate mutated sequence to protein\n",
    "aa_ls = []\n",
    "for i in range(len(mut_ls)):\n",
    "    if str(mut_ls[i]).upper() != 'NA':\n",
    "        aa_ls.append(translate(str(mut_ls[i]).upper()))\n",
    "    else:\n",
    "        aa_ls.append('NAN')\n",
    "df_variants_['Template Sequence'] = aa_ls"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compare to template sequence and get mutations\n",
    "mut = []\n",
    "temp_aa = translate(temp_seq)\n",
    "for i in range(len(aa_ls)):\n",
    "    mut.append('_'.join(get_mut(temp_aa, aa_ls[i])))\n",
    "df_variants_['Mutations'] = mut\n",
    "df_variants_['Alignment Probability'] = df_variants_['Probability'].fillna(0.0)\n",
    "df_variants_['Alignment Count'] = df_variants_['Alignment_count'].fillna(0.0)\n",
    "df_variants_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fill in parents into mutations column\n",
    "for i in df_variants_.index:\n",
    "    if df_variants_['Alignment Probability'].iloc[i] == 0.0 and df_variants_['Mutations'].iloc[i] == '':\n",
    "        df_variants_.Mutations.iat[i] = df_variants_.Mutations.iat[i].replace('', '#N.A.#')\n",
    "    if df_variants_['Mutations'].iloc[i] == '':\n",
    "        df_variants_.Mutations.iat[i] = df_variants_.Mutations.iat[i].replace('', '#PARENT#') \n",
    "df_variants_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "source": [
    "Well = df_variants_['Well'].tolist()\n",
    "column = [Well[i].strip('ABCDEFGH') for Well[i] in Well]\n",
    "row = [Well[i].rstrip('0123456789') for Well[i] in Well]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "source": [
    "df_variants_['Row'] = row\n",
    "df_variants_['Column'] = column\n",
    "df_variants_['Plate'] = df_variants_['Plate'].astype(str)\n",
    "df_variants_.loc[df_variants_['Plate'] == '9', ['Plate']] = '09'\n",
    "df_variants_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "source": [
    "hm_ = generate_platemaps(df_variants_)\n",
    "\n",
    "hm_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "source": [
    "save_platemap_to_file(hm_, demultiplex_folder, experiment_name)\n",
    "save_csv(df_variants_, demultiplex_folder, experiment_name)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
