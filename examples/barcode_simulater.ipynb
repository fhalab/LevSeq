{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barcode Demultiplexer Simulator \n",
    "\n",
    "- Simulate Demultiplexing using local and semi-global alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/emre/github_repo/MinION\")\n",
    "from minION import analyser\n",
    "from minION import consensus\n",
    "from minION import demultiplexer\n",
    "import importlib\n",
    "from minION.util import IO_processor\n",
    "from minION.util.globals import BARCODES, MEDAKA_MODELS, DEFAULT_TARGETS\n",
    "importlib.reload(IO_processor)\n",
    "importlib.reload(analyser)\n",
    "importlib.reload(consensus)\n",
    "importlib.reload(demultiplexer)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#import plotly.express as px\n",
    "import random\n",
    "from Bio import SeqIO\n",
    "import subprocess\n",
    "import re\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly version\n",
    "def barcode_score(summary):\n",
    "    fig = px.histogram(summary, x=\"barcode_score\", nbins=100, \n",
    "                       title=\"Barcode Score Distribution\", labels={'barcode_score': 'Barcode Score', 'count': 'Frequency'})\n",
    "    fig.update_traces(marker_color='red', marker_line_color='black', marker_line_width=1.5, opacity=0.5)\n",
    "    fig.update_layout(width=600, height=400)\n",
    "    return fig\n",
    "\n",
    "def barcode_barplot(summary, barcode_id=\"barcode_arrangement\", ylim=None):\n",
    "    barcodes = summary[barcode_id].value_counts().reset_index()\n",
    "    fig = px.bar(barcodes, x=barcode_id, y=\"count\", \n",
    "                 title=\"Barcode Frequency\", labels={'index': 'Barcode ID', barcode_id: 'Frequency'})\n",
    "    fig.update_traces(marker_color='red', marker_line_color='black', marker_line_width=1.5, opacity=0.5)\n",
    "    fig.update_layout(width=600, height=400)\n",
    "\n",
    "    if ylim:\n",
    "        fig.update_layout(yaxis=dict(range=[0, ylim]))\n",
    "\n",
    "    return fig\n",
    "\n",
    "def barcode_arrangement(summary, plot=True):\n",
    "    barcode_arrangements = summary[\"barcode_arrangement\"].value_counts().reset_index()\n",
    "\n",
    "    if plot:\n",
    "        fig = px.bar(barcode_arrangements, x='barcode_score', y='barcode_arrangement', \n",
    "                     title=\"Barcode Frequency\", labels={'index': 'Barcode ID', 'barcode_arrangement': 'Frequency'})\n",
    "        fig.update_traces(marker_color='red', marker_line_color='black', marker_line_width=1.5, opacity=0.5)\n",
    "        fig.update_layout(width=600, height=400)\n",
    "        return fig\n",
    "    else:\n",
    "        return barcode_arrangements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_gc_content(sequence, desired_gc_fraction, tolerance=0.05):\n",
    "    \"\"\"\n",
    "    Check if the GC content of the sequence is within the desired range.\n",
    "    \"\"\"\n",
    "    gc_count = sum(1 for nucleotide in sequence if nucleotide in ['G', 'C'])\n",
    "    gc_fraction = gc_count / len(sequence)\n",
    "    return abs(gc_fraction - desired_gc_fraction) <= tolerance\n",
    "\n",
    "def generate_gc_content_sequence(length, desired_gc_fraction):\n",
    "    \"\"\"\n",
    "    Iteratively generate a random DNA sequence until it has the desired GC content.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        sequence = ''.join(random.choice('ATCG') for _ in range(length))\n",
    "        if check_gc_content(sequence, desired_gc_fraction):\n",
    "            return sequence\n",
    "\n",
    "\n",
    "def introduce_mutations(sequence, mutation_rate, weights = [0.2, 0.4, 0.4]):\n",
    "    \"\"\"\n",
    "    Introduce mutations in a sequence with the specified mutation rate.\n",
    "    The mutations include substitution, insertion, and deletion.\n",
    "    \"\"\"\n",
    "    mutated_sequence = ''\n",
    "    nucleotides = ['A', 'C', 'G', 'T']\n",
    "    \n",
    "    weights = {'substitution': weights[0], 'insertion': weights[1], 'deletion': weights[2]}\n",
    "\n",
    "    i = 0\n",
    "    while i < len(sequence):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutation_type = random.choices(['substitution', 'insertion', 'deletion'], weights=[weights['substitution'], weights['insertion'], weights['deletion']])[0]\n",
    "            if mutation_type == 'substitution':\n",
    "                mutated_sequence += random.choice([n for n in nucleotides if n != sequence[i]])\n",
    "                i += 1\n",
    "            elif mutation_type == 'insertion':\n",
    "                mutated_sequence += random.choice(nucleotides)\n",
    "            else:  # deletion\n",
    "                i += 1\n",
    "                continue\n",
    "        else:\n",
    "            mutated_sequence += sequence[i]\n",
    "            i += 1\n",
    "    return mutated_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the synthetic sequences\n",
    "\n",
    "- GC content of 60 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_to_fastq(filename, barcodes, sequence_length, barcode_position_start, barcode_position_end, mutation_rate, num_sequences, num_noise):\n",
    "    \"\"\"\n",
    "    Write mutated sequences for each barcode into a FASTQ file using a fixed surrounding sequence.\n",
    "    \"\"\"\n",
    "    with open(filename, 'wt') as fastq_file:\n",
    "        for i in range(num_sequences):\n",
    "            # Generate one surrounding sequence for the set of barcodes\n",
    "            surrounding_sequence = generate_gc_content_sequence(sequence_length, 0.6)\n",
    "\n",
    "            for barcode_name, barcode_sequence in barcodes.items():\n",
    "                # Introduce mutations in the barcode sequence\n",
    "                mutated_barcode_sequence = introduce_mutations(barcode_sequence, mutation_rate)\n",
    "\n",
    "                # Insert the mutated barcode sequence in the surrounding sequence\n",
    "                mutated_sequence = surrounding_sequence[:barcode_position_start] + mutated_barcode_sequence + surrounding_sequence[barcode_position_end:]\n",
    "                \n",
    "                # Assign quality scores\n",
    "                quality_scores = \"I\" * len(mutated_sequence)\n",
    "                \n",
    "                mut_r = str(mutation_rate).replace(\".\", \"_\")\n",
    "                # Write to FASTQ file\n",
    "                fastq_file.write(f\"@seq_{mut_r}_{i + 1}_{barcode_name}\\n\")\n",
    "                fastq_file.write(f\"{mutated_sequence}\\n\")\n",
    "                fastq_file.write(\"+\\n\")\n",
    "                fastq_file.write(f\"{quality_scores}\\n\")\n",
    "\n",
    "\n",
    "        for i in range(num_noise):\n",
    "        # Generate random noise sequence\n",
    "            noise_sequence = generate_gc_content_sequence(sequence_length, 0.6)\n",
    "            \n",
    "            # Assign quality scores\n",
    "            quality_scores = \"I\" * sequence_length\n",
    "            \n",
    "            # Write to FASTQ file\n",
    "            fastq_file.write(f\"@noise_{i + 1}\\n\")\n",
    "            fastq_file.write(f\"{noise_sequence}\\n\")\n",
    "            fastq_file.write(\"+\\n\")\n",
    "            fastq_file.write(f\"{quality_scores}\\n\")\n",
    "\n",
    "def split_read_id(read_id):\n",
    "    \"\"\"\n",
    "    Split the read ID into the barcode ID and the read ID.\n",
    "    \"\"\"\n",
    "    parts = read_id.split(\"_\")\n",
    "    barcode_id = parts[-1]\n",
    "    read_id_prefix = \"_\".join(parts[:-1])\n",
    "\n",
    "    if barcode_id.isnumeric():\n",
    "        barcode_id = \"noise\"\n",
    "    return barcode_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "barcodes = {}\n",
    "with open(\"/home/emre/github_repo/MinION/minION/barcoding/minion_barcodes_sim.fasta\", \"r\") as handle:\n",
    "    records = list(SeqIO.parse(handle, \"fasta\"))\n",
    "    i = 0\n",
    "    for record in records:\n",
    "        if i > 24:\n",
    "            break\n",
    "        barcodes[record.id] = str(record.seq)\n",
    "        print(record.id, str(record.seq))\n",
    "        i += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "names = [\"0\", \"01\", \"02\", \"03\", \"04\"]\n",
    "for i, rate in enumerate([0, 0.1, 0.2, 0.3, 0.4]):\n",
    "    sequence_length = 150\n",
    "    barcode_position_start = 70\n",
    "    barcode_position_end = 94\n",
    "    mutation_rate = rate # 10% mutation rate\n",
    "    num_sequences = 3000\n",
    "    num_noise = 0\n",
    "\n",
    "    # Write sequences to a FASTQ file\n",
    "    write_to_fastq(f\"data/mutated_sequences_{names[i]}_24barcodes.fastq\", barcodes, sequence_length, barcode_position_start, barcode_position_end, mutation_rate, num_sequences, num_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_names = [\"00_0\", \"00_1\", \"00_2\", \"01_0\", \"01_1\", \"01_2\", \"02_0\", \"02_1\", \"02_2\"]\n",
    "file_names = [\"tpr_fpr_testing\"]\n",
    "\n",
    "for file in file_names:\n",
    "    path = Path(\"data\") / file / \"24_barcodes\" \n",
    "    demultiplexer.run_demultiplexer_single(path, BARCODES, 15, 15, basecall_folder = path)\n",
    "\n",
    "    # Calculate TP, FP, FN, TN\n",
    "    #summary = pd.read_csv(Path(\"data\") / file / \"24_barcodes\" / \"demultiplex_15\" / \"barcoding_summary.csv\")\n",
    "    #summary[\"Truth\"] = summary[\"read_id\"].apply(split_read_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPP Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summary for CPP \n",
    "\n",
    "summary = pd.read_csv(\"/home/emre/github_repo/MinION/examples/data/Demultiplex_cpp/barcoding_summary_8_barcodes.txt\", sep=\"\\t\")\n",
    "summary_24 = pd.read_csv(\"/home/emre/github_repo/MinION/examples/data/Demultiplex_cpp/barcoding_summary_24_barcodes.txt\", sep=\"\\t\")\n",
    "summary[\"Truth\"] = summary[\"ID\"].apply(split_read_id)\n",
    "summary_24[\"Truth\"] = summary_24[\"ID\"].apply(split_read_id)\n",
    "\n",
    "# summary = pd.read_csv(\"/home/emre/github_repo/MinION/examples/data/tpr_fpr_testing/8_barcodes/demultiplex_15/barcoding_summary.txt\", sep=\"\\t\")\n",
    "# summary_24 = pd.read_csv(\"/home/emre/github_repo/MinION/examples/data/tpr_fpr_testing/24_barcodes/demultiplex_15/barcoding_summary.txt\", sep=\"\\t\")\n",
    "# summary[\"Truth\"] = summary[\"read_id\"].apply(split_read_id)\n",
    "# summary_24[\"Truth\"] = summary_24[\"read_id\"].apply(split_read_id)\n",
    "\n",
    "\n",
    "\n",
    "bins = np.arange(15, 105, 5)\n",
    "# summary[\"bins\"] = pd.cut(summary[\"barcode_score\"], bins)\n",
    "# summary_24[\"bins\"] = pd.cut(summary_24[\"barcode_score\"], bins)\n",
    "\n",
    "# summary[\"bins\"] = pd.cut(summary[\"RBC_Score\"], bins)\n",
    "# summary_24[\"bins\"] = pd.cut(summary_24[\"RBC_Score\"], bins)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "#sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "\n",
    "color_8 = sns.color_palette(\"viridis\")[3]\n",
    "color_24 = sns.color_palette(\"viridis\")[5]\n",
    "# Create the histogram plot\n",
    "# sns.histplot(data=summary, x=\"RBC_Score\", bins=100, kde=False, ax=ax, color=color, alpha=0.5, edgecolor=\"black\", linewidth=1.5)\n",
    "# sns.histplot(data=summary_24, x=\"RBC_Score\", bins=100, kde=False, ax=ax, color=color_24, alpha=0.3, edgecolor=\"black\", linewidth=1.5)\n",
    "\n",
    "\n",
    "sns.histplot(data=summary, x=\"barcode_score\", bins=100, kde=False, ax=ax, color=color, alpha=0.5, edgecolor=\"black\", linewidth=1.5)\n",
    "sns.histplot(data=summary_24, x=\"barcode_score\", bins=100, kde=False, ax=ax, color=color_24, alpha=0.3, edgecolor=\"black\", linewidth=1.5)\n",
    "\n",
    "# Add custom legend with the correct colors\n",
    "#custom_lines = [plt.Line2D([0], [0], color=\"navy\", lw=4)]\n",
    "\n",
    "#ax.legend(custom_lines, [''])\n",
    "# Add labels and title\n",
    "ax.set_xlabel(\"Barcode Score\", size=22)\n",
    "ax.set_ylabel(\"Frequency\", size = 22)\n",
    "ax.tick_params(labelsize=18)\n",
    "ax.set_ylim(0, 10000)\n",
    "\n",
    "\n",
    "#ax.set_title(\"Barcode Score Distribution\")\n",
    "ax.legend([\"8 barcodes\", \"24 barcodes\"], fontsize=18)\n",
    "# Add a red vertical line\n",
    "#ax.axvline(x=60, color='red', linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"barcode_score_distribution_guppy_quality_test_barcodes_guppy.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(30, 105, 5)\n",
    "summary[\"bins\"] = pd.cut(summary[\"RBC_Score\"], bins) # Guppy\n",
    "summary_24[\"bins\"] = pd.cut(summary_24[\"RBC_Score\"], bins)\n",
    "\n",
    "# summary[\"bins\"] = pd.cut(summary[\"RBC_Score\"], bins)\n",
    "# summary_24[\"bins\"] = pd.cut(summary_24[\"RBC_Score\"], bins)\n",
    "\n",
    "\n",
    "df = summary_24.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TPR_interval = {\"Interval\" : [], \"TPR\" : [], \"FPR\" : []}\n",
    "barcode_column = \"RBC\"\n",
    "for intervals in df[\"bins\"].unique().sort_values():\n",
    "    bin_df = df[df[\"bins\"] == intervals]\n",
    "    \n",
    "    tpr = []\n",
    "    fpr = []\n",
    "\n",
    "    fp = bin_df[(bin_df[barcode_column] != bin_df[\"Truth\"])]\n",
    "    tp = bin_df[(bin_df[barcode_column] == bin_df[\"Truth\"])]\n",
    "\n",
    "    print(f\"TPR for {intervals}: {len(tp) / (len(bin_df) +1)}\")\n",
    "    print(f\"FPR for {intervals}: {len(fp) / (len(bin_df)+1)}\")\n",
    "\n",
    "    TPR_interval[\"Interval\"].append(intervals)\n",
    "    TPR_interval[\"TPR\"].append(len(tp) / (len(bin_df) +1))\n",
    "    TPR_interval[\"FPR\"].append(len(fp) / (len(bin_df)+1))\n",
    "\n",
    "pd.DataFrame(TPR_interval).to_csv(\"tpr_fpr_24barcodes_local.csv\", index=False)\n",
    "pd.DataFrame(TPR_interval).dropna().plot(x=\"Interval\", y=[\"TPR\", \"FPR\"], figsize=(10, 5), title=\"TPR and FPR for different barcode score intervals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intervals in summary[\"bins\"].unique().sort_values():\n",
    "    bin_df = summary[summary[\"bins\"] == intervals]\n",
    "    \n",
    "    tpr = []\n",
    "    fpr = []\n",
    "\n",
    "    fp = bin_df[(bin_df[barcode_column] != bin_df[\"Truth\"])]\n",
    "    tp = bin_df[(bin_df[barcode_column] == bin_df[\"Truth\"])]\n",
    "    print(f\"TPR for {intervals}: {len(tp) / (len(bin_df) +1)}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(\"/home/emre/github_repo/MinION/examples/data/tpr_fpr_testing/24_barcodes/demultiplex_15/barcoding_summary.txt\", sep=\"\\t\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guppy Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(\"/home/emre/github_repo/MinION/examples/data/tpr_fpr_testing/24_barcodes/demultiplex_15/barcoding_summary.txt\", sep=\"\\t\")\n",
    "summary[\"Truth\"] = summary[\"read_id\"].apply(split_read_id)\n",
    "bins = np.arange(15, 105, 5)\n",
    "summary[\"bins\"] = pd.cut(summary[\"barcode_score\"], bins)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Create the histogram plot\n",
    "sns.histplot(data=summary, x=\"barcode_score\", bins=100, kde=False, ax=ax, color=\"navy\", alpha=0.5)\n",
    "\n",
    "\n",
    "# Add custom legend with the correct colors\n",
    "custom_lines = [plt.Line2D([0], [0], color=\"navy\", lw=4)]\n",
    "\n",
    "#ax.legend(custom_lines, [''])\n",
    "# Add labels and title\n",
    "ax.set_xlabel(\"Barcode Score\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "#ax.set_title(\"Barcode Score Distribution\")\n",
    "\n",
    "# Add a red vertical line\n",
    "#ax.axvline(x=60, color='red', linestyle='--')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"barcode_score_distribution_guppy_quality_test_24barcodes.png\", dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR_interval = {\"Interval\" : [], \"TPR\" : [], \"FPR\" : []}\n",
    "barcode_column = \"barcode_full_arrangement\"\n",
    "for intervals in summary[\"bins\"].unique().sort_values():\n",
    "    bin_df = summary[summary[\"bins\"] == intervals]\n",
    "    \n",
    "    tpr = []\n",
    "    fpr = []\n",
    "\n",
    "    fp = bin_df[(bin_df[barcode_column] != bin_df[\"Truth\"])]\n",
    "    tp = bin_df[(bin_df[barcode_column] == bin_df[\"Truth\"])]\n",
    "\n",
    "    print(f\"TPR for {intervals}: {len(tp) / (len(bin_df) +1)}\")\n",
    "    print(f\"FPR for {intervals}: {len(fp) / (len(bin_df)+1)}\")\n",
    "\n",
    "    TPR_interval[\"Interval\"].append(intervals)\n",
    "    TPR_interval[\"TPR\"].append(len(tp) / (len(bin_df) +1))\n",
    "    TPR_interval[\"FPR\"].append(len(fp) / (len(bin_df)+1))\n",
    "\n",
    "\n",
    "    pd.DataFrame(TPR_interval).to_csv(\"tpr_fpr_8barcodes_guppy.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.groupby([\"Truth\", \"bins\"]).count()[\"read_id\"].reset_index().pivot(index=\"bins\", columns=\"Truth\", values=\"read_id\").plot.bar(stacked=True, figsize=(10, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TP and FP\n",
    "barcode_column = \"barcode_full_arrangement\"\n",
    "barcode = \"RB01\"\n",
    "tp = summary[(summary[barcode_column] == barcode) & (summary[\"Truth\"] == barcode)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPR FPR Plotting of Guppy and Local Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_8_cpp = pd.read_csv(\"/home/emre/github_repo/MinION/examples/tpr_fpr_8barcodes_CPP.csv\")\n",
    "barcode_24_cpp = pd.read_csv(\"/home/emre/github_repo/MinION/examples/tpr_fpr_24barcodes_CPP.csv\")\n",
    "barcode_24 = pd.read_csv(\"/home/emre/github_repo/MinION/examples/tpr_fpr_24barcodes.csv\")\n",
    "barcode_8 = pd.read_csv(\"/home/emre/github_repo/MinION/examples/tpr_fpr_8barcodes.csv\")\n",
    "\n",
    "barcode_8_cpp[\"Barcode\"] = \"8 barcodes (CPP)\"\n",
    "barcode_24_cpp[\"Barcode\"] = \"24 barcodes (CPP)\"\n",
    "barcode_24[\"Barcode\"] = \"24 barcodes (Guppy)\"\n",
    "barcode_8[\"Barcode\"] = \"8 barcodes (Guppy)\"\n",
    "\n",
    "summary = pd.concat([barcode_8_cpp, barcode_24_cpp, barcode_24, barcode_8]).reset_index(drop=True)\n",
    "#summary = summary.drop(summary[(summary[\"Barcode\"] == \"8 barcodes (Guppy)\") & (summary[\"Interval\"] == \"(20, 25]\")].index)\n",
    "summary = summary[summary['Interval'] >= '(30, 35]']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes as per your setup\n",
    "import matplotlib.cm as cm\n",
    "df = summary\n",
    "df_8 = df[df['Barcode'] == \"8 barcodes (CPP)\"]\n",
    "df_24 = df[df['Barcode'] == \"24 barcodes (CPP)\"]\n",
    "df_8_guppy = df[df['Barcode'] == \"8 barcodes (Guppy)\"]\n",
    "df_24_guppy = df[df['Barcode'] == \"24 barcodes (Guppy)\"]\n",
    "\n",
    "# Define bar width and positions\n",
    "barWidth = 0.2\n",
    "# r1 = np.arange(len(df_8['Interval']))\n",
    "# r2 = [x + barWidth for x in r1]\n",
    "# r3 = [x + barWidth for x in r2]\n",
    "# r4 = [x + barWidth for x in r3]\n",
    "\n",
    "# Define bar width and positions\n",
    "barWidth = 0.2\n",
    "r = np.arange(len(df_8['Interval']))\n",
    "\n",
    "# Create the figure and axes\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "viridis_colors = cm.viridis(np.linspace(0, 1, 4))\n",
    "\n",
    "# Creating bars for TPR\n",
    "plt.bar(r, df_8['TPR'], color=viridis_colors[0], width=barWidth, edgecolor='black', label='8 Barcodes - TPR - Local')\n",
    "plt.bar(r + barWidth, df_24['TPR'], color=viridis_colors[1], width=barWidth, edgecolor='black', label='24 Barcodes - TPR - Local')\n",
    "plt.bar(r + 2 * barWidth, df_8_guppy['TPR'], color=viridis_colors[2], width=barWidth, edgecolor='black', label='8 Barcodes - TPR - Semi-Global')\n",
    "plt.bar(r + 3 * barWidth, df_24_guppy['TPR'], color=viridis_colors[3], width=barWidth, edgecolor='black', label='24 Barcodes - TPR - Semi-Global')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Barcode Score Interval', size=20)\n",
    "plt.ylabel('True Positive Rate (TPR)', size=20)\n",
    "plt.xticks(r + 1.5 * barWidth, df_8['Interval'], rotation=45, size=16)\n",
    "plt.yticks(size=16)\n",
    "\n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"TPR_barcode_score_interval.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = analyser.read_summary_file(\"/home/emre/github_repo/MinION/examples/data/01_quality/demultiplex_30/\")\n",
    "\n",
    "# Calculate precision, recall, F1 score\n",
    "summary[\"Truth\"] = summary[\"read_id\"].apply(split_read_id)\n",
    "\n",
    "barcode_classification = {\"True Positive\": \"TP\", \"False Positive\": \"FP\", \"False Negative\": \"FN\", \"True Negative\": \"TN\"}\n",
    "for barcode in barcodes.keys():\n",
    "    barcode_column = \"barcode_arrangement\"\n",
    "    # barcode = RB01\n",
    "    tp = summary[(summary[barcode_column] == barcode) & (summary[\"Truth\"] == barcode)]\n",
    "    fn = summary[(summary[barcode_column] != barcode) & (summary[\"Truth\"] == barcode)]\n",
    "    fp = summary[(summary[barcode_column] == barcode) & (summary[\"Truth\"] != barcode)]\n",
    "    tn = summary[(summary[barcode_column] != barcode) & (summary[\"Truth\"] != barcode)]\n",
    "\n",
    "    tp_percentage = len(tp) / 40000 * 100\n",
    "    fp_percentage = len(fp) / 40000 * 100\n",
    "\n",
    "    print(f\"True Positive: {len(tp)} ({tp_percentage:.2f}%), False Positive: {len(fp)} ({fp_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[(summary[barcode_column] == \"RB01\") & (summary[\"Truth\"] != \"RB01\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demultiplexer.run_demultiplexer_single(Path(\"data\") / \"03_0\", BARCODES, 50, 50, basecall_folder = Path(\"data\") / \"03_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"barcode_full_arrangement\"].value_counts().reset_index()\n",
    "\n",
    "# SNS\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.bar(summary[\"barcode_arrangement\"].value_counts().index, summary[\"barcode_arrangement\"].value_counts().values, color=\"lightgrey\", edgecolor=\"black\")\n",
    "#plt.title(\"Barcode Arrangement - Guppy (Semi-Global)\")\n",
    "plt.xlabel(\"Barcode Classification\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Create the histogram plot\n",
    "sns.histplot(data=summary_01, x=\"barcode_score\", bins=100, kde=False, ax=ax, color=\"navy\", alpha=0.5)\n",
    "sns.histplot(data=summary_02, x=\"barcode_score\", bins=100, kde=False, ax=ax, color=\"pink\", alpha=0.9)\n",
    "sns.histplot(data=summary_03, x=\"barcode_score\", bins=100, kde=False, ax=ax, color=\"lightgreen\", alpha=0.5)\n",
    "sns.histplot(data=summary_04, x=\"barcode_score\", bins=100, kde=False, ax=ax, color=\"red\", alpha=0.5)\n",
    "\n",
    "# Add custom legend with the correct colors\n",
    "custom_lines = [plt.Line2D([0], [0], color=\"navy\", lw=4),\n",
    "                plt.Line2D([0], [0], color=\"pink\", lw=4),\n",
    "                plt.Line2D([0], [0], color=\"lightgreen\", lw=4),\n",
    "                plt.Line2D([0], [0], color=\"red\", lw=4)]\n",
    "\n",
    "ax.legend(custom_lines, ['10% ', '20%', \"30%\", \"40%\"])\n",
    "# Add labels and title\n",
    "ax.set_xlabel(\"Barcode Score\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "#ax.set_title(\"Barcode Score Distribution\")\n",
    "\n",
    "# Add a red vertical line\n",
    "#ax.axvline(x=60, color='red', linestyle='--')\n",
    "\n",
    "# Show the plot\n",
    "#plt.savefig(\"barcode_score_distribution_guppy.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.concat([summary_01, summary_02, summary_03, summary_04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 100, 5)\n",
    "summary[\"bins\"] = pd.cut(summary[\"barcode_score\"], bins)\n",
    "summary[\"Truth\"] = summary[\"read_id\"].apply(split_read_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"barcode_arrangement\"].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_read_id(read_id):\n",
    "    \"\"\"\n",
    "    Split the read ID into the barcode ID and the read ID.\n",
    "    \"\"\"\n",
    "    parts = read_id.split(\"_\")\n",
    "    barcode_id = parts[-1]\n",
    "    read_id_prefix = \"_\".join(parts[:-1])\n",
    "    return barcode_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Truth\"] = summary[\"read_id\"].apply(split_read_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_classified_df = get_correctly_classified_barcodes(summary_01, barcode_truth_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cpp = analyser.read_summary_file(Path('/home/emre/github_repo/MinION/examples/data/Demultiplex_cpp/50'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cpp[\"RBC\"].value_counts().reset_index()\n",
    "\n",
    "# SNS\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.barplot(x=\"RBC\", y=\"count\", data=summary_cpp[\"RBC\"].value_counts().reset_index())\n",
    "plt.title(\"Barcode Arrangement - Ours\")\n",
    "plt.xlabel(\"Barcode Classification\")\n",
    "plt.ylabel(\"Frequency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Create the histogram plot\n",
    "sns.histplot(data=summary_cpp, x=\"RBC_Score\", bins=100, kde=True, ax=ax)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel(\"Barcode Score\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Barcode Score Distribution\")\n",
    "\n",
    "# Add a red vertical line\n",
    "ax.axvline(x=60, color='red', linestyle='--')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment Simulation to predict the accuracy at different depths\n",
    "\n",
    "- Start with HETCPII (612bp)\n",
    "- Sample random mutations (Parent, Single Point Mutation, 2, 3 up to 8)\n",
    "- Generate Substitutions & indels for a given site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_variants(template, num_variants, num_mutations, seed):\n",
    "    \"\"\"\n",
    "    Generate random variants based of num of mutations and num of variants.\n",
    "    \"\"\"\n",
    "    trans_matrix = np.array([   [0,    0.01,  0.46,  0.18, 0.0], #A\n",
    "                                [0.02, 0,     0.025, 0.43, 0.0], #C\n",
    "                                [0.43, 0.025, 0,     0.02, 0.0], #G\n",
    "                                [0.18, 0.0335,0.1,   0,    0.0], #T\n",
    "                                [0.0,  0.0,   0.0,   0.0,  0]]) #DEL\n",
    "\n",
    "    bases = [\"A\", \"C\", \"G\", \"T\", \"DEL\"]\n",
    "\n",
    "    Variants = {\"Variant\": [], \"Sequence\": []}\n",
    "\n",
    "    rng = np.random.RandomState(seed)  # Random state object\n",
    "\n",
    "\n",
    "    for i in range(num_variants):\n",
    "        if num_mutations == 0:\n",
    "            Variants[\"Variant\"].append([\"#PARENT#\"])\n",
    "            Variants[\"Sequence\"].append(template)\n",
    "            continue\n",
    "\n",
    "        positions = rng.choice(range(len(template)), num_mutations, replace=False)\n",
    "        positions.sort()\n",
    "\n",
    "        \n",
    "        mutations = []\n",
    "        for pos in positions:\n",
    "            adjusted_pos = pos \n",
    "            ref_base = template[adjusted_pos]\n",
    "            ref_index = bases.index(ref_base)\n",
    "\n",
    "            prob = trans_matrix[ref_index]\n",
    "            prob = prob / prob.sum()\n",
    "\n",
    "            new_base = np.random.choice(bases, p=prob)\n",
    "\n",
    "            if new_base != \"DEL\":\n",
    "                mutation = f\"{ref_base}{adjusted_pos + 1}{new_base}\"\n",
    "            elif new_base == \"DEL\":\n",
    "                mutation = f\"{ref_base}{adjusted_pos + 1}DEL\"\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(\"Invalid base\")\n",
    "                \n",
    "\n",
    "            mutations.append((adjusted_pos, new_base, mutation))\n",
    "\n",
    "        variant = []\n",
    "        mutated_sequence = list(template)\n",
    "        for pos, new_base, mut in mutations:\n",
    "            variant.append(mut)\n",
    "            if new_base != \"DEL\":\n",
    "                mutated_sequence[pos] = new_base\n",
    "            else:\n",
    "                # Replace the base with a placeholder for deletion\n",
    "                mutated_sequence[pos] = \"_\"\n",
    "\n",
    "        mutated_sequence = \"\".join(mutated_sequence).replace(\"_\", \"\")\n",
    "        Variants[\"Variant\"].append(variant)\n",
    "        Variants[\"Sequence\"].append(mutated_sequence)\n",
    "\n",
    "    return pd.DataFrame(Variants)\n",
    "\n",
    "def select_random_reads(input_file, output_file, num_reads):\n",
    "    all_records = list(SeqIO.parse(input_file, \"fasta\"))\n",
    "\n",
    "    if num_reads > len(all_records):\n",
    "        print(\"Requested number of reads is more than available in the file. Selecting all reads.\")\n",
    "        selected_records = all_records\n",
    "    else:\n",
    "        selected_records = random.sample(all_records, num_reads)\n",
    "\n",
    "    with open(output_file, \"w\") as output_handle:\n",
    "        SeqIO.write(selected_records, output_handle, \"fasta\")\n",
    "\n",
    "def run_alignment_and_indexing_sim(ref, input_file, output_dir, site_saturation = False, alignment_name = \"alignment_minimap_Q10\"):\n",
    "    \"\"\"\n",
    "    Aligns sequences using minimap2, converts to BAM, sorts and indexes the BAM file.\n",
    "\n",
    "    Args:\n",
    "    ref (str): Path to the reference file.\n",
    "    fasta_file (str): Path to the FASTA file containing reads.\n",
    "    output_dir (Path or str): Directory to store output files.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    fastq_files = Path(input_file)\n",
    "\n",
    "    if not fastq_files:\n",
    "        raise FileNotFoundError(\"No FASTQ files found in the specified output directory.\")\n",
    "\n",
    "    print(fastq_files)\n",
    "\n",
    "    print(\"Running minimap2...\")\n",
    "    if site_saturation:\n",
    "        \n",
    "        alignment_name = \"alignment_minimap_site_saturation\"\n",
    "\n",
    "        match_score = 4\n",
    "        mismatch_score = 2\n",
    "        gap_opening_penalty = 10\n",
    "\n",
    "        minimap_cmd = f\"minimap2 -ax map-ont -A {match_score} -B {mismatch_score} -O {gap_opening_penalty},24 {ref} {fastq_files_str} > {output_dir}/{alignment_name}.sam\"\n",
    "        subprocess.run(minimap_cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    else:\n",
    "        minimap_cmd = f\"minimap2 -ax map-ont -A 2 -B 4 -O 4,24 {ref} {fastq_files} > {output_dir}/{alignment_name}.sam\"\n",
    "        subprocess.run(minimap_cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    view_cmd = f\"samtools view -bS {output_dir}/{alignment_name}.sam > {output_dir}/{alignment_name}.bam\"\n",
    "    subprocess.run(view_cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    sort_cmd = f\"samtools sort {output_dir}/{alignment_name}.bam -o {output_dir}/{alignment_name}.bam\"\n",
    "    subprocess.run(sort_cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    index_cmd = f\"samtools index {output_dir}/{alignment_name}.bam\"\n",
    "    subprocess.run(index_cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def adjust_variant(variant, padding_start):\n",
    "    \"\"\"\n",
    "    Adjust the variant position to account for the padding.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"#PARENT#\" in variant:\n",
    "        return \"#PARENT#\"\n",
    "    \n",
    "    elif variant == \"NA\":\n",
    "        return \"NA\"\n",
    "    \n",
    "    else:\n",
    "        variants = variant.split('_')\n",
    "        adjusted_variants = []\n",
    "\n",
    "        for v in variants:\n",
    "            # Find the position number using regular expression\n",
    "            match = re.search(r'([A-Za-z]+)(\\d+)([A-Za-z]+)', v)\n",
    "            if match:\n",
    "                refAA, pos, newAA = match.groups()\n",
    "                \n",
    "                adjusted_pos = max(int(pos) - padding_start, 1)  \n",
    "                adjusted_variants.append(f\"{refAA}{adjusted_pos}{newAA}\")\n",
    "\n",
    "    return '_'.join(adjusted_variants)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "template = IO_processor.read_fasta_file(Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii.fasta\"))[\"Sequence\"][0]\n",
    "\n",
    "Variants = pd.DataFrame({\"Variant\" : [], \"Sequence\" : [], \"Num_Mutations\" : []})\n",
    "\n",
    "\n",
    "for n_mut in range(0,11):\n",
    "    var = generate_variants(template, 100, n_mut, seed)\n",
    "    var[\"Num_Mutations\"] = n_mut\n",
    "    Variants = pd.concat([Variants, var]).reset_index(drop=True)\n",
    "\n",
    "Variants.to_pickle(\"Variants_100_p_s.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate mutation prediction of AF analysis and medaka consensus for different # of mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variants = pd.read_pickle(\"Variants_100_p_s.pkl\")\n",
    "# Select mutation with 0, 1, 5, 10\n",
    "# variants = Variants[Variants[\"Num_Mutations\"].isin([0, 1, 5, 10])].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variants.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Simulation\n",
    "\n",
    "- Enter the depths to analyze\n",
    "- Padding length\n",
    "- Num Mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Generate substitution and indels for each variant\n",
    "template = IO_processor.read_fasta_file(Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\"))[\"Sequence\"][0]\n",
    "padding = 50\n",
    "os.makedirs(f\"data/min_read_depth/seq\", exist_ok=True)\n",
    "\n",
    "ref = \"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\"\n",
    "reference = \"HetCPIII\"\n",
    "\n",
    "results = {\"Original Variant\" : [], \"Predicted Variant\" : [], \"Depth\" : [], \"Num Mutations\" : [], \"Correct\" : [], \"Alignment Frequency\" : []}\n",
    "\n",
    "np.random.seed(43)\n",
    "random.seed(43)\n",
    "\n",
    "for i, variant in tqdm(Variants.iterrows()):\n",
    "\n",
    "    max_depth = 50\n",
    "    \n",
    "    if \"#PARENT#\" in variant[\"Variant\"]:\n",
    "        var_name = f\"wt_{i}\"\n",
    "\n",
    "    else:\n",
    "        #sort variant\n",
    "        var_name = \"_\".join(variant[\"Variant\"])\n",
    "\n",
    "    # Create folder for each variant\n",
    "    os.makedirs(f\"data/min_read_depth/seq/{var_name}\", exist_ok=True)\n",
    "\n",
    "    padding_seq1 = \"aattcccctctagaaataattttgtttaactttaagaaggagatatacat\"\n",
    "    padding_seq2 = \"gatccggctgctaacaaagcccgaaaggaagctgagttggctgctgccac\"\n",
    "\n",
    "    with open(f\"data/min_read_depth/seq/{var_name}/{var_name}_Q10.fasta\", \"w\") as handle: # Create fasta file\n",
    "        for j in range(max_depth):\n",
    "            new_seq = introduce_mutations(variant[\"Sequence\"], 0.1)\n",
    "\n",
    "            new_seq = padding_seq1 + new_seq + padding_seq2\n",
    "\n",
    "            handle.write(f\">{var_name}_{j+1}\\n\")\n",
    "            handle.write(f\"{new_seq}\\n\")\n",
    "\n",
    "    depths = [1,3,5,7,9,11,13,15,20,25,30,35,40,45,50]\n",
    "\n",
    "    for depth in depths:\n",
    "\n",
    "        #Create depth folder\n",
    "        depth_folder_path = f\"data/min_read_depth/seq/{var_name}/depth_{depth}\"\n",
    "        os.makedirs(depth_folder_path, exist_ok=True)\n",
    "\n",
    "        # Select random reads from the fasta file, Create first all depth lengths and store all fasta files in a folder \n",
    "        select_random_reads(f\"data/min_read_depth/seq/{var_name}/{var_name}_Q10.fasta\", f\"{depth_folder_path}/{var_name}_Q10_reads.fasta\", depth)\n",
    "\n",
    "        # prompt = f'mini_align -r {ref} -i {depth_folder_path}/*.fasta -t 1 -m -p alignment && mv *.bam *.bam.bai {depth_folder_path}'\n",
    "        # subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        print(depth_folder_path)\n",
    "        # Run alignment and indexing\n",
    "        run_alignment_and_indexing_sim(ref, f\"{depth_folder_path}/{var_name}_Q10_reads.fasta\", depth_folder_path, site_saturation = False , alignment_name=\"alignment_minimap_Q10\")\n",
    "        #bam_file = f\"{depth_folder_path}/alignment_minimap.bam\"\n",
    "\n",
    "        # Call Variants with bam file\n",
    "        # if method == \"AF\":\n",
    "\n",
    "        #     variant_pred = analyser.call_variant_pop_frequency(Path(bam_file), template, reference, min_freq=0.1, min_depth= 0, padding_start=padding, padding_end= padding + 1)\n",
    "            \n",
    "        #     try:\n",
    "        #         variant_pred = pd.DataFrame(variant_pred).sort_values(\"Alignment Frequency\", ascending=False).reset_index(drop=True)\n",
    "        #         variant_pred[\"Variant\"] = variant_pred[\"Variant\"].apply(lambda x: adjust_variant(x, padding))\n",
    "        #         result = 1 if variant_pred[\"Variant\"][0] == \"_\".join(variant[\"Variant\"]) else 0\n",
    "\n",
    "        #         results[\"Original Variant\"].append(variant[\"Variant\"])\n",
    "        #         results[\"Predicted Variant\"].append(variant_pred[\"Variant\"][0])\n",
    "        #         results[\"Depth\"].append(depth)\n",
    "        #         results[\"Num Mutations\"].append(len(variant[\"Variant\"]) if \"#PARENT#\" not in variant[\"Variant\"] else 0)\n",
    "        #         results[\"Correct\"].append(result)\n",
    "        #         results[\"Alignment Frequency\"].append(variant_pred[\"Alignment Frequency\"][0])\n",
    "        #     except:\n",
    "        #         result = \"NA\"\n",
    "        #         results[\"Original Variant\"].append(variant[\"Variant\"])\n",
    "        #         results[\"Predicted Variant\"].append(\"NA\")\n",
    "        #         results[\"Depth\"].append(depth)\n",
    "        #         results[\"Num Mutations\"].append(len(variant[\"Variant\"]))\n",
    "        #         results[\"Correct\"].append(result)\n",
    "        #         results[\"Alignment Frequency\"].append(\"NA\")\n",
    "        \n",
    "        # elif method == \"guppy\":\n",
    "        \n",
    " \n",
    "            \n",
    "            \n",
    "# Delete seq folder\n",
    "\n",
    "# if os.path.exists(\"data/min_read_depth/seq\"):\n",
    "#     shutil.rmtree(\"data/min_read_depth/seq\")\n",
    "\n",
    "\n",
    "#results = pd.DataFrame(results)\n",
    "\n",
    "#results.to_csv(\"data/min_read_depth/results_100_p_s_Q10.csv\", index=False)\n",
    "#results.to_pickle(\"data/min_read_depth/results_100_p_s_Q20.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "ref_seq = Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\")\n",
    "folders = glob.glob(\"data/min_read_depth/seq/*\")\n",
    "\n",
    "for var_path in tqdm(folders):\n",
    "    var_namr = os.path.basename(var_path)\n",
    "    depths = glob.glob(f\"{var_path}/depth*\")\n",
    "    for depth in depths:\n",
    "        \n",
    "        folder_path = Path(depth)\n",
    "        print(\"Processing\", folder_path)\n",
    "        consensus.get_consensus(folder_path, ref_seq, output_name = \"consensus.fastq\", qualities = True, consensus_folder = folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get variant df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed analsyis\n",
    "- Generate synthetic sequences and alignment. Call variant with BF, AF & medaka\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "ref_seq = Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\")\n",
    "folders = glob.glob(\"data/min_read_depth/seq/*\")\n",
    "\n",
    "for var_path in tqdm(folders):\n",
    "    var_namr = os.path.basename(var_path)\n",
    "    depths = glob.glob(f\"{var_path}/depth*\")\n",
    "    for depth in depths:\n",
    "        \n",
    "        folder_path = Path(depth)\n",
    "        print(\"Processing\", folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_pickle(\"data/min_read_depth/results_100_p_s_Q20_local.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "#df.to_csv(\"data/min_read_depth/results_20_p_s_01.csv\", index=False)\n",
    "#df.drop(df[df[\"Correct\"] == \"NA\"].index, inplace=True)\n",
    "df.tail(30)[\"Original Variant\"].value_counts()\n",
    "df = df.drop(df[df[\"Correct\"] == \"NA\"].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_DEL_samples(entry):\n",
    "    for variant in entry:\n",
    "        if \"DEL\" in variant:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def check_neg_DEL_position(row):\n",
    "    variant_list = row['Original Variant']\n",
    "    check_list = row['Predicted Variant'].split(\"_\")\n",
    "\n",
    "    \n",
    "    if \"#PARENT#\" in variant_list:\n",
    "        return 0\n",
    "\n",
    "    min_length = min(len(variant_list), len(check_list))\n",
    "    \n",
    "    for i in range(min_length):\n",
    "        var = variant_list[i]\n",
    "        if \"DEL\" in var:\n",
    "            match_orig = re.search(r'([A-Za-z]+)(\\d+)([A-Za-z]+)', var)\n",
    "            match_pred = re.search(r'([A-Za-z]+)(\\d+)([A-Za-z]+)', check_list[i])\n",
    "            \n",
    "            if match_orig and match_pred:\n",
    "                pos = int(match_orig.group(2))\n",
    "                pos_pred = int(match_pred.group(2))\n",
    "                \n",
    "                if pos == pos_pred or pos_pred + 1 == pos or pos_pred - 1 == pos:\n",
    "                    return 1\n",
    "\n",
    "    return 0\n",
    "        \n",
    "        # Additional processing can be added here as needed\n",
    "df_wo_del = df.copy()\n",
    "df_wo_del[\"DEL\"] =      df_wo_del[\"Original Variant\"].apply(get_DEL_samples)\n",
    "df_wo_del[\"Corr DEL\"] = df_wo_del.apply(check_neg_DEL_position, axis=1)\n",
    "mask = df_wo_del[(df_wo_del[\"DEL\"] ==1) & (df_wo_del[\"Corr DEL\"] == 1) & (df_wo_del[\"Correct\"] == 0)].index\n",
    "df_wo_del.iloc[mask, 4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wo_del[(df_wo_del[\"Correct\"] == 0) & (df_wo_del[\"Depth\"] == 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_stats_wo_del = df_wo_del.groupby(['Num Mutations', 'Depth'])['Correct'].agg(['mean', 'std']).reset_index()\n",
    "grouped_stats_wo_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_stats = df.groupby(['Num Mutations', 'Depth'])['Correct'].agg(['mean', 'std']).reset_index()\n",
    "grouped_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"DEL\"] = results[\"Original Variant\"].apply(get_DEL_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHow row with Na\n",
    "from scipy.stats import linregress\n",
    "\n",
    "#df = pd.DataFrame(results)\n",
    "\n",
    "#df = df_wo_del\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df.drop(df[df[\"Correct\"] == \"NA\"].index, inplace=True)\n",
    "\n",
    "df = df.sort_values(\"Num Mutations\")\n",
    "#df['Num Mutations'] = df['Num Mutations'].astype(str)\n",
    "df['Correct'] = df['Correct'].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "# Find unique values in 'Num Mutations' and sort them\n",
    "unique_mutations = sorted(df['Num Mutations'].unique())\n",
    "\n",
    "# Create a color palette with a color for each unique 'Num Mutations' value\n",
    "palette = sns.color_palette(\"viridis\", n_colors=len(unique_mutations))\n",
    "\n",
    "# Map each unique 'Num Mutations' value to a color\n",
    "color_map = dict(zip(unique_mutations, palette))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use the lineplot with the custom palette\n",
    "sns.lineplot(data=df, x=\"Depth\", y=\"Correct\", hue=\"Num Mutations\", style=\"Num Mutations\", \n",
    "             markers=True, dashes=False, palette=color_map, linewidth=2, markersize=10)\n",
    "\n",
    "# Customization\n",
    "plt.xlabel(\"Read Depth\", size=16)\n",
    "plt.ylabel(\"Accuracy\", size=16)\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "# You can uncomment this if you want a legend\n",
    "# plt.legend(title=\"# Mutations\", title_fontsize=14, fontsize=14)\n",
    "\n",
    "plt.savefig(\"depth_vs_correct_Q20.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Alignment Frequency for number of mutations\n",
    "\n",
    "plt.bar(df[\"Num Mutations\"].unique(), df.groupby(\"Num Mutations\").mean()[\"Alignment Frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Num Mutations\").mean()[\"Correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = IO_processor.read_fasta_file(Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii.fasta\"))[\"Sequence\"][0]\n",
    "\n",
    "\n",
    "Variants = {\"Variant\" : [], \"Sequence\" : []}\n",
    "\n",
    "var = [\"A62T\", \"A224DEL\", \"A317T\", \"T348A\", \"A596G\"]\n",
    "template = list(template)\n",
    "# Delete base at position 2 and 3\n",
    "for v in var:\n",
    "    match = re.search(r'([A-Za-z]+)(\\d+)([A-Za-z]+)', v)\n",
    "    if match:\n",
    "        refAA, pos, newAA = match.groups()\n",
    "        template[int(pos) - 1] = \"\"\n",
    "Variants[\"Variant\"].append(var)\n",
    "Variants[\"Sequence\"].append(\"\".join(template))\n",
    "print(len(Variants[\"Sequence\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = IO_processor.read_fasta_file(Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\"))[\"Sequence\"][0]\n",
    "padding_start = 50\n",
    "padding_end = 50\n",
    "bam_file = \"/home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G22A_C54A_C93T_A105G_G178A_A335T_T519C_C607DEL/depth_50/alignment_minimap.bam\"\n",
    "alignment_count = int(subprocess.run(f\"samtools view -c {bam_file}\", shell=True, capture_output=True).stdout.decode(\"utf-8\").strip())\n",
    "range_positions = range(padding_start, len(template) - padding_end)\n",
    "freq_dist = pd.DataFrame(analyser.get_highest_non_ref_base_freq_2(bam_file, reference, range_positions, template, qualities=False)[0]).T.rename(columns={0:\"Base\", 1:\"Frequency\"})\n",
    "nb_positions = analyser.get_nb_positions(freq_dist, 0.4)\n",
    "freq_df = analyser.get_pop_frequency(bam_file, template, reference, nb_positions, min_freq=0.1, min_depth= 0)\n",
    "bases_df = analyser.get_bases_from_pileup(bam_file, reference, [655,656,657,658])\n",
    "bases_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_file = \"/home/emre/github_repo/MinION/examples/data/min_read_depth/seq/A393G/depth_50/alignment.bam\"\n",
    "variant_pred = analyser.call_variant_pop_frequency(bam_file, template, reference, min_freq=0.1, min_depth= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_count = int(subprocess.run(f\"samtools view -c {bam_file}\", shell=True, capture_output=True).stdout.decode(\"utf-8\").strip())\n",
    "freq_dist = pd.DataFrame(analyser.get_highest_non_ref_base_freq_2(bam_file, reference, range(1,len(template)), template, qualities=False)[0]).T.rename(columns={0:\"Base\", 1:\"Frequency\"})\n",
    "\n",
    "nb_positions = analyser.get_nb_positions(freq_dist, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser.get_pop_frequency(bam_file, template, reference, nb_positions, min_freq=0.1, min_depth= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(variant_pred).sort_values(\"Alignment Frequency\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variant_manual = {\"variant\" : [[\"G23A\", \"C336T\", \"C587DEL\"], [\"C283DEL\", \"C387T\", \"A478G\"], [\"G3A\", \"G123A\", \"G229A\", \"C442T\"] ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variants_manual = Variants[Variants[\"Variant\"].isin(Variant_manual[\"variant\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bam_file = \"/home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G3A_G123A_G229A_C442T/depth_50/alignment.bam\"\n",
    "prompt = f\"medaka consensus {bam_file} /home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G3A_G123A_G229A_C442T/depth_50/pre_consensus.hdf --batch 200 --threads 4\"\n",
    "subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"medaka stitch /home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G3A_G123A_G229A_C442T/depth_50/pre_consensus.hdf {ref} /home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G3A_G123A_G229A_C442T/depth_50/result.fasta --threads 4\"\n",
    "\n",
    "subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align ref and result with bioaligner\n",
    "\n",
    "ref = \"/home/emre/github_repo/MinION/minION/refseq/hetcpiii.fasta\"\n",
    "result = \"/home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G3A_G123A_G229A_C442T/depth_50/result.fasta\"\n",
    "\n",
    "prompt = f\"bioaligner align {ref} {result} --outfmt sam --out /home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G3A_G123A_G229A_C442T/depth_50/alignment.sam\"\n",
    "\n",
    "subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the reference sequence with 50 Ns at the start and end\n",
    "\n",
    "# with open(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii.fasta\", \"r\") as handle:\n",
    "#     records = list(SeqIO.parse(handle, \"fasta\"))\n",
    "#     template = str(records[0].seq)\n",
    "\n",
    "# template = \"N\" * 50 + template + \"N\" * 50\n",
    "\n",
    "# with open(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\", \"w\") as handle:\n",
    "#     handle.write(f\">{records[0].id}\\n\")\n",
    "#     handle.write(f\"{template}\\n\")\n",
    "\n",
    "# Reindexing the reference sequence\n",
    "prompt = f\"samtools faidx /home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\"\n",
    "subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment Frequency distribution accross different quality scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variant_df = pd.read_csv(\"/home/emre/github_repo/MinION/examples/data/min_read_depth/results_100_p_s_Q15.csv\")\n",
    "# Count NaN\n",
    "Variant_df.dropna(inplace=True) # NA can occur if the pileup analysis fails. For the sake of the simulation, we dropped these rows. (3 Variants out of 1100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_alignment_freq(entry):\n",
    "    if entry[\"Alignment Frequency\"] == \"-\":\n",
    "        return 0\n",
    "    else:\n",
    "        return entry[\"Alignment Frequency\"]\n",
    "\n",
    "Variant_df[\"Alignment Frequency\"] = Variant_df.apply(edit_alignment_freq, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming Variant_df is your DataFrame and it's already imported\n",
    "df = Variant_df[Variant_df[\"Num Mutations\"] > 0]\n",
    "df[\"Alignment Frequency\"] = df[\"Alignment Frequency\"].astype(float)\n",
    "\n",
    "# Sort the DataFrame numerically first\n",
    "df = df.sort_values(\"Num Mutations\")\n",
    "\n",
    "# Group by and calculate mean and SEM\n",
    "group_stats = df.groupby(\"Num Mutations\")[\"Alignment Frequency\"].agg(['mean', 'std'])\n",
    "\n",
    "# Now convert \"Num Mutations\" to string for plotting, after grouping and calculations\n",
    "group_stats.index = group_stats.index.astype(str)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(group_stats.index, group_stats[\"mean\"], yerr=group_stats[\"std\"], color = \"lightgrey\", edgecolor = \"black\", capsize=5)\n",
    "plt.tick_params(size=14, labelsize=14)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Improving the plot aesthetics\n",
    "plt.xlabel('# of Mutations', size=18)\n",
    "plt.ylabel('Alignment Frequency', size=18)\n",
    " # Rotate the x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout to fit everything nicely\n",
    "plt.savefig(\"data/min_read_depth/alignment_frequency_vs_num_mutations_Q10.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed Test\n",
    "\n",
    "- Copy 10 folder from min_read_depth and calculate the time to process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder \n",
    "\n",
    "folder_path = \"/home/emre/github_repo/MinION/examples/data/min_read_depth/\"\n",
    "\n",
    "files_to_run = []\n",
    "\n",
    "variants = glob.glob(f\"{folder_path}seq/*\")\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Select randomly 20 mutations\n",
    "\n",
    "variants = random.sample(variants, 50)\n",
    "\n",
    "for variant in variants:\n",
    "    # Get depth 50 from each variant\n",
    "    depth_50_bam = f\"{variant}/depth_50/alignment_minimap.bam\"\n",
    "    files_to_run.append(depth_50_bam)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Bayes AF analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minION.analyser_bayes_AF import *\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_Analysis = {\"Method\" : [], \"Time\" : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_seq = Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\")\n",
    "ref_name = \"HetCPIII\"\n",
    "\n",
    "\n",
    "# Measure time\n",
    "start = time.time()\n",
    "for bam_file in files_to_run:\n",
    "    get_variant_soft(bam_file, template_seq, ref_name, padding = 50)\n",
    "end = time.time()\n",
    "\n",
    "Time_Analysis[\"Method\"].append(\"Soft Probability\")\n",
    "Time_Analysis[\"Time\"].append(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Frequency Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = 50\n",
    "template = analyser.get_template_sequence(template_seq)\n",
    "\n",
    "start = time.time()\n",
    "for bam_file in files_to_run:\n",
    "    call_variant_BF(bam_file, \"HetCPIII\", range(padding, len(template) - padding + 1), template, qualities=False)\n",
    "end = time.time()\n",
    "\n",
    "Time_Analysis[\"Method\"].append(\"Base Frequency Only\")\n",
    "Time_Analysis[\"Time\"].append(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guppy Consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/emre/github_repo/MinION/examples/barcode_simulater.ipynb Cell 92\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B131.215.228.108/home/emre/github_repo/MinION/examples/barcode_simulater.ipynb#Y164sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m bam_file \u001b[39min\u001b[39;00m files_to_run:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B131.215.228.108/home/emre/github_repo/MinION/examples/barcode_simulater.ipynb#Y164sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     prompt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmedaka consensus \u001b[39m\u001b[39m{\u001b[39;00mbam_file\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mcons_folder\u001b[39m}\u001b[39;00m\u001b[39m/pre_consensus_Q10.hdf --batch 200 --threads 4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B131.215.228.108/home/emre/github_repo/MinION/examples/barcode_simulater.ipynb#Y164sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     subprocess\u001b[39m.\u001b[39;49mrun(prompt, shell\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mDEVNULL, stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mDEVNULL)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B131.215.228.108/home/emre/github_repo/MinION/examples/barcode_simulater.ipynb#Y164sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     prompt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmedaka stitch \u001b[39m\u001b[39m{\u001b[39;00mcons_folder\u001b[39m}\u001b[39;00m\u001b[39m/pre_consensus_Q10.hdf \u001b[39m\u001b[39m{\u001b[39;00mref\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mcons_folder\u001b[39m}\u001b[39;00m\u001b[39m/result.fasta --threads 4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B131.215.228.108/home/emre/github_repo/MinION/examples/barcode_simulater.ipynb#Y164sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     subprocess\u001b[39m.\u001b[39mrun(prompt, shell\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, stdout\u001b[39m=\u001b[39msubprocess\u001b[39m.\u001b[39mDEVNULL, stderr\u001b[39m=\u001b[39msubprocess\u001b[39m.\u001b[39mDEVNULL)\n",
      "File \u001b[0;32m~/miniconda3/envs/medaka/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39;49mcommunicate(\u001b[39minput\u001b[39;49m, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    506\u001b[0m     \u001b[39mexcept\u001b[39;00m TimeoutExpired \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[39m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/medaka/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m   1147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/medaka/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[39m=\u001b[39m _time() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[39m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[39m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[39m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/medaka/lib/python3.10/subprocess.py:1943\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1941\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1942\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1943\u001b[0m (pid, sts) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_wait(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m   1944\u001b[0m \u001b[39m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1945\u001b[0m \u001b[39m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39mif\u001b[39;00m pid \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/medaka/lib/python3.10/subprocess.py:1901\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1899\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1901\u001b[0m     (pid, sts) \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mwaitpid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpid, wait_flags)\n\u001b[1;32m   1902\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1903\u001b[0m     \u001b[39m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1904\u001b[0m     \u001b[39m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1905\u001b[0m     \u001b[39m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1906\u001b[0m     pid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cons_folder = \"/home/emre/github_repo/MinION/examples/data/cons_tmp_folder\"\n",
    "ref = template_seq\n",
    "start = time.time()\n",
    "for bam_file in files_to_run:\n",
    "    prompt = f\"medaka consensus {bam_file} {cons_folder}/pre_consensus_Q10.hdf --batch 200 --threads 4\"\n",
    "    subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    prompt = f\"medaka stitch {cons_folder}/pre_consensus_Q10.hdf {ref} {cons_folder}/result.fasta --threads 4\"\n",
    "    subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    analyser.call_variant_nn(template, cons_folder, ref_name, padding = 50)\n",
    "end = time.time()\n",
    "\n",
    "Time_Analysis[\"Method\"].append(\"Medaka Consensus\")\n",
    "Time_Analysis[\"Time\"].append(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Time_Analysis).to_csv(\"/home/emre/github_repo/MinION/results/3_Simulations/Time_Analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Time_Analysis)\n",
    "\n",
    "# Find the 'Time' value for 'Base Frequency Only'\n",
    "bf_time = df.loc[df['Method'] == 'Base Frequency Only', 'Time'].iloc[0]\n",
    "\n",
    "# Normalize the 'Time' column relative to 'Base Frequency Only'\n",
    "df['Normalized Time'] = df['Time'] / bf_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Variant': 'NA', 'Position': 'NA', 'Quality-Score': 'NA'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bam_file = \"/home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G160A/depth_45/alignment_minimap_Q10.bam\"\n",
    "prompt = f\"medaka consensus {bam_file} {cons_folder}/pre_consensus_Q10.hdf --batch 200 --threads 4\"\n",
    "subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "prompt = f\"medaka stitch {cons_folder}/pre_consensus_Q10.hdf {ref} {cons_folder}/result.fasta --threads 4\"\n",
    "subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "analyser.call_variant_nn(template, cons_folder, ref_name, padding = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
