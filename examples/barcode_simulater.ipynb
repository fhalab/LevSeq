{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barcode Demultiplexer Simulator \n",
    "\n",
    "- Simulate Demultiplexing using local and semi-global alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/emre/github_repo/MinION\")\n",
    "from minION import analyser\n",
    "from minION import consensus\n",
    "from minION import demultiplexer\n",
    "import importlib\n",
    "from minION.util import IO_processor\n",
    "from minION.util.globals import BARCODES, MEDAKA_MODELS, DEFAULT_TARGETS\n",
    "importlib.reload(IO_processor)\n",
    "importlib.reload(analyser)\n",
    "importlib.reload(consensus)\n",
    "importlib.reload(demultiplexer)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#import plotly.express as px\n",
    "import random\n",
    "from Bio import SeqIO\n",
    "import subprocess\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly version\n",
    "def barcode_score(summary):\n",
    "    fig = px.histogram(summary, x=\"barcode_score\", nbins=100, \n",
    "                       title=\"Barcode Score Distribution\", labels={'barcode_score': 'Barcode Score', 'count': 'Frequency'})\n",
    "    fig.update_traces(marker_color='red', marker_line_color='black', marker_line_width=1.5, opacity=0.5)\n",
    "    fig.update_layout(width=600, height=400)\n",
    "    return fig\n",
    "\n",
    "def barcode_barplot(summary, barcode_id=\"barcode_arrangement\", ylim=None):\n",
    "    barcodes = summary[barcode_id].value_counts().reset_index()\n",
    "    fig = px.bar(barcodes, x=barcode_id, y=\"count\", \n",
    "                 title=\"Barcode Frequency\", labels={'index': 'Barcode ID', barcode_id: 'Frequency'})\n",
    "    fig.update_traces(marker_color='red', marker_line_color='black', marker_line_width=1.5, opacity=0.5)\n",
    "    fig.update_layout(width=600, height=400)\n",
    "\n",
    "    if ylim:\n",
    "        fig.update_layout(yaxis=dict(range=[0, ylim]))\n",
    "\n",
    "    return fig\n",
    "\n",
    "def barcode_arrangement(summary, plot=True):\n",
    "    barcode_arrangements = summary[\"barcode_arrangement\"].value_counts().reset_index()\n",
    "\n",
    "    if plot:\n",
    "        fig = px.bar(barcode_arrangements, x='barcode_score', y='barcode_arrangement', \n",
    "                     title=\"Barcode Frequency\", labels={'index': 'Barcode ID', 'barcode_arrangement': 'Frequency'})\n",
    "        fig.update_traces(marker_color='red', marker_line_color='black', marker_line_width=1.5, opacity=0.5)\n",
    "        fig.update_layout(width=600, height=400)\n",
    "        return fig\n",
    "    else:\n",
    "        return barcode_arrangements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_gc_content(sequence, desired_gc_fraction, tolerance=0.05):\n",
    "    \"\"\"\n",
    "    Check if the GC content of the sequence is within the desired range.\n",
    "    \"\"\"\n",
    "    gc_count = sum(1 for nucleotide in sequence if nucleotide in ['G', 'C'])\n",
    "    gc_fraction = gc_count / len(sequence)\n",
    "    return abs(gc_fraction - desired_gc_fraction) <= tolerance\n",
    "\n",
    "def generate_gc_content_sequence(length, desired_gc_fraction):\n",
    "    \"\"\"\n",
    "    Iteratively generate a random DNA sequence until it has the desired GC content.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        sequence = ''.join(random.choice('ATCG') for _ in range(length))\n",
    "        if check_gc_content(sequence, desired_gc_fraction):\n",
    "            return sequence\n",
    "\n",
    "\n",
    "def introduce_mutations(sequence, mutation_rate, weights = [0.2, 0.4, 0.4]):\n",
    "    \"\"\"\n",
    "    Introduce mutations in a sequence with the specified mutation rate.\n",
    "    The mutations include substitution, insertion, and deletion.\n",
    "    \"\"\"\n",
    "    mutated_sequence = ''\n",
    "    nucleotides = ['A', 'C', 'G', 'T']\n",
    "    \n",
    "    weights = {'substitution': weights[0], 'insertion': weights[1], 'deletion': weights[2]}\n",
    "\n",
    "    i = 0\n",
    "    while i < len(sequence):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutation_type = random.choices(['substitution', 'insertion', 'deletion'], weights=[weights['substitution'], weights['insertion'], weights['deletion']])[0]\n",
    "            if mutation_type == 'substitution':\n",
    "                mutated_sequence += random.choice([n for n in nucleotides if n != sequence[i]])\n",
    "                i += 1\n",
    "            elif mutation_type == 'insertion':\n",
    "                mutated_sequence += random.choice(nucleotides)\n",
    "            else:  # deletion\n",
    "                i += 1\n",
    "                continue\n",
    "        else:\n",
    "            mutated_sequence += sequence[i]\n",
    "            i += 1\n",
    "    return mutated_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the synthetic sequences\n",
    "\n",
    "- GC content of 60 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_to_fastq(filename, barcodes, sequence_length, barcode_position_start, barcode_position_end, mutation_rate, num_sequences, num_noise):\n",
    "    \"\"\"\n",
    "    Write mutated sequences for each barcode into a FASTQ file using a fixed surrounding sequence.\n",
    "    \"\"\"\n",
    "    with open(filename, 'wt') as fastq_file:\n",
    "        for i in range(num_sequences):\n",
    "            # Generate one surrounding sequence for the set of barcodes\n",
    "            surrounding_sequence = generate_gc_content_sequence(sequence_length, 0.6)\n",
    "\n",
    "            for barcode_name, barcode_sequence in barcodes.items():\n",
    "                # Introduce mutations in the barcode sequence\n",
    "                mutated_barcode_sequence = introduce_mutations(barcode_sequence, mutation_rate)\n",
    "\n",
    "                # Insert the mutated barcode sequence in the surrounding sequence\n",
    "                mutated_sequence = surrounding_sequence[:barcode_position_start] + mutated_barcode_sequence + surrounding_sequence[barcode_position_end:]\n",
    "                \n",
    "                # Assign quality scores\n",
    "                quality_scores = \"I\" * len(mutated_sequence)\n",
    "                \n",
    "                mut_r = str(mutation_rate).replace(\".\", \"_\")\n",
    "                # Write to FASTQ file\n",
    "                fastq_file.write(f\"@seq_{mut_r}_{i + 1}_{barcode_name}\\n\")\n",
    "                fastq_file.write(f\"{mutated_sequence}\\n\")\n",
    "                fastq_file.write(\"+\\n\")\n",
    "                fastq_file.write(f\"{quality_scores}\\n\")\n",
    "\n",
    "\n",
    "        for i in range(num_noise):\n",
    "        # Generate random noise sequence\n",
    "            noise_sequence = generate_gc_content_sequence(sequence_length, 0.6)\n",
    "            \n",
    "            # Assign quality scores\n",
    "            quality_scores = \"I\" * sequence_length\n",
    "            \n",
    "            # Write to FASTQ file\n",
    "            fastq_file.write(f\"@noise_{i + 1}\\n\")\n",
    "            fastq_file.write(f\"{noise_sequence}\\n\")\n",
    "            fastq_file.write(\"+\\n\")\n",
    "            fastq_file.write(f\"{quality_scores}\\n\")\n",
    "\n",
    "def split_read_id(read_id):\n",
    "    \"\"\"\n",
    "    Split the read ID into the barcode ID and the read ID.\n",
    "    \"\"\"\n",
    "    parts = read_id.split(\"_\")\n",
    "    barcode_id = parts[-1]\n",
    "    read_id_prefix = \"_\".join(parts[:-1])\n",
    "\n",
    "    if barcode_id.isnumeric():\n",
    "        barcode_id = \"noise\"\n",
    "    return barcode_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "barcodes = {}\n",
    "with open(\"/home/emre/github_repo/MinION/minION/barcoding/minion_barcodes_sim.fasta\", \"r\") as handle:\n",
    "    records = list(SeqIO.parse(handle, \"fasta\"))\n",
    "    for record in records:\n",
    "        barcodes[record.id] = str(record.seq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "names = [\"0\", \"01\", \"02\", \"03\", \"04\"]\n",
    "for i, rate in enumerate([0, 0.1, 0.2, 0.3, 0.4]):\n",
    "    sequence_length = 150\n",
    "    barcode_position_start = 70\n",
    "    barcode_position_end = 94\n",
    "    mutation_rate = rate # 10% mutation rate\n",
    "    num_sequences = 9000\n",
    "    num_noise = 0\n",
    "\n",
    "    # Write sequences to a FASTQ file\n",
    "    write_to_fastq(f\"data/mutated_sequences_{names[i]}_8barcodes.fastq\", barcodes, sequence_length, barcode_position_start, barcode_position_end, mutation_rate, num_sequences, num_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_names = [\"00_0\", \"00_1\", \"00_2\", \"01_0\", \"01_1\", \"01_2\", \"02_0\", \"02_1\", \"02_2\"]\n",
    "file_names = [\"tpr_fpr_testing\"]\n",
    "\n",
    "for file in file_names:\n",
    "    path = Path(\"data\") / file / \"8_barcodes\" \n",
    "    demultiplexer.run_demultiplexer_single(path, BARCODES, 15, 15, basecall_folder = path)\n",
    "\n",
    "    # Calculate TP, FP, FN, TN\n",
    "    #summary = pd.read_csv(Path(\"data\") / file / \"24_barcodes\" / \"demultiplex_15\" / \"barcoding_summary.csv\")\n",
    "    #summary[\"Truth\"] = summary[\"read_id\"].apply(split_read_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPP Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summary for CPP \n",
    "\n",
    "summary = pd.read_csv(\"/home/emre/github_repo/MinION/examples/data/Demultiplex_cpp/barcoding_summary.txt\", sep=\"\\t\")\n",
    "#summary = pd.read_csv(\"/home/emre/github_repo/MinION/examples/data/tpr_fpr_testing/24_barcodes/demultiplex_15/barcoding_summary.txt\", sep=\"\\t\")\n",
    "summary[\"Truth\"] = summary[\"ID\"].apply(split_read_id)\n",
    "bins = np.arange(15, 105, 5)\n",
    "summary[\"bins\"] = pd.cut(summary[\"RBC_Score\"], bins)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Create the histogram plot\n",
    "sns.histplot(data=summary, x=\"RBC_Score\", bins=100, kde=False, ax=ax, color=\"navy\", alpha=0.5)\n",
    "\n",
    "\n",
    "# Add custom legend with the correct colors\n",
    "custom_lines = [plt.Line2D([0], [0], color=\"navy\", lw=4)]\n",
    "\n",
    "#ax.legend(custom_lines, [''])\n",
    "# Add labels and title\n",
    "ax.set_xlabel(\"Barcode Score\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "#ax.set_title(\"Barcode Score Distribution\")\n",
    "\n",
    "# Add a red vertical line\n",
    "#ax.axvline(x=60, color='red', linestyle='--')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"barcode_score_distribution_guppy_quality_test_8barcodes_CPP.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR_interval = {\"Interval\" : [], \"TPR\" : [], \"FPR\" : []}\n",
    "barcode_column = \"RBC\"\n",
    "for intervals in summary[\"bins\"].unique().sort_values():\n",
    "    bin_df = summary[summary[\"bins\"] == intervals]\n",
    "    \n",
    "    tpr = []\n",
    "    fpr = []\n",
    "\n",
    "    fp = bin_df[(bin_df[barcode_column] != bin_df[\"Truth\"])]\n",
    "    tp = bin_df[(bin_df[barcode_column] == bin_df[\"Truth\"])]\n",
    "\n",
    "    print(f\"TPR for {intervals}: {len(tp) / (len(bin_df) +1)}\")\n",
    "    print(f\"FPR for {intervals}: {len(fp) / (len(bin_df)+1)}\")\n",
    "\n",
    "    TPR_interval[\"Interval\"].append(intervals)\n",
    "    TPR_interval[\"TPR\"].append(len(tp) / (len(bin_df) +1))\n",
    "    TPR_interval[\"FPR\"].append(len(fp) / (len(bin_df)+1))\n",
    "\n",
    "pd.DataFrame(TPR_interval).to_csv(\"tpr_fpr_8barcodes_CPP.csv\", index=False)\n",
    "pd.DataFrame(TPR_interval).dropna().plot(x=\"Interval\", y=[\"TPR\", \"FPR\"], figsize=(10, 5), title=\"TPR and FPR for different barcode score intervals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(\"/home/emre/github_repo/MinION/examples/data/tpr_fpr_testing/24_barcodes/demultiplex_15/barcoding_summary.txt\", sep=\"\\t\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guppy Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(\"/home/emre/github_repo/MinION/examples/data/tpr_fpr_testing/24_barcodes/demultiplex_15/barcoding_summary.txt\", sep=\"\\t\")\n",
    "summary[\"Truth\"] = summary[\"read_id\"].apply(split_read_id)\n",
    "bins = np.arange(15, 105, 5)\n",
    "summary[\"bins\"] = pd.cut(summary[\"barcode_score\"], bins)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Create the histogram plot\n",
    "sns.histplot(data=summary, x=\"barcode_score\", bins=100, kde=False, ax=ax, color=\"navy\", alpha=0.5)\n",
    "\n",
    "\n",
    "# Add custom legend with the correct colors\n",
    "custom_lines = [plt.Line2D([0], [0], color=\"navy\", lw=4)]\n",
    "\n",
    "#ax.legend(custom_lines, [''])\n",
    "# Add labels and title\n",
    "ax.set_xlabel(\"Barcode Score\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "#ax.set_title(\"Barcode Score Distribution\")\n",
    "\n",
    "# Add a red vertical line\n",
    "#ax.axvline(x=60, color='red', linestyle='--')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"barcode_score_distribution_guppy_quality_test_24barcodes.png\", dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR_interval = {\"Interval\" : [], \"TPR\" : [], \"FPR\" : []}\n",
    "barcode_column = \"barcode_full_arrangement\"\n",
    "for intervals in summary[\"bins\"].unique().sort_values():\n",
    "    bin_df = summary[summary[\"bins\"] == intervals]\n",
    "    \n",
    "    tpr = []\n",
    "    fpr = []\n",
    "\n",
    "    fp = bin_df[(bin_df[barcode_column] != bin_df[\"Truth\"])]\n",
    "    tp = bin_df[(bin_df[barcode_column] == bin_df[\"Truth\"])]\n",
    "\n",
    "    print(f\"TPR for {intervals}: {len(tp) / (len(bin_df) +1)}\")\n",
    "    print(f\"FPR for {intervals}: {len(fp) / (len(bin_df)+1)}\")\n",
    "\n",
    "    TPR_interval[\"Interval\"].append(intervals)\n",
    "    TPR_interval[\"TPR\"].append(len(tp) / (len(bin_df) +1))\n",
    "    TPR_interval[\"FPR\"].append(len(fp) / (len(bin_df)+1))\n",
    "\n",
    "\n",
    "    pd.DataFrame(TPR_interval).to_csv(\"tpr_fpr_8barcodes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.groupby([\"Truth\", \"bins\"]).count()[\"read_id\"].reset_index().pivot(index=\"bins\", columns=\"Truth\", values=\"read_id\").plot.bar(stacked=True, figsize=(10, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TP and FP\n",
    "barcode_column = \"barcode_full_arrangement\"\n",
    "barcode = \"RB01\"\n",
    "tp = summary[(summary[barcode_column] == barcode) & (summary[\"Truth\"] == barcode)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPR FPR Plotting of Guppy and Local Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_8_cpp = pd.read_csv(\"/home/emre/github_repo/MinION/examples/tpr_fpr_8barcodes_CPP.csv\")\n",
    "barcode_24_cpp = pd.read_csv(\"/home/emre/github_repo/MinION/examples/tpr_fpr_24barcodes_CPP.csv\")\n",
    "barcode_24 = pd.read_csv(\"/home/emre/github_repo/MinION/examples/tpr_fpr_24barcodes.csv\")\n",
    "barcode_8 = pd.read_csv(\"/home/emre/github_repo/MinION/examples/tpr_fpr_8barcodes.csv\")\n",
    "\n",
    "barcode_8_cpp[\"Barcode\"] = \"8 barcodes (CPP)\"\n",
    "barcode_24_cpp[\"Barcode\"] = \"24 barcodes (CPP)\"\n",
    "barcode_24[\"Barcode\"] = \"24 barcodes (Guppy)\"\n",
    "barcode_8[\"Barcode\"] = \"8 barcodes (Guppy)\"\n",
    "\n",
    "summary = pd.concat([barcode_8_cpp, barcode_24_cpp, barcode_24, barcode_8]).reset_index(drop=True)\n",
    "summary = summary.drop(summary[(summary[\"Barcode\"] == \"8 barcodes (Guppy)\") & (summary[\"Interval\"] == \"(20, 25]\")].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes as per your setup\n",
    "df = summary\n",
    "df_8 = df[df['Barcode'] == \"8 barcodes (CPP)\"]\n",
    "df_24 = df[df['Barcode'] == \"24 barcodes (CPP)\"]\n",
    "df_8_guppy = df[df['Barcode'] == \"8 barcodes (Guppy)\"]\n",
    "df_24_guppy = df[df['Barcode'] == \"24 barcodes (Guppy)\"]\n",
    "\n",
    "# Define bar width and positions\n",
    "barWidth = 0.2\n",
    "r1 = np.arange(len(df_8['Interval']))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "r4 = [x + barWidth for x in r3]\n",
    "\n",
    "# Create the figure and axes\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Creating bars\n",
    "plt.bar(r1, df_8['TPR'], color='navy', width=barWidth, edgecolor='grey', label='8 Barcodes - TPR - Local')\n",
    "plt.bar(r2, df_24['TPR'], color=\"lightsteelblue\", width=barWidth, edgecolor='grey', label='24 Barcodes - TPR - Local')\n",
    "plt.bar(r3, df_8_guppy['TPR'], color='forestgreen', width=barWidth, edgecolor='grey', label='8 Barcodes - TPR - Semi-Global')\n",
    "plt.bar(r4, df_24_guppy['TPR'], color='limegreen', width=barWidth, edgecolor='grey', label='24 Barcodes - TPR - Semi-Global')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Barcode Score Interval', size=16)\n",
    "plt.ylabel('True Positive Rate (TPR)', size=16)\n",
    "plt.xticks([r + barWidth for r in range(len(df_8['Interval']))], df_8['Interval'], rotation=45)\n",
    "\n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"tpr_fpr_8_24_barcodes_barplot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = analyser.read_summary_file(\"/home/emre/github_repo/MinION/examples/data/01_quality/demultiplex_30/\")\n",
    "\n",
    "# Calculate precision, recall, F1 score\n",
    "summary[\"Truth\"] = summary[\"read_id\"].apply(split_read_id)\n",
    "\n",
    "barcode_classification = {\"True Positive\": \"TP\", \"False Positive\": \"FP\", \"False Negative\": \"FN\", \"True Negative\": \"TN\"}\n",
    "for barcode in barcodes.keys():\n",
    "    barcode_column = \"barcode_arrangement\"\n",
    "    # barcode = RB01\n",
    "    tp = summary[(summary[barcode_column] == barcode) & (summary[\"Truth\"] == barcode)]\n",
    "    fn = summary[(summary[barcode_column] != barcode) & (summary[\"Truth\"] == barcode)]\n",
    "    fp = summary[(summary[barcode_column] == barcode) & (summary[\"Truth\"] != barcode)]\n",
    "    tn = summary[(summary[barcode_column] != barcode) & (summary[\"Truth\"] != barcode)]\n",
    "\n",
    "    tp_percentage = len(tp) / 40000 * 100\n",
    "    fp_percentage = len(fp) / 40000 * 100\n",
    "\n",
    "    print(f\"True Positive: {len(tp)} ({tp_percentage:.2f}%), False Positive: {len(fp)} ({fp_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[(summary[barcode_column] == \"RB01\") & (summary[\"Truth\"] != \"RB01\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demultiplexer.run_demultiplexer_single(Path(\"data\") / \"03_0\", BARCODES, 50, 50, basecall_folder = Path(\"data\") / \"03_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"barcode_full_arrangement\"].value_counts().reset_index()\n",
    "\n",
    "# SNS\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.bar(summary[\"barcode_arrangement\"].value_counts().index, summary[\"barcode_arrangement\"].value_counts().values, color=\"lightgrey\", edgecolor=\"black\")\n",
    "#plt.title(\"Barcode Arrangement - Guppy (Semi-Global)\")\n",
    "plt.xlabel(\"Barcode Classification\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Create the histogram plot\n",
    "sns.histplot(data=summary_01, x=\"barcode_score\", bins=100, kde=False, ax=ax, color=\"navy\", alpha=0.5)\n",
    "sns.histplot(data=summary_02, x=\"barcode_score\", bins=100, kde=False, ax=ax, color=\"pink\", alpha=0.9)\n",
    "sns.histplot(data=summary_03, x=\"barcode_score\", bins=100, kde=False, ax=ax, color=\"lightgreen\", alpha=0.5)\n",
    "sns.histplot(data=summary_04, x=\"barcode_score\", bins=100, kde=False, ax=ax, color=\"red\", alpha=0.5)\n",
    "\n",
    "# Add custom legend with the correct colors\n",
    "custom_lines = [plt.Line2D([0], [0], color=\"navy\", lw=4),\n",
    "                plt.Line2D([0], [0], color=\"pink\", lw=4),\n",
    "                plt.Line2D([0], [0], color=\"lightgreen\", lw=4),\n",
    "                plt.Line2D([0], [0], color=\"red\", lw=4)]\n",
    "\n",
    "ax.legend(custom_lines, ['10% ', '20%', \"30%\", \"40%\"])\n",
    "# Add labels and title\n",
    "ax.set_xlabel(\"Barcode Score\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "#ax.set_title(\"Barcode Score Distribution\")\n",
    "\n",
    "# Add a red vertical line\n",
    "#ax.axvline(x=60, color='red', linestyle='--')\n",
    "\n",
    "# Show the plot\n",
    "#plt.savefig(\"barcode_score_distribution_guppy.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.concat([summary_01, summary_02, summary_03, summary_04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 100, 5)\n",
    "summary[\"bins\"] = pd.cut(summary[\"barcode_score\"], bins)\n",
    "summary[\"Truth\"] = summary[\"read_id\"].apply(split_read_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"barcode_arrangement\"].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_read_id(read_id):\n",
    "    \"\"\"\n",
    "    Split the read ID into the barcode ID and the read ID.\n",
    "    \"\"\"\n",
    "    parts = read_id.split(\"_\")\n",
    "    barcode_id = parts[-1]\n",
    "    read_id_prefix = \"_\".join(parts[:-1])\n",
    "    return barcode_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Truth\"] = summary[\"read_id\"].apply(split_read_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correctly_classified_barcodes(summary_df, barcode_truth_mapping):\n",
    "    \"\"\"\n",
    "    Get correctly classified barcodes from the summary dataframe and compile them into a single DataFrame.\n",
    "\n",
    "    :param summary_df: Pandas DataFrame containing barcode classification results\n",
    "    :param barcode_truth_mapping: Dictionary where keys are the expected barcode arrangements\n",
    "                                  and values are the corresponding truth values.\n",
    "    :return: DataFrame with an additional column 'Barcode' indicating the barcode name\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for arrangement, truth in barcode_truth_mapping.items():\n",
    "        temp_df = summary_df[(summary_df[\"barcode_full_arrangement\"] == arrangement) & (summary_df[\"Truth\"] == truth)].copy()\n",
    "        temp_df['Barcode'] = truth\n",
    "        frames.append(temp_df)\n",
    "    \n",
    "    return pd.concat(frames)\n",
    "\n",
    "# Example usage\n",
    "barcode_truth_mapping = {\n",
    "    \"barcode01\": \"RB01\",\n",
    "    \"barcode02\": \"RB02\",\n",
    "    \"barcode03\": \"RB03\",\n",
    "    \"barcode04\": \"RB04\",\n",
    "    \"barcode05\": \"RB05\",\n",
    "    \"barcode06\": \"RB06\",\n",
    "    \"barcode07\": \"RB07\",\n",
    "    \"barcode08\": \"RB08\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_classified_df = get_correctly_classified_barcodes(summary_01, barcode_truth_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_classified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly classified\n",
    "rb01 = summary[(summary[\"barcode_arrangement\"] == \"barcode01\") & (summary[\"Truth\"] == \"RB01\")]\n",
    "rb02 = summary[(summary[\"barcode_arrangement\"] == \"barcode02\") & (summary[\"Truth\"] == \"RB02\")]\n",
    "rb03 = summary[(summary[\"barcode_arrangement\"] == \"barcode03\") & (summary[\"Truth\"] == \"RB03\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cpp = analyser.read_summary_file(Path('/home/emre/github_repo/MinION/examples/data/Demultiplex_cpp/50'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cpp[\"RBC\"].value_counts().reset_index()\n",
    "\n",
    "# SNS\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.barplot(x=\"RBC\", y=\"count\", data=summary_cpp[\"RBC\"].value_counts().reset_index())\n",
    "plt.title(\"Barcode Arrangement - Ours\")\n",
    "plt.xlabel(\"Barcode Classification\")\n",
    "plt.ylabel(\"Frequency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Create the histogram plot\n",
    "sns.histplot(data=summary_cpp, x=\"RBC_Score\", bins=100, kde=True, ax=ax)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel(\"Barcode Score\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Barcode Score Distribution\")\n",
    "\n",
    "# Add a red vertical line\n",
    "ax.axvline(x=60, color='red', linestyle='--')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment Simulation to predict the accuracy at different depths\n",
    "\n",
    "- Start with HETCPII (612bp)\n",
    "- Sample random mutations (Parent, Single Point Mutation, 2, 3 up to 8)\n",
    "- Generate Substitutions & indels for a given site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_variants(template, num_variants, num_mutations, seed):\n",
    "    \"\"\"\n",
    "    Generate random variants based of num of mutations and num of variants.\n",
    "    \"\"\"\n",
    "    trans_matrix = np.array([   [0, 0.01, 0.46, 0.18, 0.01], #A\n",
    "                                [0.02, 0, 0.025, 0.43, 0.01], #C\n",
    "                                [0.43, 0.025, 0, 0.02, 0.01], #G\n",
    "                                [0.18, 0.0335, 0.1, 0, 0.01], #T\n",
    "                                [0.01, 0.01, 0.01, 0.01, 0]]) #DEL\n",
    "\n",
    "\n",
    "\n",
    "    bases = [\"A\", \"C\", \"G\", \"T\", \"DEL\"]\n",
    "\n",
    "    Variants = {\"Variant\": [], \"Sequence\": []}\n",
    "\n",
    "    rng = np.random.RandomState(seed)  # Random state object\n",
    "\n",
    "\n",
    "    for i in range(num_variants):\n",
    "        if num_mutations == 0:\n",
    "            Variants[\"Variant\"].append([\"#PARENT#\"])\n",
    "            Variants[\"Sequence\"].append(template)\n",
    "            continue\n",
    "\n",
    "        positions = rng.choice(range(len(template)), num_mutations, replace=False)\n",
    "        positions.sort()\n",
    "\n",
    "        \n",
    "        mutations = []\n",
    "        for pos in positions:\n",
    "            adjusted_pos = pos \n",
    "            ref_base = template[adjusted_pos]\n",
    "            ref_index = bases.index(ref_base)\n",
    "\n",
    "            prob = trans_matrix[ref_index]\n",
    "            prob = prob / prob.sum()\n",
    "\n",
    "            new_base = np.random.choice(bases, p=prob)\n",
    "\n",
    "            if new_base != \"DEL\":\n",
    "                mutation = f\"{ref_base}{adjusted_pos + 1}{new_base}\"\n",
    "            elif new_base == \"DEL\":\n",
    "                mutation = f\"{ref_base}{adjusted_pos + 1}DEL\"\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(\"Invalid base\")\n",
    "                \n",
    "\n",
    "            mutations.append((adjusted_pos, new_base, mutation))\n",
    "\n",
    "        variant = []\n",
    "        mutated_sequence = list(template)\n",
    "        for pos, new_base, mut in mutations:\n",
    "            variant.append(mut)\n",
    "            if new_base != \"DEL\":\n",
    "                mutated_sequence[pos] = new_base\n",
    "            else:\n",
    "                # Replace the base with a placeholder for deletion\n",
    "                mutated_sequence[pos] = \"_\"\n",
    "\n",
    "        mutated_sequence = \"\".join(mutated_sequence).replace(\"_\", \"\")\n",
    "        Variants[\"Variant\"].append(variant)\n",
    "        Variants[\"Sequence\"].append(mutated_sequence)\n",
    "\n",
    "    return pd.DataFrame(Variants)\n",
    "\n",
    "def select_random_reads(input_file, output_file, num_reads):\n",
    "    all_records = list(SeqIO.parse(input_file, \"fasta\"))\n",
    "\n",
    "    if num_reads > len(all_records):\n",
    "        print(\"Requested number of reads is more than available in the file. Selecting all reads.\")\n",
    "        selected_records = all_records\n",
    "    else:\n",
    "        selected_records = random.sample(all_records, num_reads)\n",
    "\n",
    "    with open(output_file, \"w\") as output_handle:\n",
    "        SeqIO.write(selected_records, output_handle, \"fasta\")\n",
    "\n",
    "\n",
    "def run_alignment_and_indexing(ref, fasta_file, output_dir):\n",
    "    \"\"\"\n",
    "    Aligns sequences using minimap2, converts to BAM, sorts and indexes the BAM file.\n",
    "\n",
    "    Args:\n",
    "    ref (str): Path to the reference genome file.\n",
    "    fasta_file (str): Path to the FASTA file containing reads.\n",
    "    output_dir (Path or str): Directory to store output files.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # Run Minimap2 for alignment\n",
    "    minimap_cmd = f\"minimap2 -ax map-ont -O 3,24 {ref} {fasta_file} > {output_dir}/alignment_minimap.sam\"\n",
    "    subprocess.run(minimap_cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    # Convert SAM to BAM\n",
    "    view_cmd = f\"samtools view -bS {output_dir}/alignment_minimap.sam > {output_dir}/alignment_minimap.bam\"\n",
    "    subprocess.run(view_cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    # Sort BAM file\n",
    "    sort_cmd = f\"samtools sort {output_dir}/alignment_minimap.bam -o {output_dir}/alignment_minimap.bam\"\n",
    "    subprocess.run(sort_cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    # Index BAM file\n",
    "    index_cmd = f\"samtools index {output_dir}/alignment_minimap.bam\"\n",
    "    subprocess.run(index_cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "def adjust_variant(variant, padding_start):\n",
    "\n",
    "    if \"#PARENT#\" in variant:\n",
    "        return \"#PARENT#\"\n",
    "    \n",
    "    elif variant == \"NA\":\n",
    "        return \"NA\"\n",
    "    \n",
    "    else:\n",
    "        variants = variant.split('_')\n",
    "        adjusted_variants = []\n",
    "\n",
    "        for v in variants:\n",
    "            # Find the position number using regular expression\n",
    "            match = re.search(r'([A-Za-z]+)(\\d+)([A-Za-z]+)', v)\n",
    "            if match:\n",
    "                refAA, pos, newAA = match.groups()\n",
    "                \n",
    "                adjusted_pos = max(int(pos) - padding_start, 1)  \n",
    "                adjusted_variants.append(f\"{refAA}{adjusted_pos}{newAA}\")\n",
    "\n",
    "    return '_'.join(adjusted_variants)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "template = IO_processor.read_fasta_file(Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii.fasta\"))[\"Sequence\"][0]\n",
    "\n",
    "Variants = pd.DataFrame({\"Variant\" : [], \"Sequence\" : [], \"Num_Mutations\" : []})\n",
    "\n",
    "\n",
    "for n_mut in range(0,11):\n",
    "    var = generate_variants(template, 100, n_mut, seed)\n",
    "    var[\"Num_Mutations\"] = n_mut\n",
    "    Variants = pd.concat([Variants, var]).reset_index(drop=True)\n",
    "\n",
    "Variants.to_pickle(\"Variants_100_p_s.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate mutation prediction of AF analysis and medaka consensus for different # of mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variants = pd.read_pickle(\"Variants_100_p_s.pkl\")\n",
    "# Select mutation with 0, 1, 5, 10\n",
    "variants = Variants[Variants[\"Num_Mutations\"].isin([0, 1, 5, 10])].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Simulation\n",
    "\n",
    "- Enter the depths to analyze\n",
    "- Padding length\n",
    "- Num Mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Generate substitution and indels for each variant\n",
    "template = IO_processor.read_fasta_file(Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\"))[\"Sequence\"][0]\n",
    "padding = 50\n",
    "os.makedirs(f\"data/min_read_depth/seq\", exist_ok=True)\n",
    "\n",
    "ref = \"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\"\n",
    "reference = \"HetCPIII\"\n",
    "\n",
    "results = {\"Original Variant\" : [], \"Predicted Variant\" : [], \"Depth\" : [], \"Num Mutations\" : [], \"Correct\" : [], \"Alignment Frequency\" : []}\n",
    "\n",
    "np.random.seed(43)\n",
    "random.seed(43)\n",
    "\n",
    "for i, variant in tqdm(Variants.iterrows()):\n",
    "\n",
    "    max_depth = 50\n",
    "    \n",
    "    if \"#PARENT#\" in variant[\"Variant\"]:\n",
    "        var_name = f\"wt_{i}\"\n",
    "\n",
    "    else:\n",
    "        #sort variant\n",
    "        var_name = \"_\".join(variant[\"Variant\"])\n",
    "\n",
    "    # Create folder for each variant\n",
    "    os.makedirs(f\"data/min_read_depth/seq/{var_name}\", exist_ok=True)\n",
    "\n",
    "    padding_seq1 = \"aattcccctctagaaataattttgtttaactttaagaaggagatatacat\"\n",
    "    padding_seq2 = \"gatccggctgctaacaaagcccgaaaggaagctgagttggctgctgccac\"\n",
    "\n",
    "    with open(f\"data/min_read_depth/seq/{var_name}/{var_name}.fasta\", \"w\") as handle: # Create fasta file\n",
    "        for j in range(max_depth):\n",
    "            new_seq = introduce_mutations(variant[\"Sequence\"], 0.01)\n",
    "\n",
    "            new_seq = padding_seq1 + new_seq + padding_seq2\n",
    "\n",
    "            handle.write(f\">{var_name}_{j+1}\\n\")\n",
    "            handle.write(f\"{new_seq}\\n\")\n",
    "\n",
    "    #depths = [1,3,5,7,9,11,13,15,17,19,21,23,25,30,35,40,45,50]\n",
    "    depths = [10,20,30,40,50]\n",
    "    # depths = [30,40,50]\n",
    "    for depth in depths:\n",
    "\n",
    "        #Create depth folder\n",
    "        depth_folder_path = f\"data/min_read_depth/seq/{var_name}/depth_{depth}\"\n",
    "        os.makedirs(depth_folder_path, exist_ok=True)\n",
    "\n",
    "        # Select random reads from the fasta file, Create first all depth lengths and store all fasta files in a folder \n",
    "        select_random_reads(f\"data/min_read_depth/seq/{var_name}/{var_name}.fasta\", f\"{depth_folder_path}/{var_name}_reads.fasta\", depth)\n",
    "\n",
    "        # prompt = f'mini_align -r {ref} -i {depth_folder_path}/*.fasta -t 1 -m -p alignment && mv *.bam *.bam.bai {depth_folder_path}'\n",
    "        # subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "        # Run alignment and indexing\n",
    "        run_alignment_and_indexing(ref, f\"{depth_folder_path}/{var_name}_reads.fasta\", depth_folder_path)\n",
    "\n",
    "        bam_file = f\"{depth_folder_path}/alignment_minimap.bam\"\n",
    "\n",
    "        # Call Variants with bam file\n",
    "\n",
    "        if method == \"AF\":\n",
    "            variant_pred = analyser.call_variant_pop_frequency(Path(bam_file), template, reference, min_freq=0.1, min_depth= 0, padding_start=padding, padding_end= padding + 1)\n",
    "            \n",
    "            try:\n",
    "                variant_pred = pd.DataFrame(variant_pred).sort_values(\"Alignment Frequency\", ascending=False).reset_index(drop=True)\n",
    "                variant_pred[\"Variant\"] = variant_pred[\"Variant\"].apply(lambda x: adjust_variant(x, padding))\n",
    "                result = 1 if variant_pred[\"Variant\"][0] == \"_\".join(variant[\"Variant\"]) else 0\n",
    "\n",
    "                results[\"Original Variant\"].append(variant[\"Variant\"])\n",
    "                results[\"Predicted Variant\"].append(variant_pred[\"Variant\"][0])\n",
    "                results[\"Depth\"].append(depth)\n",
    "                results[\"Num Mutations\"].append(len(variant[\"Variant\"]) if \"#PARENT#\" not in variant[\"Variant\"] else 0)\n",
    "                results[\"Correct\"].append(result)\n",
    "                results[\"Alignment Frequency\"].append(variant_pred[\"Alignment Frequency\"][0])\n",
    "            except:\n",
    "                result = \"NA\"\n",
    "                results[\"Original Variant\"].append(variant[\"Variant\"])\n",
    "                results[\"Predicted Variant\"].append(\"NA\")\n",
    "                results[\"Depth\"].append(depth)\n",
    "                results[\"Num Mutations\"].append(len(variant[\"Variant\"]))\n",
    "                results[\"Correct\"].append(result)\n",
    "                results[\"Alignment Frequency\"].append(\"NA\")\n",
    "        \n",
    "        elif method == \"guppy\":\n",
    "\n",
    "            \n",
    "            \n",
    "# Delete seq folder\n",
    "\n",
    "# if os.path.exists(\"data/min_read_depth/seq\"):\n",
    "#     shutil.rmtree(\"data/min_read_depth/seq\")\n",
    "\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "#results.to_csv(\"data/min_read_depth/results_100_p_s_Q10.csv\", index=False)\n",
    "#results.to_pickle(\"data/min_read_depth/results_100_p_s_Q20.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "ref_seq = Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\")\n",
    "folders = glob.glob(\"data/min_read_depth/seq/*\")\n",
    "\n",
    "for var_path in tqdm(folders):\n",
    "    var_namr = os.path.basename(var_path)\n",
    "    depths = glob.glob(f\"{var_path}/depth*\")\n",
    "    for depth in depths:\n",
    "        \n",
    "        folder_path = Path(depth)\n",
    "        print(\"Processing\", folder_path)\n",
    "        consensus.get_consensus(folder_path, ref_seq, output_name = \"consensus.fastq\", qualities = True, consensus_folder = folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get variant df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "ref_seq = Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\")\n",
    "folders = glob.glob(\"data/min_read_depth/seq/*\")\n",
    "\n",
    "for var_path in tqdm(folders):\n",
    "    var_namr = os.path.basename(var_path)\n",
    "    depths = glob.glob(f\"{var_path}/depth*\")\n",
    "    for depth in depths:\n",
    "        \n",
    "        folder_path = Path(depth)\n",
    "        print(\"Processing\", folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_pickle(\"data/min_read_depth/results_100_p_s_Q20_local.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "#df.to_csv(\"data/min_read_depth/results_20_p_s_01.csv\", index=False)\n",
    "#df.drop(df[df[\"Correct\"] == \"NA\"].index, inplace=True)\n",
    "df.tail(30)[\"Original Variant\"].value_counts()\n",
    "df = df.drop(df[df[\"Correct\"] == \"NA\"].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_DEL_samples(entry):\n",
    "    for variant in entry:\n",
    "        if \"DEL\" in variant:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def check_neg_DEL_position(row):\n",
    "    variant_list = row['Original Variant']\n",
    "    check_list = row['Predicted Variant'].split(\"_\")\n",
    "\n",
    "    \n",
    "    if \"#PARENT#\" in variant_list:\n",
    "        return 0\n",
    "\n",
    "    min_length = min(len(variant_list), len(check_list))\n",
    "    \n",
    "    for i in range(min_length):\n",
    "        var = variant_list[i]\n",
    "        if \"DEL\" in var:\n",
    "            match_orig = re.search(r'([A-Za-z]+)(\\d+)([A-Za-z]+)', var)\n",
    "            match_pred = re.search(r'([A-Za-z]+)(\\d+)([A-Za-z]+)', check_list[i])\n",
    "            \n",
    "            if match_orig and match_pred:\n",
    "                pos = int(match_orig.group(2))\n",
    "                pos_pred = int(match_pred.group(2))\n",
    "                \n",
    "                if pos == pos_pred or pos_pred + 1 == pos or pos_pred - 1 == pos:\n",
    "                    return 1\n",
    "\n",
    "    return 0\n",
    "        \n",
    "        # Additional processing can be added here as needed\n",
    "df_wo_del = df.copy()\n",
    "df_wo_del[\"DEL\"] =      df_wo_del[\"Original Variant\"].apply(get_DEL_samples)\n",
    "df_wo_del[\"Corr DEL\"] = df_wo_del.apply(check_neg_DEL_position, axis=1)\n",
    "mask = df_wo_del[(df_wo_del[\"DEL\"] ==1) & (df_wo_del[\"Corr DEL\"] == 1) & (df_wo_del[\"Correct\"] == 0)].index\n",
    "df_wo_del.iloc[mask, 4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wo_del[(df_wo_del[\"Correct\"] == 0) & (df_wo_del[\"Depth\"] == 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_stats_wo_del = df_wo_del.groupby(['Num Mutations', 'Depth'])['Correct'].agg(['mean', 'std']).reset_index()\n",
    "grouped_stats_wo_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_stats = df.groupby(['Num Mutations', 'Depth'])['Correct'].agg(['mean', 'std']).reset_index()\n",
    "grouped_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"DEL\"] = results[\"Original Variant\"].apply(get_DEL_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHow row with Na\n",
    "from scipy.stats import linregress\n",
    "\n",
    "#df = pd.DataFrame(results)\n",
    "\n",
    "#df = df_wo_del\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df.drop(df[df[\"Correct\"] == \"NA\"].index, inplace=True)\n",
    "\n",
    "df = df.sort_values(\"Num Mutations\")\n",
    "#df['Num Mutations'] = df['Num Mutations'].astype(str)\n",
    "df['Correct'] = df['Correct'].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "# Find unique values in 'Num Mutations' and sort them\n",
    "unique_mutations = sorted(df['Num Mutations'].unique())\n",
    "\n",
    "# Create a color palette with a color for each unique 'Num Mutations' value\n",
    "palette = sns.color_palette(\"viridis\", n_colors=len(unique_mutations))\n",
    "\n",
    "# Map each unique 'Num Mutations' value to a color\n",
    "color_map = dict(zip(unique_mutations, palette))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use the lineplot with the custom palette\n",
    "sns.lineplot(data=df, x=\"Depth\", y=\"Correct\", hue=\"Num Mutations\", style=\"Num Mutations\", \n",
    "             markers=True, dashes=False, palette=color_map, linewidth=2, markersize=10)\n",
    "\n",
    "# Customization\n",
    "plt.xlabel(\"Read Depth\", size=16)\n",
    "plt.ylabel(\"Accuracy\", size=16)\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "# You can uncomment this if you want a legend\n",
    "# plt.legend(title=\"# Mutations\", title_fontsize=14, fontsize=14)\n",
    "\n",
    "plt.savefig(\"depth_vs_correct_Q20.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Alignment Frequency for number of mutations\n",
    "\n",
    "plt.bar(df[\"Num Mutations\"].unique(), df.groupby(\"Num Mutations\").mean()[\"Alignment Frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Num Mutations\").mean()[\"Correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = IO_processor.read_fasta_file(Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii.fasta\"))[\"Sequence\"][0]\n",
    "\n",
    "\n",
    "Variants = {\"Variant\" : [], \"Sequence\" : []}\n",
    "\n",
    "var = [\"A62T\", \"A224DEL\", \"A317T\", \"T348A\", \"A596G\"]\n",
    "template = list(template)\n",
    "# Delete base at position 2 and 3\n",
    "for v in var:\n",
    "    match = re.search(r'([A-Za-z]+)(\\d+)([A-Za-z]+)', v)\n",
    "    if match:\n",
    "        refAA, pos, newAA = match.groups()\n",
    "        template[int(pos) - 1] = \"\"\n",
    "Variants[\"Variant\"].append(var)\n",
    "Variants[\"Sequence\"].append(\"\".join(template))\n",
    "print(len(Variants[\"Sequence\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = IO_processor.read_fasta_file(Path(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\"))[\"Sequence\"][0]\n",
    "padding_start = 50\n",
    "padding_end = 50\n",
    "bam_file = \"/home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G22A_C54A_C93T_A105G_G178A_A335T_T519C_C607DEL/depth_50/alignment_minimap.bam\"\n",
    "alignment_count = int(subprocess.run(f\"samtools view -c {bam_file}\", shell=True, capture_output=True).stdout.decode(\"utf-8\").strip())\n",
    "range_positions = range(padding_start, len(template) - padding_end)\n",
    "freq_dist = pd.DataFrame(analyser.get_highest_non_ref_base_freq_2(bam_file, reference, range_positions, template, qualities=False)[0]).T.rename(columns={0:\"Base\", 1:\"Frequency\"})\n",
    "nb_positions = analyser.get_nb_positions(freq_dist, 0.4)\n",
    "freq_df = analyser.get_pop_frequency(bam_file, template, reference, nb_positions, min_freq=0.1, min_depth= 0)\n",
    "bases_df = analyser.get_bases_from_pileup(bam_file, reference, [655,656,657,658])\n",
    "bases_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_file = \"/home/emre/github_repo/MinION/examples/data/min_read_depth/seq/A393G/depth_50/alignment.bam\"\n",
    "variant_pred = analyser.call_variant_pop_frequency(bam_file, template, reference, min_freq=0.1, min_depth= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_count = int(subprocess.run(f\"samtools view -c {bam_file}\", shell=True, capture_output=True).stdout.decode(\"utf-8\").strip())\n",
    "freq_dist = pd.DataFrame(analyser.get_highest_non_ref_base_freq_2(bam_file, reference, range(1,len(template)), template, qualities=False)[0]).T.rename(columns={0:\"Base\", 1:\"Frequency\"})\n",
    "\n",
    "nb_positions = analyser.get_nb_positions(freq_dist, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser.get_pop_frequency(bam_file, template, reference, nb_positions, min_freq=0.1, min_depth= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(variant_pred).sort_values(\"Alignment Frequency\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variant_manual = {\"variant\" : [[\"G23A\", \"C336T\", \"C587DEL\"], [\"C283DEL\", \"C387T\", \"A478G\"], [\"G3A\", \"G123A\", \"G229A\", \"C442T\"] ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variants_manual = Variants[Variants[\"Variant\"].isin(Variant_manual[\"variant\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bam_file = \"/home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G3A_G123A_G229A_C442T/depth_50/alignment.bam\"\n",
    "prompt = f\"medaka consensus {bam_file} /home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G3A_G123A_G229A_C442T/depth_50/pre_consensus.hdf --batch 200 --threads 4\"\n",
    "subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"medaka stitch /home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G3A_G123A_G229A_C442T/depth_50/pre_consensus.hdf {ref} /home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G3A_G123A_G229A_C442T/depth_50/result.fasta --threads 4\"\n",
    "\n",
    "subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align ref and result with bioaligner\n",
    "\n",
    "ref = \"/home/emre/github_repo/MinION/minION/refseq/hetcpiii.fasta\"\n",
    "result = \"/home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G3A_G123A_G229A_C442T/depth_50/result.fasta\"\n",
    "\n",
    "prompt = f\"bioaligner align {ref} {result} --outfmt sam --out /home/emre/github_repo/MinION/examples/data/min_read_depth/seq/G3A_G123A_G229A_C442T/depth_50/alignment.sam\"\n",
    "\n",
    "subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the reference sequence with 50 Ns at the start and end\n",
    "\n",
    "# with open(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii.fasta\", \"r\") as handle:\n",
    "#     records = list(SeqIO.parse(handle, \"fasta\"))\n",
    "#     template = str(records[0].seq)\n",
    "\n",
    "# template = \"N\" * 50 + template + \"N\" * 50\n",
    "\n",
    "# with open(\"/home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\", \"w\") as handle:\n",
    "#     handle.write(f\">{records[0].id}\\n\")\n",
    "#     handle.write(f\"{template}\\n\")\n",
    "\n",
    "# Reindexing the reference sequence\n",
    "prompt = f\"samtools faidx /home/emre/github_repo/MinION/minION/refseq/hetcpiii_padded.fasta\"\n",
    "subprocess.run(prompt, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment Frequency distribution accross different quality scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variant_df = pd.read_csv(\"/home/emre/github_repo/MinION/examples/data/min_read_depth/results_100_p_s_Q15.csv\")\n",
    "# Count NaN\n",
    "Variant_df.dropna(inplace=True) # NA can occur if the pileup analysis fails. For the sake of the simulation, we dropped these rows. (3 Variants out of 1100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_alignment_freq(entry):\n",
    "    if entry[\"Alignment Frequency\"] == \"-\":\n",
    "        return 0\n",
    "    else:\n",
    "        return entry[\"Alignment Frequency\"]\n",
    "\n",
    "Variant_df[\"Alignment Frequency\"] = Variant_df.apply(edit_alignment_freq, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming Variant_df is your DataFrame and it's already imported\n",
    "df = Variant_df[Variant_df[\"Num Mutations\"] > 0]\n",
    "df[\"Alignment Frequency\"] = df[\"Alignment Frequency\"].astype(float)\n",
    "\n",
    "# Sort the DataFrame numerically first\n",
    "df = df.sort_values(\"Num Mutations\")\n",
    "\n",
    "# Group by and calculate mean and SEM\n",
    "group_stats = df.groupby(\"Num Mutations\")[\"Alignment Frequency\"].agg(['mean', 'std'])\n",
    "\n",
    "# Now convert \"Num Mutations\" to string for plotting, after grouping and calculations\n",
    "group_stats.index = group_stats.index.astype(str)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(group_stats.index, group_stats[\"mean\"], yerr=group_stats[\"std\"], color = \"lightgrey\", edgecolor = \"black\", capsize=5)\n",
    "plt.tick_params(size=14, labelsize=14)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Improving the plot aesthetics\n",
    "plt.xlabel('# of Mutations', size=18)\n",
    "plt.ylabel('Alignment Frequency', size=18)\n",
    " # Rotate the x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout to fit everything nicely\n",
    "plt.savefig(\"data/min_read_depth/alignment_frequency_vs_num_mutations_Q10.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
