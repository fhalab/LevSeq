{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MinION with Guppy \n",
    "\n",
    "- This scripts runs guppy minion step by step. The actual run can be found in run_minion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all packages\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/emre/github_repo/MinION\")\n",
    "\n",
    "from minION.util import IO_processor\n",
    "from minION import analyser\n",
    "from minION import consensus\n",
    "from minION import demultiplexer\n",
    "from minION.util import globals\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General settings\n",
    "\n",
    "result_path = Path(\"/home/emre/\")\n",
    "experiment_name = \"20231130_RL-5sites-8plates_flongle\"\n",
    "\n",
    "# Add conditions to avoid running the script accidentally\n",
    "skip_basecalling = True\n",
    "skip_demultiplex = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 (Optional): Basecall reads\n",
    "\n",
    "- Basecall can usually be done while sequencing (if GPU available?)\n",
    "- Otherwise, basecall afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/emre/minION_results/20231130_RL-5sites-8plates_flongle_sup/basecalled_filtered\n"
     ]
    }
   ],
   "source": [
    "# Path to pod5 files\n",
    "#file_to_pod5 = \"/var/lib/minknow/data/20230905_errorprone-3_test/no_sample/20230905_1342_MN41105_flg114_5c170bfa/pod5/\"\n",
    "file_to_fastq = \"/var/lib/minknow/data/20231130_RL-5sites-8plates_flongle/no_sample/20231130_1900_MN41105_FLG114_1904f884/fastq_pass/\"\n",
    "basecall_model_type = \"sup\"\n",
    "basecall_model = globals.DORADO_MODELS[basecall_model_type]\n",
    "output_name = experiment_name\n",
    "\n",
    "\n",
    "result_folder = IO_processor.create_folder( experiment_name,\n",
    "                                            basecall_model_type, \n",
    "                                            target_path=result_path)\n",
    "                                            \n",
    "experiment_folder = IO_processor.find_experiment_folder(experiment_name) # Folder where pod5 files are located\n",
    "\n",
    "basecall_folder = result_folder / \"basecalled_filtered\"\n",
    "basecall_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(basecall_folder)\n",
    "if not skip_basecalling:\n",
    "    pod5_files = IO_processor.find_folder(experiment_folder, \"pod5\")\n",
    "    run_dorado(basecall_model, pod5_files, basecall_folder, fastq = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Demultiplex Barcodes using guppy barcoder\n",
    "\n",
    "- Define the barcodes in the barcoding folder and index them correctly\n",
    "- We first run reverse barcodes and split in to # RBC folders. Within each RBC folder, guppy barcoder is run again for front barcodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_demultiplex:\n",
    "\n",
    "    BARCODES = {\"Barcode-kit-FBC\" : \"FBC-v1\",\n",
    "                \"Barcode-kit-RBC\" : \"RBC-v1\"}\n",
    "\n",
    "    output_folder_name = \"demultiplex_50_guppy\"\n",
    "\n",
    "    demultiplexer.run_demultiplexer(result_folder, BARCODES, 50, 50, output_folder_name=output_folder_name, basecall_folder = basecall_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Get consensus sequence with guppy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "demultiplex_folder = Path(\"/home/emre/minION_results/20231130_RL-5sites-8plates_flongle_sup/Demultiplex_cpp_70_trimmed_5site\")\n",
    "ref_seq = Path(\"/home/emre/minION_results/ParPgb.fasta\")\n",
    "barcode_dicts = IO_processor.get_barcode_dict(demultiplex_folder, \"NB\", \"RB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:09:11 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:09:11 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:09:11 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:09:11 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:09:11 - Predict] Found a GPU.\n",
      "[15:09:11 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:09:11 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:09:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f97a6765ae0>\n",
      "[15:09:13 - MdlStrTF] loading weights from /tmp/tmpulpe74mt/model/variables/variables\n",
      "[15:09:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:09:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:09:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:13 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-262.\n",
      "[15:09:13 - Feature] Processed ParPgb:0.0-262.0 (median depth 178.0)\n",
      "[15:09:13 - Sampler] Took 0.14s to make features.\n",
      "[15:09:13 - Sampler] Region ParPgb:0.0-262.0 (353 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:09:13 - PWorker] Processed 0 batches\n",
      "[15:09:13 - PWorker] All done, 1 remainder regions.\n",
      "[15:09:13 - Predict] Processing 1 short region(s).\n",
      "[15:09:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f96f1795450>\n",
      "[15:09:13 - MdlStrTF] loading weights from /tmp/tmpulpe74mt/model/variables/variables\n",
      "[15:09:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-263.\n",
      "[15:09:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:20 - Feature] Processed ParPgb:0.0-262.0 (median depth 178.0)\n",
      "[15:09:20 - Sampler] Took 6.64s to make features.\n",
      "[15:09:20 - PWorker] Batches in cache: 1.\n",
      "[15:09:20 - PWorker] Processed 1 batches\n",
      "[15:09:20 - PWorker] All done, 0 remainder regions.\n",
      "[15:09:20 - Predict] Finished processing all regions.\n",
      "[15:09:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:09:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:09:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:09:24 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:09:24 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:09:24 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:09:24 - Predict] Found a GPU.\n",
      "[15:09:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:09:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:09:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7eff193c9ae0>\n",
      "[15:09:25 - MdlStrTF] loading weights from /tmp/tmpizt9t2oe/model/variables/variables\n",
      "[15:09:25 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:09:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:09:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:25 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:09:25 - Feature] Processed ParPgb:0.0-251.0 (median depth 136.0)\n",
      "[15:09:25 - Sampler] Took 0.05s to make features.\n",
      "[15:09:25 - Sampler] Region ParPgb:0.0-251.0 (326 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:09:25 - PWorker] Processed 0 batches\n",
      "[15:09:25 - PWorker] All done, 1 remainder regions.\n",
      "[15:09:25 - Predict] Processing 1 short region(s).\n",
      "[15:09:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efe885c2170>\n",
      "[15:09:26 - MdlStrTF] loading weights from /tmp/tmpizt9t2oe/model/variables/variables\n",
      "[15:09:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:09:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:26 - Feature] Processed ParPgb:0.0-251.0 (median depth 136.0)\n",
      "[15:09:26 - Sampler] Took 0.36s to make features.\n",
      "[15:09:27 - PWorker] Processed 1 batches\n",
      "[15:09:27 - PWorker] All done, 0 remainder regions.\n",
      "[15:09:27 - Predict] Finished processing all regions.\n",
      "[15:09:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:09:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:09:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:09:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:09:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:09:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:09:30 - Predict] Found a GPU.\n",
      "[15:09:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:09:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:09:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc6bd6a1ae0>\n",
      "[15:09:31 - MdlStrTF] loading weights from /tmp/tmpuexngi_o/model/variables/variables\n",
      "[15:09:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:09:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:09:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:32 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:09:32 - Feature] Processed ParPgb:0.0-245.0 (median depth 69.0)\n",
      "[15:09:32 - Sampler] Took 0.15s to make features.\n",
      "[15:09:32 - Sampler] Region ParPgb:0.0-245.0 (292 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:09:32 - PWorker] Processed 0 batches\n",
      "[15:09:32 - PWorker] All done, 1 remainder regions.\n",
      "[15:09:32 - Predict] Processing 1 short region(s).\n",
      "[15:09:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc62c8a9b10>\n",
      "[15:09:32 - MdlStrTF] loading weights from /tmp/tmpuexngi_o/model/variables/variables\n",
      "[15:09:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:09:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:32 - Feature] Processed ParPgb:0.0-245.0 (median depth 69.0)\n",
      "[15:09:32 - Sampler] Took 0.06s to make features.\n",
      "[15:09:33 - PWorker] Processed 1 batches\n",
      "[15:09:33 - PWorker] All done, 0 remainder regions.\n",
      "[15:09:33 - Predict] Finished processing all regions.\n",
      "[15:09:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:09:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:09:36 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:09:36 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:09:36 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:09:36 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:09:36 - Predict] Found a GPU.\n",
      "[15:09:36 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:09:36 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:09:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3fe69a9ae0>\n",
      "[15:09:37 - MdlStrTF] loading weights from /tmp/tmpxdpdtk1o/model/variables/variables\n",
      "[15:09:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:09:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:09:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:09:37 - Feature] Processed ParPgb:0.0-246.0 (median depth 107.0)\n",
      "[15:09:37 - Sampler] Took 0.06s to make features.\n",
      "[15:09:37 - Sampler] Region ParPgb:0.0-246.0 (317 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:09:37 - PWorker] Processed 0 batches\n",
      "[15:09:37 - PWorker] All done, 1 remainder regions.\n",
      "[15:09:37 - Predict] Processing 1 short region(s).\n",
      "[15:09:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3f48339480>\n",
      "[15:09:38 - MdlStrTF] loading weights from /tmp/tmpxdpdtk1o/model/variables/variables\n",
      "[15:09:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:09:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:38 - Feature] Processed ParPgb:0.0-246.0 (median depth 107.0)\n",
      "[15:09:38 - Sampler] Took 0.12s to make features.\n",
      "[15:09:39 - PWorker] Processed 1 batches\n",
      "[15:09:39 - PWorker] All done, 0 remainder regions.\n",
      "[15:09:39 - Predict] Finished processing all regions.\n",
      "[15:09:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:09:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:09:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:09:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:09:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:09:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:09:42 - Predict] Found a GPU.\n",
      "[15:09:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:09:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:09:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6c7c4c5a80>\n",
      "[15:09:43 - MdlStrTF] loading weights from /tmp/tmpmis6rg6v/model/variables/variables\n",
      "[15:09:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:09:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:09:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:09:43 - Feature] Processed ParPgb:0.0-244.0 (median depth 155.0)\n",
      "[15:09:43 - Sampler] Took 0.07s to make features.\n",
      "[15:09:43 - Sampler] Region ParPgb:0.0-244.0 (337 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:09:43 - PWorker] Processed 0 batches\n",
      "[15:09:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:09:43 - Predict] Processing 1 short region(s).\n",
      "[15:09:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6bdd579420>\n",
      "[15:09:44 - MdlStrTF] loading weights from /tmp/tmpmis6rg6v/model/variables/variables\n",
      "[15:09:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:09:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:46 - Feature] Processed ParPgb:0.0-244.0 (median depth 155.0)\n",
      "[15:09:46 - Sampler] Took 1.64s to make features.\n",
      "[15:09:46 - PWorker] Processed 1 batches\n",
      "[15:09:46 - PWorker] All done, 0 remainder regions.\n",
      "[15:09:46 - Predict] Finished processing all regions.\n",
      "[15:09:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:09:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:09:49 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:09:49 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:09:49 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:09:49 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:09:50 - Predict] Found a GPU.\n",
      "[15:09:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:09:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:09:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa81e981ae0>\n",
      "[15:09:51 - MdlStrTF] loading weights from /tmp/tmp2j70e0xe/model/variables/variables\n",
      "[15:09:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:09:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:09:51 - Sampler] Took 0.01s to make features.\n",
      "[15:09:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:51 - PWorker] Processed 0 batches\n",
      "[15:09:51 - PWorker] All done, 0 remainder regions.\n",
      "[15:09:51 - Predict] Finished processing all regions.\n",
      "[15:09:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:09:53 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:09:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:09:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:09:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:09:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:09:54 - Predict] Found a GPU.\n",
      "[15:09:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:09:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:09:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1529549ae0>\n",
      "[15:09:55 - MdlStrTF] loading weights from /tmp/tmpskwqp8l6/model/variables/variables\n",
      "[15:09:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:09:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:09:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-272.\n",
      "[15:09:56 - Feature] Processed ParPgb:0.0-272.0 (median depth 168.0)\n",
      "[15:09:56 - Sampler] Took 0.17s to make features.\n",
      "[15:09:56 - Sampler] Region ParPgb:0.0-272.0 (351 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:09:56 - PWorker] Processed 0 batches\n",
      "[15:09:56 - PWorker] All done, 1 remainder regions.\n",
      "[15:09:56 - Predict] Processing 1 short region(s).\n",
      "[15:09:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:09:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1488592140>\n",
      "[15:09:56 - MdlStrTF] loading weights from /tmp/tmpskwqp8l6/model/variables/variables\n",
      "[15:09:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-273.\n",
      "[15:09:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:09:59 - Feature] Processed ParPgb:0.0-272.0 (median depth 168.0)\n",
      "[15:09:59 - Sampler] Took 2.55s to make features.\n",
      "[15:09:59 - PWorker] Processed 1 batches\n",
      "[15:09:59 - PWorker] All done, 0 remainder regions.\n",
      "[15:09:59 - Predict] Finished processing all regions.\n",
      "[15:10:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:10:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:10:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:10:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:10:03 - Predict] Found a GPU.\n",
      "[15:10:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:10:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:10:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb3b1c75ae0>\n",
      "[15:10:04 - MdlStrTF] loading weights from /tmp/tmp_3v8ljhl/model/variables/variables\n",
      "[15:10:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:10:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:10:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-228.\n",
      "[15:10:04 - Feature] Processed ParPgb:0.0-228.0 (median depth 92.0)\n",
      "[15:10:04 - Sampler] Took 0.11s to make features.\n",
      "[15:10:04 - Sampler] Region ParPgb:0.0-228.0 (278 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:10:04 - PWorker] Processed 0 batches\n",
      "[15:10:04 - PWorker] All done, 1 remainder regions.\n",
      "[15:10:04 - Predict] Processing 1 short region(s).\n",
      "[15:10:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb320dbdff0>\n",
      "[15:10:05 - MdlStrTF] loading weights from /tmp/tmp_3v8ljhl/model/variables/variables\n",
      "[15:10:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-229.\n",
      "[15:10:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:05 - Feature] Processed ParPgb:0.0-228.0 (median depth 92.0)\n",
      "[15:10:05 - Sampler] Took 0.19s to make features.\n",
      "[15:10:05 - PWorker] Processed 1 batches\n",
      "[15:10:05 - PWorker] All done, 0 remainder regions.\n",
      "[15:10:05 - Predict] Finished processing all regions.\n",
      "[15:10:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:10:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:10:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:10:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:10:09 - Predict] Found a GPU.\n",
      "[15:10:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:10:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:10:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f969e3d1ae0>\n",
      "[15:10:10 - MdlStrTF] loading weights from /tmp/tmp_gsa1_1o/model/variables/variables\n",
      "[15:10:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:10:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:10:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-235.\n",
      "[15:10:14 - Feature] Processed ParPgb:0.0-235.0 (median depth 169.0)\n",
      "[15:10:14 - Sampler] Took 4.01s to make features.\n",
      "[15:10:14 - Sampler] Region ParPgb:0.0-235.0 (329 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:10:14 - PWorker] Processed 0 batches\n",
      "[15:10:14 - PWorker] All done, 1 remainder regions.\n",
      "[15:10:14 - Predict] Processing 1 short region(s).\n",
      "[15:10:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f96801b9480>\n",
      "[15:10:15 - MdlStrTF] loading weights from /tmp/tmp_gsa1_1o/model/variables/variables\n",
      "[15:10:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-236.\n",
      "[15:10:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:17 - Feature] Processed ParPgb:0.0-235.0 (median depth 169.0)\n",
      "[15:10:17 - Sampler] Took 1.98s to make features.\n",
      "[15:10:17 - PWorker] Processed 1 batches\n",
      "[15:10:17 - PWorker] All done, 0 remainder regions.\n",
      "[15:10:17 - Predict] Finished processing all regions.\n",
      "[15:10:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:10:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:10:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:10:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:10:21 - Predict] Found a GPU.\n",
      "[15:10:21 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:10:21 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:10:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f09f5a9da80>\n",
      "[15:10:22 - MdlStrTF] loading weights from /tmp/tmpe_8zd9hm/model/variables/variables\n",
      "[15:10:22 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:10:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:10:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:22 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:10:22 - Feature] Processed ParPgb:0.0-249.0 (median depth 131.0)\n",
      "[15:10:22 - Sampler] Took 0.03s to make features.\n",
      "[15:10:22 - Sampler] Region ParPgb:0.0-249.0 (326 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:10:22 - PWorker] Processed 0 batches\n",
      "[15:10:22 - PWorker] All done, 1 remainder regions.\n",
      "[15:10:22 - Predict] Processing 1 short region(s).\n",
      "[15:10:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0955776140>\n",
      "[15:10:22 - MdlStrTF] loading weights from /tmp/tmpe_8zd9hm/model/variables/variables\n",
      "[15:10:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:10:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:24 - Feature] Processed ParPgb:0.0-249.0 (median depth 131.0)\n",
      "[15:10:24 - Sampler] Took 1.98s to make features.\n",
      "[15:10:25 - PWorker] Processed 1 batches\n",
      "[15:10:25 - PWorker] All done, 0 remainder regions.\n",
      "[15:10:25 - Predict] Finished processing all regions.\n",
      "[15:10:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:28 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:10:28 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:10:28 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:10:28 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:10:28 - Predict] Found a GPU.\n",
      "[15:10:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:10:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:10:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4d3f901ae0>\n",
      "[15:10:30 - MdlStrTF] loading weights from /tmp/tmp95scjljc/model/variables/variables\n",
      "[15:10:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:10:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:10:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:30 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[15:10:30 - Feature] Processed ParPgb:0.0-253.0 (median depth 293.0)\n",
      "[15:10:30 - Sampler] Took 0.05s to make features.\n",
      "[15:10:30 - Sampler] Region ParPgb:0.0-253.0 (373 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:10:30 - PWorker] Processed 0 batches\n",
      "[15:10:30 - PWorker] All done, 1 remainder regions.\n",
      "[15:10:30 - Predict] Processing 1 short region(s).\n",
      "[15:10:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4ca0a15e70>\n",
      "[15:10:30 - MdlStrTF] loading weights from /tmp/tmp95scjljc/model/variables/variables\n",
      "[15:10:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[15:10:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:30 - Feature] Processed ParPgb:0.0-253.0 (median depth 293.0)\n",
      "[15:10:30 - Sampler] Took 0.02s to make features.\n",
      "[15:10:31 - PWorker] Processed 1 batches\n",
      "[15:10:31 - PWorker] All done, 0 remainder regions.\n",
      "[15:10:31 - Predict] Finished processing all regions.\n",
      "[15:10:33 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:33 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:34 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:10:34 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:10:34 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:10:34 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:10:34 - Predict] Found a GPU.\n",
      "[15:10:34 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:10:34 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:10:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7feaf8e01ae0>\n",
      "[15:10:36 - MdlStrTF] loading weights from /tmp/tmppaza8ug9/model/variables/variables\n",
      "[15:10:36 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:10:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:10:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:36 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:10:36 - Feature] Processed ParPgb:0.0-203.0 (median depth 108.0)\n",
      "[15:10:36 - Sampler] Took 0.03s to make features.\n",
      "[15:10:36 - Sampler] Region ParPgb:0.0-203.0 (259 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:10:36 - PWorker] Processed 0 batches\n",
      "[15:10:36 - PWorker] All done, 1 remainder regions.\n",
      "[15:10:36 - Predict] Processing 1 short region(s).\n",
      "[15:10:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fea59f9d450>\n",
      "[15:10:36 - MdlStrTF] loading weights from /tmp/tmppaza8ug9/model/variables/variables\n",
      "[15:10:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:10:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:36 - Feature] Processed ParPgb:0.0-203.0 (median depth 108.0)\n",
      "[15:10:36 - Sampler] Took 0.07s to make features.\n",
      "[15:10:37 - PWorker] Processed 1 batches\n",
      "[15:10:37 - PWorker] All done, 0 remainder regions.\n",
      "[15:10:37 - Predict] Finished processing all regions.\n",
      "[15:10:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:10:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:10:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:10:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:10:40 - Predict] Found a GPU.\n",
      "[15:10:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:10:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:10:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f27fe47dae0>\n",
      "[15:10:41 - MdlStrTF] loading weights from /tmp/tmp08ke9mvj/model/variables/variables\n",
      "[15:10:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:10:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:10:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:42 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-257.\n",
      "[15:10:42 - Feature] Processed ParPgb:0.0-257.0 (median depth 114.0)\n",
      "[15:10:44 - Sampler] Took 2.33s to make features.\n",
      "[15:10:44 - Sampler] Region ParPgb:0.0-257.0 (314 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:10:44 - PWorker] Processed 0 batches\n",
      "[15:10:44 - PWorker] All done, 1 remainder regions.\n",
      "[15:10:44 - Predict] Processing 1 short region(s).\n",
      "[15:10:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f276d2d1b10>\n",
      "[15:10:44 - MdlStrTF] loading weights from /tmp/tmp08ke9mvj/model/variables/variables\n",
      "[15:10:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-258.\n",
      "[15:10:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:44 - Feature] Processed ParPgb:0.0-257.0 (median depth 114.0)\n",
      "[15:10:44 - Sampler] Took 0.07s to make features.\n",
      "[15:10:45 - PWorker] Processed 1 batches\n",
      "[15:10:45 - PWorker] All done, 0 remainder regions.\n",
      "[15:10:45 - Predict] Finished processing all regions.\n",
      "[15:10:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:48 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:10:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:10:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:10:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:10:48 - Predict] Found a GPU.\n",
      "[15:10:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:10:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:10:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb18c319ae0>\n",
      "[15:10:50 - MdlStrTF] loading weights from /tmp/tmp5ki3go2c/model/variables/variables\n",
      "[15:10:50 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:10:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:10:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:52 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:10:52 - Feature] Processed ParPgb:0.0-245.0 (median depth 179.0)\n",
      "[15:10:52 - Sampler] Took 2.35s to make features.\n",
      "[15:10:52 - Sampler] Region ParPgb:0.0-245.0 (360 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:10:52 - PWorker] Processed 0 batches\n",
      "[15:10:52 - PWorker] All done, 1 remainder regions.\n",
      "[15:10:52 - Predict] Processing 1 short region(s).\n",
      "[15:10:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb0ed475480>\n",
      "[15:10:52 - MdlStrTF] loading weights from /tmp/tmp5ki3go2c/model/variables/variables\n",
      "[15:10:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:10:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:53 - Feature] Processed ParPgb:0.0-245.0 (median depth 179.0)\n",
      "[15:10:53 - Sampler] Took 0.06s to make features.\n",
      "[15:10:53 - PWorker] Processed 1 batches\n",
      "[15:10:53 - PWorker] All done, 0 remainder regions.\n",
      "[15:10:53 - Predict] Finished processing all regions.\n",
      "[15:10:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:10:56 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:10:56 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:10:56 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:10:56 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:10:57 - Predict] Found a GPU.\n",
      "[15:10:57 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:10:57 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:10:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f97c5d8dae0>\n",
      "[15:10:58 - MdlStrTF] loading weights from /tmp/tmpcsmp8yn4/model/variables/variables\n",
      "[15:10:58 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:10:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:10:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:58 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:10:58 - Feature] Processed ParPgb:0.0-243.0 (median depth 112.0)\n",
      "[15:10:58 - Sampler] Took 0.20s to make features.\n",
      "[15:10:58 - Sampler] Region ParPgb:0.0-243.0 (328 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:10:58 - PWorker] Processed 0 batches\n",
      "[15:10:58 - PWorker] All done, 1 remainder regions.\n",
      "[15:10:58 - Predict] Processing 1 short region(s).\n",
      "[15:10:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:10:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9730f6dff0>\n",
      "[15:10:58 - MdlStrTF] loading weights from /tmp/tmpcsmp8yn4/model/variables/variables\n",
      "[15:10:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:10:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:10:59 - Feature] Processed ParPgb:0.0-243.0 (median depth 112.0)\n",
      "[15:10:59 - Sampler] Took 0.06s to make features.\n",
      "[15:10:59 - PWorker] Processed 1 batches\n",
      "[15:10:59 - PWorker] All done, 0 remainder regions.\n",
      "[15:10:59 - Predict] Finished processing all regions.\n",
      "[15:11:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:11:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:11:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:11:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:11:03 - Predict] Found a GPU.\n",
      "[15:11:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:11:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:11:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe2c6bc5a80>\n",
      "[15:11:04 - MdlStrTF] loading weights from /tmp/tmpcoy3d3f2/model/variables/variables\n",
      "[15:11:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:11:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:11:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:11:04 - Feature] Processed ParPgb:0.0-203.0 (median depth 367.0)\n",
      "[15:11:04 - Sampler] Took 0.04s to make features.\n",
      "[15:11:04 - Sampler] Region ParPgb:0.0-203.0 (372 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:11:04 - PWorker] Processed 0 batches\n",
      "[15:11:04 - PWorker] All done, 1 remainder regions.\n",
      "[15:11:04 - Predict] Processing 1 short region(s).\n",
      "[15:11:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe22846d3f0>\n",
      "[15:11:04 - MdlStrTF] loading weights from /tmp/tmpcoy3d3f2/model/variables/variables\n",
      "[15:11:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:11:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:04 - Feature] Processed ParPgb:0.0-203.0 (median depth 367.0)\n",
      "[15:11:04 - Sampler] Took 0.05s to make features.\n",
      "[15:11:05 - PWorker] Processed 1 batches\n",
      "[15:11:05 - PWorker] All done, 0 remainder regions.\n",
      "[15:11:05 - Predict] Finished processing all regions.\n",
      "[15:11:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:11:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:11:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:11:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:11:08 - Predict] Found a GPU.\n",
      "[15:11:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:11:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:11:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4460349ae0>\n",
      "[15:11:10 - MdlStrTF] loading weights from /tmp/tmpzlnwpj81/model/variables/variables\n",
      "[15:11:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:11:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:11:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:10 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-205.\n",
      "[15:11:10 - Feature] Processed ParPgb:0.0-205.0 (median depth 122.0)\n",
      "[15:11:10 - Sampler] Took 0.06s to make features.\n",
      "[15:11:10 - Sampler] Region ParPgb:0.0-205.0 (305 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:11:10 - PWorker] Processed 0 batches\n",
      "[15:11:10 - PWorker] All done, 1 remainder regions.\n",
      "[15:11:10 - Predict] Processing 1 short region(s).\n",
      "[15:11:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f43c0391480>\n",
      "[15:11:10 - MdlStrTF] loading weights from /tmp/tmpzlnwpj81/model/variables/variables\n",
      "[15:11:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-206.\n",
      "[15:11:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:11 - Feature] Processed ParPgb:0.0-205.0 (median depth 122.0)\n",
      "[15:11:11 - Sampler] Took 0.20s to make features.\n",
      "[15:11:11 - PWorker] Processed 1 batches\n",
      "[15:11:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:11:11 - Predict] Finished processing all regions.\n",
      "[15:11:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:11:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:11:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:11:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:11:15 - Predict] Found a GPU.\n",
      "[15:11:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:11:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:11:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff63301dae0>\n",
      "[15:11:16 - MdlStrTF] loading weights from /tmp/tmpdmgwal47/model/variables/variables\n",
      "[15:11:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:11:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:11:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-256.\n",
      "[15:11:16 - Feature] Processed ParPgb:0.0-256.0 (median depth 199.0)\n",
      "[15:11:16 - Sampler] Took 0.03s to make features.\n",
      "[15:11:16 - Sampler] Region ParPgb:0.0-256.0 (358 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:11:16 - PWorker] Processed 0 batches\n",
      "[15:11:16 - PWorker] All done, 1 remainder regions.\n",
      "[15:11:16 - Predict] Processing 1 short region(s).\n",
      "[15:11:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff5a222dae0>\n",
      "[15:11:16 - MdlStrTF] loading weights from /tmp/tmpdmgwal47/model/variables/variables\n",
      "[15:11:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-257.\n",
      "[15:11:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:16 - Feature] Processed ParPgb:0.0-256.0 (median depth 199.0)\n",
      "[15:11:16 - Sampler] Took 0.11s to make features.\n",
      "[15:11:17 - PWorker] Processed 1 batches\n",
      "[15:11:17 - PWorker] All done, 0 remainder regions.\n",
      "[15:11:17 - Predict] Finished processing all regions.\n",
      "[15:11:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:11:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:11:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:11:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:11:20 - Predict] Found a GPU.\n",
      "[15:11:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:11:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:11:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7b872a9ae0>\n",
      "[15:11:22 - MdlStrTF] loading weights from /tmp/tmpkje6kveb/model/variables/variables\n",
      "[15:11:22 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:11:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:11:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:22 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[15:11:22 - Feature] Processed ParPgb:0.0-253.0 (median depth 86.0)\n",
      "[15:11:22 - Sampler] Took 0.03s to make features.\n",
      "[15:11:22 - Sampler] Region ParPgb:0.0-253.0 (311 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:11:22 - PWorker] Processed 0 batches\n",
      "[15:11:22 - PWorker] All done, 1 remainder regions.\n",
      "[15:11:22 - Predict] Processing 1 short region(s).\n",
      "[15:11:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7ae8371480>\n",
      "[15:11:22 - MdlStrTF] loading weights from /tmp/tmpkje6kveb/model/variables/variables\n",
      "[15:11:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[15:11:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:24 - Feature] Processed ParPgb:0.0-253.0 (median depth 86.0)\n",
      "[15:11:24 - Sampler] Took 2.23s to make features.\n",
      "[15:11:25 - PWorker] Processed 1 batches\n",
      "[15:11:25 - PWorker] All done, 0 remainder regions.\n",
      "[15:11:25 - Predict] Finished processing all regions.\n",
      "[15:11:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:28 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:11:28 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:11:28 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:11:28 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:11:28 - Predict] Found a GPU.\n",
      "[15:11:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:11:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:11:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc81c715a80>\n",
      "[15:11:30 - MdlStrTF] loading weights from /tmp/tmp7crzrw4p/model/variables/variables\n",
      "[15:11:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:11:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:11:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:30 - Sampler] Took 0.09s to make features.\n",
      "[15:11:30 - PWorker] Processed 0 batches\n",
      "[15:11:30 - PWorker] All done, 0 remainder regions.\n",
      "[15:11:30 - Predict] Finished processing all regions.\n",
      "[15:11:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:32 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:11:33 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:11:33 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:11:33 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:11:33 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:11:33 - Predict] Found a GPU.\n",
      "[15:11:33 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:11:33 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:11:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f06813bdae0>\n",
      "[15:11:35 - MdlStrTF] loading weights from /tmp/tmp8qaydejq/model/variables/variables\n",
      "[15:11:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:11:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:11:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:35 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[15:11:35 - Feature] Processed ParPgb:0.0-247.0 (median depth 245.0)\n",
      "[15:11:35 - Sampler] Took 0.03s to make features.\n",
      "[15:11:35 - Sampler] Region ParPgb:0.0-247.0 (355 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:11:35 - PWorker] Processed 0 batches\n",
      "[15:11:35 - PWorker] All done, 1 remainder regions.\n",
      "[15:11:35 - Predict] Processing 1 short region(s).\n",
      "[15:11:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f05e03cd480>\n",
      "[15:11:35 - MdlStrTF] loading weights from /tmp/tmp8qaydejq/model/variables/variables\n",
      "[15:11:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[15:11:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:36 - Feature] Processed ParPgb:0.0-247.0 (median depth 245.0)\n",
      "[15:11:36 - Sampler] Took 1.45s to make features.\n",
      "[15:11:37 - PWorker] Processed 1 batches\n",
      "[15:11:37 - PWorker] All done, 0 remainder regions.\n",
      "[15:11:37 - Predict] Finished processing all regions.\n",
      "[15:11:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:11:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:11:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:11:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:11:41 - Predict] Found a GPU.\n",
      "[15:11:41 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:11:41 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:11:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1080efdae0>\n",
      "[15:11:42 - MdlStrTF] loading weights from /tmp/tmphaqtpbgk/model/variables/variables\n",
      "[15:11:42 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:11:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:11:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:44 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-276.\n",
      "[15:11:44 - Feature] Processed ParPgb:0.0-276.0 (median depth 125.0)\n",
      "[15:11:44 - Sampler] Took 2.11s to make features.\n",
      "[15:11:44 - Sampler] Region ParPgb:0.0-276.0 (351 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:11:44 - PWorker] Processed 0 batches\n",
      "[15:11:44 - PWorker] All done, 1 remainder regions.\n",
      "[15:11:44 - Predict] Processing 1 short region(s).\n",
      "[15:11:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0ff00c5480>\n",
      "[15:11:44 - MdlStrTF] loading weights from /tmp/tmphaqtpbgk/model/variables/variables\n",
      "[15:11:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-277.\n",
      "[15:11:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:46 - Feature] Processed ParPgb:0.0-276.0 (median depth 125.0)\n",
      "[15:11:46 - Sampler] Took 1.42s to make features.\n",
      "[15:11:46 - PWorker] Processed 1 batches\n",
      "[15:11:46 - PWorker] All done, 0 remainder regions.\n",
      "[15:11:46 - Predict] Finished processing all regions.\n",
      "[15:11:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:11:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:11:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:11:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:11:50 - Predict] Found a GPU.\n",
      "[15:11:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:11:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:11:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8f7e50dae0>\n",
      "[15:11:51 - MdlStrTF] loading weights from /tmp/tmpjn229epc/model/variables/variables\n",
      "[15:11:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:11:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:11:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[15:11:51 - Feature] Processed ParPgb:0.0-238.0 (median depth 130.0)\n",
      "[15:11:51 - Sampler] Took 0.04s to make features.\n",
      "[15:11:51 - Sampler] Region ParPgb:0.0-238.0 (319 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:11:51 - PWorker] Processed 0 batches\n",
      "[15:11:51 - PWorker] All done, 1 remainder regions.\n",
      "[15:11:51 - Predict] Processing 1 short region(s).\n",
      "[15:11:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8f602b1480>\n",
      "[15:11:52 - MdlStrTF] loading weights from /tmp/tmpjn229epc/model/variables/variables\n",
      "[15:11:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[15:11:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:52 - Feature] Processed ParPgb:0.0-238.0 (median depth 130.0)\n",
      "[15:11:52 - Sampler] Took 0.06s to make features.\n",
      "[15:11:52 - PWorker] Processed 1 batches\n",
      "[15:11:52 - PWorker] All done, 0 remainder regions.\n",
      "[15:11:52 - Predict] Finished processing all regions.\n",
      "[15:11:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:11:56 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:11:56 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:11:56 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:11:56 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:11:56 - Predict] Found a GPU.\n",
      "[15:11:56 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:11:56 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:11:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff4ccb15ae0>\n",
      "[15:11:57 - MdlStrTF] loading weights from /tmp/tmpnhtkcfbz/model/variables/variables\n",
      "[15:11:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:11:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:11:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:11:57 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[15:11:57 - Feature] Processed ParPgb:0.0-248.0 (median depth 95.0)\n",
      "[15:11:57 - Sampler] Took 0.03s to make features.\n",
      "[15:11:57 - Sampler] Region ParPgb:0.0-248.0 (298 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:11:57 - PWorker] Processed 0 batches\n",
      "[15:11:57 - PWorker] All done, 1 remainder regions.\n",
      "[15:11:57 - Predict] Processing 1 short region(s).\n",
      "[15:11:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:11:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff43c469480>\n",
      "[15:11:58 - MdlStrTF] loading weights from /tmp/tmpnhtkcfbz/model/variables/variables\n",
      "[15:11:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[15:11:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:00 - Feature] Processed ParPgb:0.0-248.0 (median depth 95.0)\n",
      "[15:12:00 - Sampler] Took 2.34s to make features.\n",
      "[15:12:00 - PWorker] Processed 1 batches\n",
      "[15:12:00 - PWorker] All done, 0 remainder regions.\n",
      "[15:12:00 - Predict] Finished processing all regions.\n",
      "[15:12:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:12:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:12:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:12:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:12:04 - Predict] Found a GPU.\n",
      "[15:12:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:12:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:12:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe1aaef5ae0>\n",
      "[15:12:05 - MdlStrTF] loading weights from /tmp/tmpr3jy2mdt/model/variables/variables\n",
      "[15:12:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:12:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:12:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-236.\n",
      "[15:12:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:05 - Feature] Processed ParPgb:0.0-236.0 (median depth 139.0)\n",
      "[15:12:05 - Sampler] Took 0.02s to make features.\n",
      "[15:12:05 - Sampler] Region ParPgb:0.0-236.0 (307 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:12:05 - PWorker] Processed 0 batches\n",
      "[15:12:05 - PWorker] All done, 1 remainder regions.\n",
      "[15:12:05 - Predict] Processing 1 short region(s).\n",
      "[15:12:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe11a0ca320>\n",
      "[15:12:06 - MdlStrTF] loading weights from /tmp/tmpr3jy2mdt/model/variables/variables\n",
      "[15:12:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-237.\n",
      "[15:12:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:10 - Feature] Processed ParPgb:0.0-236.0 (median depth 139.0)\n",
      "[15:12:10 - Sampler] Took 4.56s to make features.\n",
      "[15:12:11 - PWorker] Batches in cache: 1.\n",
      "[15:12:11 - PWorker] Processed 1 batches\n",
      "[15:12:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:12:11 - Predict] Finished processing all regions.\n",
      "[15:12:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:12:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:12:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:12:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:12:14 - Predict] Found a GPU.\n",
      "[15:12:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:12:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:12:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0f56271ae0>\n",
      "[15:12:16 - MdlStrTF] loading weights from /tmp/tmp_tkeepsd/model/variables/variables\n",
      "[15:12:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:12:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:12:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-188.\n",
      "[15:12:16 - Feature] Processed ParPgb:0.0-188.0 (median depth 1.0)\n",
      "[15:12:16 - Sampler] Took 0.32s to make features.\n",
      "[15:12:16 - Sampler] Region ParPgb:0.0-188.0 (190 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:12:16 - PWorker] Processed 0 batches\n",
      "[15:12:16 - PWorker] All done, 1 remainder regions.\n",
      "[15:12:16 - Predict] Processing 1 short region(s).\n",
      "[15:12:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0eb9371480>\n",
      "[15:12:16 - MdlStrTF] loading weights from /tmp/tmp_tkeepsd/model/variables/variables\n",
      "[15:12:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-189.\n",
      "[15:12:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:16 - Feature] Processed ParPgb:0.0-188.0 (median depth 1.0)\n",
      "[15:12:16 - Sampler] Took 0.02s to make features.\n",
      "[15:12:17 - PWorker] Processed 1 batches\n",
      "[15:12:17 - PWorker] All done, 0 remainder regions.\n",
      "[15:12:17 - Predict] Finished processing all regions.\n",
      "[15:12:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:12:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:12:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:12:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:12:20 - Predict] Found a GPU.\n",
      "[15:12:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:12:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:12:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f49087b5ae0>\n",
      "[15:12:22 - MdlStrTF] loading weights from /tmp/tmpyap57d4h/model/variables/variables\n",
      "[15:12:22 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:12:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:12:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:22 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-239.\n",
      "[15:12:22 - Feature] Processed ParPgb:0.0-239.0 (median depth 128.0)\n",
      "[15:12:22 - Sampler] Took 0.05s to make features.\n",
      "[15:12:22 - Sampler] Region ParPgb:0.0-239.0 (323 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:12:22 - PWorker] Processed 0 batches\n",
      "[15:12:22 - PWorker] All done, 1 remainder regions.\n",
      "[15:12:22 - Predict] Processing 1 short region(s).\n",
      "[15:12:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f48781c5480>\n",
      "[15:12:22 - MdlStrTF] loading weights from /tmp/tmpyap57d4h/model/variables/variables\n",
      "[15:12:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-240.\n",
      "[15:12:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:25 - Feature] Processed ParPgb:0.0-239.0 (median depth 128.0)\n",
      "[15:12:25 - Sampler] Took 2.44s to make features.\n",
      "[15:12:25 - PWorker] Processed 1 batches\n",
      "[15:12:25 - PWorker] All done, 0 remainder regions.\n",
      "[15:12:25 - Predict] Finished processing all regions.\n",
      "[15:12:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:12:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:12:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:12:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:12:29 - Predict] Found a GPU.\n",
      "[15:12:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:12:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:12:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f34abb89a80>\n",
      "[15:12:30 - MdlStrTF] loading weights from /tmp/tmptggi4oaj/model/variables/variables\n",
      "[15:12:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:12:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:12:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:30 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-262.\n",
      "[15:12:30 - Feature] Processed ParPgb:0.0-262.0 (median depth 149.0)\n",
      "[15:12:30 - Sampler] Took 0.34s to make features.\n",
      "[15:12:30 - Sampler] Region ParPgb:0.0-262.0 (358 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:12:30 - PWorker] Processed 0 batches\n",
      "[15:12:30 - PWorker] All done, 1 remainder regions.\n",
      "[15:12:30 - Predict] Processing 1 short region(s).\n",
      "[15:12:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f341ad23010>\n",
      "[15:12:31 - MdlStrTF] loading weights from /tmp/tmptggi4oaj/model/variables/variables\n",
      "[15:12:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-263.\n",
      "[15:12:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:31 - Feature] Processed ParPgb:0.0-262.0 (median depth 149.0)\n",
      "[15:12:31 - Sampler] Took 0.08s to make features.\n",
      "[15:12:31 - PWorker] Processed 1 batches\n",
      "[15:12:31 - PWorker] All done, 0 remainder regions.\n",
      "[15:12:31 - Predict] Finished processing all regions.\n",
      "[15:12:33 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:33 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:35 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:12:35 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:12:35 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:12:35 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:12:35 - Predict] Found a GPU.\n",
      "[15:12:35 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:12:35 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:12:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7feaa4fcdae0>\n",
      "[15:12:36 - MdlStrTF] loading weights from /tmp/tmpcpvu5wz1/model/variables/variables\n",
      "[15:12:36 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:12:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:12:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-261.\n",
      "[15:12:37 - Feature] Processed ParPgb:0.0-261.0 (median depth 149.0)\n",
      "[15:12:37 - Sampler] Took 0.33s to make features.\n",
      "[15:12:37 - Sampler] Region ParPgb:0.0-261.0 (352 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:12:37 - PWorker] Processed 0 batches\n",
      "[15:12:37 - PWorker] All done, 1 remainder regions.\n",
      "[15:12:37 - Predict] Processing 1 short region(s).\n",
      "[15:12:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fea10152170>\n",
      "[15:12:37 - MdlStrTF] loading weights from /tmp/tmpcpvu5wz1/model/variables/variables\n",
      "[15:12:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-262.\n",
      "[15:12:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:37 - Feature] Processed ParPgb:0.0-261.0 (median depth 149.0)\n",
      "[15:12:37 - Sampler] Took 0.11s to make features.\n",
      "[15:12:38 - PWorker] Processed 1 batches\n",
      "[15:12:38 - PWorker] All done, 0 remainder regions.\n",
      "[15:12:38 - Predict] Finished processing all regions.\n",
      "[15:12:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:12:41 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:12:41 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:12:41 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:12:41 - Predict] Found a GPU.\n",
      "[15:12:41 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:12:41 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:12:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7a6dba9ae0>\n",
      "[15:12:42 - MdlStrTF] loading weights from /tmp/tmpgfm0k835/model/variables/variables\n",
      "[15:12:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:12:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:12:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-201.\n",
      "[15:12:43 - Feature] Processed ParPgb:0.0-201.0 (median depth 201.0)\n",
      "[15:12:43 - Sampler] Took 0.19s to make features.\n",
      "[15:12:43 - Sampler] Region ParPgb:0.0-201.0 (294 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:12:43 - PWorker] Processed 0 batches\n",
      "[15:12:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:12:43 - Predict] Processing 1 short region(s).\n",
      "[15:12:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f79dcd43070>\n",
      "[15:12:43 - MdlStrTF] loading weights from /tmp/tmpgfm0k835/model/variables/variables\n",
      "[15:12:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-202.\n",
      "[15:12:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:43 - Feature] Processed ParPgb:0.0-201.0 (median depth 201.0)\n",
      "[15:12:43 - Sampler] Took 0.05s to make features.\n",
      "[15:12:44 - PWorker] Processed 1 batches\n",
      "[15:12:44 - PWorker] All done, 0 remainder regions.\n",
      "[15:12:44 - Predict] Finished processing all regions.\n",
      "[15:12:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:12:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:12:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:12:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:12:47 - Predict] Found a GPU.\n",
      "[15:12:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:12:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:12:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7d89fc9a80>\n",
      "[15:12:48 - MdlStrTF] loading weights from /tmp/tmpnt3wht79/model/variables/variables\n",
      "[15:12:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:12:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:12:49 - Sampler] Took 0.01s to make features.\n",
      "[15:12:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:49 - PWorker] Processed 0 batches\n",
      "[15:12:49 - PWorker] All done, 0 remainder regions.\n",
      "[15:12:49 - Predict] Finished processing all regions.\n",
      "[15:12:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:50 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:12:52 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:12:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:12:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:12:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:12:52 - Predict] Found a GPU.\n",
      "[15:12:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:12:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:12:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f63cff19ae0>\n",
      "[15:12:53 - MdlStrTF] loading weights from /tmp/tmp8m4xw9n1/model/variables/variables\n",
      "[15:12:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:12:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:12:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:12:53 - Feature] Processed ParPgb:0.0-243.0 (median depth 169.0)\n",
      "[15:12:53 - Sampler] Took 0.08s to make features.\n",
      "[15:12:53 - Sampler] Region ParPgb:0.0-243.0 (363 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:12:53 - PWorker] Processed 0 batches\n",
      "[15:12:53 - PWorker] All done, 1 remainder regions.\n",
      "[15:12:53 - Predict] Processing 1 short region(s).\n",
      "[15:12:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f63400c5ae0>\n",
      "[15:12:54 - MdlStrTF] loading weights from /tmp/tmp8m4xw9n1/model/variables/variables\n",
      "[15:12:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:12:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:54 - Feature] Processed ParPgb:0.0-243.0 (median depth 169.0)\n",
      "[15:12:54 - Sampler] Took 0.06s to make features.\n",
      "[15:12:54 - PWorker] Processed 1 batches\n",
      "[15:12:54 - PWorker] All done, 0 remainder regions.\n",
      "[15:12:54 - Predict] Finished processing all regions.\n",
      "[15:12:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:12:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:12:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:12:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:12:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:12:58 - Predict] Found a GPU.\n",
      "[15:12:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:12:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:12:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:12:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5957fa9ae0>\n",
      "[15:12:59 - MdlStrTF] loading weights from /tmp/tmpcvve333f/model/variables/variables\n",
      "[15:12:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:12:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:12:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:12:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-256.\n",
      "[15:12:59 - Feature] Processed ParPgb:0.0-256.0 (median depth 108.0)\n",
      "[15:12:59 - Sampler] Took 0.15s to make features.\n",
      "[15:12:59 - Sampler] Region ParPgb:0.0-256.0 (319 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:12:59 - PWorker] Processed 0 batches\n",
      "[15:12:59 - PWorker] All done, 1 remainder regions.\n",
      "[15:12:59 - Predict] Processing 1 short region(s).\n",
      "[15:12:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f58c81c1b10>\n",
      "[15:13:00 - MdlStrTF] loading weights from /tmp/tmpcvve333f/model/variables/variables\n",
      "[15:13:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-257.\n",
      "[15:13:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:05 - Feature] Processed ParPgb:0.0-256.0 (median depth 108.0)\n",
      "[15:13:05 - Sampler] Took 5.02s to make features.\n",
      "[15:13:05 - PWorker] Batches in cache: 1.\n",
      "[15:13:05 - PWorker] Processed 1 batches\n",
      "[15:13:05 - PWorker] All done, 0 remainder regions.\n",
      "[15:13:05 - Predict] Finished processing all regions.\n",
      "[15:13:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:13:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:13:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:13:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:13:09 - Predict] Found a GPU.\n",
      "[15:13:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:13:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:13:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc4529f5ae0>\n",
      "[15:13:10 - MdlStrTF] loading weights from /tmp/tmplab59_2a/model/variables/variables\n",
      "[15:13:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:13:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:13:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:10 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-273.\n",
      "[15:13:10 - Feature] Processed ParPgb:0.0-273.0 (median depth 182.0)\n",
      "[15:13:10 - Sampler] Took 0.07s to make features.\n",
      "[15:13:10 - Sampler] Region ParPgb:0.0-273.0 (351 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:13:10 - PWorker] Processed 0 batches\n",
      "[15:13:10 - PWorker] All done, 1 remainder regions.\n",
      "[15:13:10 - Predict] Processing 1 short region(s).\n",
      "[15:13:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc3c1b25480>\n",
      "[15:13:11 - MdlStrTF] loading weights from /tmp/tmplab59_2a/model/variables/variables\n",
      "[15:13:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-274.\n",
      "[15:13:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:11 - Feature] Processed ParPgb:0.0-273.0 (median depth 182.0)\n",
      "[15:13:11 - Sampler] Took 0.16s to make features.\n",
      "[15:13:11 - PWorker] Processed 1 batches\n",
      "[15:13:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:13:11 - Predict] Finished processing all regions.\n",
      "[15:13:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:13:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:13:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:13:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:13:15 - Predict] Found a GPU.\n",
      "[15:13:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:13:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:13:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f68d5395ae0>\n",
      "[15:13:16 - MdlStrTF] loading weights from /tmp/tmp2lytl3ku/model/variables/variables\n",
      "[15:13:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:13:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:13:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:13:16 - Feature] Processed ParPgb:0.0-203.0 (median depth 42.0)\n",
      "[15:13:16 - Sampler] Took 0.24s to make features.\n",
      "[15:13:16 - Sampler] Region ParPgb:0.0-203.0 (231 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:13:16 - PWorker] Processed 0 batches\n",
      "[15:13:16 - PWorker] All done, 1 remainder regions.\n",
      "[15:13:16 - Predict] Processing 1 short region(s).\n",
      "[15:13:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f68405bd480>\n",
      "[15:13:17 - MdlStrTF] loading weights from /tmp/tmp2lytl3ku/model/variables/variables\n",
      "[15:13:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:13:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:17 - Feature] Processed ParPgb:0.0-203.0 (median depth 42.0)\n",
      "[15:13:17 - Sampler] Took 0.05s to make features.\n",
      "[15:13:17 - PWorker] Processed 1 batches\n",
      "[15:13:17 - PWorker] All done, 0 remainder regions.\n",
      "[15:13:17 - Predict] Finished processing all regions.\n",
      "[15:13:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:21 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:13:21 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:13:21 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:13:21 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:13:21 - Predict] Found a GPU.\n",
      "[15:13:21 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:13:21 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:13:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbb836a5ae0>\n",
      "[15:13:22 - MdlStrTF] loading weights from /tmp/tmp8pnejjsy/model/variables/variables\n",
      "[15:13:22 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:13:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:13:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-201.\n",
      "[15:13:24 - Feature] Processed ParPgb:0.0-201.0 (median depth 143.0)\n",
      "[15:13:24 - Sampler] Took 2.14s to make features.\n",
      "[15:13:24 - Sampler] Region ParPgb:0.0-201.0 (268 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:13:24 - PWorker] Processed 0 batches\n",
      "[15:13:24 - PWorker] All done, 1 remainder regions.\n",
      "[15:13:24 - Predict] Processing 1 short region(s).\n",
      "[15:13:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbaf27f5480>\n",
      "[15:13:25 - MdlStrTF] loading weights from /tmp/tmp8pnejjsy/model/variables/variables\n",
      "[15:13:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-202.\n",
      "[15:13:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:25 - Feature] Processed ParPgb:0.0-201.0 (median depth 143.0)\n",
      "[15:13:25 - Sampler] Took 0.13s to make features.\n",
      "[15:13:25 - PWorker] Processed 1 batches\n",
      "[15:13:25 - PWorker] All done, 0 remainder regions.\n",
      "[15:13:25 - Predict] Finished processing all regions.\n",
      "[15:13:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:13:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:13:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:13:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:13:29 - Predict] Found a GPU.\n",
      "[15:13:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:13:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:13:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3d156c9a80>\n",
      "[15:13:30 - MdlStrTF] loading weights from /tmp/tmpu9ckswvp/model/variables/variables\n",
      "[15:13:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:13:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:13:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:30 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[15:13:30 - Feature] Processed ParPgb:0.0-250.0 (median depth 145.0)\n",
      "[15:13:30 - Sampler] Took 0.13s to make features.\n",
      "[15:13:30 - Sampler] Region ParPgb:0.0-250.0 (314 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:13:30 - PWorker] Processed 0 batches\n",
      "[15:13:30 - PWorker] All done, 1 remainder regions.\n",
      "[15:13:30 - Predict] Processing 1 short region(s).\n",
      "[15:13:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3c8042da80>\n",
      "[15:13:31 - MdlStrTF] loading weights from /tmp/tmpu9ckswvp/model/variables/variables\n",
      "[15:13:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[15:13:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:33 - Feature] Processed ParPgb:0.0-250.0 (median depth 145.0)\n",
      "[15:13:33 - Sampler] Took 2.11s to make features.\n",
      "[15:13:33 - PWorker] Processed 1 batches\n",
      "[15:13:33 - PWorker] All done, 0 remainder regions.\n",
      "[15:13:33 - Predict] Finished processing all regions.\n",
      "[15:13:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:13:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:13:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:13:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:13:37 - Predict] Found a GPU.\n",
      "[15:13:37 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:13:37 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:13:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff403825ae0>\n",
      "[15:13:38 - MdlStrTF] loading weights from /tmp/tmpqa7tobz7/model/variables/variables\n",
      "[15:13:38 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:13:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:13:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-267.\n",
      "[15:13:39 - Feature] Processed ParPgb:0.0-267.0 (median depth 142.0)\n",
      "[15:13:39 - Sampler] Took 0.68s to make features.\n",
      "[15:13:39 - Sampler] Region ParPgb:0.0-267.0 (359 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:13:39 - PWorker] Processed 0 batches\n",
      "[15:13:39 - PWorker] All done, 1 remainder regions.\n",
      "[15:13:39 - Predict] Processing 1 short region(s).\n",
      "[15:13:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff360f9d480>\n",
      "[15:13:39 - MdlStrTF] loading weights from /tmp/tmpqa7tobz7/model/variables/variables\n",
      "[15:13:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-268.\n",
      "[15:13:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:44 - Feature] Processed ParPgb:0.0-267.0 (median depth 142.0)\n",
      "[15:13:44 - Sampler] Took 4.23s to make features.\n",
      "[15:13:44 - PWorker] Processed 1 batches\n",
      "[15:13:44 - PWorker] All done, 0 remainder regions.\n",
      "[15:13:44 - Predict] Finished processing all regions.\n",
      "[15:13:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:48 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:13:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:13:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:13:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:13:48 - Predict] Found a GPU.\n",
      "[15:13:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:13:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:13:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4ef6fedae0>\n",
      "[15:13:49 - MdlStrTF] loading weights from /tmp/tmpijq9j621/model/variables/variables\n",
      "[15:13:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:13:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:13:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:13:49 - Feature] Processed ParPgb:0.0-251.0 (median depth 132.0)\n",
      "[15:13:49 - Sampler] Took 0.08s to make features.\n",
      "[15:13:49 - Sampler] Region ParPgb:0.0-251.0 (332 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:13:49 - PWorker] Processed 0 batches\n",
      "[15:13:49 - PWorker] All done, 1 remainder regions.\n",
      "[15:13:49 - Predict] Processing 1 short region(s).\n",
      "[15:13:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4e5810af20>\n",
      "[15:13:49 - MdlStrTF] loading weights from /tmp/tmpijq9j621/model/variables/variables\n",
      "[15:13:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:13:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:50 - Feature] Processed ParPgb:0.0-251.0 (median depth 132.0)\n",
      "[15:13:50 - Sampler] Took 0.47s to make features.\n",
      "[15:13:51 - PWorker] Processed 1 batches\n",
      "[15:13:51 - PWorker] All done, 0 remainder regions.\n",
      "[15:13:51 - Predict] Finished processing all regions.\n",
      "[15:13:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:13:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:13:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:13:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:13:54 - Predict] Found a GPU.\n",
      "[15:13:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:13:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:13:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f727be0dae0>\n",
      "[15:13:55 - MdlStrTF] loading weights from /tmp/tmpc5egycnq/model/variables/variables\n",
      "[15:13:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:13:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:13:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:13:55 - Feature] Processed ParPgb:0.0-245.0 (median depth 176.0)\n",
      "[15:13:55 - Sampler] Took 0.04s to make features.\n",
      "[15:13:55 - Sampler] Region ParPgb:0.0-245.0 (369 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:13:55 - PWorker] Processed 0 batches\n",
      "[15:13:55 - PWorker] All done, 1 remainder regions.\n",
      "[15:13:55 - Predict] Processing 1 short region(s).\n",
      "[15:13:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:13:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f71dcf9afe0>\n",
      "[15:13:56 - MdlStrTF] loading weights from /tmp/tmpc5egycnq/model/variables/variables\n",
      "[15:13:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:13:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:13:56 - Feature] Processed ParPgb:0.0-245.0 (median depth 176.0)\n",
      "[15:13:56 - Sampler] Took 0.03s to make features.\n",
      "[15:13:56 - PWorker] Processed 1 batches\n",
      "[15:13:56 - PWorker] All done, 0 remainder regions.\n",
      "[15:13:56 - Predict] Finished processing all regions.\n",
      "[15:13:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:13:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:14:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:14:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:14:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:14:00 - Predict] Found a GPU.\n",
      "[15:14:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:14:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:14:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb9244a5ae0>\n",
      "[15:14:01 - MdlStrTF] loading weights from /tmp/tmpacjsqnwx/model/variables/variables\n",
      "[15:14:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:14:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:14:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-227.\n",
      "[15:14:01 - Feature] Processed ParPgb:0.0-227.0 (median depth 108.0)\n",
      "[15:14:01 - Sampler] Took 0.09s to make features.\n",
      "[15:14:01 - Sampler] Region ParPgb:0.0-227.0 (287 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:14:01 - PWorker] Processed 0 batches\n",
      "[15:14:01 - PWorker] All done, 1 remainder regions.\n",
      "[15:14:01 - Predict] Processing 1 short region(s).\n",
      "[15:14:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb888431b10>\n",
      "[15:14:02 - MdlStrTF] loading weights from /tmp/tmpacjsqnwx/model/variables/variables\n",
      "[15:14:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-228.\n",
      "[15:14:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:02 - Feature] Processed ParPgb:0.0-227.0 (median depth 108.0)\n",
      "[15:14:02 - Sampler] Took 0.05s to make features.\n",
      "[15:14:02 - PWorker] Processed 1 batches\n",
      "[15:14:02 - PWorker] All done, 0 remainder regions.\n",
      "[15:14:02 - Predict] Finished processing all regions.\n",
      "[15:14:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:06 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:14:06 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:14:06 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:14:06 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:14:06 - Predict] Found a GPU.\n",
      "[15:14:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:14:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:14:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5b22915ae0>\n",
      "[15:14:07 - MdlStrTF] loading weights from /tmp/tmpsh28697w/model/variables/variables\n",
      "[15:14:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:14:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:14:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-201.\n",
      "[15:14:07 - Feature] Processed ParPgb:0.0-201.0 (median depth 149.0)\n",
      "[15:14:07 - Sampler] Took 0.03s to make features.\n",
      "[15:14:07 - Sampler] Region ParPgb:0.0-201.0 (279 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:14:07 - PWorker] Processed 0 batches\n",
      "[15:14:07 - PWorker] All done, 1 remainder regions.\n",
      "[15:14:07 - Predict] Processing 1 short region(s).\n",
      "[15:14:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5a91a51450>\n",
      "[15:14:08 - MdlStrTF] loading weights from /tmp/tmpsh28697w/model/variables/variables\n",
      "[15:14:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-202.\n",
      "[15:14:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:08 - Feature] Processed ParPgb:0.0-201.0 (median depth 149.0)\n",
      "[15:14:08 - Sampler] Took 0.05s to make features.\n",
      "[15:14:08 - PWorker] Processed 1 batches\n",
      "[15:14:08 - PWorker] All done, 0 remainder regions.\n",
      "[15:14:08 - Predict] Finished processing all regions.\n",
      "[15:14:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:14:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:14:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:14:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:14:12 - Predict] Found a GPU.\n",
      "[15:14:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:14:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:14:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc907f91ae0>\n",
      "[15:14:13 - MdlStrTF] loading weights from /tmp/tmps0j1gwvh/model/variables/variables\n",
      "[15:14:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:14:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:14:13 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-261.\n",
      "[15:14:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:13 - Feature] Processed ParPgb:0.0-261.0 (median depth 142.0)\n",
      "[15:14:13 - Sampler] Took 0.12s to make features.\n",
      "[15:14:13 - Sampler] Region ParPgb:0.0-261.0 (359 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:14:13 - PWorker] Processed 0 batches\n",
      "[15:14:13 - PWorker] All done, 1 remainder regions.\n",
      "[15:14:13 - Predict] Processing 1 short region(s).\n",
      "[15:14:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc8780be320>\n",
      "[15:14:14 - MdlStrTF] loading weights from /tmp/tmps0j1gwvh/model/variables/variables\n",
      "[15:14:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-262.\n",
      "[15:14:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:16 - Feature] Processed ParPgb:0.0-261.0 (median depth 142.0)\n",
      "[15:14:16 - Sampler] Took 2.27s to make features.\n",
      "[15:14:16 - PWorker] Processed 1 batches\n",
      "[15:14:16 - PWorker] All done, 0 remainder regions.\n",
      "[15:14:16 - Predict] Finished processing all regions.\n",
      "[15:14:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:14:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:14:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:14:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:14:20 - Predict] Found a GPU.\n",
      "[15:14:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:14:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:14:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcbac095ae0>\n",
      "[15:14:21 - MdlStrTF] loading weights from /tmp/tmp2ydttbak/model/variables/variables\n",
      "[15:14:21 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:14:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:14:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:21 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[15:14:21 - Feature] Processed ParPgb:0.0-254.0 (median depth 134.0)\n",
      "[15:14:21 - Sampler] Took 0.06s to make features.\n",
      "[15:14:21 - Sampler] Region ParPgb:0.0-254.0 (331 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:14:21 - PWorker] Processed 0 batches\n",
      "[15:14:21 - PWorker] All done, 1 remainder regions.\n",
      "[15:14:21 - Predict] Processing 1 short region(s).\n",
      "[15:14:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcb1c206350>\n",
      "[15:14:22 - MdlStrTF] loading weights from /tmp/tmp2ydttbak/model/variables/variables\n",
      "[15:14:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[15:14:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:26 - Feature] Processed ParPgb:0.0-254.0 (median depth 134.0)\n",
      "[15:14:26 - Sampler] Took 4.09s to make features.\n",
      "[15:14:26 - PWorker] Processed 1 batches\n",
      "[15:14:26 - PWorker] All done, 0 remainder regions.\n",
      "[15:14:26 - Predict] Finished processing all regions.\n",
      "[15:14:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:14:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:14:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:14:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:14:30 - Predict] Found a GPU.\n",
      "[15:14:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:14:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:14:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f492f089ae0>\n",
      "[15:14:31 - MdlStrTF] loading weights from /tmp/tmpgj7ek_kb/model/variables/variables\n",
      "[15:14:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:14:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:14:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-200.\n",
      "[15:14:31 - Feature] Processed ParPgb:0.0-200.0 (median depth 149.0)\n",
      "[15:14:31 - Sampler] Took 0.04s to make features.\n",
      "[15:14:31 - Sampler] Region ParPgb:0.0-200.0 (298 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:14:31 - PWorker] Processed 0 batches\n",
      "[15:14:31 - PWorker] All done, 1 remainder regions.\n",
      "[15:14:31 - Predict] Processing 1 short region(s).\n",
      "[15:14:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f489e1e5480>\n",
      "[15:14:32 - MdlStrTF] loading weights from /tmp/tmpgj7ek_kb/model/variables/variables\n",
      "[15:14:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-201.\n",
      "[15:14:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:32 - Feature] Processed ParPgb:0.0-200.0 (median depth 149.0)\n",
      "[15:14:32 - Sampler] Took 0.04s to make features.\n",
      "[15:14:32 - PWorker] Processed 1 batches\n",
      "[15:14:32 - PWorker] All done, 0 remainder regions.\n",
      "[15:14:32 - Predict] Finished processing all regions.\n",
      "[15:14:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:35 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:14:36 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:14:36 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:14:36 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:14:36 - Predict] Found a GPU.\n",
      "[15:14:36 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:14:36 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:14:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f61514e5ae0>\n",
      "[15:14:37 - MdlStrTF] loading weights from /tmp/tmpfd2z4fvx/model/variables/variables\n",
      "[15:14:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:14:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:14:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-258.\n",
      "[15:14:37 - Feature] Processed ParPgb:0.0-258.0 (median depth 147.0)\n",
      "[15:14:37 - Sampler] Took 0.05s to make features.\n",
      "[15:14:37 - Sampler] Region ParPgb:0.0-258.0 (324 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:14:37 - PWorker] Processed 0 batches\n",
      "[15:14:37 - PWorker] All done, 1 remainder regions.\n",
      "[15:14:37 - Predict] Processing 1 short region(s).\n",
      "[15:14:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f60b0589480>\n",
      "[15:14:37 - MdlStrTF] loading weights from /tmp/tmpfd2z4fvx/model/variables/variables\n",
      "[15:14:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-259.\n",
      "[15:14:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:38 - Feature] Processed ParPgb:0.0-258.0 (median depth 147.0)\n",
      "[15:14:38 - Sampler] Took 0.09s to make features.\n",
      "[15:14:38 - PWorker] Processed 1 batches\n",
      "[15:14:38 - PWorker] All done, 0 remainder regions.\n",
      "[15:14:38 - Predict] Finished processing all regions.\n",
      "[15:14:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:14:41 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:14:41 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:14:41 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:14:41 - Predict] Found a GPU.\n",
      "[15:14:41 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:14:41 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:14:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6f63bd5ae0>\n",
      "[15:14:43 - MdlStrTF] loading weights from /tmp/tmp_cltqm4c/model/variables/variables\n",
      "[15:14:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:14:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:14:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[15:14:43 - Feature] Processed ParPgb:0.0-240.0 (median depth 45.0)\n",
      "[15:14:43 - Sampler] Took 0.08s to make features.\n",
      "[15:14:43 - Sampler] Region ParPgb:0.0-240.0 (262 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:14:43 - PWorker] Processed 0 batches\n",
      "[15:14:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:14:43 - Predict] Processing 1 short region(s).\n",
      "[15:14:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6ed2d1d480>\n",
      "[15:14:43 - MdlStrTF] loading weights from /tmp/tmp_cltqm4c/model/variables/variables\n",
      "[15:14:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[15:14:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:46 - Feature] Processed ParPgb:0.0-240.0 (median depth 45.0)\n",
      "[15:14:46 - Sampler] Took 2.44s to make features.\n",
      "[15:14:46 - PWorker] Processed 1 batches\n",
      "[15:14:46 - PWorker] All done, 0 remainder regions.\n",
      "[15:14:46 - Predict] Finished processing all regions.\n",
      "[15:14:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:14:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:14:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:14:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:14:50 - Predict] Found a GPU.\n",
      "[15:14:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:14:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:14:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2453011ae0>\n",
      "[15:14:51 - MdlStrTF] loading weights from /tmp/tmpk8smzhn7/model/variables/variables\n",
      "[15:14:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:14:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:14:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-219.\n",
      "[15:14:51 - Feature] Processed ParPgb:0.0-219.0 (median depth 364.0)\n",
      "[15:14:51 - Sampler] Took 0.20s to make features.\n",
      "[15:14:51 - Sampler] Region ParPgb:0.0-219.0 (418 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:14:51 - PWorker] Processed 0 batches\n",
      "[15:14:51 - PWorker] All done, 1 remainder regions.\n",
      "[15:14:51 - Predict] Processing 1 short region(s).\n",
      "[15:14:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f23c1ede1a0>\n",
      "[15:14:52 - MdlStrTF] loading weights from /tmp/tmpk8smzhn7/model/variables/variables\n",
      "[15:14:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-220.\n",
      "[15:14:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:54 - Feature] Processed ParPgb:0.0-219.0 (median depth 364.0)\n",
      "[15:14:54 - Sampler] Took 1.74s to make features.\n",
      "[15:14:54 - PWorker] Processed 1 batches\n",
      "[15:14:54 - PWorker] All done, 0 remainder regions.\n",
      "[15:14:54 - Predict] Finished processing all regions.\n",
      "[15:14:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:14:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:14:57 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:14:57 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:14:57 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:14:58 - Predict] Found a GPU.\n",
      "[15:14:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:14:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:14:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7feedac5dae0>\n",
      "[15:14:59 - MdlStrTF] loading weights from /tmp/tmpigaaw7fj/model/variables/variables\n",
      "[15:14:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:14:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:14:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:14:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-259.\n",
      "[15:14:59 - Feature] Processed ParPgb:0.0-259.0 (median depth 107.0)\n",
      "[15:14:59 - Sampler] Took 0.04s to make features.\n",
      "[15:14:59 - Sampler] Region ParPgb:0.0-259.0 (332 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:14:59 - PWorker] Processed 0 batches\n",
      "[15:14:59 - PWorker] All done, 1 remainder regions.\n",
      "[15:14:59 - Predict] Processing 1 short region(s).\n",
      "[15:14:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:14:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fee48439990>\n",
      "[15:14:59 - MdlStrTF] loading weights from /tmp/tmpigaaw7fj/model/variables/variables\n",
      "[15:14:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-260.\n",
      "[15:14:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:02 - Feature] Processed ParPgb:0.0-259.0 (median depth 107.0)\n",
      "[15:15:02 - Sampler] Took 2.26s to make features.\n",
      "[15:15:02 - PWorker] Processed 1 batches\n",
      "[15:15:02 - PWorker] All done, 0 remainder regions.\n",
      "[15:15:02 - Predict] Finished processing all regions.\n",
      "[15:15:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:06 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:15:06 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:15:06 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:15:06 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:15:06 - Predict] Found a GPU.\n",
      "[15:15:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:15:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:15:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5902021ae0>\n",
      "[15:15:07 - MdlStrTF] loading weights from /tmp/tmptwl_rgeo/model/variables/variables\n",
      "[15:15:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:15:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:15:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-266.\n",
      "[15:15:07 - Feature] Processed ParPgb:0.0-266.0 (median depth 173.0)\n",
      "[15:15:07 - Sampler] Took 0.10s to make features.\n",
      "[15:15:07 - Sampler] Region ParPgb:0.0-266.0 (366 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:15:07 - PWorker] Processed 0 batches\n",
      "[15:15:07 - PWorker] All done, 1 remainder regions.\n",
      "[15:15:07 - Predict] Processing 1 short region(s).\n",
      "[15:15:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5871229b10>\n",
      "[15:15:08 - MdlStrTF] loading weights from /tmp/tmptwl_rgeo/model/variables/variables\n",
      "[15:15:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-267.\n",
      "[15:15:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:08 - Feature] Processed ParPgb:0.0-266.0 (median depth 173.0)\n",
      "[15:15:08 - Sampler] Took 0.80s to make features.\n",
      "[15:15:09 - PWorker] Processed 1 batches\n",
      "[15:15:09 - PWorker] All done, 0 remainder regions.\n",
      "[15:15:09 - Predict] Finished processing all regions.\n",
      "[15:15:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:15:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:15:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:15:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:15:12 - Predict] Found a GPU.\n",
      "[15:15:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:15:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:15:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd257791a80>\n",
      "[15:15:14 - MdlStrTF] loading weights from /tmp/tmpb0l9054o/model/variables/variables\n",
      "[15:15:14 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:15:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:15:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:15:14 - Feature] Processed ParPgb:0.0-251.0 (median depth 147.0)\n",
      "[15:15:14 - Sampler] Took 0.04s to make features.\n",
      "[15:15:14 - Sampler] Region ParPgb:0.0-251.0 (335 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:15:14 - PWorker] Processed 0 batches\n",
      "[15:15:14 - PWorker] All done, 1 remainder regions.\n",
      "[15:15:14 - Predict] Processing 1 short region(s).\n",
      "[15:15:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd1b8109420>\n",
      "[15:15:14 - MdlStrTF] loading weights from /tmp/tmpb0l9054o/model/variables/variables\n",
      "[15:15:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:15:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:15 - Feature] Processed ParPgb:0.0-251.0 (median depth 147.0)\n",
      "[15:15:15 - Sampler] Took 0.62s to make features.\n",
      "[15:15:15 - PWorker] Processed 1 batches\n",
      "[15:15:15 - PWorker] All done, 0 remainder regions.\n",
      "[15:15:15 - Predict] Finished processing all regions.\n",
      "[15:15:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:15:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:15:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:15:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:15:19 - Predict] Found a GPU.\n",
      "[15:15:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:15:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:15:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb0f4b75ae0>\n",
      "[15:15:20 - MdlStrTF] loading weights from /tmp/tmpnp215k8x/model/variables/variables\n",
      "[15:15:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:15:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:15:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-226.\n",
      "[15:15:20 - Feature] Processed ParPgb:0.0-226.0 (median depth 272.0)\n",
      "[15:15:20 - Sampler] Took 0.04s to make features.\n",
      "[15:15:20 - Sampler] Region ParPgb:0.0-226.0 (390 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:15:20 - PWorker] Processed 0 batches\n",
      "[15:15:20 - PWorker] All done, 1 remainder regions.\n",
      "[15:15:20 - Predict] Processing 1 short region(s).\n",
      "[15:15:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb0581a5480>\n",
      "[15:15:21 - MdlStrTF] loading weights from /tmp/tmpnp215k8x/model/variables/variables\n",
      "[15:15:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-227.\n",
      "[15:15:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:21 - Feature] Processed ParPgb:0.0-226.0 (median depth 272.0)\n",
      "[15:15:21 - Sampler] Took 0.04s to make features.\n",
      "[15:15:21 - PWorker] Processed 1 batches\n",
      "[15:15:21 - PWorker] All done, 0 remainder regions.\n",
      "[15:15:21 - Predict] Finished processing all regions.\n",
      "[15:15:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:15:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:15:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:15:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:15:25 - Predict] Found a GPU.\n",
      "[15:15:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:15:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:15:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3b84769ae0>\n",
      "[15:15:26 - MdlStrTF] loading weights from /tmp/tmpm039axa8/model/variables/variables\n",
      "[15:15:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:15:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:15:26 - Sampler] Took 0.01s to make features.\n",
      "[15:15:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:26 - PWorker] Processed 0 batches\n",
      "[15:15:26 - PWorker] All done, 0 remainder regions.\n",
      "[15:15:26 - Predict] Finished processing all regions.\n",
      "[15:15:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:28 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:15:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:15:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:15:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:15:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:15:29 - Predict] Found a GPU.\n",
      "[15:15:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:15:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:15:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f77695bdae0>\n",
      "[15:15:31 - MdlStrTF] loading weights from /tmp/tmpv7ynugrw/model/variables/variables\n",
      "[15:15:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:15:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:15:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[15:15:31 - Feature] Processed ParPgb:0.0-254.0 (median depth 124.0)\n",
      "[15:15:31 - Sampler] Took 0.04s to make features.\n",
      "[15:15:31 - Sampler] Region ParPgb:0.0-254.0 (330 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:15:31 - PWorker] Processed 0 batches\n",
      "[15:15:31 - PWorker] All done, 1 remainder regions.\n",
      "[15:15:31 - Predict] Processing 1 short region(s).\n",
      "[15:15:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f76b079d480>\n",
      "[15:15:31 - MdlStrTF] loading weights from /tmp/tmpv7ynugrw/model/variables/variables\n",
      "[15:15:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[15:15:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:31 - Feature] Processed ParPgb:0.0-254.0 (median depth 124.0)\n",
      "[15:15:31 - Sampler] Took 0.04s to make features.\n",
      "[15:15:32 - PWorker] Processed 1 batches\n",
      "[15:15:32 - PWorker] All done, 0 remainder regions.\n",
      "[15:15:32 - Predict] Finished processing all regions.\n",
      "[15:15:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:35 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:15:35 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:15:35 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:15:35 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:15:35 - Predict] Found a GPU.\n",
      "[15:15:35 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:15:35 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:15:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb5fe6b9ae0>\n",
      "[15:15:37 - MdlStrTF] loading weights from /tmp/tmp873jhysk/model/variables/variables\n",
      "[15:15:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:15:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:15:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:15:37 - Feature] Processed ParPgb:0.0-245.0 (median depth 35.0)\n",
      "[15:15:37 - Sampler] Took 0.05s to make features.\n",
      "[15:15:37 - Sampler] Region ParPgb:0.0-245.0 (292 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:15:37 - PWorker] Processed 0 batches\n",
      "[15:15:37 - PWorker] All done, 1 remainder regions.\n",
      "[15:15:37 - Predict] Processing 1 short region(s).\n",
      "[15:15:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb56d8a5480>\n",
      "[15:15:37 - MdlStrTF] loading weights from /tmp/tmp873jhysk/model/variables/variables\n",
      "[15:15:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:15:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:37 - Feature] Processed ParPgb:0.0-245.0 (median depth 35.0)\n",
      "[15:15:37 - Sampler] Took 0.04s to make features.\n",
      "[15:15:38 - PWorker] Processed 1 batches\n",
      "[15:15:38 - PWorker] All done, 0 remainder regions.\n",
      "[15:15:38 - Predict] Finished processing all regions.\n",
      "[15:15:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:15:41 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:15:41 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:15:41 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:15:41 - Predict] Found a GPU.\n",
      "[15:15:41 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:15:41 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:15:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fed516e9ae0>\n",
      "[15:15:43 - MdlStrTF] loading weights from /tmp/tmpf5z3ms60/model/variables/variables\n",
      "[15:15:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:15:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:15:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:44 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-256.\n",
      "[15:15:44 - Feature] Processed ParPgb:0.0-256.0 (median depth 262.0)\n",
      "[15:15:44 - Sampler] Took 1.52s to make features.\n",
      "[15:15:44 - Sampler] Region ParPgb:0.0-256.0 (385 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:15:44 - PWorker] Processed 0 batches\n",
      "[15:15:44 - PWorker] All done, 1 remainder regions.\n",
      "[15:15:44 - Predict] Processing 1 short region(s).\n",
      "[15:15:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fecc00eee90>\n",
      "[15:15:44 - MdlStrTF] loading weights from /tmp/tmpf5z3ms60/model/variables/variables\n",
      "[15:15:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-257.\n",
      "[15:15:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:46 - Feature] Processed ParPgb:0.0-256.0 (median depth 262.0)\n",
      "[15:15:46 - Sampler] Took 2.00s to make features.\n",
      "[15:15:47 - PWorker] Processed 1 batches\n",
      "[15:15:47 - PWorker] All done, 0 remainder regions.\n",
      "[15:15:47 - Predict] Finished processing all regions.\n",
      "[15:15:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:15:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:15:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:15:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:15:50 - Predict] Found a GPU.\n",
      "[15:15:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:15:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:15:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2bdf905ae0>\n",
      "[15:15:52 - MdlStrTF] loading weights from /tmp/tmp1rl_2s2i/model/variables/variables\n",
      "[15:15:52 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:15:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:15:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:52 - Sampler] Took 0.01s to make features.\n",
      "[15:15:52 - PWorker] Processed 0 batches\n",
      "[15:15:52 - PWorker] All done, 0 remainder regions.\n",
      "[15:15:52 - Predict] Finished processing all regions.\n",
      "[15:15:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:54 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:15:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:15:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:15:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:15:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:15:55 - Predict] Found a GPU.\n",
      "[15:15:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:15:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:15:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f20e1679ae0>\n",
      "[15:15:56 - MdlStrTF] loading weights from /tmp/tmp06zdl710/model/variables/variables\n",
      "[15:15:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:15:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:15:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:57 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-267.\n",
      "[15:15:57 - Feature] Processed ParPgb:0.0-267.0 (median depth 277.0)\n",
      "[15:15:57 - Sampler] Took 0.06s to make features.\n",
      "[15:15:57 - Sampler] Region ParPgb:0.0-267.0 (390 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:15:57 - PWorker] Processed 0 batches\n",
      "[15:15:57 - PWorker] All done, 1 remainder regions.\n",
      "[15:15:57 - Predict] Processing 1 short region(s).\n",
      "[15:15:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:15:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2040511480>\n",
      "[15:15:57 - MdlStrTF] loading weights from /tmp/tmp06zdl710/model/variables/variables\n",
      "[15:15:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-268.\n",
      "[15:15:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:15:57 - Feature] Processed ParPgb:0.0-267.0 (median depth 277.0)\n",
      "[15:15:57 - Sampler] Took 0.03s to make features.\n",
      "[15:15:58 - PWorker] Processed 1 batches\n",
      "[15:15:58 - PWorker] All done, 0 remainder regions.\n",
      "[15:15:58 - Predict] Finished processing all regions.\n",
      "[15:15:59 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:15:59 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:01 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:16:01 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:16:01 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:16:01 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:16:01 - Predict] Found a GPU.\n",
      "[15:16:01 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:16:01 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:16:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3fe4991ae0>\n",
      "[15:16:02 - MdlStrTF] loading weights from /tmp/tmprotxaav2/model/variables/variables\n",
      "[15:16:02 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:16:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:16:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:03 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:16:05 - Feature] Processed ParPgb:0.0-251.0 (median depth 80.0)\n",
      "[15:16:05 - Sampler] Took 2.14s to make features.\n",
      "[15:16:05 - Sampler] Region ParPgb:0.0-251.0 (298 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:16:05 - PWorker] Processed 0 batches\n",
      "[15:16:05 - PWorker] All done, 1 remainder regions.\n",
      "[15:16:05 - Predict] Processing 1 short region(s).\n",
      "[15:16:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3f5038d480>\n",
      "[15:16:05 - MdlStrTF] loading weights from /tmp/tmprotxaav2/model/variables/variables\n",
      "[15:16:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:16:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:05 - Feature] Processed ParPgb:0.0-251.0 (median depth 80.0)\n",
      "[15:16:05 - Sampler] Took 0.05s to make features.\n",
      "[15:16:06 - PWorker] Processed 1 batches\n",
      "[15:16:06 - PWorker] All done, 0 remainder regions.\n",
      "[15:16:06 - Predict] Finished processing all regions.\n",
      "[15:16:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:16:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:16:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:16:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:16:09 - Predict] Found a GPU.\n",
      "[15:16:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:16:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:16:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f838c495ae0>\n",
      "[15:16:10 - MdlStrTF] loading weights from /tmp/tmpb4keo7hk/model/variables/variables\n",
      "[15:16:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:16:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:16:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-266.\n",
      "[15:16:11 - Feature] Processed ParPgb:0.0-266.0 (median depth 232.0)\n",
      "[15:16:11 - Sampler] Took 0.13s to make features.\n",
      "[15:16:11 - Sampler] Region ParPgb:0.0-266.0 (362 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:16:11 - PWorker] Processed 0 batches\n",
      "[15:16:11 - PWorker] All done, 1 remainder regions.\n",
      "[15:16:11 - Predict] Processing 1 short region(s).\n",
      "[15:16:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f82ed56e1a0>\n",
      "[15:16:11 - MdlStrTF] loading weights from /tmp/tmpb4keo7hk/model/variables/variables\n",
      "[15:16:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-267.\n",
      "[15:16:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:11 - Feature] Processed ParPgb:0.0-266.0 (median depth 232.0)\n",
      "[15:16:11 - Sampler] Took 0.09s to make features.\n",
      "[15:16:12 - PWorker] Processed 1 batches\n",
      "[15:16:12 - PWorker] All done, 0 remainder regions.\n",
      "[15:16:12 - Predict] Finished processing all regions.\n",
      "[15:16:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:16:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:16:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:16:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:16:15 - Predict] Found a GPU.\n",
      "[15:16:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:16:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:16:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa8ea27dae0>\n",
      "[15:16:16 - MdlStrTF] loading weights from /tmp/tmpk2_66pv9/model/variables/variables\n",
      "[15:16:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:16:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:16:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:16:17 - Feature] Processed ParPgb:0.0-244.0 (median depth 151.0)\n",
      "[15:16:17 - Sampler] Took 0.18s to make features.\n",
      "[15:16:17 - Sampler] Region ParPgb:0.0-244.0 (318 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:16:17 - PWorker] Processed 0 batches\n",
      "[15:16:17 - PWorker] All done, 1 remainder regions.\n",
      "[15:16:17 - Predict] Processing 1 short region(s).\n",
      "[15:16:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa8594521a0>\n",
      "[15:16:17 - MdlStrTF] loading weights from /tmp/tmpk2_66pv9/model/variables/variables\n",
      "[15:16:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:16:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:17 - Feature] Processed ParPgb:0.0-244.0 (median depth 151.0)\n",
      "[15:16:17 - Sampler] Took 0.04s to make features.\n",
      "[15:16:18 - PWorker] Processed 1 batches\n",
      "[15:16:18 - PWorker] All done, 0 remainder regions.\n",
      "[15:16:18 - Predict] Finished processing all regions.\n",
      "[15:16:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:21 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:16:21 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:16:21 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:16:21 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:16:21 - Predict] Found a GPU.\n",
      "[15:16:21 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:16:21 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:16:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6713061ae0>\n",
      "[15:16:22 - MdlStrTF] loading weights from /tmp/tmp0klae21_/model/variables/variables\n",
      "[15:16:22 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:16:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:16:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:23 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-199.\n",
      "[15:16:23 - Feature] Processed ParPgb:0.0-199.0 (median depth 35.0)\n",
      "[15:16:23 - Sampler] Took 0.16s to make features.\n",
      "[15:16:23 - Sampler] Region ParPgb:0.0-199.0 (234 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:16:23 - PWorker] Processed 0 batches\n",
      "[15:16:23 - PWorker] All done, 1 remainder regions.\n",
      "[15:16:23 - Predict] Processing 1 short region(s).\n",
      "[15:16:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6680645480>\n",
      "[15:16:23 - MdlStrTF] loading weights from /tmp/tmp0klae21_/model/variables/variables\n",
      "[15:16:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-200.\n",
      "[15:16:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:23 - Feature] Processed ParPgb:0.0-199.0 (median depth 35.0)\n",
      "[15:16:23 - Sampler] Took 0.08s to make features.\n",
      "[15:16:24 - PWorker] Processed 1 batches\n",
      "[15:16:24 - PWorker] All done, 0 remainder regions.\n",
      "[15:16:24 - Predict] Finished processing all regions.\n",
      "[15:16:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:27 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:16:27 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:16:27 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:16:27 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:16:27 - Predict] Found a GPU.\n",
      "[15:16:27 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:16:27 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:16:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faaea2ada80>\n",
      "[15:16:29 - MdlStrTF] loading weights from /tmp/tmp7fv2_qtt/model/variables/variables\n",
      "[15:16:29 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:16:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:16:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:29 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:16:29 - Feature] Processed ParPgb:0.0-249.0 (median depth 85.0)\n",
      "[15:16:29 - Sampler] Took 0.04s to make features.\n",
      "[15:16:29 - Sampler] Region ParPgb:0.0-249.0 (304 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:16:29 - PWorker] Processed 0 batches\n",
      "[15:16:29 - PWorker] All done, 1 remainder regions.\n",
      "[15:16:29 - Predict] Processing 1 short region(s).\n",
      "[15:16:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faa59429420>\n",
      "[15:16:29 - MdlStrTF] loading weights from /tmp/tmp7fv2_qtt/model/variables/variables\n",
      "[15:16:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:16:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:29 - Feature] Processed ParPgb:0.0-249.0 (median depth 85.0)\n",
      "[15:16:29 - Sampler] Took 0.05s to make features.\n",
      "[15:16:30 - PWorker] Processed 1 batches\n",
      "[15:16:30 - PWorker] All done, 0 remainder regions.\n",
      "[15:16:30 - Predict] Finished processing all regions.\n",
      "[15:16:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:33 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:16:33 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:16:33 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:16:33 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:16:33 - Predict] Found a GPU.\n",
      "[15:16:33 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:16:33 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:16:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f949b92dae0>\n",
      "[15:16:34 - MdlStrTF] loading weights from /tmp/tmp7bqc9nwy/model/variables/variables\n",
      "[15:16:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:16:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:16:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:34 - Sampler] Took 0.01s to make features.\n",
      "[15:16:34 - PWorker] Processed 0 batches\n",
      "[15:16:34 - PWorker] All done, 0 remainder regions.\n",
      "[15:16:34 - Predict] Finished processing all regions.\n",
      "[15:16:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:36 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:16:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:16:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:16:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:16:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:16:38 - Predict] Found a GPU.\n",
      "[15:16:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:16:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:16:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f011f919ae0>\n",
      "[15:16:39 - MdlStrTF] loading weights from /tmp/tmpvgkd9pdp/model/variables/variables\n",
      "[15:16:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:16:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:16:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:16:39 - Feature] Processed ParPgb:0.0-249.0 (median depth 123.0)\n",
      "[15:16:39 - Sampler] Took 0.11s to make features.\n",
      "[15:16:39 - Sampler] Region ParPgb:0.0-249.0 (316 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:16:39 - PWorker] Processed 0 batches\n",
      "[15:16:39 - PWorker] All done, 1 remainder regions.\n",
      "[15:16:39 - Predict] Processing 1 short region(s).\n",
      "[15:16:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0080a15480>\n",
      "[15:16:40 - MdlStrTF] loading weights from /tmp/tmpvgkd9pdp/model/variables/variables\n",
      "[15:16:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:16:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:40 - Feature] Processed ParPgb:0.0-249.0 (median depth 123.0)\n",
      "[15:16:40 - Sampler] Took 0.64s to make features.\n",
      "[15:16:41 - PWorker] Processed 1 batches\n",
      "[15:16:41 - PWorker] All done, 0 remainder regions.\n",
      "[15:16:41 - Predict] Finished processing all regions.\n",
      "[15:16:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:44 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:16:44 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:16:44 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:16:44 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:16:44 - Predict] Found a GPU.\n",
      "[15:16:44 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:16:44 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:16:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f276e005ae0>\n",
      "[15:16:46 - MdlStrTF] loading weights from /tmp/tmp8vj472ei/model/variables/variables\n",
      "[15:16:46 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:16:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:16:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:48 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-266.\n",
      "[15:16:48 - Feature] Processed ParPgb:0.0-266.0 (median depth 114.0)\n",
      "[15:16:48 - Sampler] Took 2.00s to make features.\n",
      "[15:16:48 - Sampler] Region ParPgb:0.0-266.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:16:48 - PWorker] Processed 0 batches\n",
      "[15:16:48 - PWorker] All done, 1 remainder regions.\n",
      "[15:16:48 - Predict] Processing 1 short region(s).\n",
      "[15:16:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f26dce8dea0>\n",
      "[15:16:48 - MdlStrTF] loading weights from /tmp/tmp8vj472ei/model/variables/variables\n",
      "[15:16:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-267.\n",
      "[15:16:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:48 - Feature] Processed ParPgb:0.0-266.0 (median depth 114.0)\n",
      "[15:16:48 - Sampler] Took 0.25s to make features.\n",
      "[15:16:49 - PWorker] Processed 1 batches\n",
      "[15:16:49 - PWorker] All done, 0 remainder regions.\n",
      "[15:16:49 - Predict] Finished processing all regions.\n",
      "[15:16:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:52 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:16:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:16:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:16:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:16:52 - Predict] Found a GPU.\n",
      "[15:16:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:16:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:16:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f02f8b81ae0>\n",
      "[15:16:54 - MdlStrTF] loading weights from /tmp/tmpz5jbyqin/model/variables/variables\n",
      "[15:16:54 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:16:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:16:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:54 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-199.\n",
      "[15:16:54 - Feature] Processed ParPgb:0.0-199.0 (median depth 117.0)\n",
      "[15:16:54 - Sampler] Took 0.05s to make features.\n",
      "[15:16:54 - Sampler] Region ParPgb:0.0-199.0 (272 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:16:54 - PWorker] Processed 0 batches\n",
      "[15:16:54 - PWorker] All done, 1 remainder regions.\n",
      "[15:16:54 - Predict] Processing 1 short region(s).\n",
      "[15:16:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:16:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0259c75ea0>\n",
      "[15:16:54 - MdlStrTF] loading weights from /tmp/tmpz5jbyqin/model/variables/variables\n",
      "[15:16:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-200.\n",
      "[15:16:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:16:54 - Feature] Processed ParPgb:0.0-199.0 (median depth 117.0)\n",
      "[15:16:54 - Sampler] Took 0.07s to make features.\n",
      "[15:16:55 - PWorker] Processed 1 batches\n",
      "[15:16:55 - PWorker] All done, 0 remainder regions.\n",
      "[15:16:55 - Predict] Finished processing all regions.\n",
      "[15:16:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:16:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:16:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:16:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:16:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:16:58 - Predict] Found a GPU.\n",
      "[15:16:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:16:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:16:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff15e87dae0>\n",
      "[15:17:00 - MdlStrTF] loading weights from /tmp/tmpd2ee7zw2/model/variables/variables\n",
      "[15:17:00 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:17:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:17:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:00 - Sampler] Took 0.07s to make features.\n",
      "[15:17:00 - PWorker] Processed 0 batches\n",
      "[15:17:00 - PWorker] All done, 0 remainder regions.\n",
      "[15:17:00 - Predict] Finished processing all regions.\n",
      "[15:17:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:01 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:17:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:17:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:17:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:17:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:17:03 - Predict] Found a GPU.\n",
      "[15:17:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:17:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:17:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5741a2dae0>\n",
      "[15:17:04 - MdlStrTF] loading weights from /tmp/tmpni1zupys/model/variables/variables\n",
      "[15:17:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:17:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:17:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[15:17:04 - Feature] Processed ParPgb:0.0-248.0 (median depth 198.0)\n",
      "[15:17:04 - Sampler] Took 0.05s to make features.\n",
      "[15:17:04 - Sampler] Region ParPgb:0.0-248.0 (380 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:17:04 - PWorker] Processed 0 batches\n",
      "[15:17:04 - PWorker] All done, 1 remainder regions.\n",
      "[15:17:04 - Predict] Processing 1 short region(s).\n",
      "[15:17:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f56b0365450>\n",
      "[15:17:05 - MdlStrTF] loading weights from /tmp/tmpni1zupys/model/variables/variables\n",
      "[15:17:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[15:17:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:05 - Feature] Processed ParPgb:0.0-248.0 (median depth 198.0)\n",
      "[15:17:05 - Sampler] Took 0.09s to make features.\n",
      "[15:17:05 - PWorker] Processed 1 batches\n",
      "[15:17:05 - PWorker] All done, 0 remainder regions.\n",
      "[15:17:05 - Predict] Finished processing all regions.\n",
      "[15:17:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:17:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:17:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:17:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:17:09 - Predict] Found a GPU.\n",
      "[15:17:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:17:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:17:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb84285dae0>\n",
      "[15:17:10 - MdlStrTF] loading weights from /tmp/tmprlpqbaee/model/variables/variables\n",
      "[15:17:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:17:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:17:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:12 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[15:17:12 - Feature] Processed ParPgb:0.0-255.0 (median depth 91.0)\n",
      "[15:17:12 - Sampler] Took 2.17s to make features.\n",
      "[15:17:12 - Sampler] Region ParPgb:0.0-255.0 (327 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:17:12 - PWorker] Processed 0 batches\n",
      "[15:17:12 - PWorker] All done, 1 remainder regions.\n",
      "[15:17:12 - Predict] Processing 1 short region(s).\n",
      "[15:17:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb7b1a29f90>\n",
      "[15:17:13 - MdlStrTF] loading weights from /tmp/tmprlpqbaee/model/variables/variables\n",
      "[15:17:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[15:17:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:13 - Feature] Processed ParPgb:0.0-255.0 (median depth 91.0)\n",
      "[15:17:13 - Sampler] Took 0.06s to make features.\n",
      "[15:17:13 - PWorker] Processed 1 batches\n",
      "[15:17:13 - PWorker] All done, 0 remainder regions.\n",
      "[15:17:13 - Predict] Finished processing all regions.\n",
      "[15:17:15 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:15 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:17 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:17:17 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:17:17 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:17:17 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:17:17 - Predict] Found a GPU.\n",
      "[15:17:17 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:17:17 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:17:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fee44035ae0>\n",
      "[15:17:18 - MdlStrTF] loading weights from /tmp/tmpz152cbcb/model/variables/variables\n",
      "[15:17:18 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:17:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:17:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:18 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:17:18 - Feature] Processed ParPgb:0.0-246.0 (median depth 101.0)\n",
      "[15:17:18 - Sampler] Took 0.08s to make features.\n",
      "[15:17:18 - Sampler] Region ParPgb:0.0-246.0 (306 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:17:18 - PWorker] Processed 0 batches\n",
      "[15:17:18 - PWorker] All done, 1 remainder regions.\n",
      "[15:17:18 - Predict] Processing 1 short region(s).\n",
      "[15:17:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fed8657dae0>\n",
      "[15:17:19 - MdlStrTF] loading weights from /tmp/tmpz152cbcb/model/variables/variables\n",
      "[15:17:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:17:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:19 - Feature] Processed ParPgb:0.0-246.0 (median depth 101.0)\n",
      "[15:17:19 - Sampler] Took 0.05s to make features.\n",
      "[15:17:19 - PWorker] Processed 1 batches\n",
      "[15:17:19 - PWorker] All done, 0 remainder regions.\n",
      "[15:17:19 - Predict] Finished processing all regions.\n",
      "[15:17:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:23 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:17:23 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:17:23 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:17:23 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:17:23 - Predict] Found a GPU.\n",
      "[15:17:23 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:17:23 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:17:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f25b8995ae0>\n",
      "[15:17:24 - MdlStrTF] loading weights from /tmp/tmpy2wxqabt/model/variables/variables\n",
      "[15:17:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:17:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:17:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-197.\n",
      "[15:17:24 - Feature] Processed ParPgb:0.0-197.0 (median depth 5.0)\n",
      "[15:17:24 - Sampler] Took 0.10s to make features.\n",
      "[15:17:24 - Sampler] Region ParPgb:0.0-197.0 (204 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:17:24 - PWorker] Processed 0 batches\n",
      "[15:17:24 - PWorker] All done, 1 remainder regions.\n",
      "[15:17:24 - Predict] Processing 1 short region(s).\n",
      "[15:17:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f252838e200>\n",
      "[15:17:25 - MdlStrTF] loading weights from /tmp/tmpy2wxqabt/model/variables/variables\n",
      "[15:17:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-198.\n",
      "[15:17:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:25 - Feature] Processed ParPgb:0.0-197.0 (median depth 5.0)\n",
      "[15:17:25 - Sampler] Took 0.07s to make features.\n",
      "[15:17:25 - PWorker] Processed 1 batches\n",
      "[15:17:25 - PWorker] All done, 0 remainder regions.\n",
      "[15:17:25 - Predict] Finished processing all regions.\n",
      "[15:17:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:17:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:17:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:17:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:17:29 - Predict] Found a GPU.\n",
      "[15:17:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:17:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:17:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8e26221ae0>\n",
      "[15:17:30 - MdlStrTF] loading weights from /tmp/tmpgm7elogo/model/variables/variables\n",
      "[15:17:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:17:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:17:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:17:31 - Feature] Processed ParPgb:0.0-243.0 (median depth 221.0)\n",
      "[15:17:31 - Sampler] Took 1.10s to make features.\n",
      "[15:17:31 - Sampler] Region ParPgb:0.0-243.0 (342 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:17:31 - PWorker] Processed 0 batches\n",
      "[15:17:31 - PWorker] All done, 1 remainder regions.\n",
      "[15:17:31 - Predict] Processing 1 short region(s).\n",
      "[15:17:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8d8939e1a0>\n",
      "[15:17:32 - MdlStrTF] loading weights from /tmp/tmpgm7elogo/model/variables/variables\n",
      "[15:17:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:17:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:34 - Feature] Processed ParPgb:0.0-243.0 (median depth 221.0)\n",
      "[15:17:34 - Sampler] Took 1.87s to make features.\n",
      "[15:17:34 - PWorker] Processed 1 batches\n",
      "[15:17:34 - PWorker] All done, 0 remainder regions.\n",
      "[15:17:34 - Predict] Finished processing all regions.\n",
      "[15:17:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:17:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:17:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:17:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:17:38 - Predict] Found a GPU.\n",
      "[15:17:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:17:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:17:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7feac4255ae0>\n",
      "[15:17:39 - MdlStrTF] loading weights from /tmp/tmp9lh91ux4/model/variables/variables\n",
      "[15:17:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:17:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:17:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:44 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:17:44 - Feature] Processed ParPgb:0.0-252.0 (median depth 118.0)\n",
      "[15:17:44 - Sampler] Took 4.91s to make features.\n",
      "[15:17:44 - Sampler] Region ParPgb:0.0-252.0 (324 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:17:44 - PWorker] Processed 0 batches\n",
      "[15:17:44 - PWorker] All done, 1 remainder regions.\n",
      "[15:17:44 - Predict] Processing 1 short region(s).\n",
      "[15:17:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fea073755a0>\n",
      "[15:17:44 - MdlStrTF] loading weights from /tmp/tmp9lh91ux4/model/variables/variables\n",
      "[15:17:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:17:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:44 - Feature] Processed ParPgb:0.0-252.0 (median depth 118.0)\n",
      "[15:17:44 - Sampler] Took 0.07s to make features.\n",
      "[15:17:45 - PWorker] Processed 1 batches\n",
      "[15:17:45 - PWorker] All done, 0 remainder regions.\n",
      "[15:17:45 - Predict] Finished processing all regions.\n",
      "[15:17:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:48 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:17:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:17:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:17:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:17:48 - Predict] Found a GPU.\n",
      "[15:17:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:17:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:17:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f542554dae0>\n",
      "[15:17:50 - MdlStrTF] loading weights from /tmp/tmpr049qftq/model/variables/variables\n",
      "[15:17:50 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:17:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:17:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:50 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:17:50 - Feature] Processed ParPgb:0.0-249.0 (median depth 170.0)\n",
      "[15:17:50 - Sampler] Took 0.04s to make features.\n",
      "[15:17:50 - Sampler] Region ParPgb:0.0-249.0 (354 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:17:50 - PWorker] Processed 0 batches\n",
      "[15:17:50 - PWorker] All done, 1 remainder regions.\n",
      "[15:17:50 - Predict] Processing 1 short region(s).\n",
      "[15:17:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5390259b10>\n",
      "[15:17:50 - MdlStrTF] loading weights from /tmp/tmpr049qftq/model/variables/variables\n",
      "[15:17:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:17:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:50 - Feature] Processed ParPgb:0.0-249.0 (median depth 170.0)\n",
      "[15:17:50 - Sampler] Took 0.07s to make features.\n",
      "[15:17:51 - PWorker] Processed 1 batches\n",
      "[15:17:51 - PWorker] All done, 0 remainder regions.\n",
      "[15:17:51 - Predict] Finished processing all regions.\n",
      "[15:17:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:17:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:17:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:17:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:17:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:17:54 - Predict] Found a GPU.\n",
      "[15:17:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:17:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:17:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f04bdd95ae0>\n",
      "[15:17:55 - MdlStrTF] loading weights from /tmp/tmpr4ry8m0l/model/variables/variables\n",
      "[15:17:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:17:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:17:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:17:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[15:17:56 - Feature] Processed ParPgb:0.0-250.0 (median depth 153.0)\n",
      "[15:17:56 - Sampler] Took 0.12s to make features.\n",
      "[15:17:56 - Sampler] Region ParPgb:0.0-250.0 (353 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:17:56 - PWorker] Processed 0 batches\n",
      "[15:17:56 - PWorker] All done, 1 remainder regions.\n",
      "[15:17:56 - Predict] Processing 1 short region(s).\n",
      "[15:17:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:17:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f041d671fc0>\n",
      "[15:17:56 - MdlStrTF] loading weights from /tmp/tmpr4ry8m0l/model/variables/variables\n",
      "[15:17:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[15:17:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:00 - Feature] Processed ParPgb:0.0-250.0 (median depth 153.0)\n",
      "[15:18:00 - Sampler] Took 3.83s to make features.\n",
      "[15:18:00 - PWorker] Processed 1 batches\n",
      "[15:18:00 - PWorker] All done, 0 remainder regions.\n",
      "[15:18:00 - Predict] Finished processing all regions.\n",
      "[15:18:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:18:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:18:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:18:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:18:04 - Predict] Found a GPU.\n",
      "[15:18:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:18:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:18:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2a98d55ae0>\n",
      "[15:18:05 - MdlStrTF] loading weights from /tmp/tmpnxfdity1/model/variables/variables\n",
      "[15:18:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:18:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:18:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:18:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:05 - Feature] Processed ParPgb:0.0-245.0 (median depth 143.0)\n",
      "[15:18:05 - Sampler] Took 0.07s to make features.\n",
      "[15:18:05 - Sampler] Region ParPgb:0.0-245.0 (354 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:18:05 - PWorker] Processed 0 batches\n",
      "[15:18:05 - PWorker] All done, 1 remainder regions.\n",
      "[15:18:05 - Predict] Processing 1 short region(s).\n",
      "[15:18:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f29f858e320>\n",
      "[15:18:06 - MdlStrTF] loading weights from /tmp/tmpnxfdity1/model/variables/variables\n",
      "[15:18:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:18:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:10 - Feature] Processed ParPgb:0.0-245.0 (median depth 143.0)\n",
      "[15:18:10 - Sampler] Took 4.22s to make features.\n",
      "[15:18:11 - PWorker] Processed 1 batches\n",
      "[15:18:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:18:11 - Predict] Finished processing all regions.\n",
      "[15:18:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:18:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:18:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:18:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:18:14 - Predict] Found a GPU.\n",
      "[15:18:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:18:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:18:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f87d4301ae0>\n",
      "[15:18:15 - MdlStrTF] loading weights from /tmp/tmp9jo9lb3h/model/variables/variables\n",
      "[15:18:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:18:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:18:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-264.\n",
      "[15:18:20 - Feature] Processed ParPgb:0.0-264.0 (median depth 261.0)\n",
      "[15:18:20 - Sampler] Took 4.48s to make features.\n",
      "[15:18:20 - Sampler] Region ParPgb:0.0-264.0 (395 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:18:20 - PWorker] Processed 0 batches\n",
      "[15:18:20 - PWorker] All done, 1 remainder regions.\n",
      "[15:18:20 - Predict] Processing 1 short region(s).\n",
      "[15:18:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f871747a1d0>\n",
      "[15:18:20 - MdlStrTF] loading weights from /tmp/tmp9jo9lb3h/model/variables/variables\n",
      "[15:18:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-265.\n",
      "[15:18:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:20 - Feature] Processed ParPgb:0.0-264.0 (median depth 261.0)\n",
      "[15:18:20 - Sampler] Took 0.05s to make features.\n",
      "[15:18:21 - PWorker] Processed 1 batches\n",
      "[15:18:21 - PWorker] All done, 0 remainder regions.\n",
      "[15:18:21 - Predict] Finished processing all regions.\n",
      "[15:18:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:18:24 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:18:24 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:18:24 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:18:24 - Predict] Found a GPU.\n",
      "[15:18:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:18:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:18:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd622599a80>\n",
      "[15:18:26 - MdlStrTF] loading weights from /tmp/tmpkl_zbuis/model/variables/variables\n",
      "[15:18:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:18:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:18:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-234.\n",
      "[15:18:26 - Feature] Processed ParPgb:0.0-234.0 (median depth 75.0)\n",
      "[15:18:26 - Sampler] Took 0.04s to make features.\n",
      "[15:18:26 - Sampler] Region ParPgb:0.0-234.0 (290 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:18:26 - PWorker] Processed 0 batches\n",
      "[15:18:26 - PWorker] All done, 1 remainder regions.\n",
      "[15:18:26 - Predict] Processing 1 short region(s).\n",
      "[15:18:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd5916c5420>\n",
      "[15:18:26 - MdlStrTF] loading weights from /tmp/tmpkl_zbuis/model/variables/variables\n",
      "[15:18:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-235.\n",
      "[15:18:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:26 - Feature] Processed ParPgb:0.0-234.0 (median depth 75.0)\n",
      "[15:18:26 - Sampler] Took 0.03s to make features.\n",
      "[15:18:27 - PWorker] Processed 1 batches\n",
      "[15:18:27 - PWorker] All done, 0 remainder regions.\n",
      "[15:18:27 - Predict] Finished processing all regions.\n",
      "[15:18:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:18:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:18:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:18:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:18:30 - Predict] Found a GPU.\n",
      "[15:18:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:18:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:18:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb1c30fdae0>\n",
      "[15:18:31 - MdlStrTF] loading weights from /tmp/tmpneqjjvtj/model/variables/variables\n",
      "[15:18:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:18:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:18:31 - Sampler] Took 0.00s to make features.\n",
      "[15:18:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:31 - PWorker] Processed 0 batches\n",
      "[15:18:31 - PWorker] All done, 0 remainder regions.\n",
      "[15:18:31 - Predict] Finished processing all regions.\n",
      "[15:18:33 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:33 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:18:35 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:18:35 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:18:35 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:18:35 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:18:35 - Predict] Found a GPU.\n",
      "[15:18:35 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:18:35 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:18:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc9a00a9ae0>\n",
      "[15:18:36 - MdlStrTF] loading weights from /tmp/tmpgg_8k0lg/model/variables/variables\n",
      "[15:18:36 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:18:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:18:36 - Sampler] Took 0.01s to make features.\n",
      "[15:18:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:36 - PWorker] Processed 0 batches\n",
      "[15:18:36 - PWorker] All done, 0 remainder regions.\n",
      "[15:18:36 - Predict] Finished processing all regions.\n",
      "[15:18:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:38 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:18:39 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:18:39 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:18:39 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:18:39 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:18:39 - Predict] Found a GPU.\n",
      "[15:18:39 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:18:39 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:18:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f31aed3dae0>\n",
      "[15:18:41 - MdlStrTF] loading weights from /tmp/tmpg7wobkhd/model/variables/variables\n",
      "[15:18:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:18:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:18:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:41 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-266.\n",
      "[15:18:41 - Feature] Processed ParPgb:0.0-266.0 (median depth 265.0)\n",
      "[15:18:41 - Sampler] Took 0.04s to make features.\n",
      "[15:18:41 - Sampler] Region ParPgb:0.0-266.0 (381 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:18:41 - PWorker] Processed 0 batches\n",
      "[15:18:41 - PWorker] All done, 1 remainder regions.\n",
      "[15:18:41 - Predict] Processing 1 short region(s).\n",
      "[15:18:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f31902b5480>\n",
      "[15:18:41 - MdlStrTF] loading weights from /tmp/tmpg7wobkhd/model/variables/variables\n",
      "[15:18:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-267.\n",
      "[15:18:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:41 - Feature] Processed ParPgb:0.0-266.0 (median depth 265.0)\n",
      "[15:18:41 - Sampler] Took 0.08s to make features.\n",
      "[15:18:42 - PWorker] Processed 1 batches\n",
      "[15:18:42 - PWorker] All done, 0 remainder regions.\n",
      "[15:18:42 - Predict] Finished processing all regions.\n",
      "[15:18:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:45 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:18:45 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:18:45 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:18:45 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:18:45 - Predict] Found a GPU.\n",
      "[15:18:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:18:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:18:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff13bf81ae0>\n",
      "[15:18:47 - MdlStrTF] loading weights from /tmp/tmpi1imdp8u/model/variables/variables\n",
      "[15:18:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:18:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:18:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[15:18:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:47 - Feature] Processed ParPgb:0.0-253.0 (median depth 159.0)\n",
      "[15:18:47 - Sampler] Took 0.20s to make features.\n",
      "[15:18:47 - Sampler] Region ParPgb:0.0-253.0 (334 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:18:47 - PWorker] Processed 0 batches\n",
      "[15:18:47 - PWorker] All done, 1 remainder regions.\n",
      "[15:18:47 - Predict] Processing 1 short region(s).\n",
      "[15:18:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff0ac0de320>\n",
      "[15:18:47 - MdlStrTF] loading weights from /tmp/tmpi1imdp8u/model/variables/variables\n",
      "[15:18:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[15:18:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:47 - Feature] Processed ParPgb:0.0-253.0 (median depth 159.0)\n",
      "[15:18:47 - Sampler] Took 0.03s to make features.\n",
      "[15:18:48 - PWorker] Processed 1 batches\n",
      "[15:18:48 - PWorker] All done, 0 remainder regions.\n",
      "[15:18:48 - Predict] Finished processing all regions.\n",
      "[15:18:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:51 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:18:51 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:18:51 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:18:51 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:18:51 - Predict] Found a GPU.\n",
      "[15:18:51 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:18:51 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:18:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1d100a1ae0>\n",
      "[15:18:53 - MdlStrTF] loading weights from /tmp/tmp18ol76jm/model/variables/variables\n",
      "[15:18:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:18:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:18:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-287.\n",
      "[15:18:53 - Feature] Processed ParPgb:0.0-287.0 (median depth 103.0)\n",
      "[15:18:53 - Sampler] Took 0.15s to make features.\n",
      "[15:18:53 - Sampler] Region ParPgb:0.0-287.0 (361 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:18:53 - PWorker] Processed 0 batches\n",
      "[15:18:53 - PWorker] All done, 1 remainder regions.\n",
      "[15:18:53 - Predict] Processing 1 short region(s).\n",
      "[15:18:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1c801c1b10>\n",
      "[15:18:53 - MdlStrTF] loading weights from /tmp/tmp18ol76jm/model/variables/variables\n",
      "[15:18:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-288.\n",
      "[15:18:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:53 - Feature] Processed ParPgb:0.0-287.0 (median depth 103.0)\n",
      "[15:18:53 - Sampler] Took 0.04s to make features.\n",
      "[15:18:54 - PWorker] Processed 1 batches\n",
      "[15:18:54 - PWorker] All done, 0 remainder regions.\n",
      "[15:18:54 - Predict] Finished processing all regions.\n",
      "[15:18:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:18:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:18:57 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:18:57 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:18:57 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:18:57 - Predict] Found a GPU.\n",
      "[15:18:57 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:18:57 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:18:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:18:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5a86175ae0>\n",
      "[15:18:59 - MdlStrTF] loading weights from /tmp/tmposm1c922/model/variables/variables\n",
      "[15:18:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:18:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:18:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:18:59 - Sampler] Took 0.01s to make features.\n",
      "[15:18:59 - PWorker] Processed 0 batches\n",
      "[15:18:59 - PWorker] All done, 0 remainder regions.\n",
      "[15:18:59 - Predict] Finished processing all regions.\n",
      "[15:19:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:00 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:19:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:19:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:19:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:19:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:19:02 - Predict] Found a GPU.\n",
      "[15:19:02 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:19:02 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:19:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f20b16c5ae0>\n",
      "[15:19:03 - MdlStrTF] loading weights from /tmp/tmpktrvb05z/model/variables/variables\n",
      "[15:19:03 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:19:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:19:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:03 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-140.\n",
      "[15:19:03 - Feature] Processed ParPgb:0.0-140.0 (median depth 1.0)\n",
      "[15:19:03 - Sampler] Took 0.08s to make features.\n",
      "[15:19:03 - Sampler] Region ParPgb:0.0-140.0 (141 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:19:03 - PWorker] Processed 0 batches\n",
      "[15:19:03 - PWorker] All done, 1 remainder regions.\n",
      "[15:19:03 - Predict] Processing 1 short region(s).\n",
      "[15:19:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f20208c1b10>\n",
      "[15:19:04 - MdlStrTF] loading weights from /tmp/tmpktrvb05z/model/variables/variables\n",
      "[15:19:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-141.\n",
      "[15:19:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:04 - Feature] Processed ParPgb:0.0-140.0 (median depth 1.0)\n",
      "[15:19:04 - Sampler] Took 0.09s to make features.\n",
      "[15:19:05 - PWorker] Processed 1 batches\n",
      "[15:19:05 - PWorker] All done, 0 remainder regions.\n",
      "[15:19:05 - Predict] Finished processing all regions.\n",
      "[15:19:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:19:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:19:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:19:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:19:08 - Predict] Found a GPU.\n",
      "[15:19:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:19:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:19:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc72fc51ae0>\n",
      "[15:19:09 - MdlStrTF] loading weights from /tmp/tmpraddluv6/model/variables/variables\n",
      "[15:19:09 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:19:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:19:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:09 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-231.\n",
      "[15:19:09 - Feature] Processed ParPgb:0.0-231.0 (median depth 134.0)\n",
      "[15:19:09 - Sampler] Took 0.14s to make features.\n",
      "[15:19:09 - Sampler] Region ParPgb:0.0-231.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:19:09 - PWorker] Processed 0 batches\n",
      "[15:19:10 - PWorker] All done, 1 remainder regions.\n",
      "[15:19:10 - Predict] Processing 1 short region(s).\n",
      "[15:19:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc690d75ff0>\n",
      "[15:19:10 - MdlStrTF] loading weights from /tmp/tmpraddluv6/model/variables/variables\n",
      "[15:19:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-232.\n",
      "[15:19:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:10 - Feature] Processed ParPgb:0.0-231.0 (median depth 134.0)\n",
      "[15:19:10 - Sampler] Took 0.15s to make features.\n",
      "[15:19:11 - PWorker] Processed 1 batches\n",
      "[15:19:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:19:11 - Predict] Finished processing all regions.\n",
      "[15:19:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:19:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:19:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:19:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:19:14 - Predict] Found a GPU.\n",
      "[15:19:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:19:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:19:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd30647dae0>\n",
      "[15:19:15 - MdlStrTF] loading weights from /tmp/tmpsg9x90jj/model/variables/variables\n",
      "[15:19:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:19:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:19:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-199.\n",
      "[15:19:15 - Feature] Processed ParPgb:0.0-199.0 (median depth 70.0)\n",
      "[15:19:15 - Sampler] Took 0.06s to make features.\n",
      "[15:19:15 - Sampler] Region ParPgb:0.0-199.0 (236 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:19:15 - PWorker] Processed 0 batches\n",
      "[15:19:15 - PWorker] All done, 1 remainder regions.\n",
      "[15:19:15 - Predict] Processing 1 short region(s).\n",
      "[15:19:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd269671480>\n",
      "[15:19:16 - MdlStrTF] loading weights from /tmp/tmpsg9x90jj/model/variables/variables\n",
      "[15:19:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-200.\n",
      "[15:19:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:16 - Feature] Processed ParPgb:0.0-199.0 (median depth 70.0)\n",
      "[15:19:16 - Sampler] Took 0.04s to make features.\n",
      "[15:19:17 - PWorker] Processed 1 batches\n",
      "[15:19:17 - PWorker] All done, 0 remainder regions.\n",
      "[15:19:17 - Predict] Finished processing all regions.\n",
      "[15:19:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:19:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:19:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:19:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:19:20 - Predict] Found a GPU.\n",
      "[15:19:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:19:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:19:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8a2e5adae0>\n",
      "[15:19:21 - MdlStrTF] loading weights from /tmp/tmpshsmtdd1/model/variables/variables\n",
      "[15:19:21 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:19:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:19:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:21 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[15:19:21 - Feature] Processed ParPgb:0.0-247.0 (median depth 24.0)\n",
      "[15:19:21 - Sampler] Took 0.12s to make features.\n",
      "[15:19:21 - Sampler] Region ParPgb:0.0-247.0 (261 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:19:21 - PWorker] Processed 0 batches\n",
      "[15:19:21 - PWorker] All done, 1 remainder regions.\n",
      "[15:19:21 - Predict] Processing 1 short region(s).\n",
      "[15:19:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f899d7aa170>\n",
      "[15:19:22 - MdlStrTF] loading weights from /tmp/tmpshsmtdd1/model/variables/variables\n",
      "[15:19:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[15:19:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:24 - Feature] Processed ParPgb:0.0-247.0 (median depth 24.0)\n",
      "[15:19:24 - Sampler] Took 2.48s to make features.\n",
      "[15:19:25 - PWorker] Processed 1 batches\n",
      "[15:19:25 - PWorker] All done, 0 remainder regions.\n",
      "[15:19:25 - Predict] Finished processing all regions.\n",
      "[15:19:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:28 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:19:28 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:19:28 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:19:28 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:19:28 - Predict] Found a GPU.\n",
      "[15:19:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:19:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:19:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1ca177dae0>\n",
      "[15:19:30 - MdlStrTF] loading weights from /tmp/tmp5yf04lhn/model/variables/variables\n",
      "[15:19:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:19:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:19:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-209.\n",
      "[15:19:37 - Feature] Processed ParPgb:0.0-209.0 (median depth 53.0)\n",
      "[15:19:37 - Sampler] Took 6.92s to make features.\n",
      "[15:19:37 - Sampler] Region ParPgb:0.0-209.0 (233 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:19:37 - PWorker] Processed 0 batches\n",
      "[15:19:37 - PWorker] All done, 1 remainder regions.\n",
      "[15:19:37 - Predict] Processing 1 short region(s).\n",
      "[15:19:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1c108c5ff0>\n",
      "[15:19:37 - MdlStrTF] loading weights from /tmp/tmp5yf04lhn/model/variables/variables\n",
      "[15:19:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-210.\n",
      "[15:19:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:39 - Feature] Processed ParPgb:0.0-209.0 (median depth 53.0)\n",
      "[15:19:39 - Sampler] Took 2.06s to make features.\n",
      "[15:19:40 - PWorker] Processed 1 batches\n",
      "[15:19:40 - PWorker] All done, 0 remainder regions.\n",
      "[15:19:40 - Predict] Finished processing all regions.\n",
      "[15:19:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:19:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:19:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:19:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:19:43 - Predict] Found a GPU.\n",
      "[15:19:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:19:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:19:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbb38f9dae0>\n",
      "[15:19:44 - MdlStrTF] loading weights from /tmp/tmprvqb37k3/model/variables/variables\n",
      "[15:19:45 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:19:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:19:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:46 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:19:46 - Feature] Processed ParPgb:0.0-243.0 (median depth 60.0)\n",
      "[15:19:46 - Sampler] Took 1.81s to make features.\n",
      "[15:19:46 - Sampler] Region ParPgb:0.0-243.0 (287 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:19:46 - PWorker] Processed 0 batches\n",
      "[15:19:46 - PWorker] All done, 1 remainder regions.\n",
      "[15:19:46 - Predict] Processing 1 short region(s).\n",
      "[15:19:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbaa81c5480>\n",
      "[15:19:47 - MdlStrTF] loading weights from /tmp/tmprvqb37k3/model/variables/variables\n",
      "[15:19:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:19:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:47 - Feature] Processed ParPgb:0.0-243.0 (median depth 60.0)\n",
      "[15:19:47 - Sampler] Took 0.06s to make features.\n",
      "[15:19:47 - PWorker] Processed 1 batches\n",
      "[15:19:47 - PWorker] All done, 0 remainder regions.\n",
      "[15:19:47 - Predict] Finished processing all regions.\n",
      "[15:19:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:51 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:19:51 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:19:51 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:19:51 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:19:51 - Predict] Found a GPU.\n",
      "[15:19:51 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:19:51 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:19:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fccef84dae0>\n",
      "[15:19:52 - MdlStrTF] loading weights from /tmp/tmp053jod9s/model/variables/variables\n",
      "[15:19:52 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:19:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:19:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:19:53 - Feature] Processed ParPgb:0.0-245.0 (median depth 122.0)\n",
      "[15:19:53 - Sampler] Took 0.50s to make features.\n",
      "[15:19:53 - Sampler] Region ParPgb:0.0-245.0 (313 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:19:53 - PWorker] Processed 0 batches\n",
      "[15:19:53 - PWorker] All done, 1 remainder regions.\n",
      "[15:19:53 - Predict] Processing 1 short region(s).\n",
      "[15:19:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcc60219480>\n",
      "[15:19:53 - MdlStrTF] loading weights from /tmp/tmp053jod9s/model/variables/variables\n",
      "[15:19:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:19:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:53 - Feature] Processed ParPgb:0.0-245.0 (median depth 122.0)\n",
      "[15:19:53 - Sampler] Took 0.04s to make features.\n",
      "[15:19:54 - PWorker] Processed 1 batches\n",
      "[15:19:54 - PWorker] All done, 0 remainder regions.\n",
      "[15:19:54 - Predict] Finished processing all regions.\n",
      "[15:19:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:19:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:19:57 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:19:57 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:19:57 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:19:57 - Predict] Found a GPU.\n",
      "[15:19:57 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:19:57 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:19:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4d49a09ae0>\n",
      "[15:19:59 - MdlStrTF] loading weights from /tmp/tmpmo6h_b90/model/variables/variables\n",
      "[15:19:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:19:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:19:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:19:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:19:59 - Feature] Processed ParPgb:0.0-249.0 (median depth 125.0)\n",
      "[15:19:59 - Sampler] Took 0.03s to make features.\n",
      "[15:19:59 - Sampler] Region ParPgb:0.0-249.0 (343 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:19:59 - PWorker] Processed 0 batches\n",
      "[15:19:59 - PWorker] All done, 1 remainder regions.\n",
      "[15:19:59 - Predict] Processing 1 short region(s).\n",
      "[15:19:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:19:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4cb8b8d480>\n",
      "[15:19:59 - MdlStrTF] loading weights from /tmp/tmpmo6h_b90/model/variables/variables\n",
      "[15:19:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:19:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:01 - Feature] Processed ParPgb:0.0-249.0 (median depth 125.0)\n",
      "[15:20:01 - Sampler] Took 1.69s to make features.\n",
      "[15:20:01 - PWorker] Processed 1 batches\n",
      "[15:20:01 - PWorker] All done, 0 remainder regions.\n",
      "[15:20:01 - Predict] Finished processing all regions.\n",
      "[15:20:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:20:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:20:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:20:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:20:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:20:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:20:05 - Predict] Found a GPU.\n",
      "[15:20:05 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:20:05 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:20:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:20:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f33eed41ae0>\n",
      "[15:20:06 - MdlStrTF] loading weights from /tmp/tmp2zkhj5w_/model/variables/variables\n",
      "[15:20:06 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:20:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:20:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:06 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-239.\n",
      "[15:20:06 - Feature] Processed ParPgb:0.0-239.0 (median depth 126.0)\n",
      "[15:20:06 - Sampler] Took 0.04s to make features.\n",
      "[15:20:06 - Sampler] Region ParPgb:0.0-239.0 (304 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:20:06 - PWorker] Processed 0 batches\n",
      "[15:20:06 - PWorker] All done, 1 remainder regions.\n",
      "[15:20:06 - Predict] Processing 1 short region(s).\n",
      "[15:20:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:20:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f33d02b1480>\n",
      "[15:20:07 - MdlStrTF] loading weights from /tmp/tmp2zkhj5w_/model/variables/variables\n",
      "[15:20:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-240.\n",
      "[15:20:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:11 - Feature] Processed ParPgb:0.0-239.0 (median depth 126.0)\n",
      "[15:20:11 - Sampler] Took 3.99s to make features.\n",
      "[15:20:11 - PWorker] Processed 1 batches\n",
      "[15:20:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:20:11 - Predict] Finished processing all regions.\n",
      "[15:20:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:20:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:20:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:20:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:20:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:20:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:20:15 - Predict] Found a GPU.\n",
      "[15:20:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:20:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:20:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:20:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3e99845ae0>\n",
      "[15:20:16 - MdlStrTF] loading weights from /tmp/tmpp31rl62n/model/variables/variables\n",
      "[15:20:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:20:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:20:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-259.\n",
      "[15:20:16 - Feature] Processed ParPgb:0.0-259.0 (median depth 119.0)\n",
      "[15:20:16 - Sampler] Took 0.04s to make features.\n",
      "[15:20:16 - Sampler] Region ParPgb:0.0-259.0 (329 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:20:16 - PWorker] Processed 0 batches\n",
      "[15:20:16 - PWorker] All done, 1 remainder regions.\n",
      "[15:20:16 - Predict] Processing 1 short region(s).\n",
      "[15:20:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:20:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3e08229480>\n",
      "[15:20:16 - MdlStrTF] loading weights from /tmp/tmpp31rl62n/model/variables/variables\n",
      "[15:20:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-260.\n",
      "[15:20:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:19 - Feature] Processed ParPgb:0.0-259.0 (median depth 119.0)\n",
      "[15:20:19 - Sampler] Took 2.20s to make features.\n",
      "[15:20:19 - PWorker] Processed 1 batches\n",
      "[15:20:19 - PWorker] All done, 0 remainder regions.\n",
      "[15:20:19 - Predict] Finished processing all regions.\n",
      "[15:20:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:20:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:20:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:20:23 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:20:23 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:20:23 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:20:23 - Predict] Found a GPU.\n",
      "[15:20:23 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:20:23 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:20:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:20:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1e3d0a1ae0>\n",
      "[15:20:24 - MdlStrTF] loading weights from /tmp/tmp4d_a7iot/model/variables/variables\n",
      "[15:20:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:20:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:20:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[15:20:24 - Feature] Processed ParPgb:0.0-238.0 (median depth 108.0)\n",
      "[15:20:24 - Sampler] Took 0.16s to make features.\n",
      "[15:20:24 - Sampler] Region ParPgb:0.0-238.0 (303 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:20:24 - PWorker] Processed 0 batches\n",
      "[15:20:24 - PWorker] All done, 1 remainder regions.\n",
      "[15:20:24 - Predict] Processing 1 short region(s).\n",
      "[15:20:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:20:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1dac199fc0>\n",
      "[15:20:24 - MdlStrTF] loading weights from /tmp/tmp4d_a7iot/model/variables/variables\n",
      "[15:20:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[15:20:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:27 - Feature] Processed ParPgb:0.0-238.0 (median depth 108.0)\n",
      "[15:20:27 - Sampler] Took 2.57s to make features.\n",
      "[15:20:28 - PWorker] Processed 1 batches\n",
      "[15:20:28 - PWorker] All done, 0 remainder regions.\n",
      "[15:20:28 - Predict] Finished processing all regions.\n",
      "[15:20:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:20:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:20:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:20:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:20:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:20:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:20:31 - Predict] Found a GPU.\n",
      "[15:20:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:20:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:20:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:20:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd7bdf4dae0>\n",
      "[15:20:32 - MdlStrTF] loading weights from /tmp/tmpubrbuigg/model/variables/variables\n",
      "[15:20:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:20:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:20:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:33 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-220.\n",
      "[15:20:33 - Feature] Processed ParPgb:0.0-220.0 (median depth 155.0)\n",
      "[15:20:35 - Sampler] Took 2.66s to make features.\n",
      "[15:20:35 - Sampler] Region ParPgb:0.0-220.0 (331 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:20:35 - PWorker] Processed 0 batches\n",
      "[15:20:35 - PWorker] All done, 1 remainder regions.\n",
      "[15:20:35 - Predict] Processing 1 short region(s).\n",
      "[15:20:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:20:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd72d0a9b10>\n",
      "[15:20:36 - MdlStrTF] loading weights from /tmp/tmpubrbuigg/model/variables/variables\n",
      "[15:20:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-221.\n",
      "[15:20:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:38 - Feature] Processed ParPgb:0.0-220.0 (median depth 155.0)\n",
      "[15:20:38 - Sampler] Took 2.55s to make features.\n",
      "[15:20:39 - PWorker] Processed 1 batches\n",
      "[15:20:39 - PWorker] All done, 0 remainder regions.\n",
      "[15:20:39 - Predict] Finished processing all regions.\n",
      "[15:20:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:20:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:20:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:20:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:20:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:20:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:20:42 - Predict] Found a GPU.\n",
      "[15:20:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:20:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:20:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:20:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe870f79ae0>\n",
      "[15:20:43 - MdlStrTF] loading weights from /tmp/tmp55fd5tjq/model/variables/variables\n",
      "[15:20:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:20:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:20:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:46 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-220.\n",
      "[15:20:48 - Feature] Processed ParPgb:0.0-220.0 (median depth 54.0)\n",
      "[15:20:48 - Sampler] Took 4.61s to make features.\n",
      "[15:20:48 - Sampler] Region ParPgb:0.0-220.0 (259 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:20:48 - PWorker] Processed 0 batches\n",
      "[15:20:48 - PWorker] All done, 1 remainder regions.\n",
      "[15:20:48 - Predict] Processing 1 short region(s).\n",
      "[15:20:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:20:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe7e00f1480>\n",
      "[15:20:48 - MdlStrTF] loading weights from /tmp/tmp55fd5tjq/model/variables/variables\n",
      "[15:20:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-221.\n",
      "[15:20:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:49 - Feature] Processed ParPgb:0.0-220.0 (median depth 54.0)\n",
      "[15:20:51 - Sampler] Took 2.81s to make features.\n",
      "[15:20:52 - PWorker] Processed 1 batches\n",
      "[15:20:52 - PWorker] All done, 0 remainder regions.\n",
      "[15:20:52 - Predict] Finished processing all regions.\n",
      "[15:20:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:20:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:20:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:20:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:20:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:20:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:20:55 - Predict] Found a GPU.\n",
      "[15:20:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:20:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:20:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:20:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f046d321ae0>\n",
      "[15:20:57 - MdlStrTF] loading weights from /tmp/tmpgieolcx0/model/variables/variables\n",
      "[15:20:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:20:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:20:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:57 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-209.\n",
      "[15:20:57 - Feature] Processed ParPgb:0.0-209.0 (median depth 71.0)\n",
      "[15:20:57 - Sampler] Took 0.78s to make features.\n",
      "[15:20:57 - Sampler] Region ParPgb:0.0-209.0 (268 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:20:58 - PWorker] Processed 0 batches\n",
      "[15:20:58 - PWorker] All done, 1 remainder regions.\n",
      "[15:20:58 - Predict] Processing 1 short region(s).\n",
      "[15:20:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:20:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f03dc539ff0>\n",
      "[15:20:58 - MdlStrTF] loading weights from /tmp/tmpgieolcx0/model/variables/variables\n",
      "[15:20:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-210.\n",
      "[15:20:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:20:58 - Feature] Processed ParPgb:0.0-209.0 (median depth 71.0)\n",
      "[15:20:58 - Sampler] Took 0.17s to make features.\n",
      "[15:20:59 - PWorker] Processed 1 batches\n",
      "[15:20:59 - PWorker] All done, 0 remainder regions.\n",
      "[15:20:59 - Predict] Finished processing all regions.\n",
      "[15:21:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:21:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:21:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:21:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:21:02 - Predict] Found a GPU.\n",
      "[15:21:02 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:21:02 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:21:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f305b549ae0>\n",
      "[15:21:03 - MdlStrTF] loading weights from /tmp/tmp09k0rwzj/model/variables/variables\n",
      "[15:21:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:21:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:21:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-265.\n",
      "[15:21:04 - Feature] Processed ParPgb:0.0-265.0 (median depth 101.0)\n",
      "[15:21:04 - Sampler] Took 0.04s to make features.\n",
      "[15:21:04 - Sampler] Region ParPgb:0.0-265.0 (327 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:21:04 - PWorker] Processed 0 batches\n",
      "[15:21:04 - PWorker] All done, 1 remainder regions.\n",
      "[15:21:04 - Predict] Processing 1 short region(s).\n",
      "[15:21:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2fca3c21a0>\n",
      "[15:21:04 - MdlStrTF] loading weights from /tmp/tmp09k0rwzj/model/variables/variables\n",
      "[15:21:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-266.\n",
      "[15:21:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:04 - Feature] Processed ParPgb:0.0-265.0 (median depth 101.0)\n",
      "[15:21:04 - Sampler] Took 0.09s to make features.\n",
      "[15:21:05 - PWorker] Processed 1 batches\n",
      "[15:21:05 - PWorker] All done, 0 remainder regions.\n",
      "[15:21:05 - Predict] Finished processing all regions.\n",
      "[15:21:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:21:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:21:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:21:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:21:08 - Predict] Found a GPU.\n",
      "[15:21:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:21:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:21:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fca4a4a5ae0>\n",
      "[15:21:09 - MdlStrTF] loading weights from /tmp/tmpisdrw0ad/model/variables/variables\n",
      "[15:21:09 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:21:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:21:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:09 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-293.\n",
      "[15:21:09 - Feature] Processed ParPgb:0.0-293.0 (median depth 166.0)\n",
      "[15:21:09 - Sampler] Took 0.03s to make features.\n",
      "[15:21:09 - Sampler] Region ParPgb:0.0-293.0 (400 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:21:09 - PWorker] Processed 0 batches\n",
      "[15:21:09 - PWorker] All done, 1 remainder regions.\n",
      "[15:21:09 - Predict] Processing 1 short region(s).\n",
      "[15:21:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc9b96c9480>\n",
      "[15:21:10 - MdlStrTF] loading weights from /tmp/tmpisdrw0ad/model/variables/variables\n",
      "[15:21:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-294.\n",
      "[15:21:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:10 - Feature] Processed ParPgb:0.0-293.0 (median depth 166.0)\n",
      "[15:21:10 - Sampler] Took 0.04s to make features.\n",
      "[15:21:10 - PWorker] Processed 1 batches\n",
      "[15:21:10 - PWorker] All done, 0 remainder regions.\n",
      "[15:21:10 - Predict] Finished processing all regions.\n",
      "[15:21:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:21:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:21:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:21:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:21:14 - Predict] Found a GPU.\n",
      "[15:21:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:21:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:21:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f527e679ae0>\n",
      "[15:21:15 - MdlStrTF] loading weights from /tmp/tmp8ftttwjd/model/variables/variables\n",
      "[15:21:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:21:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:21:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-201.\n",
      "[15:21:15 - Feature] Processed ParPgb:0.0-201.0 (median depth 98.0)\n",
      "[15:21:15 - Sampler] Took 0.07s to make features.\n",
      "[15:21:15 - Sampler] Region ParPgb:0.0-201.0 (267 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:21:15 - PWorker] Processed 0 batches\n",
      "[15:21:15 - PWorker] All done, 1 remainder regions.\n",
      "[15:21:15 - Predict] Processing 1 short region(s).\n",
      "[15:21:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f51ed4bdae0>\n",
      "[15:21:16 - MdlStrTF] loading weights from /tmp/tmp8ftttwjd/model/variables/variables\n",
      "[15:21:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-202.\n",
      "[15:21:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:18 - Feature] Processed ParPgb:0.0-201.0 (median depth 98.0)\n",
      "[15:21:18 - Sampler] Took 2.13s to make features.\n",
      "[15:21:18 - PWorker] Processed 1 batches\n",
      "[15:21:18 - PWorker] All done, 0 remainder regions.\n",
      "[15:21:18 - Predict] Finished processing all regions.\n",
      "[15:21:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:21:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:21:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:21:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:21:22 - Predict] Found a GPU.\n",
      "[15:21:22 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:21:22 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:21:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3601995ae0>\n",
      "[15:21:23 - MdlStrTF] loading weights from /tmp/tmpu6ktq8wk/model/variables/variables\n",
      "[15:21:23 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:21:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:21:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:23 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[15:21:23 - Feature] Processed ParPgb:0.0-255.0 (median depth 163.0)\n",
      "[15:21:23 - Sampler] Took 0.06s to make features.\n",
      "[15:21:23 - Sampler] Region ParPgb:0.0-255.0 (347 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:21:23 - PWorker] Processed 0 batches\n",
      "[15:21:23 - PWorker] All done, 1 remainder regions.\n",
      "[15:21:23 - Predict] Processing 1 short region(s).\n",
      "[15:21:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f35703661a0>\n",
      "[15:21:24 - MdlStrTF] loading weights from /tmp/tmpu6ktq8wk/model/variables/variables\n",
      "[15:21:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[15:21:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:24 - Feature] Processed ParPgb:0.0-255.0 (median depth 163.0)\n",
      "[15:21:24 - Sampler] Took 0.08s to make features.\n",
      "[15:21:24 - PWorker] Processed 1 batches\n",
      "[15:21:24 - PWorker] All done, 0 remainder regions.\n",
      "[15:21:24 - Predict] Finished processing all regions.\n",
      "[15:21:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:28 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:21:28 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:21:28 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:21:28 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:21:28 - Predict] Found a GPU.\n",
      "[15:21:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:21:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:21:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdd89ee1a80>\n",
      "[15:21:29 - MdlStrTF] loading weights from /tmp/tmpoj9i3y1a/model/variables/variables\n",
      "[15:21:29 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:21:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:21:29 - Sampler] Took 0.01s to make features.\n",
      "[15:21:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:29 - PWorker] Processed 0 batches\n",
      "[15:21:29 - PWorker] All done, 0 remainder regions.\n",
      "[15:21:29 - Predict] Finished processing all regions.\n",
      "[15:21:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:31 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:21:32 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:21:32 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:21:32 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:21:32 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:21:32 - Predict] Found a GPU.\n",
      "[15:21:32 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:21:32 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:21:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f83b5b81ae0>\n",
      "[15:21:34 - MdlStrTF] loading weights from /tmp/tmpum902lsv/model/variables/variables\n",
      "[15:21:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:21:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:21:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-200.\n",
      "[15:21:34 - Feature] Processed ParPgb:0.0-200.0 (median depth 10.0)\n",
      "[15:21:34 - Sampler] Took 0.09s to make features.\n",
      "[15:21:34 - Sampler] Region ParPgb:0.0-200.0 (204 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:21:34 - PWorker] Processed 0 batches\n",
      "[15:21:34 - PWorker] All done, 1 remainder regions.\n",
      "[15:21:34 - Predict] Processing 1 short region(s).\n",
      "[15:21:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8320959e70>\n",
      "[15:21:34 - MdlStrTF] loading weights from /tmp/tmpum902lsv/model/variables/variables\n",
      "[15:21:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-201.\n",
      "[15:21:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:34 - Feature] Processed ParPgb:0.0-200.0 (median depth 10.0)\n",
      "[15:21:34 - Sampler] Took 0.07s to make features.\n",
      "[15:21:35 - PWorker] Processed 1 batches\n",
      "[15:21:35 - PWorker] All done, 0 remainder regions.\n",
      "[15:21:35 - Predict] Finished processing all regions.\n",
      "[15:21:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:21:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:21:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:21:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:21:38 - Predict] Found a GPU.\n",
      "[15:21:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:21:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:21:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7f09775a80>\n",
      "[15:21:40 - MdlStrTF] loading weights from /tmp/tmpse4wgkxc/model/variables/variables\n",
      "[15:21:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:21:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:21:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:40 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[15:21:42 - Feature] Processed ParPgb:0.0-238.0 (median depth 150.0)\n",
      "[15:21:42 - Sampler] Took 1.98s to make features.\n",
      "[15:21:42 - Sampler] Region ParPgb:0.0-238.0 (305 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:21:42 - PWorker] Processed 0 batches\n",
      "[15:21:42 - PWorker] All done, 1 remainder regions.\n",
      "[15:21:42 - Predict] Processing 1 short region(s).\n",
      "[15:21:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7e788c93f0>\n",
      "[15:21:42 - MdlStrTF] loading weights from /tmp/tmpse4wgkxc/model/variables/variables\n",
      "[15:21:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[15:21:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:42 - Feature] Processed ParPgb:0.0-238.0 (median depth 150.0)\n",
      "[15:21:42 - Sampler] Took 0.04s to make features.\n",
      "[15:21:43 - PWorker] Processed 1 batches\n",
      "[15:21:43 - PWorker] All done, 0 remainder regions.\n",
      "[15:21:43 - Predict] Finished processing all regions.\n",
      "[15:21:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:46 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:21:46 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:21:46 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:21:46 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:21:46 - Predict] Found a GPU.\n",
      "[15:21:46 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:21:46 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:21:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc09292dae0>\n",
      "[15:21:48 - MdlStrTF] loading weights from /tmp/tmpk94bqy57/model/variables/variables\n",
      "[15:21:48 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:21:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:21:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:48 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-193.\n",
      "[15:21:48 - Feature] Processed ParPgb:0.0-193.0 (median depth 1.0)\n",
      "[15:21:48 - Sampler] Took 0.49s to make features.\n",
      "[15:21:48 - Sampler] Region ParPgb:0.0-193.0 (194 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:21:48 - PWorker] Processed 0 batches\n",
      "[15:21:48 - PWorker] All done, 1 remainder regions.\n",
      "[15:21:48 - Predict] Processing 1 short region(s).\n",
      "[15:21:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc00026b010>\n",
      "[15:21:49 - MdlStrTF] loading weights from /tmp/tmpk94bqy57/model/variables/variables\n",
      "[15:21:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-194.\n",
      "[15:21:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:49 - Feature] Processed ParPgb:0.0-193.0 (median depth 1.0)\n",
      "[15:21:49 - Sampler] Took 0.03s to make features.\n",
      "[15:21:49 - PWorker] Processed 1 batches\n",
      "[15:21:49 - PWorker] All done, 0 remainder regions.\n",
      "[15:21:49 - Predict] Finished processing all regions.\n",
      "[15:21:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:21:52 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:21:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:21:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:21:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:21:53 - Predict] Found a GPU.\n",
      "[15:21:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:21:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:21:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb7f11a9ae0>\n",
      "[15:21:54 - MdlStrTF] loading weights from /tmp/tmphk5j5zlp/model/variables/variables\n",
      "[15:21:54 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:21:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:21:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:21:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-241.\n",
      "[15:21:56 - Feature] Processed ParPgb:0.0-241.0 (median depth 71.0)\n",
      "[15:21:56 - Sampler] Took 1.68s to make features.\n",
      "[15:21:56 - Sampler] Region ParPgb:0.0-241.0 (277 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:21:56 - PWorker] Processed 0 batches\n",
      "[15:21:56 - PWorker] All done, 1 remainder regions.\n",
      "[15:21:56 - Predict] Processing 1 short region(s).\n",
      "[15:21:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:21:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb76035dff0>\n",
      "[15:21:56 - MdlStrTF] loading weights from /tmp/tmphk5j5zlp/model/variables/variables\n",
      "[15:21:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-242.\n",
      "[15:21:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:01 - Feature] Processed ParPgb:0.0-241.0 (median depth 71.0)\n",
      "[15:22:01 - Sampler] Took 4.53s to make features.\n",
      "[15:22:01 - PWorker] Batches in cache: 1.\n",
      "[15:22:01 - PWorker] Processed 1 batches\n",
      "[15:22:01 - PWorker] All done, 0 remainder regions.\n",
      "[15:22:01 - Predict] Finished processing all regions.\n",
      "[15:22:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:22:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:22:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:22:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:22:05 - Predict] Found a GPU.\n",
      "[15:22:05 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:22:05 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:22:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1e86031ae0>\n",
      "[15:22:06 - MdlStrTF] loading weights from /tmp/tmpj839q0wa/model/variables/variables\n",
      "[15:22:06 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:22:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:22:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:06 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-201.\n",
      "[15:22:06 - Feature] Processed ParPgb:0.0-201.0 (median depth 19.0)\n",
      "[15:22:06 - Sampler] Took 0.06s to make features.\n",
      "[15:22:06 - Sampler] Region ParPgb:0.0-201.0 (216 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:22:06 - PWorker] Processed 0 batches\n",
      "[15:22:06 - PWorker] All done, 1 remainder regions.\n",
      "[15:22:06 - Predict] Processing 1 short region(s).\n",
      "[15:22:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1de811d270>\n",
      "[15:22:06 - MdlStrTF] loading weights from /tmp/tmpj839q0wa/model/variables/variables\n",
      "[15:22:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-202.\n",
      "[15:22:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:06 - Feature] Processed ParPgb:0.0-201.0 (median depth 19.0)\n",
      "[15:22:06 - Sampler] Took 0.08s to make features.\n",
      "[15:22:07 - PWorker] Processed 1 batches\n",
      "[15:22:07 - PWorker] All done, 0 remainder regions.\n",
      "[15:22:07 - Predict] Finished processing all regions.\n",
      "[15:22:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:10 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:22:10 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:22:10 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:22:10 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:22:10 - Predict] Found a GPU.\n",
      "[15:22:10 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:22:10 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:22:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:12 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb0a94ddae0>\n",
      "[15:22:12 - MdlStrTF] loading weights from /tmp/tmprr4ysv39/model/variables/variables\n",
      "[15:22:12 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:22:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:22:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:12 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:22:12 - Feature] Processed ParPgb:0.0-252.0 (median depth 112.0)\n",
      "[15:22:13 - Sampler] Took 0.67s to make features.\n",
      "[15:22:13 - Sampler] Region ParPgb:0.0-252.0 (324 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:22:13 - PWorker] Processed 0 batches\n",
      "[15:22:13 - PWorker] All done, 1 remainder regions.\n",
      "[15:22:13 - Predict] Processing 1 short region(s).\n",
      "[15:22:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb008ad1480>\n",
      "[15:22:13 - MdlStrTF] loading weights from /tmp/tmprr4ysv39/model/variables/variables\n",
      "[15:22:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:22:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:15 - Feature] Processed ParPgb:0.0-252.0 (median depth 112.0)\n",
      "[15:22:15 - Sampler] Took 2.03s to make features.\n",
      "[15:22:16 - PWorker] Processed 1 batches\n",
      "[15:22:16 - PWorker] All done, 0 remainder regions.\n",
      "[15:22:16 - Predict] Finished processing all regions.\n",
      "[15:22:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:22:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:22:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:22:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:22:19 - Predict] Found a GPU.\n",
      "[15:22:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:22:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:22:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7feac5dd5ae0>\n",
      "[15:22:20 - MdlStrTF] loading weights from /tmp/tmpmfh15dnt/model/variables/variables\n",
      "[15:22:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:22:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:22:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:22 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[15:22:22 - Feature] Processed ParPgb:0.0-253.0 (median depth 103.0)\n",
      "[15:22:22 - Sampler] Took 1.85s to make features.\n",
      "[15:22:22 - Sampler] Region ParPgb:0.0-253.0 (311 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:22:22 - PWorker] Processed 0 batches\n",
      "[15:22:22 - PWorker] All done, 1 remainder regions.\n",
      "[15:22:22 - Predict] Processing 1 short region(s).\n",
      "[15:22:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fea28f0d480>\n",
      "[15:22:23 - MdlStrTF] loading weights from /tmp/tmpmfh15dnt/model/variables/variables\n",
      "[15:22:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[15:22:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:25 - Feature] Processed ParPgb:0.0-253.0 (median depth 103.0)\n",
      "[15:22:25 - Sampler] Took 2.16s to make features.\n",
      "[15:22:25 - PWorker] Processed 1 batches\n",
      "[15:22:25 - PWorker] All done, 0 remainder regions.\n",
      "[15:22:25 - Predict] Finished processing all regions.\n",
      "[15:22:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:22:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:22:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:22:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:22:29 - Predict] Found a GPU.\n",
      "[15:22:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:22:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:22:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcf74421ae0>\n",
      "[15:22:30 - MdlStrTF] loading weights from /tmp/tmpoo7bbpa6/model/variables/variables\n",
      "[15:22:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:22:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:22:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:30 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[15:22:30 - Feature] Processed ParPgb:0.0-248.0 (median depth 125.0)\n",
      "[15:22:30 - Sampler] Took 0.05s to make features.\n",
      "[15:22:30 - Sampler] Region ParPgb:0.0-248.0 (318 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:22:30 - PWorker] Processed 0 batches\n",
      "[15:22:30 - PWorker] All done, 1 remainder regions.\n",
      "[15:22:30 - Predict] Processing 1 short region(s).\n",
      "[15:22:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fceb633d450>\n",
      "[15:22:31 - MdlStrTF] loading weights from /tmp/tmpoo7bbpa6/model/variables/variables\n",
      "[15:22:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[15:22:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:34 - Feature] Processed ParPgb:0.0-248.0 (median depth 125.0)\n",
      "[15:22:34 - Sampler] Took 3.12s to make features.\n",
      "[15:22:34 - PWorker] Processed 1 batches\n",
      "[15:22:34 - PWorker] All done, 0 remainder regions.\n",
      "[15:22:34 - Predict] Finished processing all regions.\n",
      "[15:22:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:22:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:22:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:22:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:22:38 - Predict] Found a GPU.\n",
      "[15:22:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:22:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:22:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f561ced1ae0>\n",
      "[15:22:39 - MdlStrTF] loading weights from /tmp/tmp1oolo752/model/variables/variables\n",
      "[15:22:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:22:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:22:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:22:39 - Feature] Processed ParPgb:0.0-244.0 (median depth 171.0)\n",
      "[15:22:39 - Sampler] Took 0.04s to make features.\n",
      "[15:22:39 - Sampler] Region ParPgb:0.0-244.0 (336 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:22:39 - PWorker] Processed 0 batches\n",
      "[15:22:39 - PWorker] All done, 1 remainder regions.\n",
      "[15:22:39 - Predict] Processing 1 short region(s).\n",
      "[15:22:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f558c09d480>\n",
      "[15:22:40 - MdlStrTF] loading weights from /tmp/tmp1oolo752/model/variables/variables\n",
      "[15:22:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:22:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:40 - Feature] Processed ParPgb:0.0-244.0 (median depth 171.0)\n",
      "[15:22:40 - Sampler] Took 0.05s to make features.\n",
      "[15:22:40 - PWorker] Processed 1 batches\n",
      "[15:22:40 - PWorker] All done, 0 remainder regions.\n",
      "[15:22:40 - Predict] Finished processing all regions.\n",
      "[15:22:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:22:44 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:22:44 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:22:44 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:22:44 - Predict] Found a GPU.\n",
      "[15:22:44 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:22:44 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:22:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb49da75ae0>\n",
      "[15:22:45 - MdlStrTF] loading weights from /tmp/tmpm5lcwrnc/model/variables/variables\n",
      "[15:22:45 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:22:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:22:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-236.\n",
      "[15:22:45 - Feature] Processed ParPgb:0.0-236.0 (median depth 102.0)\n",
      "[15:22:45 - Sampler] Took 0.04s to make features.\n",
      "[15:22:45 - Sampler] Region ParPgb:0.0-236.0 (272 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:22:45 - PWorker] Processed 0 batches\n",
      "[15:22:45 - PWorker] All done, 1 remainder regions.\n",
      "[15:22:45 - Predict] Processing 1 short region(s).\n",
      "[15:22:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb40c3a1480>\n",
      "[15:22:45 - MdlStrTF] loading weights from /tmp/tmpm5lcwrnc/model/variables/variables\n",
      "[15:22:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-237.\n",
      "[15:22:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:45 - Feature] Processed ParPgb:0.0-236.0 (median depth 102.0)\n",
      "[15:22:45 - Sampler] Took 0.03s to make features.\n",
      "[15:22:46 - PWorker] Processed 1 batches\n",
      "[15:22:46 - PWorker] All done, 0 remainder regions.\n",
      "[15:22:46 - Predict] Finished processing all regions.\n",
      "[15:22:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:49 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:22:49 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:22:49 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:22:49 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:22:49 - Predict] Found a GPU.\n",
      "[15:22:49 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:22:49 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:22:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fba62d31a80>\n",
      "[15:22:51 - MdlStrTF] loading weights from /tmp/tmp80qp96lg/model/variables/variables\n",
      "[15:22:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:22:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:22:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:22:51 - Feature] Processed ParPgb:0.0-243.0 (median depth 129.0)\n",
      "[15:22:51 - Sampler] Took 0.03s to make features.\n",
      "[15:22:53 - Sampler] Region ParPgb:0.0-243.0 (333 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:22:53 - PWorker] Processed 0 batches\n",
      "[15:22:53 - PWorker] All done, 1 remainder regions.\n",
      "[15:22:53 - Predict] Processing 1 short region(s).\n",
      "[15:22:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:22:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb9d1e25a80>\n",
      "[15:22:54 - MdlStrTF] loading weights from /tmp/tmp80qp96lg/model/variables/variables\n",
      "[15:22:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:22:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:22:56 - Feature] Processed ParPgb:0.0-243.0 (median depth 129.0)\n",
      "[15:22:56 - Sampler] Took 2.21s to make features.\n",
      "[15:22:56 - PWorker] Processed 1 batches\n",
      "[15:22:56 - PWorker] All done, 0 remainder regions.\n",
      "[15:22:56 - Predict] Finished processing all regions.\n",
      "[15:22:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:22:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:23:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:23:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:23:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:23:00 - Predict] Found a GPU.\n",
      "[15:23:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:23:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:23:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f41b9f5da80>\n",
      "[15:23:01 - MdlStrTF] loading weights from /tmp/tmphoe3me5p/model/variables/variables\n",
      "[15:23:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:23:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:23:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:23:01 - Feature] Processed ParPgb:0.0-252.0 (median depth 100.0)\n",
      "[15:23:01 - Sampler] Took 0.07s to make features.\n",
      "[15:23:01 - Sampler] Region ParPgb:0.0-252.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:23:01 - PWorker] Processed 0 batches\n",
      "[15:23:01 - PWorker] All done, 1 remainder regions.\n",
      "[15:23:01 - Predict] Processing 1 short region(s).\n",
      "[15:23:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f41290c2140>\n",
      "[15:23:02 - MdlStrTF] loading weights from /tmp/tmphoe3me5p/model/variables/variables\n",
      "[15:23:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:23:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:02 - Feature] Processed ParPgb:0.0-252.0 (median depth 100.0)\n",
      "[15:23:02 - Sampler] Took 0.08s to make features.\n",
      "[15:23:02 - PWorker] Processed 1 batches\n",
      "[15:23:02 - PWorker] All done, 0 remainder regions.\n",
      "[15:23:02 - Predict] Finished processing all regions.\n",
      "[15:23:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:06 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:23:06 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:23:06 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:23:06 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:23:06 - Predict] Found a GPU.\n",
      "[15:23:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:23:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:23:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8892d91ae0>\n",
      "[15:23:07 - MdlStrTF] loading weights from /tmp/tmpzeqevydz/model/variables/variables\n",
      "[15:23:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:23:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:23:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-221.\n",
      "[15:23:07 - Feature] Processed ParPgb:0.0-221.0 (median depth 128.0)\n",
      "[15:23:07 - Sampler] Took 0.23s to make features.\n",
      "[15:23:07 - Sampler] Region ParPgb:0.0-221.0 (289 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:23:07 - PWorker] Processed 0 batches\n",
      "[15:23:07 - PWorker] All done, 1 remainder regions.\n",
      "[15:23:07 - Predict] Processing 1 short region(s).\n",
      "[15:23:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8801e26170>\n",
      "[15:23:08 - MdlStrTF] loading weights from /tmp/tmpzeqevydz/model/variables/variables\n",
      "[15:23:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-222.\n",
      "[15:23:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:08 - Feature] Processed ParPgb:0.0-221.0 (median depth 128.0)\n",
      "[15:23:08 - Sampler] Took 0.04s to make features.\n",
      "[15:23:08 - PWorker] Processed 1 batches\n",
      "[15:23:08 - PWorker] All done, 0 remainder regions.\n",
      "[15:23:08 - Predict] Finished processing all regions.\n",
      "[15:23:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:23:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:23:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:23:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:23:12 - Predict] Found a GPU.\n",
      "[15:23:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:23:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:23:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8f9f291ae0>\n",
      "[15:23:13 - MdlStrTF] loading weights from /tmp/tmp1w3q1jri/model/variables/variables\n",
      "[15:23:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:23:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:23:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:18 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-218.\n",
      "[15:23:18 - Feature] Processed ParPgb:0.0-218.0 (median depth 5.0)\n",
      "[15:23:18 - Sampler] Took 4.35s to make features.\n",
      "[15:23:18 - Sampler] Region ParPgb:0.0-218.0 (220 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:23:18 - PWorker] Processed 0 batches\n",
      "[15:23:18 - PWorker] All done, 1 remainder regions.\n",
      "[15:23:18 - Predict] Processing 1 short region(s).\n",
      "[15:23:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8f0c11af20>\n",
      "[15:23:18 - MdlStrTF] loading weights from /tmp/tmp1w3q1jri/model/variables/variables\n",
      "[15:23:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-219.\n",
      "[15:23:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:21 - Feature] Processed ParPgb:0.0-218.0 (median depth 5.0)\n",
      "[15:23:21 - Sampler] Took 2.81s to make features.\n",
      "[15:23:21 - PWorker] Processed 1 batches\n",
      "[15:23:21 - PWorker] All done, 0 remainder regions.\n",
      "[15:23:21 - Predict] Finished processing all regions.\n",
      "[15:23:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:23:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:23:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:23:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:23:25 - Predict] Found a GPU.\n",
      "[15:23:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:23:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:23:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4554a65a80>\n",
      "[15:23:26 - MdlStrTF] loading weights from /tmp/tmpmx8zspnf/model/variables/variables\n",
      "[15:23:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:23:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:23:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:28 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-211.\n",
      "[15:23:28 - Feature] Processed ParPgb:0.0-211.0 (median depth 74.0)\n",
      "[15:23:28 - Sampler] Took 1.86s to make features.\n",
      "[15:23:28 - Sampler] Region ParPgb:0.0-211.0 (267 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:23:28 - PWorker] Processed 0 batches\n",
      "[15:23:28 - PWorker] All done, 1 remainder regions.\n",
      "[15:23:28 - Predict] Processing 1 short region(s).\n",
      "[15:23:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f449023dab0>\n",
      "[15:23:29 - MdlStrTF] loading weights from /tmp/tmpmx8zspnf/model/variables/variables\n",
      "[15:23:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-212.\n",
      "[15:23:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:33 - Feature] Processed ParPgb:0.0-211.0 (median depth 74.0)\n",
      "[15:23:33 - Sampler] Took 4.56s to make features.\n",
      "[15:23:34 - PWorker] Batches in cache: 1.\n",
      "[15:23:34 - PWorker] Processed 1 batches\n",
      "[15:23:34 - PWorker] All done, 0 remainder regions.\n",
      "[15:23:34 - Predict] Finished processing all regions.\n",
      "[15:23:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:23:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:23:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:23:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:23:37 - Predict] Found a GPU.\n",
      "[15:23:37 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:23:37 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:23:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f34c794dae0>\n",
      "[15:23:38 - MdlStrTF] loading weights from /tmp/tmpp5v23aut/model/variables/variables\n",
      "[15:23:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:23:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:23:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[15:23:39 - Feature] Processed ParPgb:0.0-238.0 (median depth 141.0)\n",
      "[15:23:39 - Sampler] Took 0.07s to make features.\n",
      "[15:23:39 - Sampler] Region ParPgb:0.0-238.0 (315 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:23:39 - PWorker] Processed 0 batches\n",
      "[15:23:39 - PWorker] All done, 1 remainder regions.\n",
      "[15:23:39 - Predict] Processing 1 short region(s).\n",
      "[15:23:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f342833ef20>\n",
      "[15:23:39 - MdlStrTF] loading weights from /tmp/tmpp5v23aut/model/variables/variables\n",
      "[15:23:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[15:23:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:39 - Feature] Processed ParPgb:0.0-238.0 (median depth 141.0)\n",
      "[15:23:39 - Sampler] Took 0.10s to make features.\n",
      "[15:23:40 - PWorker] Processed 1 batches\n",
      "[15:23:40 - PWorker] All done, 0 remainder regions.\n",
      "[15:23:40 - Predict] Finished processing all regions.\n",
      "[15:23:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:23:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:23:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:23:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:23:43 - Predict] Found a GPU.\n",
      "[15:23:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:23:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:23:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f30b1db9ae0>\n",
      "[15:23:44 - MdlStrTF] loading weights from /tmp/tmpuh2d7y18/model/variables/variables\n",
      "[15:23:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:23:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:23:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[15:23:45 - Feature] Processed ParPgb:0.0-254.0 (median depth 62.0)\n",
      "[15:23:45 - Sampler] Took 0.12s to make features.\n",
      "[15:23:45 - Sampler] Region ParPgb:0.0-254.0 (299 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:23:45 - PWorker] Processed 0 batches\n",
      "[15:23:45 - PWorker] All done, 1 remainder regions.\n",
      "[15:23:45 - Predict] Processing 1 short region(s).\n",
      "[15:23:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3020cd5ea0>\n",
      "[15:23:45 - MdlStrTF] loading weights from /tmp/tmpuh2d7y18/model/variables/variables\n",
      "[15:23:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[15:23:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:45 - Feature] Processed ParPgb:0.0-254.0 (median depth 62.0)\n",
      "[15:23:45 - Sampler] Took 0.14s to make features.\n",
      "[15:23:46 - PWorker] Processed 1 batches\n",
      "[15:23:46 - PWorker] All done, 0 remainder regions.\n",
      "[15:23:46 - Predict] Finished processing all regions.\n",
      "[15:23:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:49 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:23:49 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:23:49 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:23:49 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:23:49 - Predict] Found a GPU.\n",
      "[15:23:49 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:23:49 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:23:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0180a39ae0>\n",
      "[15:23:51 - MdlStrTF] loading weights from /tmp/tmpmmt7nhqo/model/variables/variables\n",
      "[15:23:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:23:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:23:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-222.\n",
      "[15:23:51 - Feature] Processed ParPgb:0.0-222.0 (median depth 55.0)\n",
      "[15:23:51 - Sampler] Took 0.15s to make features.\n",
      "[15:23:51 - Sampler] Region ParPgb:0.0-222.0 (250 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:23:51 - PWorker] Processed 0 batches\n",
      "[15:23:51 - PWorker] All done, 1 remainder regions.\n",
      "[15:23:51 - Predict] Processing 1 short region(s).\n",
      "[15:23:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f00f0461fc0>\n",
      "[15:23:51 - MdlStrTF] loading weights from /tmp/tmpmmt7nhqo/model/variables/variables\n",
      "[15:23:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-223.\n",
      "[15:23:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:51 - Feature] Processed ParPgb:0.0-222.0 (median depth 55.0)\n",
      "[15:23:51 - Sampler] Took 0.06s to make features.\n",
      "[15:23:52 - PWorker] Processed 1 batches\n",
      "[15:23:52 - PWorker] All done, 0 remainder regions.\n",
      "[15:23:52 - Predict] Finished processing all regions.\n",
      "[15:23:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:23:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:23:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:23:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:23:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:23:55 - Predict] Found a GPU.\n",
      "[15:23:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:23:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:23:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f235f8d1ae0>\n",
      "[15:23:57 - MdlStrTF] loading weights from /tmp/tmprne_bw0d/model/variables/variables\n",
      "[15:23:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:23:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:23:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:57 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-193.\n",
      "[15:23:57 - Feature] Processed ParPgb:0.0-193.0 (median depth 4.0)\n",
      "[15:23:57 - Sampler] Took 0.06s to make features.\n",
      "[15:23:57 - Sampler] Region ParPgb:0.0-193.0 (196 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:23:57 - PWorker] Processed 0 batches\n",
      "[15:23:57 - PWorker] All done, 1 remainder regions.\n",
      "[15:23:57 - Predict] Processing 1 short region(s).\n",
      "[15:23:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:23:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f22d0215ea0>\n",
      "[15:23:57 - MdlStrTF] loading weights from /tmp/tmprne_bw0d/model/variables/variables\n",
      "[15:23:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-194.\n",
      "[15:23:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:23:57 - Feature] Processed ParPgb:0.0-193.0 (median depth 4.0)\n",
      "[15:23:57 - Sampler] Took 0.09s to make features.\n",
      "[15:23:58 - PWorker] Processed 1 batches\n",
      "[15:23:58 - PWorker] All done, 0 remainder regions.\n",
      "[15:23:58 - Predict] Finished processing all regions.\n",
      "[15:24:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:01 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:24:01 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:24:01 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:24:01 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:24:01 - Predict] Found a GPU.\n",
      "[15:24:01 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:24:01 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:24:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1fd4489ae0>\n",
      "[15:24:03 - MdlStrTF] loading weights from /tmp/tmphwjo86vp/model/variables/variables\n",
      "[15:24:03 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:24:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:24:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:03 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[15:24:03 - Feature] Processed ParPgb:0.0-247.0 (median depth 116.0)\n",
      "[15:24:03 - Sampler] Took 0.04s to make features.\n",
      "[15:24:03 - Sampler] Region ParPgb:0.0-247.0 (316 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:24:03 - PWorker] Processed 0 batches\n",
      "[15:24:03 - PWorker] All done, 1 remainder regions.\n",
      "[15:24:03 - Predict] Processing 1 short region(s).\n",
      "[15:24:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1f3b675480>\n",
      "[15:24:03 - MdlStrTF] loading weights from /tmp/tmphwjo86vp/model/variables/variables\n",
      "[15:24:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[15:24:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:07 - Feature] Processed ParPgb:0.0-247.0 (median depth 116.0)\n",
      "[15:24:07 - Sampler] Took 4.16s to make features.\n",
      "[15:24:08 - PWorker] Processed 1 batches\n",
      "[15:24:08 - PWorker] All done, 0 remainder regions.\n",
      "[15:24:08 - Predict] Finished processing all regions.\n",
      "[15:24:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:11 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:24:11 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:24:11 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:24:11 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:24:11 - Predict] Found a GPU.\n",
      "[15:24:11 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:24:11 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:24:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f972faf9ae0>\n",
      "[15:24:13 - MdlStrTF] loading weights from /tmp/tmpj0ly7mvc/model/variables/variables\n",
      "[15:24:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:24:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:24:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:13 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:24:15 - Feature] Processed ParPgb:0.0-246.0 (median depth 112.0)\n",
      "[15:24:15 - Sampler] Took 2.47s to make features.\n",
      "[15:24:15 - Sampler] Region ParPgb:0.0-246.0 (313 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:24:15 - PWorker] Processed 0 batches\n",
      "[15:24:15 - PWorker] All done, 1 remainder regions.\n",
      "[15:24:15 - Predict] Processing 1 short region(s).\n",
      "[15:24:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9690c16320>\n",
      "[15:24:15 - MdlStrTF] loading weights from /tmp/tmpj0ly7mvc/model/variables/variables\n",
      "[15:24:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:24:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:18 - Feature] Processed ParPgb:0.0-246.0 (median depth 112.0)\n",
      "[15:24:18 - Sampler] Took 2.90s to make features.\n",
      "[15:24:19 - PWorker] Processed 1 batches\n",
      "[15:24:19 - PWorker] All done, 0 remainder regions.\n",
      "[15:24:19 - Predict] Finished processing all regions.\n",
      "[15:24:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:24:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:24:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:24:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:24:22 - Predict] Found a GPU.\n",
      "[15:24:22 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:24:22 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:24:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f583cc81ae0>\n",
      "[15:24:24 - MdlStrTF] loading weights from /tmp/tmpcds56kwo/model/variables/variables\n",
      "[15:24:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:24:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:24:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:24:24 - Feature] Processed ParPgb:0.0-252.0 (median depth 10.0)\n",
      "[15:24:24 - Sampler] Took 0.07s to make features.\n",
      "[15:24:24 - Sampler] Region ParPgb:0.0-252.0 (259 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:24:24 - PWorker] Processed 0 batches\n",
      "[15:24:24 - PWorker] All done, 1 remainder regions.\n",
      "[15:24:24 - Predict] Processing 1 short region(s).\n",
      "[15:24:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f579dc76320>\n",
      "[15:24:24 - MdlStrTF] loading weights from /tmp/tmpcds56kwo/model/variables/variables\n",
      "[15:24:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:24:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:24 - Feature] Processed ParPgb:0.0-252.0 (median depth 10.0)\n",
      "[15:24:24 - Sampler] Took 0.14s to make features.\n",
      "[15:24:25 - PWorker] Processed 1 batches\n",
      "[15:24:25 - PWorker] All done, 0 remainder regions.\n",
      "[15:24:25 - Predict] Finished processing all regions.\n",
      "[15:24:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:28 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:24:28 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:24:28 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:24:28 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:24:28 - Predict] Found a GPU.\n",
      "[15:24:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:24:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:24:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3458ec5ae0>\n",
      "[15:24:30 - MdlStrTF] loading weights from /tmp/tmp39wglua4/model/variables/variables\n",
      "[15:24:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:24:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:24:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:30 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:24:30 - Feature] Processed ParPgb:0.0-249.0 (median depth 20.0)\n",
      "[15:24:30 - Sampler] Took 0.03s to make features.\n",
      "[15:24:30 - Sampler] Region ParPgb:0.0-249.0 (258 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:24:30 - PWorker] Processed 0 batches\n",
      "[15:24:30 - PWorker] All done, 1 remainder regions.\n",
      "[15:24:30 - Predict] Processing 1 short region(s).\n",
      "[15:24:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f33c80c1ff0>\n",
      "[15:24:30 - MdlStrTF] loading weights from /tmp/tmp39wglua4/model/variables/variables\n",
      "[15:24:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:24:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:30 - Feature] Processed ParPgb:0.0-249.0 (median depth 20.0)\n",
      "[15:24:30 - Sampler] Took 0.07s to make features.\n",
      "[15:24:31 - PWorker] Processed 1 batches\n",
      "[15:24:31 - PWorker] All done, 0 remainder regions.\n",
      "[15:24:31 - Predict] Finished processing all regions.\n",
      "[15:24:33 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:33 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:34 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:24:34 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:24:34 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:24:34 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:24:34 - Predict] Found a GPU.\n",
      "[15:24:34 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:24:34 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:24:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fef9ac55a80>\n",
      "[15:24:36 - MdlStrTF] loading weights from /tmp/tmpc7nx5xxd/model/variables/variables\n",
      "[15:24:36 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:24:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:24:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:36 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-221.\n",
      "[15:24:36 - Feature] Processed ParPgb:0.0-221.0 (median depth 99.0)\n",
      "[15:24:36 - Sampler] Took 0.10s to make features.\n",
      "[15:24:36 - Sampler] Region ParPgb:0.0-221.0 (255 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:24:36 - PWorker] Processed 0 batches\n",
      "[15:24:36 - PWorker] All done, 1 remainder regions.\n",
      "[15:24:36 - Predict] Processing 1 short region(s).\n",
      "[15:24:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fef09d59a80>\n",
      "[15:24:36 - MdlStrTF] loading weights from /tmp/tmpc7nx5xxd/model/variables/variables\n",
      "[15:24:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-222.\n",
      "[15:24:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:38 - Feature] Processed ParPgb:0.0-221.0 (median depth 99.0)\n",
      "[15:24:38 - Sampler] Took 1.48s to make features.\n",
      "[15:24:38 - PWorker] Processed 1 batches\n",
      "[15:24:38 - PWorker] All done, 0 remainder regions.\n",
      "[15:24:38 - Predict] Finished processing all regions.\n",
      "[15:24:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:24:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:24:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:24:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:24:42 - Predict] Found a GPU.\n",
      "[15:24:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:24:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:24:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd842c7dae0>\n",
      "[15:24:43 - MdlStrTF] loading weights from /tmp/tmp8dpn9lft/model/variables/variables\n",
      "[15:24:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:24:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:24:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-225.\n",
      "[15:24:43 - Feature] Processed ParPgb:0.0-225.0 (median depth 112.0)\n",
      "[15:24:43 - Sampler] Took 0.03s to make features.\n",
      "[15:24:43 - Sampler] Region ParPgb:0.0-225.0 (277 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:24:43 - PWorker] Processed 0 batches\n",
      "[15:24:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:24:43 - Predict] Processing 1 short region(s).\n",
      "[15:24:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd7b0439480>\n",
      "[15:24:44 - MdlStrTF] loading weights from /tmp/tmp8dpn9lft/model/variables/variables\n",
      "[15:24:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-226.\n",
      "[15:24:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:44 - Feature] Processed ParPgb:0.0-225.0 (median depth 112.0)\n",
      "[15:24:44 - Sampler] Took 0.07s to make features.\n",
      "[15:24:44 - PWorker] Processed 1 batches\n",
      "[15:24:44 - PWorker] All done, 0 remainder regions.\n",
      "[15:24:44 - Predict] Finished processing all regions.\n",
      "[15:24:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:48 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:24:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:24:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:24:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:24:48 - Predict] Found a GPU.\n",
      "[15:24:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:24:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:24:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5a64209ae0>\n",
      "[15:24:49 - MdlStrTF] loading weights from /tmp/tmp20ndj603/model/variables/variables\n",
      "[15:24:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:24:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:24:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:24:49 - Feature] Processed ParPgb:0.0-244.0 (median depth 40.0)\n",
      "[15:24:49 - Sampler] Took 0.16s to make features.\n",
      "[15:24:49 - Sampler] Region ParPgb:0.0-244.0 (272 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:24:49 - PWorker] Processed 0 batches\n",
      "[15:24:49 - PWorker] All done, 1 remainder regions.\n",
      "[15:24:49 - Predict] Processing 1 short region(s).\n",
      "[15:24:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f59d0389990>\n",
      "[15:24:50 - MdlStrTF] loading weights from /tmp/tmp20ndj603/model/variables/variables\n",
      "[15:24:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:24:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:50 - Feature] Processed ParPgb:0.0-244.0 (median depth 40.0)\n",
      "[15:24:50 - Sampler] Took 0.04s to make features.\n",
      "[15:24:50 - PWorker] Processed 1 batches\n",
      "[15:24:50 - PWorker] All done, 0 remainder regions.\n",
      "[15:24:50 - Predict] Finished processing all regions.\n",
      "[15:24:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:24:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:24:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:24:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:24:54 - Predict] Found a GPU.\n",
      "[15:24:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:24:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:24:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f860b4fda80>\n",
      "[15:24:55 - MdlStrTF] loading weights from /tmp/tmpx7u442oo/model/variables/variables\n",
      "[15:24:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:24:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:24:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[15:24:55 - Feature] Processed ParPgb:0.0-250.0 (median depth 94.0)\n",
      "[15:24:55 - Sampler] Took 0.05s to make features.\n",
      "[15:24:55 - Sampler] Region ParPgb:0.0-250.0 (312 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:24:55 - PWorker] Processed 0 batches\n",
      "[15:24:55 - PWorker] All done, 1 remainder regions.\n",
      "[15:24:55 - Predict] Processing 1 short region(s).\n",
      "[15:24:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:24:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f857a621420>\n",
      "[15:24:55 - MdlStrTF] loading weights from /tmp/tmpx7u442oo/model/variables/variables\n",
      "[15:24:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[15:24:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:24:55 - Feature] Processed ParPgb:0.0-250.0 (median depth 94.0)\n",
      "[15:24:55 - Sampler] Took 0.07s to make features.\n",
      "[15:24:56 - PWorker] Processed 1 batches\n",
      "[15:24:56 - PWorker] All done, 0 remainder regions.\n",
      "[15:24:56 - Predict] Finished processing all regions.\n",
      "[15:24:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:24:59 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:24:59 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:24:59 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:24:59 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:25:00 - Predict] Found a GPU.\n",
      "[15:25:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:25:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:25:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2149031ae0>\n",
      "[15:25:01 - MdlStrTF] loading weights from /tmp/tmptvnjaoet/model/variables/variables\n",
      "[15:25:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:25:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:25:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-200.\n",
      "[15:25:01 - Feature] Processed ParPgb:0.0-200.0 (median depth 97.0)\n",
      "[15:25:01 - Sampler] Took 0.02s to make features.\n",
      "[15:25:01 - Sampler] Region ParPgb:0.0-200.0 (243 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:25:01 - PWorker] Processed 0 batches\n",
      "[15:25:01 - PWorker] All done, 1 remainder regions.\n",
      "[15:25:01 - Predict] Processing 1 short region(s).\n",
      "[15:25:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f20b8229480>\n",
      "[15:25:01 - MdlStrTF] loading weights from /tmp/tmptvnjaoet/model/variables/variables\n",
      "[15:25:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-201.\n",
      "[15:25:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:01 - Feature] Processed ParPgb:0.0-200.0 (median depth 97.0)\n",
      "[15:25:01 - Sampler] Took 0.09s to make features.\n",
      "[15:25:02 - PWorker] Processed 1 batches\n",
      "[15:25:02 - PWorker] All done, 0 remainder regions.\n",
      "[15:25:02 - Predict] Finished processing all regions.\n",
      "[15:25:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:25:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:25:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:25:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:25:05 - Predict] Found a GPU.\n",
      "[15:25:05 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:25:05 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:25:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe5b9de1ae0>\n",
      "[15:25:07 - MdlStrTF] loading weights from /tmp/tmp5fz_o4nr/model/variables/variables\n",
      "[15:25:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:25:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:25:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-213.\n",
      "[15:25:07 - Feature] Processed ParPgb:0.0-213.0 (median depth 139.0)\n",
      "[15:25:07 - Sampler] Took 0.06s to make features.\n",
      "[15:25:07 - Sampler] Region ParPgb:0.0-213.0 (280 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:25:07 - PWorker] Processed 0 batches\n",
      "[15:25:07 - PWorker] All done, 1 remainder regions.\n",
      "[15:25:07 - Predict] Processing 1 short region(s).\n",
      "[15:25:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe528fbd450>\n",
      "[15:25:07 - MdlStrTF] loading weights from /tmp/tmp5fz_o4nr/model/variables/variables\n",
      "[15:25:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-214.\n",
      "[15:25:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:07 - Feature] Processed ParPgb:0.0-213.0 (median depth 139.0)\n",
      "[15:25:07 - Sampler] Took 0.03s to make features.\n",
      "[15:25:08 - PWorker] Processed 1 batches\n",
      "[15:25:08 - PWorker] All done, 0 remainder regions.\n",
      "[15:25:08 - Predict] Finished processing all regions.\n",
      "[15:25:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:11 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:25:11 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:25:11 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:25:11 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:25:11 - Predict] Found a GPU.\n",
      "[15:25:11 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:25:11 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:25:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f16d7495a80>\n",
      "[15:25:13 - MdlStrTF] loading weights from /tmp/tmp1atpyz7b/model/variables/variables\n",
      "[15:25:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:25:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:25:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:13 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:25:13 - Feature] Processed ParPgb:0.0-252.0 (median depth 121.0)\n",
      "[15:25:13 - Sampler] Took 0.09s to make features.\n",
      "[15:25:13 - Sampler] Region ParPgb:0.0-252.0 (336 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:25:13 - PWorker] Processed 0 batches\n",
      "[15:25:13 - PWorker] All done, 1 remainder regions.\n",
      "[15:25:13 - Predict] Processing 1 short region(s).\n",
      "[15:25:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f16386753c0>\n",
      "[15:25:13 - MdlStrTF] loading weights from /tmp/tmp1atpyz7b/model/variables/variables\n",
      "[15:25:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:25:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:13 - Feature] Processed ParPgb:0.0-252.0 (median depth 121.0)\n",
      "[15:25:13 - Sampler] Took 0.04s to make features.\n",
      "[15:25:14 - PWorker] Processed 1 batches\n",
      "[15:25:14 - PWorker] All done, 0 remainder regions.\n",
      "[15:25:14 - Predict] Finished processing all regions.\n",
      "[15:25:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:17 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:25:17 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:25:17 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:25:17 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:25:17 - Predict] Found a GPU.\n",
      "[15:25:17 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:25:17 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:25:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efca5109ae0>\n",
      "[15:25:19 - MdlStrTF] loading weights from /tmp/tmp7adqtq9j/model/variables/variables\n",
      "[15:25:19 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:25:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:25:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:19 - Sampler] Took 0.02s to make features.\n",
      "[15:25:19 - PWorker] Processed 0 batches\n",
      "[15:25:19 - PWorker] All done, 0 remainder regions.\n",
      "[15:25:19 - Predict] Finished processing all regions.\n",
      "[15:25:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:20 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:25:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:25:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:25:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:25:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:25:22 - Predict] Found a GPU.\n",
      "[15:25:22 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:25:22 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:25:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f95f7f05ae0>\n",
      "[15:25:23 - MdlStrTF] loading weights from /tmp/tmp0gzrdmr8/model/variables/variables\n",
      "[15:25:23 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:25:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:25:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:23 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:25:23 - Feature] Processed ParPgb:0.0-251.0 (median depth 75.0)\n",
      "[15:25:23 - Sampler] Took 0.04s to make features.\n",
      "[15:25:23 - Sampler] Region ParPgb:0.0-251.0 (289 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:25:23 - PWorker] Processed 0 batches\n",
      "[15:25:23 - PWorker] All done, 1 remainder regions.\n",
      "[15:25:23 - Predict] Processing 1 short region(s).\n",
      "[15:25:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f95680c1420>\n",
      "[15:25:24 - MdlStrTF] loading weights from /tmp/tmp0gzrdmr8/model/variables/variables\n",
      "[15:25:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:25:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:27 - Feature] Processed ParPgb:0.0-251.0 (median depth 75.0)\n",
      "[15:25:27 - Sampler] Took 3.12s to make features.\n",
      "[15:25:28 - PWorker] Processed 1 batches\n",
      "[15:25:28 - PWorker] All done, 0 remainder regions.\n",
      "[15:25:28 - Predict] Finished processing all regions.\n",
      "[15:25:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:25:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:25:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:25:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:25:31 - Predict] Found a GPU.\n",
      "[15:25:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:25:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:25:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1b47de1ae0>\n",
      "[15:25:32 - MdlStrTF] loading weights from /tmp/tmp_r2_kpqk/model/variables/variables\n",
      "[15:25:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:25:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:25:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:33 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-236.\n",
      "[15:25:33 - Feature] Processed ParPgb:0.0-236.0 (median depth 156.0)\n",
      "[15:25:33 - Sampler] Took 0.32s to make features.\n",
      "[15:25:33 - Sampler] Region ParPgb:0.0-236.0 (351 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:25:33 - PWorker] Processed 0 batches\n",
      "[15:25:33 - PWorker] All done, 1 remainder regions.\n",
      "[15:25:33 - Predict] Processing 1 short region(s).\n",
      "[15:25:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1aa8f71e70>\n",
      "[15:25:33 - MdlStrTF] loading weights from /tmp/tmp_r2_kpqk/model/variables/variables\n",
      "[15:25:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-237.\n",
      "[15:25:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:33 - Feature] Processed ParPgb:0.0-236.0 (median depth 156.0)\n",
      "[15:25:33 - Sampler] Took 0.04s to make features.\n",
      "[15:25:34 - PWorker] Processed 1 batches\n",
      "[15:25:34 - PWorker] All done, 0 remainder regions.\n",
      "[15:25:34 - Predict] Finished processing all regions.\n",
      "[15:25:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:25:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:25:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:25:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:25:37 - Predict] Found a GPU.\n",
      "[15:25:37 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:25:37 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:25:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc30ce21ae0>\n",
      "[15:25:39 - MdlStrTF] loading weights from /tmp/tmpxcadusoe/model/variables/variables\n",
      "[15:25:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:25:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:25:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-194.\n",
      "[15:25:39 - Feature] Processed ParPgb:0.0-194.0 (median depth 6.0)\n",
      "[15:25:39 - Sampler] Took 0.07s to make features.\n",
      "[15:25:39 - Sampler] Region ParPgb:0.0-194.0 (197 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:25:39 - PWorker] Processed 0 batches\n",
      "[15:25:39 - PWorker] All done, 1 remainder regions.\n",
      "[15:25:39 - Predict] Processing 1 short region(s).\n",
      "[15:25:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc26df6dae0>\n",
      "[15:25:39 - MdlStrTF] loading weights from /tmp/tmpxcadusoe/model/variables/variables\n",
      "[15:25:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-195.\n",
      "[15:25:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:39 - Feature] Processed ParPgb:0.0-194.0 (median depth 6.0)\n",
      "[15:25:39 - Sampler] Took 0.04s to make features.\n",
      "[15:25:40 - PWorker] Processed 1 batches\n",
      "[15:25:40 - PWorker] All done, 0 remainder regions.\n",
      "[15:25:40 - Predict] Finished processing all regions.\n",
      "[15:25:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:25:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:25:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:25:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:25:43 - Predict] Found a GPU.\n",
      "[15:25:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:25:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:25:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa424b25ae0>\n",
      "[15:25:44 - MdlStrTF] loading weights from /tmp/tmpmvt71mny/model/variables/variables\n",
      "[15:25:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:25:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:25:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[15:25:45 - Feature] Processed ParPgb:0.0-240.0 (median depth 33.0)\n",
      "[15:25:45 - Sampler] Took 0.17s to make features.\n",
      "[15:25:45 - Sampler] Region ParPgb:0.0-240.0 (263 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:25:45 - PWorker] Processed 0 batches\n",
      "[15:25:45 - PWorker] All done, 1 remainder regions.\n",
      "[15:25:45 - Predict] Processing 1 short region(s).\n",
      "[15:25:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa36195db10>\n",
      "[15:25:45 - MdlStrTF] loading weights from /tmp/tmpmvt71mny/model/variables/variables\n",
      "[15:25:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[15:25:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:47 - Feature] Processed ParPgb:0.0-240.0 (median depth 33.0)\n",
      "[15:25:47 - Sampler] Took 1.73s to make features.\n",
      "[15:25:47 - PWorker] Processed 1 batches\n",
      "[15:25:47 - PWorker] All done, 0 remainder regions.\n",
      "[15:25:47 - Predict] Finished processing all regions.\n",
      "[15:25:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:25:51 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:25:51 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:25:51 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:25:51 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:25:51 - Predict] Found a GPU.\n",
      "[15:25:51 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:25:51 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:25:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcbff29dae0>\n",
      "[15:25:52 - MdlStrTF] loading weights from /tmp/tmphxiqb6u7/model/variables/variables\n",
      "[15:25:52 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:25:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:25:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-192.\n",
      "[15:25:55 - Feature] Processed ParPgb:0.0-192.0 (median depth 1.0)\n",
      "[15:25:55 - Sampler] Took 3.16s to make features.\n",
      "[15:25:55 - Sampler] Region ParPgb:0.0-192.0 (194 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:25:55 - PWorker] Processed 0 batches\n",
      "[15:25:55 - PWorker] All done, 1 remainder regions.\n",
      "[15:25:55 - Predict] Processing 1 short region(s).\n",
      "[15:25:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:25:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcb6e446230>\n",
      "[15:25:56 - MdlStrTF] loading weights from /tmp/tmphxiqb6u7/model/variables/variables\n",
      "[15:25:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-193.\n",
      "[15:25:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:25:58 - Feature] Processed ParPgb:0.0-192.0 (median depth 1.0)\n",
      "[15:25:58 - Sampler] Took 2.40s to make features.\n",
      "[15:25:59 - PWorker] Processed 1 batches\n",
      "[15:25:59 - PWorker] All done, 0 remainder regions.\n",
      "[15:25:59 - Predict] Finished processing all regions.\n",
      "[15:26:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:26:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:26:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:26:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:26:02 - Predict] Found a GPU.\n",
      "[15:26:02 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:26:02 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:26:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f02f87edae0>\n",
      "[15:26:03 - MdlStrTF] loading weights from /tmp/tmpiqu3a74z/model/variables/variables\n",
      "[15:26:03 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:26:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:26:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:26:04 - Feature] Processed ParPgb:0.0-243.0 (median depth 178.0)\n",
      "[15:26:04 - Sampler] Took 0.14s to make features.\n",
      "[15:26:04 - Sampler] Region ParPgb:0.0-243.0 (327 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:26:04 - PWorker] Processed 0 batches\n",
      "[15:26:04 - PWorker] All done, 1 remainder regions.\n",
      "[15:26:04 - Predict] Processing 1 short region(s).\n",
      "[15:26:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0268222170>\n",
      "[15:26:04 - MdlStrTF] loading weights from /tmp/tmpiqu3a74z/model/variables/variables\n",
      "[15:26:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:26:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:04 - Feature] Processed ParPgb:0.0-243.0 (median depth 178.0)\n",
      "[15:26:04 - Sampler] Took 0.04s to make features.\n",
      "[15:26:05 - PWorker] Processed 1 batches\n",
      "[15:26:05 - PWorker] All done, 0 remainder regions.\n",
      "[15:26:05 - Predict] Finished processing all regions.\n",
      "[15:26:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:26:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:26:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:26:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:26:08 - Predict] Found a GPU.\n",
      "[15:26:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:26:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:26:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6e2f969a80>\n",
      "[15:26:09 - MdlStrTF] loading weights from /tmp/tmpmy7l6dts/model/variables/variables\n",
      "[15:26:09 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:26:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:26:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:10 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-234.\n",
      "[15:26:10 - Feature] Processed ParPgb:0.0-234.0 (median depth 110.0)\n",
      "[15:26:10 - Sampler] Took 0.09s to make features.\n",
      "[15:26:10 - Sampler] Region ParPgb:0.0-234.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:26:10 - PWorker] Processed 0 batches\n",
      "[15:26:10 - PWorker] All done, 1 remainder regions.\n",
      "[15:26:10 - Predict] Processing 1 short region(s).\n",
      "[15:26:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6d90b3dab0>\n",
      "[15:26:10 - MdlStrTF] loading weights from /tmp/tmpmy7l6dts/model/variables/variables\n",
      "[15:26:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-235.\n",
      "[15:26:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:12 - Feature] Processed ParPgb:0.0-234.0 (median depth 110.0)\n",
      "[15:26:12 - Sampler] Took 2.10s to make features.\n",
      "[15:26:13 - PWorker] Processed 1 batches\n",
      "[15:26:13 - PWorker] All done, 0 remainder regions.\n",
      "[15:26:13 - Predict] Finished processing all regions.\n",
      "[15:26:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:16 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:26:16 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:26:16 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:26:16 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:26:16 - Predict] Found a GPU.\n",
      "[15:26:16 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:26:16 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:26:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc063635ae0>\n",
      "[15:26:17 - MdlStrTF] loading weights from /tmp/tmpxodwyr0s/model/variables/variables\n",
      "[15:26:17 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:26:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:26:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:26:20 - Feature] Processed ParPgb:0.0-246.0 (median depth 109.0)\n",
      "[15:26:20 - Sampler] Took 2.95s to make features.\n",
      "[15:26:20 - Sampler] Region ParPgb:0.0-246.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:26:20 - PWorker] Processed 0 batches\n",
      "[15:26:20 - PWorker] All done, 1 remainder regions.\n",
      "[15:26:20 - Predict] Processing 1 short region(s).\n",
      "[15:26:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbfd27c9ff0>\n",
      "[15:26:21 - MdlStrTF] loading weights from /tmp/tmpxodwyr0s/model/variables/variables\n",
      "[15:26:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:26:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:23 - Feature] Processed ParPgb:0.0-246.0 (median depth 109.0)\n",
      "[15:26:23 - Sampler] Took 2.19s to make features.\n",
      "[15:26:24 - PWorker] Processed 1 batches\n",
      "[15:26:24 - PWorker] All done, 0 remainder regions.\n",
      "[15:26:24 - Predict] Finished processing all regions.\n",
      "[15:26:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:27 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:26:27 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:26:27 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:26:27 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:26:27 - Predict] Found a GPU.\n",
      "[15:26:27 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:26:27 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:26:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fee09acdae0>\n",
      "[15:26:28 - MdlStrTF] loading weights from /tmp/tmpkj1uyt6_/model/variables/variables\n",
      "[15:26:28 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:26:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:26:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:29 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-241.\n",
      "[15:26:29 - Feature] Processed ParPgb:0.0-241.0 (median depth 151.0)\n",
      "[15:26:29 - Sampler] Took 1.10s to make features.\n",
      "[15:26:29 - Sampler] Region ParPgb:0.0-241.0 (335 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:26:29 - PWorker] Processed 0 batches\n",
      "[15:26:29 - PWorker] All done, 1 remainder regions.\n",
      "[15:26:29 - Predict] Processing 1 short region(s).\n",
      "[15:26:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fed78465450>\n",
      "[15:26:30 - MdlStrTF] loading weights from /tmp/tmpkj1uyt6_/model/variables/variables\n",
      "[15:26:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-242.\n",
      "[15:26:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:32 - Feature] Processed ParPgb:0.0-241.0 (median depth 151.0)\n",
      "[15:26:32 - Sampler] Took 2.13s to make features.\n",
      "[15:26:33 - PWorker] Processed 1 batches\n",
      "[15:26:33 - PWorker] All done, 0 remainder regions.\n",
      "[15:26:33 - Predict] Finished processing all regions.\n",
      "[15:26:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:36 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:26:36 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:26:36 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:26:36 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:26:36 - Predict] Found a GPU.\n",
      "[15:26:36 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:26:36 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:26:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f65f1be5ae0>\n",
      "[15:26:37 - MdlStrTF] loading weights from /tmp/tmp5k2cjt9f/model/variables/variables\n",
      "[15:26:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:26:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:26:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:38 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-213.\n",
      "[15:26:38 - Feature] Processed ParPgb:0.0-213.0 (median depth 139.0)\n",
      "[15:26:38 - Sampler] Took 0.71s to make features.\n",
      "[15:26:38 - Sampler] Region ParPgb:0.0-213.0 (302 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:26:38 - PWorker] Processed 0 batches\n",
      "[15:26:38 - PWorker] All done, 1 remainder regions.\n",
      "[15:26:38 - Predict] Processing 1 short region(s).\n",
      "[15:26:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6550359fc0>\n",
      "[15:26:39 - MdlStrTF] loading weights from /tmp/tmp5k2cjt9f/model/variables/variables\n",
      "[15:26:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-214.\n",
      "[15:26:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:39 - Feature] Processed ParPgb:0.0-213.0 (median depth 139.0)\n",
      "[15:26:39 - Sampler] Took 0.08s to make features.\n",
      "[15:26:39 - PWorker] Processed 1 batches\n",
      "[15:26:39 - PWorker] All done, 0 remainder regions.\n",
      "[15:26:39 - Predict] Finished processing all regions.\n",
      "[15:26:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:26:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:26:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:26:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:26:43 - Predict] Found a GPU.\n",
      "[15:26:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:26:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:26:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f189345dae0>\n",
      "[15:26:44 - MdlStrTF] loading weights from /tmp/tmpajn15hpx/model/variables/variables\n",
      "[15:26:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:26:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:26:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:44 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-259.\n",
      "[15:26:44 - Feature] Processed ParPgb:0.0-259.0 (median depth 130.0)\n",
      "[15:26:44 - Sampler] Took 0.04s to make features.\n",
      "[15:26:44 - Sampler] Region ParPgb:0.0-259.0 (330 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:26:44 - PWorker] Processed 0 batches\n",
      "[15:26:44 - PWorker] All done, 1 remainder regions.\n",
      "[15:26:44 - Predict] Processing 1 short region(s).\n",
      "[15:26:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f180254d450>\n",
      "[15:26:44 - MdlStrTF] loading weights from /tmp/tmpajn15hpx/model/variables/variables\n",
      "[15:26:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-260.\n",
      "[15:26:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:45 - Feature] Processed ParPgb:0.0-259.0 (median depth 130.0)\n",
      "[15:26:45 - Sampler] Took 0.04s to make features.\n",
      "[15:26:45 - PWorker] Processed 1 batches\n",
      "[15:26:45 - PWorker] All done, 0 remainder regions.\n",
      "[15:26:45 - Predict] Finished processing all regions.\n",
      "[15:26:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:48 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:26:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:26:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:26:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:26:49 - Predict] Found a GPU.\n",
      "[15:26:49 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:26:49 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:26:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8b21e6dae0>\n",
      "[15:26:50 - MdlStrTF] loading weights from /tmp/tmpdhzpg9q3/model/variables/variables\n",
      "[15:26:50 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:26:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:26:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:50 - Sampler] Took 0.01s to make features.\n",
      "[15:26:50 - PWorker] Processed 0 batches\n",
      "[15:26:50 - PWorker] All done, 0 remainder regions.\n",
      "[15:26:50 - Predict] Finished processing all regions.\n",
      "[15:26:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:26:52 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:26:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:26:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:26:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:26:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:26:53 - Predict] Found a GPU.\n",
      "[15:26:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:26:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:26:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb25ba75ae0>\n",
      "[15:26:55 - MdlStrTF] loading weights from /tmp/tmpu15tloew/model/variables/variables\n",
      "[15:26:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:26:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:26:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:26:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-236.\n",
      "[15:26:55 - Feature] Processed ParPgb:0.0-236.0 (median depth 190.0)\n",
      "[15:26:55 - Sampler] Took 0.04s to make features.\n",
      "[15:26:55 - Sampler] Region ParPgb:0.0-236.0 (321 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:26:55 - PWorker] Processed 0 batches\n",
      "[15:26:55 - PWorker] All done, 1 remainder regions.\n",
      "[15:26:55 - Predict] Processing 1 short region(s).\n",
      "[15:26:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:26:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb1ca8f5480>\n",
      "[15:26:55 - MdlStrTF] loading weights from /tmp/tmpu15tloew/model/variables/variables\n",
      "[15:26:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-237.\n",
      "[15:26:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:00 - Feature] Processed ParPgb:0.0-236.0 (median depth 190.0)\n",
      "[15:27:00 - Sampler] Took 4.68s to make features.\n",
      "[15:27:00 - PWorker] Batches in cache: 1.\n",
      "[15:27:00 - PWorker] Processed 1 batches\n",
      "[15:27:00 - PWorker] All done, 0 remainder regions.\n",
      "[15:27:00 - Predict] Finished processing all regions.\n",
      "[15:27:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:27:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:27:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:27:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:27:04 - Predict] Found a GPU.\n",
      "[15:27:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:27:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:27:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f68e02edae0>\n",
      "[15:27:05 - MdlStrTF] loading weights from /tmp/tmpy86wpn_v/model/variables/variables\n",
      "[15:27:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:27:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:27:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:27:05 - Feature] Processed ParPgb:0.0-245.0 (median depth 69.0)\n",
      "[15:27:05 - Sampler] Took 0.05s to make features.\n",
      "[15:27:05 - Sampler] Region ParPgb:0.0-245.0 (288 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:27:05 - PWorker] Processed 0 batches\n",
      "[15:27:05 - PWorker] All done, 1 remainder regions.\n",
      "[15:27:05 - Predict] Processing 1 short region(s).\n",
      "[15:27:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6841411480>\n",
      "[15:27:06 - MdlStrTF] loading weights from /tmp/tmpy86wpn_v/model/variables/variables\n",
      "[15:27:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:27:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:10 - Feature] Processed ParPgb:0.0-245.0 (median depth 69.0)\n",
      "[15:27:10 - Sampler] Took 4.86s to make features.\n",
      "[15:27:11 - PWorker] Batches in cache: 1.\n",
      "[15:27:11 - PWorker] Processed 1 batches\n",
      "[15:27:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:27:11 - Predict] Finished processing all regions.\n",
      "[15:27:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:27:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:27:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:27:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:27:14 - Predict] Found a GPU.\n",
      "[15:27:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:27:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:27:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7eff06ecdae0>\n",
      "[15:27:16 - MdlStrTF] loading weights from /tmp/tmpibnasnh3/model/variables/variables\n",
      "[15:27:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:27:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:27:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-221.\n",
      "[15:27:16 - Feature] Processed ParPgb:0.0-221.0 (median depth 80.0)\n",
      "[15:27:16 - Sampler] Took 0.04s to make features.\n",
      "[15:27:16 - Sampler] Region ParPgb:0.0-221.0 (287 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:27:16 - PWorker] Processed 0 batches\n",
      "[15:27:16 - PWorker] All done, 1 remainder regions.\n",
      "[15:27:16 - Predict] Processing 1 short region(s).\n",
      "[15:27:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efe51f76f20>\n",
      "[15:27:16 - MdlStrTF] loading weights from /tmp/tmpibnasnh3/model/variables/variables\n",
      "[15:27:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-222.\n",
      "[15:27:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:25 - Feature] Processed ParPgb:0.0-221.0 (median depth 80.0)\n",
      "[15:27:25 - Sampler] Took 8.48s to make features.\n",
      "[15:27:25 - PWorker] Batches in cache: 1.\n",
      "[15:27:25 - PWorker] Processed 1 batches\n",
      "[15:27:25 - PWorker] All done, 0 remainder regions.\n",
      "[15:27:25 - Predict] Finished processing all regions.\n",
      "[15:27:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:27:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:27:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:27:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:27:29 - Predict] Found a GPU.\n",
      "[15:27:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:27:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:27:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc31ffcdae0>\n",
      "[15:27:30 - MdlStrTF] loading weights from /tmp/tmp4awwp7vj/model/variables/variables\n",
      "[15:27:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:27:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:27:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:30 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[15:27:30 - Feature] Processed ParPgb:0.0-242.0 (median depth 108.0)\n",
      "[15:27:30 - Sampler] Took 0.16s to make features.\n",
      "[15:27:30 - Sampler] Region ParPgb:0.0-242.0 (300 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:27:30 - PWorker] Processed 0 batches\n",
      "[15:27:30 - PWorker] All done, 1 remainder regions.\n",
      "[15:27:30 - Predict] Processing 1 short region(s).\n",
      "[15:27:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc2901c1480>\n",
      "[15:27:31 - MdlStrTF] loading weights from /tmp/tmp4awwp7vj/model/variables/variables\n",
      "[15:27:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[15:27:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:33 - Feature] Processed ParPgb:0.0-242.0 (median depth 108.0)\n",
      "[15:27:33 - Sampler] Took 2.38s to make features.\n",
      "[15:27:34 - PWorker] Processed 1 batches\n",
      "[15:27:34 - PWorker] All done, 0 remainder regions.\n",
      "[15:27:34 - Predict] Finished processing all regions.\n",
      "[15:27:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:27:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:27:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:27:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:27:37 - Predict] Found a GPU.\n",
      "[15:27:37 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:27:37 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:27:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f33f05f5ae0>\n",
      "[15:27:38 - MdlStrTF] loading weights from /tmp/tmp_7kgmq53/model/variables/variables\n",
      "[15:27:38 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:27:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:27:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:38 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-195.\n",
      "[15:27:38 - Feature] Processed ParPgb:0.0-195.0 (median depth 27.0)\n",
      "[15:27:38 - Sampler] Took 0.03s to make features.\n",
      "[15:27:38 - Sampler] Region ParPgb:0.0-195.0 (204 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:27:38 - PWorker] Processed 0 batches\n",
      "[15:27:38 - PWorker] All done, 1 remainder regions.\n",
      "[15:27:38 - Predict] Processing 1 short region(s).\n",
      "[15:27:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3351771b10>\n",
      "[15:27:39 - MdlStrTF] loading weights from /tmp/tmp_7kgmq53/model/variables/variables\n",
      "[15:27:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-196.\n",
      "[15:27:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:39 - Feature] Processed ParPgb:0.0-195.0 (median depth 27.0)\n",
      "[15:27:39 - Sampler] Took 0.08s to make features.\n",
      "[15:27:40 - PWorker] Processed 1 batches\n",
      "[15:27:40 - PWorker] All done, 0 remainder regions.\n",
      "[15:27:40 - Predict] Finished processing all regions.\n",
      "[15:27:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:27:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:27:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:27:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:27:43 - Predict] Found a GPU.\n",
      "[15:27:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:27:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:27:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f54bdda5ae0>\n",
      "[15:27:44 - MdlStrTF] loading weights from /tmp/tmp011edqwb/model/variables/variables\n",
      "[15:27:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:27:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:27:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:44 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:27:44 - Feature] Processed ParPgb:0.0-243.0 (median depth 81.0)\n",
      "[15:27:44 - Sampler] Took 0.05s to make features.\n",
      "[15:27:44 - Sampler] Region ParPgb:0.0-243.0 (299 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:27:44 - PWorker] Processed 0 batches\n",
      "[15:27:44 - PWorker] All done, 1 remainder regions.\n",
      "[15:27:44 - Predict] Processing 1 short region(s).\n",
      "[15:27:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f541c552ef0>\n",
      "[15:27:45 - MdlStrTF] loading weights from /tmp/tmp011edqwb/model/variables/variables\n",
      "[15:27:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:27:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:46 - Feature] Processed ParPgb:0.0-243.0 (median depth 81.0)\n",
      "[15:27:46 - Sampler] Took 0.86s to make features.\n",
      "[15:27:46 - PWorker] Processed 1 batches\n",
      "[15:27:46 - PWorker] All done, 0 remainder regions.\n",
      "[15:27:46 - Predict] Finished processing all regions.\n",
      "[15:27:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:27:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:27:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:27:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:27:50 - Predict] Found a GPU.\n",
      "[15:27:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:27:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:27:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f678d861ae0>\n",
      "[15:27:51 - MdlStrTF] loading weights from /tmp/tmpo5_mvtk8/model/variables/variables\n",
      "[15:27:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:27:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:27:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:27:51 - Feature] Processed ParPgb:0.0-245.0 (median depth 40.0)\n",
      "[15:27:51 - Sampler] Took 0.09s to make features.\n",
      "[15:27:51 - Sampler] Region ParPgb:0.0-245.0 (282 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:27:51 - PWorker] Processed 0 batches\n",
      "[15:27:51 - PWorker] All done, 1 remainder regions.\n",
      "[15:27:51 - Predict] Processing 1 short region(s).\n",
      "[15:27:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f66fc9aa320>\n",
      "[15:27:52 - MdlStrTF] loading weights from /tmp/tmpo5_mvtk8/model/variables/variables\n",
      "[15:27:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:27:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:52 - Feature] Processed ParPgb:0.0-245.0 (median depth 40.0)\n",
      "[15:27:52 - Sampler] Took 0.04s to make features.\n",
      "[15:27:52 - PWorker] Processed 1 batches\n",
      "[15:27:52 - PWorker] All done, 0 remainder regions.\n",
      "[15:27:52 - Predict] Finished processing all regions.\n",
      "[15:27:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:27:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:27:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:27:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:27:56 - Predict] Found a GPU.\n",
      "[15:27:56 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:27:56 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:27:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:27:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f378f15dae0>\n",
      "[15:27:57 - MdlStrTF] loading weights from /tmp/tmpvb136lvc/model/variables/variables\n",
      "[15:27:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:27:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:27:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:27:57 - Sampler] Took 0.10s to make features.\n",
      "[15:27:57 - PWorker] Processed 0 batches\n",
      "[15:27:57 - PWorker] All done, 0 remainder regions.\n",
      "[15:27:57 - Predict] Finished processing all regions.\n",
      "[15:27:59 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:27:59 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:28:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:28:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:28:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:28:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:28:00 - Predict] Found a GPU.\n",
      "[15:28:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:28:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:28:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f286d395ae0>\n",
      "[15:28:02 - MdlStrTF] loading weights from /tmp/tmp56ntr088/model/variables/variables\n",
      "[15:28:02 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:28:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:28:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:02 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[15:28:02 - Feature] Processed ParPgb:0.0-253.0 (median depth 93.0)\n",
      "[15:28:02 - Sampler] Took 0.02s to make features.\n",
      "[15:28:02 - Sampler] Region ParPgb:0.0-253.0 (295 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:28:02 - PWorker] Processed 0 batches\n",
      "[15:28:02 - PWorker] All done, 1 remainder regions.\n",
      "[15:28:02 - Predict] Processing 1 short region(s).\n",
      "[15:28:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f27dc539ea0>\n",
      "[15:28:02 - MdlStrTF] loading weights from /tmp/tmp56ntr088/model/variables/variables\n",
      "[15:28:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[15:28:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:02 - Feature] Processed ParPgb:0.0-253.0 (median depth 93.0)\n",
      "[15:28:02 - Sampler] Took 0.02s to make features.\n",
      "[15:28:03 - PWorker] Processed 1 batches\n",
      "[15:28:03 - PWorker] All done, 0 remainder regions.\n",
      "[15:28:03 - Predict] Finished processing all regions.\n",
      "[15:28:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:06 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:28:06 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:28:06 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:28:06 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:28:06 - Predict] Found a GPU.\n",
      "[15:28:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:28:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:28:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f18bdd89ae0>\n",
      "[15:28:07 - MdlStrTF] loading weights from /tmp/tmps4kk15w1/model/variables/variables\n",
      "[15:28:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:28:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:28:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:08 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-225.\n",
      "[15:28:08 - Feature] Processed ParPgb:0.0-225.0 (median depth 14.0)\n",
      "[15:28:08 - Sampler] Took 0.14s to make features.\n",
      "[15:28:08 - Sampler] Region ParPgb:0.0-225.0 (239 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:28:08 - PWorker] Processed 0 batches\n",
      "[15:28:08 - PWorker] All done, 1 remainder regions.\n",
      "[15:28:08 - Predict] Processing 1 short region(s).\n",
      "[15:28:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f182cfa2320>\n",
      "[15:28:08 - MdlStrTF] loading weights from /tmp/tmps4kk15w1/model/variables/variables\n",
      "[15:28:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-226.\n",
      "[15:28:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:08 - Feature] Processed ParPgb:0.0-225.0 (median depth 14.0)\n",
      "[15:28:08 - Sampler] Took 0.07s to make features.\n",
      "[15:28:09 - PWorker] Processed 1 batches\n",
      "[15:28:09 - PWorker] All done, 0 remainder regions.\n",
      "[15:28:09 - Predict] Finished processing all regions.\n",
      "[15:28:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:28:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:28:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:28:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:28:12 - Predict] Found a GPU.\n",
      "[15:28:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:28:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:28:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6a3983dae0>\n",
      "[15:28:13 - MdlStrTF] loading weights from /tmp/tmpz_2kc2gr/model/variables/variables\n",
      "[15:28:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:28:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:28:13 - Sampler] Took 0.01s to make features.\n",
      "[15:28:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:13 - PWorker] Processed 0 batches\n",
      "[15:28:13 - PWorker] All done, 0 remainder regions.\n",
      "[15:28:13 - Predict] Finished processing all regions.\n",
      "[15:28:15 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:15 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:28:17 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:28:17 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:28:17 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:28:17 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:28:17 - Predict] Found a GPU.\n",
      "[15:28:17 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:28:17 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:28:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1ff742da80>\n",
      "[15:28:18 - MdlStrTF] loading weights from /tmp/tmpcay1ebth/model/variables/variables\n",
      "[15:28:18 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:28:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:28:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:18 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-261.\n",
      "[15:28:18 - Feature] Processed ParPgb:0.0-261.0 (median depth 162.0)\n",
      "[15:28:18 - Sampler] Took 0.22s to make features.\n",
      "[15:28:18 - Sampler] Region ParPgb:0.0-261.0 (356 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:28:18 - PWorker] Processed 0 batches\n",
      "[15:28:18 - PWorker] All done, 1 remainder regions.\n",
      "[15:28:18 - Predict] Processing 1 short region(s).\n",
      "[15:28:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1f58259f90>\n",
      "[15:28:19 - MdlStrTF] loading weights from /tmp/tmpcay1ebth/model/variables/variables\n",
      "[15:28:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-262.\n",
      "[15:28:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:21 - Feature] Processed ParPgb:0.0-261.0 (median depth 162.0)\n",
      "[15:28:21 - Sampler] Took 2.19s to make features.\n",
      "[15:28:21 - PWorker] Processed 1 batches\n",
      "[15:28:21 - PWorker] All done, 0 remainder regions.\n",
      "[15:28:21 - Predict] Finished processing all regions.\n",
      "[15:28:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:28:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:28:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:28:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:28:25 - Predict] Found a GPU.\n",
      "[15:28:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:28:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:28:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe43b919ae0>\n",
      "[15:28:26 - MdlStrTF] loading weights from /tmp/tmperfvh3ap/model/variables/variables\n",
      "[15:28:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:28:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:28:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-197.\n",
      "[15:28:26 - Feature] Processed ParPgb:0.0-197.0 (median depth 2.0)\n",
      "[15:28:26 - Sampler] Took 0.08s to make features.\n",
      "[15:28:26 - Sampler] Region ParPgb:0.0-197.0 (202 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:28:26 - PWorker] Processed 0 batches\n",
      "[15:28:26 - PWorker] All done, 1 remainder regions.\n",
      "[15:28:26 - Predict] Processing 1 short region(s).\n",
      "[15:28:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe3aaa25e70>\n",
      "[15:28:27 - MdlStrTF] loading weights from /tmp/tmperfvh3ap/model/variables/variables\n",
      "[15:28:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-198.\n",
      "[15:28:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:34 - Feature] Processed ParPgb:0.0-197.0 (median depth 2.0)\n",
      "[15:28:34 - Sampler] Took 7.31s to make features.\n",
      "[15:28:35 - PWorker] Batches in cache: 1.\n",
      "[15:28:35 - PWorker] Processed 1 batches\n",
      "[15:28:35 - PWorker] All done, 0 remainder regions.\n",
      "[15:28:35 - Predict] Finished processing all regions.\n",
      "[15:28:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:28:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:28:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:28:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:28:38 - Predict] Found a GPU.\n",
      "[15:28:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:28:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:28:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdb7f48dae0>\n",
      "[15:28:39 - MdlStrTF] loading weights from /tmp/tmp0za4tko6/model/variables/variables\n",
      "[15:28:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:28:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:28:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:40 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-267.\n",
      "[15:28:40 - Feature] Processed ParPgb:0.0-267.0 (median depth 101.0)\n",
      "[15:28:40 - Sampler] Took 0.21s to make features.\n",
      "[15:28:40 - Sampler] Region ParPgb:0.0-267.0 (340 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:28:40 - PWorker] Processed 0 batches\n",
      "[15:28:40 - PWorker] All done, 1 remainder regions.\n",
      "[15:28:40 - Predict] Processing 1 short region(s).\n",
      "[15:28:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdaee64a1a0>\n",
      "[15:28:40 - MdlStrTF] loading weights from /tmp/tmp0za4tko6/model/variables/variables\n",
      "[15:28:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-268.\n",
      "[15:28:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:40 - Feature] Processed ParPgb:0.0-267.0 (median depth 101.0)\n",
      "[15:28:40 - Sampler] Took 0.03s to make features.\n",
      "[15:28:41 - PWorker] Processed 1 batches\n",
      "[15:28:41 - PWorker] All done, 0 remainder regions.\n",
      "[15:28:41 - Predict] Finished processing all regions.\n",
      "[15:28:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:44 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:28:44 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:28:44 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:28:44 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:28:44 - Predict] Found a GPU.\n",
      "[15:28:44 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:28:44 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:28:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb346089ae0>\n",
      "[15:28:45 - MdlStrTF] loading weights from /tmp/tmpn_ase0mi/model/variables/variables\n",
      "[15:28:46 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:28:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:28:46 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-236.\n",
      "[15:28:46 - Feature] Processed ParPgb:0.0-236.0 (median depth 53.0)\n",
      "[15:28:46 - Sampler] Took 0.02s to make features.\n",
      "[15:28:46 - Sampler] Region ParPgb:0.0-236.0 (292 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:28:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:46 - PWorker] Processed 0 batches\n",
      "[15:28:46 - PWorker] All done, 1 remainder regions.\n",
      "[15:28:46 - Predict] Processing 1 short region(s).\n",
      "[15:28:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb2a9211240>\n",
      "[15:28:46 - MdlStrTF] loading weights from /tmp/tmpn_ase0mi/model/variables/variables\n",
      "[15:28:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-237.\n",
      "[15:28:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:46 - Feature] Processed ParPgb:0.0-236.0 (median depth 53.0)\n",
      "[15:28:46 - Sampler] Took 0.05s to make features.\n",
      "[15:28:47 - PWorker] Processed 1 batches\n",
      "[15:28:47 - PWorker] All done, 0 remainder regions.\n",
      "[15:28:47 - Predict] Finished processing all regions.\n",
      "[15:28:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:28:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:28:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:28:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:28:50 - Predict] Found a GPU.\n",
      "[15:28:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:28:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:28:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fca67b01ae0>\n",
      "[15:28:51 - MdlStrTF] loading weights from /tmp/tmpuxfkeq1q/model/variables/variables\n",
      "[15:28:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:28:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:28:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:54 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-193.\n",
      "[15:28:54 - Feature] Processed ParPgb:0.0-193.0 (median depth 1.0)\n",
      "[15:28:54 - Sampler] Took 2.75s to make features.\n",
      "[15:28:54 - Sampler] Region ParPgb:0.0-193.0 (198 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:28:54 - PWorker] Processed 0 batches\n",
      "[15:28:54 - PWorker] All done, 1 remainder regions.\n",
      "[15:28:54 - Predict] Processing 1 short region(s).\n",
      "[15:28:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:28:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc9c8c76f50>\n",
      "[15:28:55 - MdlStrTF] loading weights from /tmp/tmpuxfkeq1q/model/variables/variables\n",
      "[15:28:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-194.\n",
      "[15:28:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:28:55 - Feature] Processed ParPgb:0.0-193.0 (median depth 1.0)\n",
      "[15:28:55 - Sampler] Took 0.08s to make features.\n",
      "[15:28:55 - PWorker] Processed 1 batches\n",
      "[15:28:55 - PWorker] All done, 0 remainder regions.\n",
      "[15:28:55 - Predict] Finished processing all regions.\n",
      "[15:28:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:28:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:28:59 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:28:59 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:28:59 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:28:59 - Predict] Found a GPU.\n",
      "[15:28:59 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:28:59 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:28:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f43fbce9ae0>\n",
      "[15:29:00 - MdlStrTF] loading weights from /tmp/tmp8q8d6g5x/model/variables/variables\n",
      "[15:29:00 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:29:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:29:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:00 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-212.\n",
      "[15:29:00 - Feature] Processed ParPgb:0.0-212.0 (median depth 126.0)\n",
      "[15:29:00 - Sampler] Took 0.05s to make features.\n",
      "[15:29:00 - Sampler] Region ParPgb:0.0-212.0 (290 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:29:00 - PWorker] Processed 0 batches\n",
      "[15:29:00 - PWorker] All done, 1 remainder regions.\n",
      "[15:29:00 - Predict] Processing 1 short region(s).\n",
      "[15:29:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f435ce6d480>\n",
      "[15:29:00 - MdlStrTF] loading weights from /tmp/tmp8q8d6g5x/model/variables/variables\n",
      "[15:29:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-213.\n",
      "[15:29:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:01 - Feature] Processed ParPgb:0.0-212.0 (median depth 126.0)\n",
      "[15:29:01 - Sampler] Took 0.15s to make features.\n",
      "[15:29:01 - PWorker] Processed 1 batches\n",
      "[15:29:01 - PWorker] All done, 0 remainder regions.\n",
      "[15:29:01 - Predict] Finished processing all regions.\n",
      "[15:29:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:29:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:29:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:29:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:29:05 - Predict] Found a GPU.\n",
      "[15:29:05 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:29:05 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:29:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ffa67665ae0>\n",
      "[15:29:06 - MdlStrTF] loading weights from /tmp/tmpw83zhixv/model/variables/variables\n",
      "[15:29:06 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:29:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:29:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:06 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-233.\n",
      "[15:29:06 - Feature] Processed ParPgb:0.0-233.0 (median depth 209.0)\n",
      "[15:29:06 - Sampler] Took 0.12s to make features.\n",
      "[15:29:06 - Sampler] Region ParPgb:0.0-233.0 (326 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:29:06 - PWorker] Processed 0 batches\n",
      "[15:29:06 - PWorker] All done, 1 remainder regions.\n",
      "[15:29:06 - Predict] Processing 1 short region(s).\n",
      "[15:29:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff9c879a1a0>\n",
      "[15:29:06 - MdlStrTF] loading weights from /tmp/tmpw83zhixv/model/variables/variables\n",
      "[15:29:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-234.\n",
      "[15:29:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:07 - Feature] Processed ParPgb:0.0-233.0 (median depth 209.0)\n",
      "[15:29:07 - Sampler] Took 0.08s to make features.\n",
      "[15:29:07 - PWorker] Processed 1 batches\n",
      "[15:29:07 - PWorker] All done, 0 remainder regions.\n",
      "[15:29:07 - Predict] Finished processing all regions.\n",
      "[15:29:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:10 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:29:10 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:29:10 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:29:10 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:29:11 - Predict] Found a GPU.\n",
      "[15:29:11 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:29:11 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:29:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:12 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd0d0765a80>\n",
      "[15:29:12 - MdlStrTF] loading weights from /tmp/tmp63e44wiy/model/variables/variables\n",
      "[15:29:12 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:29:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:29:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:12 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[15:29:12 - Feature] Processed ParPgb:0.0-254.0 (median depth 93.0)\n",
      "[15:29:12 - Sampler] Took 0.20s to make features.\n",
      "[15:29:12 - Sampler] Region ParPgb:0.0-254.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:29:12 - PWorker] Processed 0 batches\n",
      "[15:29:12 - PWorker] All done, 1 remainder regions.\n",
      "[15:29:12 - Predict] Processing 1 short region(s).\n",
      "[15:29:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd0400f5ab0>\n",
      "[15:29:13 - MdlStrTF] loading weights from /tmp/tmp63e44wiy/model/variables/variables\n",
      "[15:29:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[15:29:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:13 - Feature] Processed ParPgb:0.0-254.0 (median depth 93.0)\n",
      "[15:29:13 - Sampler] Took 0.08s to make features.\n",
      "[15:29:13 - PWorker] Processed 1 batches\n",
      "[15:29:13 - PWorker] All done, 0 remainder regions.\n",
      "[15:29:13 - Predict] Finished processing all regions.\n",
      "[15:29:15 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:15 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:16 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:29:17 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:29:17 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:29:17 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:29:17 - Predict] Found a GPU.\n",
      "[15:29:17 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:29:17 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:29:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe23b7d1ae0>\n",
      "[15:29:18 - MdlStrTF] loading weights from /tmp/tmp8yv7wgei/model/variables/variables\n",
      "[15:29:18 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:29:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:29:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:18 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-227.\n",
      "[15:29:18 - Feature] Processed ParPgb:0.0-227.0 (median depth 70.0)\n",
      "[15:29:18 - Sampler] Took 0.03s to make features.\n",
      "[15:29:18 - Sampler] Region ParPgb:0.0-227.0 (292 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:29:18 - PWorker] Processed 0 batches\n",
      "[15:29:18 - PWorker] All done, 1 remainder regions.\n",
      "[15:29:18 - Predict] Processing 1 short region(s).\n",
      "[15:29:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe1aa91d480>\n",
      "[15:29:18 - MdlStrTF] loading weights from /tmp/tmp8yv7wgei/model/variables/variables\n",
      "[15:29:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-228.\n",
      "[15:29:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:18 - Feature] Processed ParPgb:0.0-227.0 (median depth 70.0)\n",
      "[15:29:18 - Sampler] Took 0.06s to make features.\n",
      "[15:29:19 - PWorker] Processed 1 batches\n",
      "[15:29:19 - PWorker] All done, 0 remainder regions.\n",
      "[15:29:19 - Predict] Finished processing all regions.\n",
      "[15:29:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:29:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:29:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:29:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:29:22 - Predict] Found a GPU.\n",
      "[15:29:22 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:29:22 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:29:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc113f91ae0>\n",
      "[15:29:24 - MdlStrTF] loading weights from /tmp/tmp7_uipz4v/model/variables/variables\n",
      "[15:29:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:29:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:29:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[15:29:24 - Feature] Processed ParPgb:0.0-247.0 (median depth 107.0)\n",
      "[15:29:24 - Sampler] Took 0.05s to make features.\n",
      "[15:29:24 - Sampler] Region ParPgb:0.0-247.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:29:24 - PWorker] Processed 0 batches\n",
      "[15:29:24 - PWorker] All done, 1 remainder regions.\n",
      "[15:29:24 - Predict] Processing 1 short region(s).\n",
      "[15:29:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc0ec271b10>\n",
      "[15:29:24 - MdlStrTF] loading weights from /tmp/tmp7_uipz4v/model/variables/variables\n",
      "[15:29:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[15:29:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:26 - Feature] Processed ParPgb:0.0-247.0 (median depth 107.0)\n",
      "[15:29:26 - Sampler] Took 1.89s to make features.\n",
      "[15:29:27 - PWorker] Processed 1 batches\n",
      "[15:29:27 - PWorker] All done, 0 remainder regions.\n",
      "[15:29:27 - Predict] Finished processing all regions.\n",
      "[15:29:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:29:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:29:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:29:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:29:30 - Predict] Found a GPU.\n",
      "[15:29:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:29:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:29:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f21cc4f5a80>\n",
      "[15:29:31 - MdlStrTF] loading weights from /tmp/tmpzk1q04uf/model/variables/variables\n",
      "[15:29:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:29:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:29:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-199.\n",
      "[15:29:38 - Feature] Processed ParPgb:0.0-199.0 (median depth 16.0)\n",
      "[15:29:38 - Sampler] Took 6.12s to make features.\n",
      "[15:29:38 - Sampler] Region ParPgb:0.0-199.0 (208 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:29:38 - PWorker] Processed 0 batches\n",
      "[15:29:38 - PWorker] All done, 1 remainder regions.\n",
      "[15:29:38 - Predict] Processing 1 short region(s).\n",
      "[15:29:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f212d576ec0>\n",
      "[15:29:38 - MdlStrTF] loading weights from /tmp/tmpzk1q04uf/model/variables/variables\n",
      "[15:29:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-200.\n",
      "[15:29:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:38 - Feature] Processed ParPgb:0.0-199.0 (median depth 16.0)\n",
      "[15:29:38 - Sampler] Took 0.03s to make features.\n",
      "[15:29:39 - PWorker] Processed 1 batches\n",
      "[15:29:39 - PWorker] All done, 0 remainder regions.\n",
      "[15:29:39 - Predict] Finished processing all regions.\n",
      "[15:29:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:29:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:29:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:29:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:29:42 - Predict] Found a GPU.\n",
      "[15:29:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:29:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:29:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efe76e19ae0>\n",
      "[15:29:43 - MdlStrTF] loading weights from /tmp/tmpkd76m1_d/model/variables/variables\n",
      "[15:29:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:29:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:29:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-200.\n",
      "[15:29:43 - Feature] Processed ParPgb:0.0-200.0 (median depth 8.0)\n",
      "[15:29:43 - Sampler] Took 0.08s to make features.\n",
      "[15:29:43 - Sampler] Region ParPgb:0.0-200.0 (201 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:29:43 - PWorker] Processed 0 batches\n",
      "[15:29:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:29:43 - Predict] Processing 1 short region(s).\n",
      "[15:29:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efdc1e9a1d0>\n",
      "[15:29:44 - MdlStrTF] loading weights from /tmp/tmpkd76m1_d/model/variables/variables\n",
      "[15:29:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-201.\n",
      "[15:29:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:44 - Feature] Processed ParPgb:0.0-200.0 (median depth 8.0)\n",
      "[15:29:44 - Sampler] Took 0.06s to make features.\n",
      "[15:29:44 - PWorker] Processed 1 batches\n",
      "[15:29:44 - PWorker] All done, 0 remainder regions.\n",
      "[15:29:44 - Predict] Finished processing all regions.\n",
      "[15:29:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:48 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:29:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:29:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:29:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:29:48 - Predict] Found a GPU.\n",
      "[15:29:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:29:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:29:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3ca9c31ae0>\n",
      "[15:29:49 - MdlStrTF] loading weights from /tmp/tmppyb6qqme/model/variables/variables\n",
      "[15:29:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:29:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:29:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:29:49 - Feature] Processed ParPgb:0.0-203.0 (median depth 108.0)\n",
      "[15:29:49 - Sampler] Took 0.03s to make features.\n",
      "[15:29:49 - Sampler] Region ParPgb:0.0-203.0 (276 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:29:49 - PWorker] Processed 0 batches\n",
      "[15:29:49 - PWorker] All done, 1 remainder regions.\n",
      "[15:29:49 - Predict] Processing 1 short region(s).\n",
      "[15:29:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3c18dbd480>\n",
      "[15:29:50 - MdlStrTF] loading weights from /tmp/tmppyb6qqme/model/variables/variables\n",
      "[15:29:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:29:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:50 - Feature] Processed ParPgb:0.0-203.0 (median depth 108.0)\n",
      "[15:29:50 - Sampler] Took 0.04s to make features.\n",
      "[15:29:50 - PWorker] Processed 1 batches\n",
      "[15:29:50 - PWorker] All done, 0 remainder regions.\n",
      "[15:29:50 - Predict] Finished processing all regions.\n",
      "[15:29:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:29:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:29:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:29:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:29:54 - Predict] Found a GPU.\n",
      "[15:29:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:29:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:29:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5ee2a2dae0>\n",
      "[15:29:55 - MdlStrTF] loading weights from /tmp/tmpii91hle_/model/variables/variables\n",
      "[15:29:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:29:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:29:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[15:29:55 - Feature] Processed ParPgb:0.0-238.0 (median depth 108.0)\n",
      "[15:29:55 - Sampler] Took 0.04s to make features.\n",
      "[15:29:55 - Sampler] Region ParPgb:0.0-238.0 (300 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:29:55 - PWorker] Processed 0 batches\n",
      "[15:29:55 - PWorker] All done, 1 remainder regions.\n",
      "[15:29:55 - Predict] Processing 1 short region(s).\n",
      "[15:29:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:29:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5e51c29b10>\n",
      "[15:29:56 - MdlStrTF] loading weights from /tmp/tmpii91hle_/model/variables/variables\n",
      "[15:29:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[15:29:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:29:56 - Feature] Processed ParPgb:0.0-238.0 (median depth 108.0)\n",
      "[15:29:56 - Sampler] Took 0.10s to make features.\n",
      "[15:29:56 - PWorker] Processed 1 batches\n",
      "[15:29:56 - PWorker] All done, 0 remainder regions.\n",
      "[15:29:56 - Predict] Finished processing all regions.\n",
      "[15:29:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:29:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:30:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:30:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:30:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:30:00 - Predict] Found a GPU.\n",
      "[15:30:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:30:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:30:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7324a79ae0>\n",
      "[15:30:01 - MdlStrTF] loading weights from /tmp/tmpkp2frlnu/model/variables/variables\n",
      "[15:30:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:30:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:30:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:30:01 - Feature] Processed ParPgb:0.0-246.0 (median depth 173.0)\n",
      "[15:30:01 - Sampler] Took 0.24s to make features.\n",
      "[15:30:01 - Sampler] Region ParPgb:0.0-246.0 (341 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:30:01 - PWorker] Processed 0 batches\n",
      "[15:30:01 - PWorker] All done, 1 remainder regions.\n",
      "[15:30:01 - Predict] Processing 1 short region(s).\n",
      "[15:30:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7290491480>\n",
      "[15:30:02 - MdlStrTF] loading weights from /tmp/tmpkp2frlnu/model/variables/variables\n",
      "[15:30:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:30:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:04 - Feature] Processed ParPgb:0.0-246.0 (median depth 173.0)\n",
      "[15:30:04 - Sampler] Took 2.16s to make features.\n",
      "[15:30:04 - PWorker] Processed 1 batches\n",
      "[15:30:04 - PWorker] All done, 0 remainder regions.\n",
      "[15:30:04 - Predict] Finished processing all regions.\n",
      "[15:30:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:30:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:30:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:30:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:30:08 - Predict] Found a GPU.\n",
      "[15:30:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:30:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:30:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f231a1d9ae0>\n",
      "[15:30:09 - MdlStrTF] loading weights from /tmp/tmpd6iqexeb/model/variables/variables\n",
      "[15:30:09 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:30:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:30:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:09 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[15:30:09 - Feature] Processed ParPgb:0.0-250.0 (median depth 81.0)\n",
      "[15:30:09 - Sampler] Took 0.23s to make features.\n",
      "[15:30:09 - Sampler] Region ParPgb:0.0-250.0 (295 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:30:09 - PWorker] Processed 0 batches\n",
      "[15:30:09 - PWorker] All done, 1 remainder regions.\n",
      "[15:30:09 - Predict] Processing 1 short region(s).\n",
      "[15:30:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f228932dff0>\n",
      "[15:30:10 - MdlStrTF] loading weights from /tmp/tmpd6iqexeb/model/variables/variables\n",
      "[15:30:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[15:30:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:11 - Feature] Processed ParPgb:0.0-250.0 (median depth 81.0)\n",
      "[15:30:11 - Sampler] Took 1.61s to make features.\n",
      "[15:30:12 - PWorker] Processed 1 batches\n",
      "[15:30:12 - PWorker] All done, 0 remainder regions.\n",
      "[15:30:12 - Predict] Finished processing all regions.\n",
      "[15:30:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:30:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:30:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:30:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:30:15 - Predict] Found a GPU.\n",
      "[15:30:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:30:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:30:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd3724e5ae0>\n",
      "[15:30:17 - MdlStrTF] loading weights from /tmp/tmpgujlnjcd/model/variables/variables\n",
      "[15:30:17 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:30:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:30:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:30:17 - Feature] Processed ParPgb:0.0-246.0 (median depth 110.0)\n",
      "[15:30:17 - Sampler] Took 0.03s to make features.\n",
      "[15:30:17 - Sampler] Region ParPgb:0.0-246.0 (316 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:30:17 - PWorker] Processed 0 batches\n",
      "[15:30:17 - PWorker] All done, 1 remainder regions.\n",
      "[15:30:17 - Predict] Processing 1 short region(s).\n",
      "[15:30:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd2e16c5ea0>\n",
      "[15:30:17 - MdlStrTF] loading weights from /tmp/tmpgujlnjcd/model/variables/variables\n",
      "[15:30:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:30:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:19 - Feature] Processed ParPgb:0.0-246.0 (median depth 110.0)\n",
      "[15:30:19 - Sampler] Took 2.12s to make features.\n",
      "[15:30:20 - PWorker] Processed 1 batches\n",
      "[15:30:20 - PWorker] All done, 0 remainder regions.\n",
      "[15:30:20 - Predict] Finished processing all regions.\n",
      "[15:30:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:23 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:30:23 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:30:23 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:30:23 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:30:23 - Predict] Found a GPU.\n",
      "[15:30:23 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:30:23 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:30:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f25f6f81ae0>\n",
      "[15:30:25 - MdlStrTF] loading weights from /tmp/tmp_3z6mp4u/model/variables/variables\n",
      "[15:30:25 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:30:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:30:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:25 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-256.\n",
      "[15:30:25 - Feature] Processed ParPgb:0.0-256.0 (median depth 80.0)\n",
      "[15:30:25 - Sampler] Took 0.02s to make features.\n",
      "[15:30:25 - Sampler] Region ParPgb:0.0-256.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:30:25 - PWorker] Processed 0 batches\n",
      "[15:30:25 - PWorker] All done, 1 remainder regions.\n",
      "[15:30:25 - Predict] Processing 1 short region(s).\n",
      "[15:30:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2541f6db10>\n",
      "[15:30:25 - MdlStrTF] loading weights from /tmp/tmp_3z6mp4u/model/variables/variables\n",
      "[15:30:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-257.\n",
      "[15:30:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:25 - Feature] Processed ParPgb:0.0-256.0 (median depth 80.0)\n",
      "[15:30:25 - Sampler] Took 0.10s to make features.\n",
      "[15:30:26 - PWorker] Processed 1 batches\n",
      "[15:30:26 - PWorker] All done, 0 remainder regions.\n",
      "[15:30:26 - Predict] Finished processing all regions.\n",
      "[15:30:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:30:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:30:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:30:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:30:29 - Predict] Found a GPU.\n",
      "[15:30:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:30:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:30:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f85f2779ae0>\n",
      "[15:30:31 - MdlStrTF] loading weights from /tmp/tmplh1gbgkd/model/variables/variables\n",
      "[15:30:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:30:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:30:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[15:30:31 - Feature] Processed ParPgb:0.0-255.0 (median depth 95.0)\n",
      "[15:30:31 - Sampler] Took 0.07s to make features.\n",
      "[15:30:31 - Sampler] Region ParPgb:0.0-255.0 (306 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:30:31 - PWorker] Processed 0 batches\n",
      "[15:30:31 - PWorker] All done, 1 remainder regions.\n",
      "[15:30:31 - Predict] Processing 1 short region(s).\n",
      "[15:30:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f85618c5480>\n",
      "[15:30:31 - MdlStrTF] loading weights from /tmp/tmplh1gbgkd/model/variables/variables\n",
      "[15:30:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[15:30:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:31 - Feature] Processed ParPgb:0.0-255.0 (median depth 95.0)\n",
      "[15:30:31 - Sampler] Took 0.05s to make features.\n",
      "[15:30:32 - PWorker] Processed 1 batches\n",
      "[15:30:32 - PWorker] All done, 0 remainder regions.\n",
      "[15:30:32 - Predict] Finished processing all regions.\n",
      "[15:30:33 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:35 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:30:35 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:30:35 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:30:35 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:30:35 - Predict] Found a GPU.\n",
      "[15:30:35 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:30:35 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:30:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7eff07241ae0>\n",
      "[15:30:36 - MdlStrTF] loading weights from /tmp/tmpnoaxe21s/model/variables/variables\n",
      "[15:30:36 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:30:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:30:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:30:39 - Feature] Processed ParPgb:0.0-251.0 (median depth 171.0)\n",
      "[15:30:39 - Sampler] Took 2.17s to make features.\n",
      "[15:30:39 - Sampler] Region ParPgb:0.0-251.0 (323 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:30:39 - PWorker] Processed 0 batches\n",
      "[15:30:39 - PWorker] All done, 1 remainder regions.\n",
      "[15:30:39 - Predict] Processing 1 short region(s).\n",
      "[15:30:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efe68371fc0>\n",
      "[15:30:39 - MdlStrTF] loading weights from /tmp/tmpnoaxe21s/model/variables/variables\n",
      "[15:30:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:30:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:41 - Feature] Processed ParPgb:0.0-251.0 (median depth 171.0)\n",
      "[15:30:41 - Sampler] Took 2.36s to make features.\n",
      "[15:30:42 - PWorker] Processed 1 batches\n",
      "[15:30:42 - PWorker] All done, 0 remainder regions.\n",
      "[15:30:42 - Predict] Finished processing all regions.\n",
      "[15:30:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:45 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:30:45 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:30:45 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:30:45 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:30:45 - Predict] Found a GPU.\n",
      "[15:30:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:30:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:30:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcf726edae0>\n",
      "[15:30:47 - MdlStrTF] loading weights from /tmp/tmpcdifdesh/model/variables/variables\n",
      "[15:30:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:30:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:30:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:30:47 - Feature] Processed ParPgb:0.0-246.0 (median depth 94.0)\n",
      "[15:30:47 - Sampler] Took 0.08s to make features.\n",
      "[15:30:47 - Sampler] Region ParPgb:0.0-246.0 (304 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:30:47 - PWorker] Processed 0 batches\n",
      "[15:30:47 - PWorker] All done, 1 remainder regions.\n",
      "[15:30:47 - Predict] Processing 1 short region(s).\n",
      "[15:30:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcee18c6f20>\n",
      "[15:30:47 - MdlStrTF] loading weights from /tmp/tmpcdifdesh/model/variables/variables\n",
      "[15:30:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:30:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:47 - Feature] Processed ParPgb:0.0-246.0 (median depth 94.0)\n",
      "[15:30:47 - Sampler] Took 0.13s to make features.\n",
      "[15:30:48 - PWorker] Processed 1 batches\n",
      "[15:30:48 - PWorker] All done, 0 remainder regions.\n",
      "[15:30:48 - Predict] Finished processing all regions.\n",
      "[15:30:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:51 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:30:51 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:30:51 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:30:51 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:30:51 - Predict] Found a GPU.\n",
      "[15:30:51 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:30:51 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:30:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2ba56ddae0>\n",
      "[15:30:53 - MdlStrTF] loading weights from /tmp/tmphj2l8bjr/model/variables/variables\n",
      "[15:30:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:30:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:30:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[15:30:53 - Feature] Processed ParPgb:0.0-255.0 (median depth 132.0)\n",
      "[15:30:53 - Sampler] Took 0.03s to make features.\n",
      "[15:30:53 - Sampler] Region ParPgb:0.0-255.0 (316 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:30:53 - PWorker] Processed 0 batches\n",
      "[15:30:53 - PWorker] All done, 1 remainder regions.\n",
      "[15:30:53 - Predict] Processing 1 short region(s).\n",
      "[15:30:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2b108f1480>\n",
      "[15:30:53 - MdlStrTF] loading weights from /tmp/tmphj2l8bjr/model/variables/variables\n",
      "[15:30:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[15:30:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:53 - Feature] Processed ParPgb:0.0-255.0 (median depth 132.0)\n",
      "[15:30:53 - Sampler] Took 0.04s to make features.\n",
      "[15:30:54 - PWorker] Processed 1 batches\n",
      "[15:30:54 - PWorker] All done, 0 remainder regions.\n",
      "[15:30:54 - Predict] Finished processing all regions.\n",
      "[15:30:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:30:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:30:57 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:30:57 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:30:57 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:30:57 - Predict] Found a GPU.\n",
      "[15:30:57 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:30:57 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:30:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f66f7f09ae0>\n",
      "[15:30:59 - MdlStrTF] loading weights from /tmp/tmp51zj7m_p/model/variables/variables\n",
      "[15:30:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:30:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:30:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:30:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-208.\n",
      "[15:30:59 - Feature] Processed ParPgb:0.0-208.0 (median depth 72.0)\n",
      "[15:30:59 - Sampler] Took 0.04s to make features.\n",
      "[15:30:59 - Sampler] Region ParPgb:0.0-208.0 (249 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:30:59 - PWorker] Processed 0 batches\n",
      "[15:30:59 - PWorker] All done, 1 remainder regions.\n",
      "[15:30:59 - Predict] Processing 1 short region(s).\n",
      "[15:30:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:30:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f66680c5480>\n",
      "[15:30:59 - MdlStrTF] loading weights from /tmp/tmp51zj7m_p/model/variables/variables\n",
      "[15:30:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-209.\n",
      "[15:30:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:02 - Feature] Processed ParPgb:0.0-208.0 (median depth 72.0)\n",
      "[15:31:02 - Sampler] Took 2.86s to make features.\n",
      "[15:31:02 - PWorker] Processed 1 batches\n",
      "[15:31:02 - PWorker] All done, 0 remainder regions.\n",
      "[15:31:02 - Predict] Finished processing all regions.\n",
      "[15:31:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:06 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:31:06 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:31:06 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:31:06 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:31:06 - Predict] Found a GPU.\n",
      "[15:31:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:31:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:31:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb23fd8da80>\n",
      "[15:31:07 - MdlStrTF] loading weights from /tmp/tmpgc0m8nhx/model/variables/variables\n",
      "[15:31:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:31:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:31:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-241.\n",
      "[15:31:07 - Feature] Processed ParPgb:0.0-241.0 (median depth 160.0)\n",
      "[15:31:07 - Sampler] Took 0.04s to make features.\n",
      "[15:31:07 - Sampler] Region ParPgb:0.0-241.0 (317 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:31:07 - PWorker] Processed 0 batches\n",
      "[15:31:07 - PWorker] All done, 1 remainder regions.\n",
      "[15:31:07 - Predict] Processing 1 short region(s).\n",
      "[15:31:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb1a0e79420>\n",
      "[15:31:08 - MdlStrTF] loading weights from /tmp/tmpgc0m8nhx/model/variables/variables\n",
      "[15:31:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-242.\n",
      "[15:31:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:10 - Feature] Processed ParPgb:0.0-241.0 (median depth 160.0)\n",
      "[15:31:10 - Sampler] Took 2.15s to make features.\n",
      "[15:31:10 - PWorker] Processed 1 batches\n",
      "[15:31:10 - PWorker] All done, 0 remainder regions.\n",
      "[15:31:10 - Predict] Finished processing all regions.\n",
      "[15:31:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:31:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:31:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:31:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:31:14 - Predict] Found a GPU.\n",
      "[15:31:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:31:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:31:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f483b081ae0>\n",
      "[15:31:15 - MdlStrTF] loading weights from /tmp/tmph8k6sr_u/model/variables/variables\n",
      "[15:31:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:31:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:31:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[15:31:15 - Feature] Processed ParPgb:0.0-248.0 (median depth 134.0)\n",
      "[15:31:15 - Sampler] Took 0.10s to make features.\n",
      "[15:31:15 - Sampler] Region ParPgb:0.0-248.0 (329 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:31:15 - PWorker] Processed 0 batches\n",
      "[15:31:15 - PWorker] All done, 1 remainder regions.\n",
      "[15:31:15 - Predict] Processing 1 short region(s).\n",
      "[15:31:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f47aa22d450>\n",
      "[15:31:16 - MdlStrTF] loading weights from /tmp/tmph8k6sr_u/model/variables/variables\n",
      "[15:31:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[15:31:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:16 - Feature] Processed ParPgb:0.0-248.0 (median depth 134.0)\n",
      "[15:31:16 - Sampler] Took 0.05s to make features.\n",
      "[15:31:16 - PWorker] Processed 1 batches\n",
      "[15:31:16 - PWorker] All done, 0 remainder regions.\n",
      "[15:31:16 - Predict] Finished processing all regions.\n",
      "[15:31:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:31:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:31:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:31:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:31:20 - Predict] Found a GPU.\n",
      "[15:31:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:31:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:31:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcf0e099ae0>\n",
      "[15:31:21 - MdlStrTF] loading weights from /tmp/tmppkjxwi8r/model/variables/variables\n",
      "[15:31:21 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:31:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:31:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:22 - Sampler] Took 0.73s to make features.\n",
      "[15:31:22 - PWorker] Processed 0 batches\n",
      "[15:31:22 - PWorker] All done, 0 remainder regions.\n",
      "[15:31:22 - Predict] Finished processing all regions.\n",
      "[15:31:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:23 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:31:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:31:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:31:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:31:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:31:25 - Predict] Found a GPU.\n",
      "[15:31:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:31:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:31:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f86898a9ae0>\n",
      "[15:31:26 - MdlStrTF] loading weights from /tmp/tmp7iaadzi7/model/variables/variables\n",
      "[15:31:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:31:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:31:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:26 - Sampler] Took 0.07s to make features.\n",
      "[15:31:26 - PWorker] Processed 0 batches\n",
      "[15:31:26 - PWorker] All done, 0 remainder regions.\n",
      "[15:31:26 - Predict] Finished processing all regions.\n",
      "[15:31:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:28 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:31:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:31:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:31:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:31:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:31:30 - Predict] Found a GPU.\n",
      "[15:31:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:31:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:31:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f47ae5ddae0>\n",
      "[15:31:31 - MdlStrTF] loading weights from /tmp/tmpqb57zg1t/model/variables/variables\n",
      "[15:31:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:31:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:31:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-262.\n",
      "[15:31:31 - Feature] Processed ParPgb:0.0-262.0 (median depth 242.0)\n",
      "[15:31:31 - Sampler] Took 0.07s to make features.\n",
      "[15:31:31 - Sampler] Region ParPgb:0.0-262.0 (379 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:31:31 - PWorker] Processed 0 batches\n",
      "[15:31:31 - PWorker] All done, 1 remainder regions.\n",
      "[15:31:31 - Predict] Processing 1 short region(s).\n",
      "[15:31:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f471c56d480>\n",
      "[15:31:32 - MdlStrTF] loading weights from /tmp/tmpqb57zg1t/model/variables/variables\n",
      "[15:31:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-263.\n",
      "[15:31:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:32 - Feature] Processed ParPgb:0.0-262.0 (median depth 242.0)\n",
      "[15:31:32 - Sampler] Took 0.20s to make features.\n",
      "[15:31:32 - PWorker] Processed 1 batches\n",
      "[15:31:32 - PWorker] All done, 0 remainder regions.\n",
      "[15:31:32 - Predict] Finished processing all regions.\n",
      "[15:31:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:36 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:31:36 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:31:36 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:31:36 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:31:36 - Predict] Found a GPU.\n",
      "[15:31:36 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:31:36 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:31:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe240099ae0>\n",
      "[15:31:37 - MdlStrTF] loading weights from /tmp/tmpv3z6a499/model/variables/variables\n",
      "[15:31:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:31:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:31:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-202.\n",
      "[15:31:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:37 - Feature] Processed ParPgb:0.0-202.0 (median depth 91.0)\n",
      "[15:31:37 - Sampler] Took 0.14s to make features.\n",
      "[15:31:37 - Sampler] Region ParPgb:0.0-202.0 (256 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:31:37 - PWorker] Processed 0 batches\n",
      "[15:31:37 - PWorker] All done, 1 remainder regions.\n",
      "[15:31:37 - Predict] Processing 1 short region(s).\n",
      "[15:31:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe1b01c6320>\n",
      "[15:31:38 - MdlStrTF] loading weights from /tmp/tmpv3z6a499/model/variables/variables\n",
      "[15:31:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-203.\n",
      "[15:31:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:38 - Feature] Processed ParPgb:0.0-202.0 (median depth 91.0)\n",
      "[15:31:38 - Sampler] Took 0.15s to make features.\n",
      "[15:31:38 - PWorker] Processed 1 batches\n",
      "[15:31:38 - PWorker] All done, 0 remainder regions.\n",
      "[15:31:38 - Predict] Finished processing all regions.\n",
      "[15:31:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:31:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:31:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:31:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:31:42 - Predict] Found a GPU.\n",
      "[15:31:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:31:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:31:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4e8e4edae0>\n",
      "[15:31:43 - MdlStrTF] loading weights from /tmp/tmpzhvkqvmm/model/variables/variables\n",
      "[15:31:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:31:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:31:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:43 - Sampler] Took 0.03s to make features.\n",
      "[15:31:43 - PWorker] Processed 0 batches\n",
      "[15:31:43 - PWorker] All done, 0 remainder regions.\n",
      "[15:31:43 - Predict] Finished processing all regions.\n",
      "[15:31:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:45 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:31:46 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:31:46 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:31:46 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:31:46 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:31:46 - Predict] Found a GPU.\n",
      "[15:31:46 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:31:46 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:31:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbf53919ae0>\n",
      "[15:31:48 - MdlStrTF] loading weights from /tmp/tmp9x_srrr2/model/variables/variables\n",
      "[15:31:48 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:31:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:31:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:48 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[15:31:48 - Feature] Processed ParPgb:0.0-253.0 (median depth 201.0)\n",
      "[15:31:48 - Sampler] Took 0.05s to make features.\n",
      "[15:31:48 - Sampler] Region ParPgb:0.0-253.0 (355 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:31:48 - PWorker] Processed 0 batches\n",
      "[15:31:48 - PWorker] All done, 1 remainder regions.\n",
      "[15:31:48 - Predict] Processing 1 short region(s).\n",
      "[15:31:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbec2a49480>\n",
      "[15:31:48 - MdlStrTF] loading weights from /tmp/tmp9x_srrr2/model/variables/variables\n",
      "[15:31:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[15:31:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:48 - Feature] Processed ParPgb:0.0-253.0 (median depth 201.0)\n",
      "[15:31:48 - Sampler] Took 0.07s to make features.\n",
      "[15:31:49 - PWorker] Processed 1 batches\n",
      "[15:31:49 - PWorker] All done, 0 remainder regions.\n",
      "[15:31:49 - Predict] Finished processing all regions.\n",
      "[15:31:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:31:52 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:31:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:31:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:31:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:31:52 - Predict] Found a GPU.\n",
      "[15:31:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:31:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:31:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f66ca139ae0>\n",
      "[15:31:54 - MdlStrTF] loading weights from /tmp/tmpsup2e7q6/model/variables/variables\n",
      "[15:31:54 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:31:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:31:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:31:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[15:31:56 - Feature] Processed ParPgb:0.0-248.0 (median depth 141.0)\n",
      "[15:31:56 - Sampler] Took 2.09s to make features.\n",
      "[15:31:56 - Sampler] Region ParPgb:0.0-248.0 (302 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:31:56 - PWorker] Processed 0 batches\n",
      "[15:31:56 - PWorker] All done, 1 remainder regions.\n",
      "[15:31:56 - Predict] Processing 1 short region(s).\n",
      "[15:31:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:31:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f663932a1a0>\n",
      "[15:31:56 - MdlStrTF] loading weights from /tmp/tmpsup2e7q6/model/variables/variables\n",
      "[15:31:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[15:31:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:00 - Feature] Processed ParPgb:0.0-248.0 (median depth 141.0)\n",
      "[15:32:00 - Sampler] Took 4.00s to make features.\n",
      "[15:32:01 - PWorker] Processed 1 batches\n",
      "[15:32:01 - PWorker] All done, 0 remainder regions.\n",
      "[15:32:01 - Predict] Finished processing all regions.\n",
      "[15:32:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:32:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:32:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:32:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:32:04 - Predict] Found a GPU.\n",
      "[15:32:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:32:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:32:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa946eb5ae0>\n",
      "[15:32:06 - MdlStrTF] loading weights from /tmp/tmp5cx17_5_/model/variables/variables\n",
      "[15:32:06 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:32:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:32:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:06 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[15:32:06 - Feature] Processed ParPgb:0.0-255.0 (median depth 199.0)\n",
      "[15:32:06 - Sampler] Took 0.09s to make features.\n",
      "[15:32:06 - Sampler] Region ParPgb:0.0-255.0 (374 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:32:06 - PWorker] Processed 0 batches\n",
      "[15:32:06 - PWorker] All done, 1 remainder regions.\n",
      "[15:32:06 - Predict] Processing 1 short region(s).\n",
      "[15:32:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa891f9d480>\n",
      "[15:32:06 - MdlStrTF] loading weights from /tmp/tmp5cx17_5_/model/variables/variables\n",
      "[15:32:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[15:32:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:06 - Feature] Processed ParPgb:0.0-255.0 (median depth 199.0)\n",
      "[15:32:06 - Sampler] Took 0.07s to make features.\n",
      "[15:32:07 - PWorker] Processed 1 batches\n",
      "[15:32:07 - PWorker] All done, 0 remainder regions.\n",
      "[15:32:07 - Predict] Finished processing all regions.\n",
      "[15:32:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:10 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:32:10 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:32:10 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:32:10 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:32:10 - Predict] Found a GPU.\n",
      "[15:32:10 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:32:10 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:32:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:12 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbda0b55ae0>\n",
      "[15:32:12 - MdlStrTF] loading weights from /tmp/tmp6a6gagiq/model/variables/variables\n",
      "[15:32:12 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:32:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:32:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:21 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-230.\n",
      "[15:32:21 - Feature] Processed ParPgb:0.0-230.0 (median depth 198.0)\n",
      "[15:32:21 - Sampler] Took 9.24s to make features.\n",
      "[15:32:21 - Sampler] Region ParPgb:0.0-230.0 (345 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:32:21 - PWorker] Processed 0 batches\n",
      "[15:32:21 - PWorker] All done, 1 remainder regions.\n",
      "[15:32:21 - Predict] Processing 1 short region(s).\n",
      "[15:32:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbd01c6dfc0>\n",
      "[15:32:21 - MdlStrTF] loading weights from /tmp/tmp6a6gagiq/model/variables/variables\n",
      "[15:32:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-231.\n",
      "[15:32:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:21 - Feature] Processed ParPgb:0.0-230.0 (median depth 198.0)\n",
      "[15:32:21 - Sampler] Took 0.11s to make features.\n",
      "[15:32:22 - PWorker] Processed 1 batches\n",
      "[15:32:22 - PWorker] All done, 0 remainder regions.\n",
      "[15:32:22 - Predict] Finished processing all regions.\n",
      "[15:32:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:32:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:32:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:32:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:32:25 - Predict] Found a GPU.\n",
      "[15:32:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:32:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:32:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3626b65ae0>\n",
      "[15:32:27 - MdlStrTF] loading weights from /tmp/tmpate1qgxn/model/variables/variables\n",
      "[15:32:27 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:32:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:32:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:27 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-217.\n",
      "[15:32:27 - Feature] Processed ParPgb:0.0-217.0 (median depth 119.0)\n",
      "[15:32:27 - Sampler] Took 0.04s to make features.\n",
      "[15:32:27 - Sampler] Region ParPgb:0.0-217.0 (277 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:32:27 - PWorker] Processed 0 batches\n",
      "[15:32:27 - PWorker] All done, 1 remainder regions.\n",
      "[15:32:27 - Predict] Processing 1 short region(s).\n",
      "[15:32:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3588479450>\n",
      "[15:32:27 - MdlStrTF] loading weights from /tmp/tmpate1qgxn/model/variables/variables\n",
      "[15:32:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-218.\n",
      "[15:32:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:27 - Feature] Processed ParPgb:0.0-217.0 (median depth 119.0)\n",
      "[15:32:27 - Sampler] Took 0.05s to make features.\n",
      "[15:32:28 - PWorker] Processed 1 batches\n",
      "[15:32:28 - PWorker] All done, 0 remainder regions.\n",
      "[15:32:28 - Predict] Finished processing all regions.\n",
      "[15:32:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:32:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:32:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:32:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:32:31 - Predict] Found a GPU.\n",
      "[15:32:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:32:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:32:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f70657c5ae0>\n",
      "[15:32:32 - MdlStrTF] loading weights from /tmp/tmpj74ndwhf/model/variables/variables\n",
      "[15:32:33 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:32:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:32:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:33 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:32:33 - Feature] Processed ParPgb:0.0-246.0 (median depth 156.0)\n",
      "[15:32:33 - Sampler] Took 0.04s to make features.\n",
      "[15:32:33 - Sampler] Region ParPgb:0.0-246.0 (354 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:32:33 - PWorker] Processed 0 batches\n",
      "[15:32:33 - PWorker] All done, 1 remainder regions.\n",
      "[15:32:33 - Predict] Processing 1 short region(s).\n",
      "[15:32:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6fd0a15480>\n",
      "[15:32:33 - MdlStrTF] loading weights from /tmp/tmpj74ndwhf/model/variables/variables\n",
      "[15:32:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:32:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:38 - Feature] Processed ParPgb:0.0-246.0 (median depth 156.0)\n",
      "[15:32:38 - Sampler] Took 4.58s to make features.\n",
      "[15:32:38 - PWorker] Batches in cache: 1.\n",
      "[15:32:38 - PWorker] Processed 1 batches\n",
      "[15:32:38 - PWorker] All done, 0 remainder regions.\n",
      "[15:32:38 - Predict] Finished processing all regions.\n",
      "[15:32:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:32:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:32:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:32:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:32:42 - Predict] Found a GPU.\n",
      "[15:32:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:32:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:32:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd1b5bd9ae0>\n",
      "[15:32:43 - MdlStrTF] loading weights from /tmp/tmp6fs24qdc/model/variables/variables\n",
      "[15:32:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:32:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:32:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:32:43 - Feature] Processed ParPgb:0.0-249.0 (median depth 83.0)\n",
      "[15:32:43 - Sampler] Took 0.05s to make features.\n",
      "[15:32:43 - Sampler] Region ParPgb:0.0-249.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:32:43 - PWorker] Processed 0 batches\n",
      "[15:32:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:32:43 - Predict] Processing 1 short region(s).\n",
      "[15:32:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd12046d480>\n",
      "[15:32:43 - MdlStrTF] loading weights from /tmp/tmp6fs24qdc/model/variables/variables\n",
      "[15:32:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:32:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:43 - Feature] Processed ParPgb:0.0-249.0 (median depth 83.0)\n",
      "[15:32:43 - Sampler] Took 0.04s to make features.\n",
      "[15:32:44 - PWorker] Processed 1 batches\n",
      "[15:32:44 - PWorker] All done, 0 remainder regions.\n",
      "[15:32:44 - Predict] Finished processing all regions.\n",
      "[15:32:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:32:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:32:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:32:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:32:47 - Predict] Found a GPU.\n",
      "[15:32:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:32:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:32:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f31a747dae0>\n",
      "[15:32:49 - MdlStrTF] loading weights from /tmp/tmpwq8koqiz/model/variables/variables\n",
      "[15:32:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:32:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:32:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[15:32:49 - Feature] Processed ParPgb:0.0-254.0 (median depth 114.0)\n",
      "[15:32:49 - Sampler] Took 0.12s to make features.\n",
      "[15:32:49 - Sampler] Region ParPgb:0.0-254.0 (320 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:32:49 - PWorker] Processed 0 batches\n",
      "[15:32:49 - PWorker] All done, 1 remainder regions.\n",
      "[15:32:49 - Predict] Processing 1 short region(s).\n",
      "[15:32:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3108671b10>\n",
      "[15:32:49 - MdlStrTF] loading weights from /tmp/tmpwq8koqiz/model/variables/variables\n",
      "[15:32:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[15:32:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:49 - Feature] Processed ParPgb:0.0-254.0 (median depth 114.0)\n",
      "[15:32:49 - Sampler] Took 0.06s to make features.\n",
      "[15:32:50 - PWorker] Processed 1 batches\n",
      "[15:32:50 - PWorker] All done, 0 remainder regions.\n",
      "[15:32:50 - Predict] Finished processing all regions.\n",
      "[15:32:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:32:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:32:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:32:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:32:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:32:53 - Predict] Found a GPU.\n",
      "[15:32:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:32:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:32:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f20d5d9dae0>\n",
      "[15:32:55 - MdlStrTF] loading weights from /tmp/tmp_cnew2ft/model/variables/variables\n",
      "[15:32:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:32:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:32:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:32:59 - Feature] Processed ParPgb:0.0-252.0 (median depth 169.0)\n",
      "[15:32:59 - Sampler] Took 3.96s to make features.\n",
      "[15:32:59 - Sampler] Region ParPgb:0.0-252.0 (323 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:32:59 - PWorker] Processed 0 batches\n",
      "[15:32:59 - PWorker] All done, 1 remainder regions.\n",
      "[15:32:59 - Predict] Processing 1 short region(s).\n",
      "[15:32:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:32:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2038f121a0>\n",
      "[15:32:59 - MdlStrTF] loading weights from /tmp/tmp_cnew2ft/model/variables/variables\n",
      "[15:32:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:32:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:32:59 - Feature] Processed ParPgb:0.0-252.0 (median depth 169.0)\n",
      "[15:32:59 - Sampler] Took 0.03s to make features.\n",
      "[15:33:00 - PWorker] Processed 1 batches\n",
      "[15:33:00 - PWorker] All done, 0 remainder regions.\n",
      "[15:33:00 - Predict] Finished processing all regions.\n",
      "[15:33:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:33:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:33:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:33:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:33:03 - Predict] Found a GPU.\n",
      "[15:33:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:33:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:33:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb297e85ae0>\n",
      "[15:33:04 - MdlStrTF] loading weights from /tmp/tmpzzr8p9c5/model/variables/variables\n",
      "[15:33:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:33:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:33:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:33:05 - Feature] Processed ParPgb:0.0-244.0 (median depth 17.0)\n",
      "[15:33:05 - Sampler] Took 0.14s to make features.\n",
      "[15:33:05 - Sampler] Region ParPgb:0.0-244.0 (255 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:33:05 - PWorker] Processed 0 batches\n",
      "[15:33:05 - PWorker] All done, 1 remainder regions.\n",
      "[15:33:05 - Predict] Processing 1 short region(s).\n",
      "[15:33:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb1f8f75ae0>\n",
      "[15:33:05 - MdlStrTF] loading weights from /tmp/tmpzzr8p9c5/model/variables/variables\n",
      "[15:33:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:33:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:08 - Feature] Processed ParPgb:0.0-244.0 (median depth 17.0)\n",
      "[15:33:08 - Sampler] Took 2.55s to make features.\n",
      "[15:33:08 - PWorker] Processed 1 batches\n",
      "[15:33:08 - PWorker] All done, 0 remainder regions.\n",
      "[15:33:08 - Predict] Finished processing all regions.\n",
      "[15:33:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:33:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:33:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:33:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:33:12 - Predict] Found a GPU.\n",
      "[15:33:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:33:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:33:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd51c6e5ae0>\n",
      "[15:33:13 - MdlStrTF] loading weights from /tmp/tmpng9mn3e7/model/variables/variables\n",
      "[15:33:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:33:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:33:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[15:33:17 - Feature] Processed ParPgb:0.0-255.0 (median depth 122.0)\n",
      "[15:33:17 - Sampler] Took 4.14s to make features.\n",
      "[15:33:17 - Sampler] Region ParPgb:0.0-255.0 (335 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:33:17 - PWorker] Processed 0 batches\n",
      "[15:33:17 - PWorker] All done, 1 remainder regions.\n",
      "[15:33:17 - Predict] Processing 1 short region(s).\n",
      "[15:33:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd48c0a2ef0>\n",
      "[15:33:18 - MdlStrTF] loading weights from /tmp/tmpng9mn3e7/model/variables/variables\n",
      "[15:33:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[15:33:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:18 - Feature] Processed ParPgb:0.0-255.0 (median depth 122.0)\n",
      "[15:33:18 - Sampler] Took 0.14s to make features.\n",
      "[15:33:18 - PWorker] Processed 1 batches\n",
      "[15:33:18 - PWorker] All done, 0 remainder regions.\n",
      "[15:33:18 - Predict] Finished processing all regions.\n",
      "[15:33:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:33:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:33:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:33:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:33:22 - Predict] Found a GPU.\n",
      "[15:33:22 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:33:22 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:33:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0dfeab5ae0>\n",
      "[15:33:23 - MdlStrTF] loading weights from /tmp/tmpm4szzwim/model/variables/variables\n",
      "[15:33:23 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:33:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:33:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:23 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-201.\n",
      "[15:33:23 - Feature] Processed ParPgb:0.0-201.0 (median depth 1.0)\n",
      "[15:33:23 - Sampler] Took 0.23s to make features.\n",
      "[15:33:23 - Sampler] Region ParPgb:0.0-201.0 (204 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:33:23 - PWorker] Processed 0 batches\n",
      "[15:33:23 - PWorker] All done, 1 remainder regions.\n",
      "[15:33:23 - Predict] Processing 1 short region(s).\n",
      "[15:33:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0d6db9d480>\n",
      "[15:33:24 - MdlStrTF] loading weights from /tmp/tmpm4szzwim/model/variables/variables\n",
      "[15:33:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-202.\n",
      "[15:33:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:24 - Feature] Processed ParPgb:0.0-201.0 (median depth 1.0)\n",
      "[15:33:24 - Sampler] Took 0.08s to make features.\n",
      "[15:33:24 - PWorker] Processed 1 batches\n",
      "[15:33:24 - PWorker] All done, 0 remainder regions.\n",
      "[15:33:24 - Predict] Finished processing all regions.\n",
      "[15:33:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:28 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:33:28 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:33:28 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:33:28 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:33:28 - Predict] Found a GPU.\n",
      "[15:33:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:33:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:33:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f64dd371ae0>\n",
      "[15:33:29 - MdlStrTF] loading weights from /tmp/tmpwv0gugcg/model/variables/variables\n",
      "[15:33:29 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:33:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:33:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:29 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[15:33:29 - Feature] Processed ParPgb:0.0-247.0 (median depth 54.0)\n",
      "[15:33:29 - Sampler] Took 0.10s to make features.\n",
      "[15:33:29 - Sampler] Region ParPgb:0.0-247.0 (271 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:33:29 - PWorker] Processed 0 batches\n",
      "[15:33:29 - PWorker] All done, 1 remainder regions.\n",
      "[15:33:29 - Predict] Processing 1 short region(s).\n",
      "[15:33:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f644c565b10>\n",
      "[15:33:30 - MdlStrTF] loading weights from /tmp/tmpwv0gugcg/model/variables/variables\n",
      "[15:33:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[15:33:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:30 - Feature] Processed ParPgb:0.0-247.0 (median depth 54.0)\n",
      "[15:33:30 - Sampler] Took 0.04s to make features.\n",
      "[15:33:30 - PWorker] Processed 1 batches\n",
      "[15:33:30 - PWorker] All done, 0 remainder regions.\n",
      "[15:33:30 - Predict] Finished processing all regions.\n",
      "[15:33:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:34 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:33:34 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:33:34 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:33:34 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:33:34 - Predict] Found a GPU.\n",
      "[15:33:34 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:33:34 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:33:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbc502cdae0>\n",
      "[15:33:35 - MdlStrTF] loading weights from /tmp/tmptsa_ismd/model/variables/variables\n",
      "[15:33:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:33:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:33:35 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-263.\n",
      "[15:33:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:35 - Feature] Processed ParPgb:0.0-263.0 (median depth 137.0)\n",
      "[15:33:35 - Sampler] Took 0.14s to make features.\n",
      "[15:33:35 - Sampler] Region ParPgb:0.0-263.0 (357 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:33:35 - PWorker] Processed 0 batches\n",
      "[15:33:35 - PWorker] All done, 1 remainder regions.\n",
      "[15:33:35 - Predict] Processing 1 short region(s).\n",
      "[15:33:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbbb1412320>\n",
      "[15:33:36 - MdlStrTF] loading weights from /tmp/tmptsa_ismd/model/variables/variables\n",
      "[15:33:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-264.\n",
      "[15:33:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:36 - Feature] Processed ParPgb:0.0-263.0 (median depth 137.0)\n",
      "[15:33:36 - Sampler] Took 0.05s to make features.\n",
      "[15:33:36 - PWorker] Processed 1 batches\n",
      "[15:33:36 - PWorker] All done, 0 remainder regions.\n",
      "[15:33:36 - Predict] Finished processing all regions.\n",
      "[15:33:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:33:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:33:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:33:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:33:40 - Predict] Found a GPU.\n",
      "[15:33:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:33:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:33:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8d89c45ae0>\n",
      "[15:33:41 - MdlStrTF] loading weights from /tmp/tmpa0cjwuar/model/variables/variables\n",
      "[15:33:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:33:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:33:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:42 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-239.\n",
      "[15:33:44 - Feature] Processed ParPgb:0.0-239.0 (median depth 137.0)\n",
      "[15:33:44 - Sampler] Took 3.28s to make features.\n",
      "[15:33:44 - Sampler] Region ParPgb:0.0-239.0 (305 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:33:44 - PWorker] Processed 0 batches\n",
      "[15:33:44 - PWorker] All done, 1 remainder regions.\n",
      "[15:33:44 - Predict] Processing 1 short region(s).\n",
      "[15:33:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8ce835afb0>\n",
      "[15:33:45 - MdlStrTF] loading weights from /tmp/tmpa0cjwuar/model/variables/variables\n",
      "[15:33:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-240.\n",
      "[15:33:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:46 - Feature] Processed ParPgb:0.0-239.0 (median depth 137.0)\n",
      "[15:33:46 - Sampler] Took 0.95s to make features.\n",
      "[15:33:46 - PWorker] Processed 1 batches\n",
      "[15:33:46 - PWorker] All done, 0 remainder regions.\n",
      "[15:33:46 - Predict] Finished processing all regions.\n",
      "[15:33:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:33:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:33:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:33:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:33:50 - Predict] Found a GPU.\n",
      "[15:33:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:33:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:33:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe9f9fadae0>\n",
      "[15:33:51 - MdlStrTF] loading weights from /tmp/tmpefg6fs15/model/variables/variables\n",
      "[15:33:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:33:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:33:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-263.\n",
      "[15:33:51 - Feature] Processed ParPgb:0.0-263.0 (median depth 172.0)\n",
      "[15:33:51 - Sampler] Took 0.11s to make features.\n",
      "[15:33:51 - Sampler] Region ParPgb:0.0-263.0 (362 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:33:51 - PWorker] Processed 0 batches\n",
      "[15:33:51 - PWorker] All done, 1 remainder regions.\n",
      "[15:33:51 - Predict] Processing 1 short region(s).\n",
      "[15:33:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:33:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe968e9db10>\n",
      "[15:33:52 - MdlStrTF] loading weights from /tmp/tmpefg6fs15/model/variables/variables\n",
      "[15:33:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-264.\n",
      "[15:33:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:33:54 - Feature] Processed ParPgb:0.0-263.0 (median depth 172.0)\n",
      "[15:33:54 - Sampler] Took 2.66s to make features.\n",
      "[15:33:55 - PWorker] Processed 1 batches\n",
      "[15:33:55 - PWorker] All done, 0 remainder regions.\n",
      "[15:33:55 - Predict] Finished processing all regions.\n",
      "[15:33:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:33:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:33:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:33:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:33:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:33:58 - Predict] Found a GPU.\n",
      "[15:33:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:33:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:33:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2cde881a80>\n",
      "[15:34:00 - MdlStrTF] loading weights from /tmp/tmpvrabcpdy/model/variables/variables\n",
      "[15:34:00 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:34:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:34:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:00 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[15:34:00 - Feature] Processed ParPgb:0.0-242.0 (median depth 139.0)\n",
      "[15:34:00 - Sampler] Took 0.04s to make features.\n",
      "[15:34:00 - Sampler] Region ParPgb:0.0-242.0 (353 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:34:00 - PWorker] Processed 0 batches\n",
      "[15:34:00 - PWorker] All done, 1 remainder regions.\n",
      "[15:34:00 - Predict] Processing 1 short region(s).\n",
      "[15:34:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2c4d9a9420>\n",
      "[15:34:00 - MdlStrTF] loading weights from /tmp/tmpvrabcpdy/model/variables/variables\n",
      "[15:34:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[15:34:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:00 - Feature] Processed ParPgb:0.0-242.0 (median depth 139.0)\n",
      "[15:34:00 - Sampler] Took 0.05s to make features.\n",
      "[15:34:01 - PWorker] Processed 1 batches\n",
      "[15:34:01 - PWorker] All done, 0 remainder regions.\n",
      "[15:34:01 - Predict] Finished processing all regions.\n",
      "[15:34:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:34:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:34:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:34:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:34:04 - Predict] Found a GPU.\n",
      "[15:34:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:34:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:34:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc5249d1ae0>\n",
      "[15:34:05 - MdlStrTF] loading weights from /tmp/tmpypfxkktr/model/variables/variables\n",
      "[15:34:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:34:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:34:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:06 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:34:06 - Feature] Processed ParPgb:0.0-251.0 (median depth 127.0)\n",
      "[15:34:06 - Sampler] Took 0.02s to make features.\n",
      "[15:34:06 - Sampler] Region ParPgb:0.0-251.0 (341 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:34:06 - PWorker] Processed 0 batches\n",
      "[15:34:06 - PWorker] All done, 1 remainder regions.\n",
      "[15:34:06 - Predict] Processing 1 short region(s).\n",
      "[15:34:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc490365480>\n",
      "[15:34:06 - MdlStrTF] loading weights from /tmp/tmpypfxkktr/model/variables/variables\n",
      "[15:34:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:34:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:08 - Feature] Processed ParPgb:0.0-251.0 (median depth 127.0)\n",
      "[15:34:08 - Sampler] Took 2.35s to make features.\n",
      "[15:34:09 - PWorker] Processed 1 batches\n",
      "[15:34:09 - PWorker] All done, 0 remainder regions.\n",
      "[15:34:09 - Predict] Finished processing all regions.\n",
      "[15:34:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:34:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:34:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:34:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:34:12 - Predict] Found a GPU.\n",
      "[15:34:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:34:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:34:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9a7c979ae0>\n",
      "[15:34:14 - MdlStrTF] loading weights from /tmp/tmp6mql5x9k/model/variables/variables\n",
      "[15:34:14 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:34:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:34:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:34:14 - Feature] Processed ParPgb:0.0-252.0 (median depth 121.0)\n",
      "[15:34:14 - Sampler] Took 0.09s to make features.\n",
      "[15:34:14 - Sampler] Region ParPgb:0.0-252.0 (336 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:34:14 - PWorker] Processed 0 batches\n",
      "[15:34:14 - PWorker] All done, 1 remainder regions.\n",
      "[15:34:14 - Predict] Processing 1 short region(s).\n",
      "[15:34:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f99ec365ff0>\n",
      "[15:34:14 - MdlStrTF] loading weights from /tmp/tmp6mql5x9k/model/variables/variables\n",
      "[15:34:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:34:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:14 - Feature] Processed ParPgb:0.0-252.0 (median depth 121.0)\n",
      "[15:34:14 - Sampler] Took 0.05s to make features.\n",
      "[15:34:15 - PWorker] Processed 1 batches\n",
      "[15:34:15 - PWorker] All done, 0 remainder regions.\n",
      "[15:34:15 - Predict] Finished processing all regions.\n",
      "[15:34:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:18 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:34:18 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:34:18 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:34:18 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:34:18 - Predict] Found a GPU.\n",
      "[15:34:18 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:34:18 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:34:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8707c01ae0>\n",
      "[15:34:19 - MdlStrTF] loading weights from /tmp/tmpthmt0ff0/model/variables/variables\n",
      "[15:34:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:34:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:34:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:34:20 - Feature] Processed ParPgb:0.0-203.0 (median depth 148.0)\n",
      "[15:34:20 - Sampler] Took 0.04s to make features.\n",
      "[15:34:20 - Sampler] Region ParPgb:0.0-203.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:34:20 - PWorker] Processed 0 batches\n",
      "[15:34:20 - PWorker] All done, 1 remainder regions.\n",
      "[15:34:20 - Predict] Processing 1 short region(s).\n",
      "[15:34:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8668ca1480>\n",
      "[15:34:20 - MdlStrTF] loading weights from /tmp/tmpthmt0ff0/model/variables/variables\n",
      "[15:34:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:34:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:20 - Feature] Processed ParPgb:0.0-203.0 (median depth 148.0)\n",
      "[15:34:20 - Sampler] Took 0.06s to make features.\n",
      "[15:34:21 - PWorker] Processed 1 batches\n",
      "[15:34:21 - PWorker] All done, 0 remainder regions.\n",
      "[15:34:21 - Predict] Finished processing all regions.\n",
      "[15:34:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:34:24 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:34:24 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:34:24 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:34:24 - Predict] Found a GPU.\n",
      "[15:34:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:34:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:34:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd27fa89ae0>\n",
      "[15:34:25 - MdlStrTF] loading weights from /tmp/tmp4vt_yfp5/model/variables/variables\n",
      "[15:34:25 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:34:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:34:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:25 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:34:25 - Feature] Processed ParPgb:0.0-245.0 (median depth 101.0)\n",
      "[15:34:25 - Sampler] Took 0.02s to make features.\n",
      "[15:34:25 - Sampler] Region ParPgb:0.0-245.0 (319 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:34:25 - PWorker] Processed 0 batches\n",
      "[15:34:25 - PWorker] All done, 1 remainder regions.\n",
      "[15:34:25 - Predict] Processing 1 short region(s).\n",
      "[15:34:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd1e0411450>\n",
      "[15:34:26 - MdlStrTF] loading weights from /tmp/tmp4vt_yfp5/model/variables/variables\n",
      "[15:34:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:34:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:28 - Feature] Processed ParPgb:0.0-245.0 (median depth 101.0)\n",
      "[15:34:28 - Sampler] Took 2.47s to make features.\n",
      "[15:34:29 - PWorker] Processed 1 batches\n",
      "[15:34:29 - PWorker] All done, 0 remainder regions.\n",
      "[15:34:29 - Predict] Finished processing all regions.\n",
      "[15:34:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:32 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:34:32 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:34:32 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:34:32 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:34:32 - Predict] Found a GPU.\n",
      "[15:34:32 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:34:32 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:34:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9f45229ae0>\n",
      "[15:34:34 - MdlStrTF] loading weights from /tmp/tmprzrfduwi/model/variables/variables\n",
      "[15:34:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:34:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:34:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:34:34 - Feature] Processed ParPgb:0.0-203.0 (median depth 125.0)\n",
      "[15:34:34 - Sampler] Took 0.18s to make features.\n",
      "[15:34:34 - Sampler] Region ParPgb:0.0-203.0 (277 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:34:34 - PWorker] Processed 0 batches\n",
      "[15:34:34 - PWorker] All done, 1 remainder regions.\n",
      "[15:34:34 - Predict] Processing 1 short region(s).\n",
      "[15:34:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9eb0465ff0>\n",
      "[15:34:34 - MdlStrTF] loading weights from /tmp/tmprzrfduwi/model/variables/variables\n",
      "[15:34:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:34:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:34 - Feature] Processed ParPgb:0.0-203.0 (median depth 125.0)\n",
      "[15:34:34 - Sampler] Took 0.14s to make features.\n",
      "[15:34:35 - PWorker] Processed 1 batches\n",
      "[15:34:35 - PWorker] All done, 0 remainder regions.\n",
      "[15:34:35 - Predict] Finished processing all regions.\n",
      "[15:34:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:34:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:34:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:34:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:34:38 - Predict] Found a GPU.\n",
      "[15:34:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:34:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:34:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f17177f1ae0>\n",
      "[15:34:40 - MdlStrTF] loading weights from /tmp/tmpu2juyfum/model/variables/variables\n",
      "[15:34:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:34:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:34:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:40 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:34:40 - Feature] Processed ParPgb:0.0-251.0 (median depth 122.0)\n",
      "[15:34:40 - Sampler] Took 0.04s to make features.\n",
      "[15:34:40 - Sampler] Region ParPgb:0.0-251.0 (332 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:34:40 - PWorker] Processed 0 batches\n",
      "[15:34:40 - PWorker] All done, 1 remainder regions.\n",
      "[15:34:40 - Predict] Processing 1 short region(s).\n",
      "[15:34:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1678915480>\n",
      "[15:34:40 - MdlStrTF] loading weights from /tmp/tmpu2juyfum/model/variables/variables\n",
      "[15:34:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:34:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:40 - Feature] Processed ParPgb:0.0-251.0 (median depth 122.0)\n",
      "[15:34:40 - Sampler] Took 0.06s to make features.\n",
      "[15:34:41 - PWorker] Processed 1 batches\n",
      "[15:34:41 - PWorker] All done, 0 remainder regions.\n",
      "[15:34:41 - Predict] Finished processing all regions.\n",
      "[15:34:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:44 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:34:44 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:34:44 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:34:44 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:34:44 - Predict] Found a GPU.\n",
      "[15:34:44 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:34:44 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:34:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb3395ada80>\n",
      "[15:34:46 - MdlStrTF] loading weights from /tmp/tmpzli6aps1/model/variables/variables\n",
      "[15:34:46 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:34:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:34:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:50 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[15:34:50 - Feature] Processed ParPgb:0.0-238.0 (median depth 16.0)\n",
      "[15:34:50 - Sampler] Took 4.09s to make features.\n",
      "[15:34:50 - Sampler] Region ParPgb:0.0-238.0 (246 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:34:50 - PWorker] Processed 0 batches\n",
      "[15:34:50 - PWorker] All done, 1 remainder regions.\n",
      "[15:34:50 - Predict] Processing 1 short region(s).\n",
      "[15:34:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb2a84a53f0>\n",
      "[15:34:50 - MdlStrTF] loading weights from /tmp/tmpzli6aps1/model/variables/variables\n",
      "[15:34:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[15:34:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:50 - Feature] Processed ParPgb:0.0-238.0 (median depth 16.0)\n",
      "[15:34:50 - Sampler] Took 0.08s to make features.\n",
      "[15:34:51 - PWorker] Processed 1 batches\n",
      "[15:34:51 - PWorker] All done, 0 remainder regions.\n",
      "[15:34:51 - Predict] Finished processing all regions.\n",
      "[15:34:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:34:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:34:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:34:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:34:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:34:54 - Predict] Found a GPU.\n",
      "[15:34:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:34:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:34:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc9af8a9ae0>\n",
      "[15:34:56 - MdlStrTF] loading weights from /tmp/tmpru8_ajtq/model/variables/variables\n",
      "[15:34:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:34:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:34:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:34:56 - Feature] Processed ParPgb:0.0-203.0 (median depth 83.0)\n",
      "[15:34:56 - Sampler] Took 0.09s to make features.\n",
      "[15:34:56 - Sampler] Region ParPgb:0.0-203.0 (245 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:34:56 - PWorker] Processed 0 batches\n",
      "[15:34:56 - PWorker] All done, 1 remainder regions.\n",
      "[15:34:56 - Predict] Processing 1 short region(s).\n",
      "[15:34:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:34:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc9201f1fc0>\n",
      "[15:34:56 - MdlStrTF] loading weights from /tmp/tmpru8_ajtq/model/variables/variables\n",
      "[15:34:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:34:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:34:59 - Feature] Processed ParPgb:0.0-203.0 (median depth 83.0)\n",
      "[15:34:59 - Sampler] Took 2.31s to make features.\n",
      "[15:34:59 - PWorker] Processed 1 batches\n",
      "[15:34:59 - PWorker] All done, 0 remainder regions.\n",
      "[15:34:59 - Predict] Finished processing all regions.\n",
      "[15:35:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:35:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:35:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:35:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:35:03 - Predict] Found a GPU.\n",
      "[15:35:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:35:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:35:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0406c9da80>\n",
      "[15:35:04 - MdlStrTF] loading weights from /tmp/tmprw8ikmut/model/variables/variables\n",
      "[15:35:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:35:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:35:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-207.\n",
      "[15:35:04 - Feature] Processed ParPgb:0.0-207.0 (median depth 113.0)\n",
      "[15:35:04 - Sampler] Took 0.10s to make features.\n",
      "[15:35:04 - Sampler] Region ParPgb:0.0-207.0 (285 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:35:04 - PWorker] Processed 0 batches\n",
      "[15:35:04 - PWorker] All done, 1 remainder regions.\n",
      "[15:35:04 - Predict] Processing 1 short region(s).\n",
      "[15:35:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0368671f90>\n",
      "[15:35:04 - MdlStrTF] loading weights from /tmp/tmprw8ikmut/model/variables/variables\n",
      "[15:35:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-208.\n",
      "[15:35:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:04 - Feature] Processed ParPgb:0.0-207.0 (median depth 113.0)\n",
      "[15:35:04 - Sampler] Took 0.04s to make features.\n",
      "[15:35:05 - PWorker] Processed 1 batches\n",
      "[15:35:05 - PWorker] All done, 0 remainder regions.\n",
      "[15:35:05 - Predict] Finished processing all regions.\n",
      "[15:35:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:35:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:35:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:35:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:35:08 - Predict] Found a GPU.\n",
      "[15:35:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:35:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:35:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f813a5e9ae0>\n",
      "[15:35:10 - MdlStrTF] loading weights from /tmp/tmp4argm60z/model/variables/variables\n",
      "[15:35:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:35:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:35:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:10 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-258.\n",
      "[15:35:10 - Feature] Processed ParPgb:0.0-258.0 (median depth 98.0)\n",
      "[15:35:10 - Sampler] Took 0.03s to make features.\n",
      "[15:35:10 - Sampler] Region ParPgb:0.0-258.0 (314 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:35:10 - PWorker] Processed 0 batches\n",
      "[15:35:10 - PWorker] All done, 1 remainder regions.\n",
      "[15:35:10 - Predict] Processing 1 short region(s).\n",
      "[15:35:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f80a94cd480>\n",
      "[15:35:10 - MdlStrTF] loading weights from /tmp/tmp4argm60z/model/variables/variables\n",
      "[15:35:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-259.\n",
      "[15:35:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:10 - Feature] Processed ParPgb:0.0-258.0 (median depth 98.0)\n",
      "[15:35:10 - Sampler] Took 0.09s to make features.\n",
      "[15:35:11 - PWorker] Processed 1 batches\n",
      "[15:35:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:35:11 - Predict] Finished processing all regions.\n",
      "[15:35:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:35:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:35:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:35:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:35:14 - Predict] Found a GPU.\n",
      "[15:35:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:35:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:35:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbce7019a80>\n",
      "[15:35:16 - MdlStrTF] loading weights from /tmp/tmpn5zx7tqh/model/variables/variables\n",
      "[15:35:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:35:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:35:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[15:35:16 - Feature] Processed ParPgb:0.0-242.0 (median depth 116.0)\n",
      "[15:35:16 - Sampler] Took 0.03s to make features.\n",
      "[15:35:16 - Sampler] Region ParPgb:0.0-242.0 (311 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:35:16 - PWorker] Processed 0 batches\n",
      "[15:35:16 - PWorker] All done, 1 remainder regions.\n",
      "[15:35:16 - Predict] Processing 1 short region(s).\n",
      "[15:35:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbc4823d420>\n",
      "[15:35:16 - MdlStrTF] loading weights from /tmp/tmpn5zx7tqh/model/variables/variables\n",
      "[15:35:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[15:35:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:16 - Feature] Processed ParPgb:0.0-242.0 (median depth 116.0)\n",
      "[15:35:16 - Sampler] Took 0.17s to make features.\n",
      "[15:35:17 - PWorker] Processed 1 batches\n",
      "[15:35:17 - PWorker] All done, 0 remainder regions.\n",
      "[15:35:17 - Predict] Finished processing all regions.\n",
      "[15:35:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:35:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:35:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:35:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:35:20 - Predict] Found a GPU.\n",
      "[15:35:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:35:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:35:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9b5af35ae0>\n",
      "[15:35:22 - MdlStrTF] loading weights from /tmp/tmp5up6z_f9/model/variables/variables\n",
      "[15:35:22 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:35:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:35:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:22 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:35:22 - Feature] Processed ParPgb:0.0-251.0 (median depth 114.0)\n",
      "[15:35:22 - Sampler] Took 0.08s to make features.\n",
      "[15:35:22 - Sampler] Region ParPgb:0.0-251.0 (321 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:35:22 - PWorker] Processed 0 batches\n",
      "[15:35:22 - PWorker] All done, 1 remainder regions.\n",
      "[15:35:22 - Predict] Processing 1 short region(s).\n",
      "[15:35:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9aca0ca1a0>\n",
      "[15:35:22 - MdlStrTF] loading weights from /tmp/tmp5up6z_f9/model/variables/variables\n",
      "[15:35:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:35:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:22 - Feature] Processed ParPgb:0.0-251.0 (median depth 114.0)\n",
      "[15:35:22 - Sampler] Took 0.04s to make features.\n",
      "[15:35:23 - PWorker] Processed 1 batches\n",
      "[15:35:23 - PWorker] All done, 0 remainder regions.\n",
      "[15:35:23 - Predict] Finished processing all regions.\n",
      "[15:35:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:26 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:35:26 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:35:26 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:35:26 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:35:26 - Predict] Found a GPU.\n",
      "[15:35:26 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:35:26 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:35:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9806bb5ae0>\n",
      "[15:35:27 - MdlStrTF] loading weights from /tmp/tmp8lkh99r0/model/variables/variables\n",
      "[15:35:28 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:35:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:35:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:28 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[15:35:28 - Feature] Processed ParPgb:0.0-253.0 (median depth 158.0)\n",
      "[15:35:28 - Sampler] Took 0.12s to make features.\n",
      "[15:35:28 - Sampler] Region ParPgb:0.0-253.0 (329 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:35:28 - PWorker] Processed 0 batches\n",
      "[15:35:28 - PWorker] All done, 1 remainder regions.\n",
      "[15:35:28 - Predict] Processing 1 short region(s).\n",
      "[15:35:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9768471ae0>\n",
      "[15:35:28 - MdlStrTF] loading weights from /tmp/tmp8lkh99r0/model/variables/variables\n",
      "[15:35:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[15:35:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:28 - Feature] Processed ParPgb:0.0-253.0 (median depth 158.0)\n",
      "[15:35:28 - Sampler] Took 0.13s to make features.\n",
      "[15:35:29 - PWorker] Processed 1 batches\n",
      "[15:35:29 - PWorker] All done, 0 remainder regions.\n",
      "[15:35:29 - Predict] Finished processing all regions.\n",
      "[15:35:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:32 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:35:32 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:35:32 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:35:32 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:35:32 - Predict] Found a GPU.\n",
      "[15:35:32 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:35:32 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:35:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc5224c9ae0>\n",
      "[15:35:33 - MdlStrTF] loading weights from /tmp/tmp3a5nf1al/model/variables/variables\n",
      "[15:35:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:35:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:35:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:35:34 - Feature] Processed ParPgb:0.0-246.0 (median depth 102.0)\n",
      "[15:35:34 - Sampler] Took 0.03s to make features.\n",
      "[15:35:34 - Sampler] Region ParPgb:0.0-246.0 (286 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:35:34 - PWorker] Processed 0 batches\n",
      "[15:35:34 - PWorker] All done, 1 remainder regions.\n",
      "[15:35:34 - Predict] Processing 1 short region(s).\n",
      "[15:35:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc4916c5480>\n",
      "[15:35:34 - MdlStrTF] loading weights from /tmp/tmp3a5nf1al/model/variables/variables\n",
      "[15:35:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:35:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:35 - Feature] Processed ParPgb:0.0-246.0 (median depth 102.0)\n",
      "[15:35:35 - Sampler] Took 0.86s to make features.\n",
      "[15:35:35 - PWorker] Processed 1 batches\n",
      "[15:35:35 - PWorker] All done, 0 remainder regions.\n",
      "[15:35:35 - Predict] Finished processing all regions.\n",
      "[15:35:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:39 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:35:39 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:35:39 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:35:39 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:35:39 - Predict] Found a GPU.\n",
      "[15:35:39 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:35:39 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:35:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc039301ae0>\n",
      "[15:35:40 - MdlStrTF] loading weights from /tmp/tmp432ci7ya/model/variables/variables\n",
      "[15:35:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:35:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:35:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:35:43 - Feature] Processed ParPgb:0.0-203.0 (median depth 42.0)\n",
      "[15:35:43 - Sampler] Took 2.39s to make features.\n",
      "[15:35:43 - Sampler] Region ParPgb:0.0-203.0 (227 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:35:43 - PWorker] Processed 0 batches\n",
      "[15:35:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:35:43 - Predict] Processing 1 short region(s).\n",
      "[15:35:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbfa8461480>\n",
      "[15:35:43 - MdlStrTF] loading weights from /tmp/tmp432ci7ya/model/variables/variables\n",
      "[15:35:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:35:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:43 - Feature] Processed ParPgb:0.0-203.0 (median depth 42.0)\n",
      "[15:35:43 - Sampler] Took 0.08s to make features.\n",
      "[15:35:44 - PWorker] Processed 1 batches\n",
      "[15:35:44 - PWorker] All done, 0 remainder regions.\n",
      "[15:35:44 - Predict] Finished processing all regions.\n",
      "[15:35:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:35:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:35:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:35:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:35:47 - Predict] Found a GPU.\n",
      "[15:35:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:35:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:35:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fed7fed9ae0>\n",
      "[15:35:48 - MdlStrTF] loading weights from /tmp/tmpywzinlrm/model/variables/variables\n",
      "[15:35:48 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:35:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:35:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:48 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[15:35:49 - Feature] Processed ParPgb:0.0-242.0 (median depth 73.0)\n",
      "[15:35:49 - Sampler] Took 0.03s to make features.\n",
      "[15:35:49 - Sampler] Region ParPgb:0.0-242.0 (289 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:35:49 - PWorker] Processed 0 batches\n",
      "[15:35:49 - PWorker] All done, 1 remainder regions.\n",
      "[15:35:49 - Predict] Processing 1 short region(s).\n",
      "[15:35:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fecf00c1450>\n",
      "[15:35:49 - MdlStrTF] loading weights from /tmp/tmpywzinlrm/model/variables/variables\n",
      "[15:35:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[15:35:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:49 - Feature] Processed ParPgb:0.0-242.0 (median depth 73.0)\n",
      "[15:35:49 - Sampler] Took 0.06s to make features.\n",
      "[15:35:50 - PWorker] Processed 1 batches\n",
      "[15:35:50 - PWorker] All done, 0 remainder regions.\n",
      "[15:35:50 - Predict] Finished processing all regions.\n",
      "[15:35:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:35:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:35:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:35:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:35:53 - Predict] Found a GPU.\n",
      "[15:35:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:35:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:35:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4ca32c5ae0>\n",
      "[15:35:54 - MdlStrTF] loading weights from /tmp/tmpa2tn6g0v/model/variables/variables\n",
      "[15:35:54 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:35:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:35:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:54 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-235.\n",
      "[15:35:54 - Feature] Processed ParPgb:0.0-235.0 (median depth 18.0)\n",
      "[15:35:54 - Sampler] Took 0.11s to make features.\n",
      "[15:35:54 - Sampler] Region ParPgb:0.0-235.0 (237 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:35:54 - PWorker] Processed 0 batches\n",
      "[15:35:54 - PWorker] All done, 1 remainder regions.\n",
      "[15:35:54 - Predict] Processing 1 short region(s).\n",
      "[15:35:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:35:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4c12429ae0>\n",
      "[15:35:55 - MdlStrTF] loading weights from /tmp/tmpa2tn6g0v/model/variables/variables\n",
      "[15:35:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-236.\n",
      "[15:35:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:35:57 - Feature] Processed ParPgb:0.0-235.0 (median depth 18.0)\n",
      "[15:35:57 - Sampler] Took 2.24s to make features.\n",
      "[15:35:58 - PWorker] Processed 1 batches\n",
      "[15:35:58 - PWorker] All done, 0 remainder regions.\n",
      "[15:35:58 - Predict] Finished processing all regions.\n",
      "[15:35:59 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:35:59 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:01 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:36:01 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:36:01 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:36:01 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:36:01 - Predict] Found a GPU.\n",
      "[15:36:01 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:36:01 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:36:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2729a75ae0>\n",
      "[15:36:02 - MdlStrTF] loading weights from /tmp/tmpif9jrcmu/model/variables/variables\n",
      "[15:36:02 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:36:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:36:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:03 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-257.\n",
      "[15:36:03 - Feature] Processed ParPgb:0.0-257.0 (median depth 99.0)\n",
      "[15:36:03 - Sampler] Took 0.09s to make features.\n",
      "[15:36:03 - Sampler] Region ParPgb:0.0-257.0 (309 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:36:03 - PWorker] Processed 0 batches\n",
      "[15:36:03 - PWorker] All done, 1 remainder regions.\n",
      "[15:36:03 - Predict] Processing 1 short region(s).\n",
      "[15:36:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2698489990>\n",
      "[15:36:03 - MdlStrTF] loading weights from /tmp/tmpif9jrcmu/model/variables/variables\n",
      "[15:36:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-258.\n",
      "[15:36:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:03 - Feature] Processed ParPgb:0.0-257.0 (median depth 99.0)\n",
      "[15:36:03 - Sampler] Took 0.08s to make features.\n",
      "[15:36:04 - PWorker] Processed 1 batches\n",
      "[15:36:04 - PWorker] All done, 0 remainder regions.\n",
      "[15:36:04 - Predict] Finished processing all regions.\n",
      "[15:36:05 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:05 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:07 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:36:07 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:36:07 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:36:07 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:36:07 - Predict] Found a GPU.\n",
      "[15:36:07 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:36:07 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:36:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3a7e329ae0>\n",
      "[15:36:08 - MdlStrTF] loading weights from /tmp/tmp6ladomh3/model/variables/variables\n",
      "[15:36:08 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:36:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:36:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:08 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-209.\n",
      "[15:36:08 - Feature] Processed ParPgb:0.0-209.0 (median depth 251.0)\n",
      "[15:36:08 - Sampler] Took 0.13s to make features.\n",
      "[15:36:08 - Sampler] Region ParPgb:0.0-209.0 (339 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:36:09 - PWorker] Processed 0 batches\n",
      "[15:36:09 - PWorker] All done, 1 remainder regions.\n",
      "[15:36:09 - Predict] Processing 1 short region(s).\n",
      "[15:36:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f39ed39ee90>\n",
      "[15:36:09 - MdlStrTF] loading weights from /tmp/tmp6ladomh3/model/variables/variables\n",
      "[15:36:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-210.\n",
      "[15:36:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:09 - Feature] Processed ParPgb:0.0-209.0 (median depth 251.0)\n",
      "[15:36:09 - Sampler] Took 0.04s to make features.\n",
      "[15:36:10 - PWorker] Processed 1 batches\n",
      "[15:36:10 - PWorker] All done, 0 remainder regions.\n",
      "[15:36:10 - Predict] Finished processing all regions.\n",
      "[15:36:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:13 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:36:13 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:36:13 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:36:13 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:36:13 - Predict] Found a GPU.\n",
      "[15:36:13 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:36:13 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:36:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3cea3f9ae0>\n",
      "[15:36:14 - MdlStrTF] loading weights from /tmp/tmpnb0ac6ot/model/variables/variables\n",
      "[15:36:14 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:36:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:36:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-206.\n",
      "[15:36:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:14 - Feature] Processed ParPgb:0.0-206.0 (median depth 152.0)\n",
      "[15:36:14 - Sampler] Took 0.04s to make features.\n",
      "[15:36:14 - Sampler] Region ParPgb:0.0-206.0 (313 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:36:14 - PWorker] Processed 0 batches\n",
      "[15:36:14 - PWorker] All done, 1 remainder regions.\n",
      "[15:36:14 - Predict] Processing 1 short region(s).\n",
      "[15:36:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3c595ca3b0>\n",
      "[15:36:15 - MdlStrTF] loading weights from /tmp/tmpnb0ac6ot/model/variables/variables\n",
      "[15:36:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-207.\n",
      "[15:36:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:15 - Feature] Processed ParPgb:0.0-206.0 (median depth 152.0)\n",
      "[15:36:15 - Sampler] Took 0.06s to make features.\n",
      "[15:36:15 - PWorker] Processed 1 batches\n",
      "[15:36:15 - PWorker] All done, 0 remainder regions.\n",
      "[15:36:15 - Predict] Finished processing all regions.\n",
      "[15:36:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:36:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:36:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:36:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:36:19 - Predict] Found a GPU.\n",
      "[15:36:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:36:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:36:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f79b2929ae0>\n",
      "[15:36:20 - MdlStrTF] loading weights from /tmp/tmp8mfuuv1m/model/variables/variables\n",
      "[15:36:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:36:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:36:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-259.\n",
      "[15:36:20 - Feature] Processed ParPgb:0.0-259.0 (median depth 226.0)\n",
      "[15:36:20 - Sampler] Took 0.08s to make features.\n",
      "[15:36:20 - Sampler] Region ParPgb:0.0-259.0 (402 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:36:20 - PWorker] Processed 0 batches\n",
      "[15:36:20 - PWorker] All done, 1 remainder regions.\n",
      "[15:36:20 - Predict] Processing 1 short region(s).\n",
      "[15:36:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7921b55450>\n",
      "[15:36:21 - MdlStrTF] loading weights from /tmp/tmp8mfuuv1m/model/variables/variables\n",
      "[15:36:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-260.\n",
      "[15:36:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:21 - Feature] Processed ParPgb:0.0-259.0 (median depth 226.0)\n",
      "[15:36:21 - Sampler] Took 0.10s to make features.\n",
      "[15:36:21 - PWorker] Processed 1 batches\n",
      "[15:36:21 - PWorker] All done, 0 remainder regions.\n",
      "[15:36:21 - Predict] Finished processing all regions.\n",
      "[15:36:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:36:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:36:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:36:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:36:25 - Predict] Found a GPU.\n",
      "[15:36:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:36:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:36:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f55e5de1ae0>\n",
      "[15:36:26 - MdlStrTF] loading weights from /tmp/tmp_xxld31h/model/variables/variables\n",
      "[15:36:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:36:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:36:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:30 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-236.\n",
      "[15:36:30 - Feature] Processed ParPgb:0.0-236.0 (median depth 111.0)\n",
      "[15:36:30 - Sampler] Took 3.54s to make features.\n",
      "[15:36:30 - Sampler] Region ParPgb:0.0-236.0 (311 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:36:30 - PWorker] Processed 0 batches\n",
      "[15:36:30 - PWorker] All done, 1 remainder regions.\n",
      "[15:36:30 - Predict] Processing 1 short region(s).\n",
      "[15:36:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5550f11450>\n",
      "[15:36:30 - MdlStrTF] loading weights from /tmp/tmp_xxld31h/model/variables/variables\n",
      "[15:36:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-237.\n",
      "[15:36:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:30 - Feature] Processed ParPgb:0.0-236.0 (median depth 111.0)\n",
      "[15:36:30 - Sampler] Took 0.08s to make features.\n",
      "[15:36:31 - PWorker] Processed 1 batches\n",
      "[15:36:31 - PWorker] All done, 0 remainder regions.\n",
      "[15:36:31 - Predict] Finished processing all regions.\n",
      "[15:36:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:34 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:36:34 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:36:34 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:36:34 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:36:34 - Predict] Found a GPU.\n",
      "[15:36:34 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:36:34 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:36:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8474aadae0>\n",
      "[15:36:35 - MdlStrTF] loading weights from /tmp/tmp1zndaax3/model/variables/variables\n",
      "[15:36:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:36:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:36:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:35 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-258.\n",
      "[15:36:35 - Feature] Processed ParPgb:0.0-258.0 (median depth 58.0)\n",
      "[15:36:35 - Sampler] Took 0.07s to make features.\n",
      "[15:36:35 - Sampler] Region ParPgb:0.0-258.0 (294 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:36:35 - PWorker] Processed 0 batches\n",
      "[15:36:35 - PWorker] All done, 1 remainder regions.\n",
      "[15:36:35 - Predict] Processing 1 short region(s).\n",
      "[15:36:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f83b1c6a1a0>\n",
      "[15:36:36 - MdlStrTF] loading weights from /tmp/tmp1zndaax3/model/variables/variables\n",
      "[15:36:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-259.\n",
      "[15:36:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:37 - Feature] Processed ParPgb:0.0-258.0 (median depth 58.0)\n",
      "[15:36:37 - Sampler] Took 0.72s to make features.\n",
      "[15:36:37 - PWorker] Processed 1 batches\n",
      "[15:36:37 - PWorker] All done, 0 remainder regions.\n",
      "[15:36:37 - Predict] Finished processing all regions.\n",
      "[15:36:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:36:41 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:36:41 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:36:41 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:36:41 - Predict] Found a GPU.\n",
      "[15:36:41 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:36:41 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:36:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f328e789ae0>\n",
      "[15:36:42 - MdlStrTF] loading weights from /tmp/tmppv8klecj/model/variables/variables\n",
      "[15:36:42 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:36:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:36:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-233.\n",
      "[15:36:43 - Feature] Processed ParPgb:0.0-233.0 (median depth 165.0)\n",
      "[15:36:43 - Sampler] Took 1.41s to make features.\n",
      "[15:36:43 - Sampler] Region ParPgb:0.0-233.0 (346 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:36:43 - PWorker] Processed 0 batches\n",
      "[15:36:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:36:43 - Predict] Processing 1 short region(s).\n",
      "[15:36:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f31fc0adff0>\n",
      "[15:36:44 - MdlStrTF] loading weights from /tmp/tmppv8klecj/model/variables/variables\n",
      "[15:36:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-234.\n",
      "[15:36:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:44 - Feature] Processed ParPgb:0.0-233.0 (median depth 165.0)\n",
      "[15:36:44 - Sampler] Took 0.09s to make features.\n",
      "[15:36:45 - PWorker] Processed 1 batches\n",
      "[15:36:45 - PWorker] All done, 0 remainder regions.\n",
      "[15:36:45 - Predict] Finished processing all regions.\n",
      "[15:36:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:48 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:36:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:36:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:36:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:36:48 - Predict] Found a GPU.\n",
      "[15:36:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:36:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:36:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7349509ae0>\n",
      "[15:36:49 - MdlStrTF] loading weights from /tmp/tmpeuoi63lr/model/variables/variables\n",
      "[15:36:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:36:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:36:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:36:51 - Feature] Processed ParPgb:0.0-244.0 (median depth 122.0)\n",
      "[15:36:51 - Sampler] Took 1.27s to make features.\n",
      "[15:36:51 - Sampler] Region ParPgb:0.0-244.0 (306 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:36:51 - PWorker] Processed 0 batches\n",
      "[15:36:51 - PWorker] All done, 1 remainder regions.\n",
      "[15:36:51 - Predict] Processing 1 short region(s).\n",
      "[15:36:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f72b86c9b10>\n",
      "[15:36:51 - MdlStrTF] loading weights from /tmp/tmpeuoi63lr/model/variables/variables\n",
      "[15:36:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:36:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:36:53 - Feature] Processed ParPgb:0.0-244.0 (median depth 122.0)\n",
      "[15:36:53 - Sampler] Took 1.93s to make features.\n",
      "[15:36:53 - PWorker] Processed 1 batches\n",
      "[15:36:53 - PWorker] All done, 0 remainder regions.\n",
      "[15:36:53 - Predict] Finished processing all regions.\n",
      "[15:36:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:36:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:36:57 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:36:57 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:36:57 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:36:57 - Predict] Found a GPU.\n",
      "[15:36:57 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:36:57 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:36:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:36:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1f5d285a80>\n",
      "[15:36:58 - MdlStrTF] loading weights from /tmp/tmpb_fv8xjf/model/variables/variables\n",
      "[15:36:58 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:36:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:36:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-264.\n",
      "[15:37:01 - Feature] Processed ParPgb:0.0-264.0 (median depth 102.0)\n",
      "[15:37:01 - Sampler] Took 2.28s to make features.\n",
      "[15:37:01 - Sampler] Region ParPgb:0.0-264.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:37:01 - PWorker] Processed 0 batches\n",
      "[15:37:01 - PWorker] All done, 1 remainder regions.\n",
      "[15:37:01 - Predict] Processing 1 short region(s).\n",
      "[15:37:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1ecc3ce110>\n",
      "[15:37:01 - MdlStrTF] loading weights from /tmp/tmpb_fv8xjf/model/variables/variables\n",
      "[15:37:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-265.\n",
      "[15:37:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:01 - Feature] Processed ParPgb:0.0-264.0 (median depth 102.0)\n",
      "[15:37:01 - Sampler] Took 0.04s to make features.\n",
      "[15:37:02 - PWorker] Processed 1 batches\n",
      "[15:37:02 - PWorker] All done, 0 remainder regions.\n",
      "[15:37:02 - Predict] Finished processing all regions.\n",
      "[15:37:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:37:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:37:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:37:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:37:05 - Predict] Found a GPU.\n",
      "[15:37:05 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:37:05 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:37:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc834aada80>\n",
      "[15:37:06 - MdlStrTF] loading weights from /tmp/tmpbscajoo6/model/variables/variables\n",
      "[15:37:06 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:37:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:37:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:37:07 - Feature] Processed ParPgb:0.0-203.0 (median depth 108.0)\n",
      "[15:37:07 - Sampler] Took 0.21s to make features.\n",
      "[15:37:07 - Sampler] Region ParPgb:0.0-203.0 (270 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:37:07 - PWorker] Processed 0 batches\n",
      "[15:37:07 - PWorker] All done, 1 remainder regions.\n",
      "[15:37:07 - Predict] Processing 1 short region(s).\n",
      "[15:37:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc7703bdf60>\n",
      "[15:37:07 - MdlStrTF] loading weights from /tmp/tmpbscajoo6/model/variables/variables\n",
      "[15:37:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:37:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:08 - Feature] Processed ParPgb:0.0-203.0 (median depth 108.0)\n",
      "[15:37:08 - Sampler] Took 1.43s to make features.\n",
      "[15:37:09 - PWorker] Processed 1 batches\n",
      "[15:37:09 - PWorker] All done, 0 remainder regions.\n",
      "[15:37:09 - Predict] Finished processing all regions.\n",
      "[15:37:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:37:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:37:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:37:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:37:12 - Predict] Found a GPU.\n",
      "[15:37:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:37:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:37:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7e230f1ae0>\n",
      "[15:37:14 - MdlStrTF] loading weights from /tmp/tmpbxtclyh_/model/variables/variables\n",
      "[15:37:14 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:37:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:37:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:18 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-207.\n",
      "[15:37:18 - Feature] Processed ParPgb:0.0-207.0 (median depth 161.0)\n",
      "[15:37:18 - Sampler] Took 4.22s to make features.\n",
      "[15:37:18 - Sampler] Region ParPgb:0.0-207.0 (293 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:37:18 - PWorker] Processed 0 batches\n",
      "[15:37:18 - PWorker] All done, 1 remainder regions.\n",
      "[15:37:18 - Predict] Processing 1 short region(s).\n",
      "[15:37:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7d9013d480>\n",
      "[15:37:18 - MdlStrTF] loading weights from /tmp/tmpbxtclyh_/model/variables/variables\n",
      "[15:37:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-208.\n",
      "[15:37:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:23 - Feature] Processed ParPgb:0.0-207.0 (median depth 161.0)\n",
      "[15:37:23 - Sampler] Took 4.54s to make features.\n",
      "[15:37:23 - PWorker] Batches in cache: 1.\n",
      "[15:37:23 - PWorker] Processed 1 batches\n",
      "[15:37:23 - PWorker] All done, 0 remainder regions.\n",
      "[15:37:23 - Predict] Finished processing all regions.\n",
      "[15:37:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:27 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:37:27 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:37:27 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:37:27 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:37:27 - Predict] Found a GPU.\n",
      "[15:37:27 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:37:27 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:37:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4d35559ae0>\n",
      "[15:37:28 - MdlStrTF] loading weights from /tmp/tmpwurtwlup/model/variables/variables\n",
      "[15:37:28 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:37:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:37:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:28 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:37:28 - Feature] Processed ParPgb:0.0-203.0 (median depth 129.0)\n",
      "[15:37:28 - Sampler] Took 0.03s to make features.\n",
      "[15:37:28 - Sampler] Region ParPgb:0.0-203.0 (267 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:37:28 - PWorker] Processed 0 batches\n",
      "[15:37:28 - PWorker] All done, 1 remainder regions.\n",
      "[15:37:28 - Predict] Processing 1 short region(s).\n",
      "[15:37:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4c70455480>\n",
      "[15:37:29 - MdlStrTF] loading weights from /tmp/tmpwurtwlup/model/variables/variables\n",
      "[15:37:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:37:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:29 - Feature] Processed ParPgb:0.0-203.0 (median depth 129.0)\n",
      "[15:37:29 - Sampler] Took 0.04s to make features.\n",
      "[15:37:29 - PWorker] Processed 1 batches\n",
      "[15:37:29 - PWorker] All done, 0 remainder regions.\n",
      "[15:37:29 - Predict] Finished processing all regions.\n",
      "[15:37:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:33 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:37:33 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:37:33 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:37:33 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:37:33 - Predict] Found a GPU.\n",
      "[15:37:33 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:37:33 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:37:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f34cdf8dae0>\n",
      "[15:37:34 - MdlStrTF] loading weights from /tmp/tmpbgjauv97/model/variables/variables\n",
      "[15:37:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:37:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:37:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:34 - Sampler] Took 0.09s to make features.\n",
      "[15:37:34 - PWorker] Processed 0 batches\n",
      "[15:37:34 - PWorker] All done, 0 remainder regions.\n",
      "[15:37:34 - Predict] Finished processing all regions.\n",
      "[15:37:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:36 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:37:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:37:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:37:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:37:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:37:37 - Predict] Found a GPU.\n",
      "[15:37:37 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:37:37 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:37:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4d3087dae0>\n",
      "[15:37:39 - MdlStrTF] loading weights from /tmp/tmp110gmmp3/model/variables/variables\n",
      "[15:37:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:37:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:37:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:39 - Sampler] Took 0.05s to make features.\n",
      "[15:37:39 - PWorker] Processed 0 batches\n",
      "[15:37:39 - PWorker] All done, 0 remainder regions.\n",
      "[15:37:39 - Predict] Finished processing all regions.\n",
      "[15:37:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:40 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:37:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:37:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:37:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:37:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:37:42 - Predict] Found a GPU.\n",
      "[15:37:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:37:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:37:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3a24269ae0>\n",
      "[15:37:43 - MdlStrTF] loading weights from /tmp/tmp_fek4kzn/model/variables/variables\n",
      "[15:37:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:37:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:37:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:37:43 - Feature] Processed ParPgb:0.0-244.0 (median depth 212.0)\n",
      "[15:37:43 - Sampler] Took 0.03s to make features.\n",
      "[15:37:43 - Sampler] Region ParPgb:0.0-244.0 (357 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:37:43 - PWorker] Processed 0 batches\n",
      "[15:37:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:37:43 - Predict] Processing 1 short region(s).\n",
      "[15:37:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3967375480>\n",
      "[15:37:44 - MdlStrTF] loading weights from /tmp/tmp_fek4kzn/model/variables/variables\n",
      "[15:37:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:37:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:44 - Feature] Processed ParPgb:0.0-244.0 (median depth 212.0)\n",
      "[15:37:44 - Sampler] Took 0.05s to make features.\n",
      "[15:37:44 - PWorker] Processed 1 batches\n",
      "[15:37:44 - PWorker] All done, 0 remainder regions.\n",
      "[15:37:44 - Predict] Finished processing all regions.\n",
      "[15:37:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:48 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:37:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:37:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:37:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:37:48 - Predict] Found a GPU.\n",
      "[15:37:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:37:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:37:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb08a555ae0>\n",
      "[15:37:49 - MdlStrTF] loading weights from /tmp/tmpu1d0f0tq/model/variables/variables\n",
      "[15:37:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:37:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:37:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[15:37:49 - Feature] Processed ParPgb:0.0-248.0 (median depth 336.0)\n",
      "[15:37:49 - Sampler] Took 0.09s to make features.\n",
      "[15:37:49 - Sampler] Region ParPgb:0.0-248.0 (428 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:37:49 - PWorker] Processed 0 batches\n",
      "[15:37:49 - PWorker] All done, 1 remainder regions.\n",
      "[15:37:49 - Predict] Processing 1 short region(s).\n",
      "[15:37:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faff85d6f20>\n",
      "[15:37:50 - MdlStrTF] loading weights from /tmp/tmpu1d0f0tq/model/variables/variables\n",
      "[15:37:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[15:37:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:50 - Feature] Processed ParPgb:0.0-248.0 (median depth 336.0)\n",
      "[15:37:50 - Sampler] Took 0.06s to make features.\n",
      "[15:37:50 - PWorker] Processed 1 batches\n",
      "[15:37:50 - PWorker] All done, 0 remainder regions.\n",
      "[15:37:50 - Predict] Finished processing all regions.\n",
      "[15:37:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:37:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:37:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:37:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:37:54 - Predict] Found a GPU.\n",
      "[15:37:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:37:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:37:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f59e8399ae0>\n",
      "[15:37:55 - MdlStrTF] loading weights from /tmp/tmp9pxyf10_/model/variables/variables\n",
      "[15:37:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:37:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:37:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:37:56 - Feature] Processed ParPgb:0.0-245.0 (median depth 164.0)\n",
      "[15:37:56 - Sampler] Took 0.44s to make features.\n",
      "[15:37:56 - Sampler] Region ParPgb:0.0-245.0 (341 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:37:56 - PWorker] Processed 0 batches\n",
      "[15:37:56 - PWorker] All done, 1 remainder regions.\n",
      "[15:37:56 - Predict] Processing 1 short region(s).\n",
      "[15:37:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:37:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5948165480>\n",
      "[15:37:56 - MdlStrTF] loading weights from /tmp/tmp9pxyf10_/model/variables/variables\n",
      "[15:37:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:37:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:37:56 - Feature] Processed ParPgb:0.0-245.0 (median depth 164.0)\n",
      "[15:37:56 - Sampler] Took 0.03s to make features.\n",
      "[15:37:57 - PWorker] Processed 1 batches\n",
      "[15:37:57 - PWorker] All done, 0 remainder regions.\n",
      "[15:37:57 - Predict] Finished processing all regions.\n",
      "[15:37:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:37:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:38:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:38:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:38:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:38:00 - Predict] Found a GPU.\n",
      "[15:38:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:38:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:38:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f98376cdae0>\n",
      "[15:38:01 - MdlStrTF] loading weights from /tmp/tmphk61x90d/model/variables/variables\n",
      "[15:38:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:38:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:38:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-257.\n",
      "[15:38:01 - Feature] Processed ParPgb:0.0-257.0 (median depth 322.0)\n",
      "[15:38:01 - Sampler] Took 0.04s to make features.\n",
      "[15:38:01 - Sampler] Region ParPgb:0.0-257.0 (421 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:38:01 - PWorker] Processed 0 batches\n",
      "[15:38:01 - PWorker] All done, 1 remainder regions.\n",
      "[15:38:01 - Predict] Processing 1 short region(s).\n",
      "[15:38:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f97a80e9480>\n",
      "[15:38:02 - MdlStrTF] loading weights from /tmp/tmphk61x90d/model/variables/variables\n",
      "[15:38:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-258.\n",
      "[15:38:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:04 - Feature] Processed ParPgb:0.0-257.0 (median depth 322.0)\n",
      "[15:38:04 - Sampler] Took 2.22s to make features.\n",
      "[15:38:05 - PWorker] Processed 1 batches\n",
      "[15:38:05 - PWorker] All done, 0 remainder regions.\n",
      "[15:38:05 - Predict] Finished processing all regions.\n",
      "[15:38:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:38:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:38:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:38:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:38:08 - Predict] Found a GPU.\n",
      "[15:38:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:38:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:38:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe891c0dae0>\n",
      "[15:38:09 - MdlStrTF] loading weights from /tmp/tmpamx9v2pr/model/variables/variables\n",
      "[15:38:09 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:38:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:38:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:09 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-265.\n",
      "[15:38:10 - Feature] Processed ParPgb:0.0-265.0 (median depth 157.0)\n",
      "[15:38:10 - Sampler] Took 0.09s to make features.\n",
      "[15:38:10 - Sampler] Region ParPgb:0.0-265.0 (376 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:38:10 - PWorker] Processed 0 batches\n",
      "[15:38:10 - PWorker] All done, 1 remainder regions.\n",
      "[15:38:10 - Predict] Processing 1 short region(s).\n",
      "[15:38:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe7f02e5ae0>\n",
      "[15:38:10 - MdlStrTF] loading weights from /tmp/tmpamx9v2pr/model/variables/variables\n",
      "[15:38:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-266.\n",
      "[15:38:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:10 - Feature] Processed ParPgb:0.0-265.0 (median depth 157.0)\n",
      "[15:38:10 - Sampler] Took 0.05s to make features.\n",
      "[15:38:11 - PWorker] Processed 1 batches\n",
      "[15:38:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:38:11 - Predict] Finished processing all regions.\n",
      "[15:38:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:38:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:38:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:38:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:38:14 - Predict] Found a GPU.\n",
      "[15:38:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:38:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:38:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbd601b5ae0>\n",
      "[15:38:15 - MdlStrTF] loading weights from /tmp/tmpu5ykr2dq/model/variables/variables\n",
      "[15:38:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:38:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:38:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[15:38:15 - Feature] Processed ParPgb:0.0-242.0 (median depth 69.0)\n",
      "[15:38:15 - Sampler] Took 0.07s to make features.\n",
      "[15:38:15 - Sampler] Region ParPgb:0.0-242.0 (289 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:38:15 - PWorker] Processed 0 batches\n",
      "[15:38:15 - PWorker] All done, 1 remainder regions.\n",
      "[15:38:15 - Predict] Processing 1 short region(s).\n",
      "[15:38:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbcc1311480>\n",
      "[15:38:16 - MdlStrTF] loading weights from /tmp/tmpu5ykr2dq/model/variables/variables\n",
      "[15:38:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[15:38:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:16 - Feature] Processed ParPgb:0.0-242.0 (median depth 69.0)\n",
      "[15:38:16 - Sampler] Took 0.04s to make features.\n",
      "[15:38:16 - PWorker] Processed 1 batches\n",
      "[15:38:16 - PWorker] All done, 0 remainder regions.\n",
      "[15:38:16 - Predict] Finished processing all regions.\n",
      "[15:38:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:38:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:38:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:38:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:38:20 - Predict] Found a GPU.\n",
      "[15:38:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:38:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:38:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb1e6011ae0>\n",
      "[15:38:21 - MdlStrTF] loading weights from /tmp/tmp2a_d1j7b/model/variables/variables\n",
      "[15:38:21 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:38:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:38:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:21 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-204.\n",
      "[15:38:21 - Feature] Processed ParPgb:0.0-204.0 (median depth 140.0)\n",
      "[15:38:21 - Sampler] Took 0.03s to make features.\n",
      "[15:38:21 - Sampler] Region ParPgb:0.0-204.0 (275 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:38:21 - PWorker] Processed 0 batches\n",
      "[15:38:21 - PWorker] All done, 1 remainder regions.\n",
      "[15:38:21 - Predict] Processing 1 short region(s).\n",
      "[15:38:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb14913d480>\n",
      "[15:38:22 - MdlStrTF] loading weights from /tmp/tmp2a_d1j7b/model/variables/variables\n",
      "[15:38:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-205.\n",
      "[15:38:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:22 - Feature] Processed ParPgb:0.0-204.0 (median depth 140.0)\n",
      "[15:38:22 - Sampler] Took 0.11s to make features.\n",
      "[15:38:22 - PWorker] Processed 1 batches\n",
      "[15:38:22 - PWorker] All done, 0 remainder regions.\n",
      "[15:38:22 - Predict] Finished processing all regions.\n",
      "[15:38:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:26 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:38:26 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:38:26 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:38:26 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:38:26 - Predict] Found a GPU.\n",
      "[15:38:26 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:38:26 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:38:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd8ef341ae0>\n",
      "[15:38:27 - MdlStrTF] loading weights from /tmp/tmpapqyh805/model/variables/variables\n",
      "[15:38:27 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:38:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:38:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:27 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:38:27 - Feature] Processed ParPgb:0.0-246.0 (median depth 96.0)\n",
      "[15:38:27 - Sampler] Took 0.04s to make features.\n",
      "[15:38:27 - Sampler] Region ParPgb:0.0-246.0 (290 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:38:27 - PWorker] Processed 0 batches\n",
      "[15:38:27 - PWorker] All done, 1 remainder regions.\n",
      "[15:38:27 - Predict] Processing 1 short region(s).\n",
      "[15:38:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd85e53d450>\n",
      "[15:38:28 - MdlStrTF] loading weights from /tmp/tmpapqyh805/model/variables/variables\n",
      "[15:38:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:38:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:28 - Feature] Processed ParPgb:0.0-246.0 (median depth 96.0)\n",
      "[15:38:28 - Sampler] Took 0.04s to make features.\n",
      "[15:38:28 - PWorker] Processed 1 batches\n",
      "[15:38:28 - PWorker] All done, 0 remainder regions.\n",
      "[15:38:28 - Predict] Finished processing all regions.\n",
      "[15:38:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:38:32 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:38:32 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:38:32 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:38:32 - Predict] Found a GPU.\n",
      "[15:38:32 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:38:32 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:38:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc894ee1ae0>\n",
      "[15:38:33 - MdlStrTF] loading weights from /tmp/tmpbszo8l4l/model/variables/variables\n",
      "[15:38:33 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:38:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:38:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:33 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-204.\n",
      "[15:38:35 - Feature] Processed ParPgb:0.0-204.0 (median depth 135.0)\n",
      "[15:38:35 - Sampler] Took 1.65s to make features.\n",
      "[15:38:35 - Sampler] Region ParPgb:0.0-204.0 (280 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:38:35 - PWorker] Processed 0 batches\n",
      "[15:38:35 - PWorker] All done, 1 remainder regions.\n",
      "[15:38:35 - Predict] Processing 1 short region(s).\n",
      "[15:38:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc8000c9480>\n",
      "[15:38:35 - MdlStrTF] loading weights from /tmp/tmpbszo8l4l/model/variables/variables\n",
      "[15:38:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-205.\n",
      "[15:38:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:35 - Feature] Processed ParPgb:0.0-204.0 (median depth 135.0)\n",
      "[15:38:35 - Sampler] Took 0.04s to make features.\n",
      "[15:38:36 - PWorker] Processed 1 batches\n",
      "[15:38:36 - PWorker] All done, 0 remainder regions.\n",
      "[15:38:36 - Predict] Finished processing all regions.\n",
      "[15:38:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:39 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:38:39 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:38:39 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:38:39 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:38:39 - Predict] Found a GPU.\n",
      "[15:38:39 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:38:39 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:38:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff705b0dae0>\n",
      "[15:38:40 - MdlStrTF] loading weights from /tmp/tmpbjw6yg24/model/variables/variables\n",
      "[15:38:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:38:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:38:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:40 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-272.\n",
      "[15:38:40 - Feature] Processed ParPgb:0.0-272.0 (median depth 119.0)\n",
      "[15:38:40 - Sampler] Took 0.06s to make features.\n",
      "[15:38:40 - Sampler] Region ParPgb:0.0-272.0 (331 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:38:40 - PWorker] Processed 0 batches\n",
      "[15:38:40 - PWorker] All done, 1 remainder regions.\n",
      "[15:38:40 - Predict] Processing 1 short region(s).\n",
      "[15:38:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff67094aef0>\n",
      "[15:38:41 - MdlStrTF] loading weights from /tmp/tmpbjw6yg24/model/variables/variables\n",
      "[15:38:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-273.\n",
      "[15:38:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:41 - Feature] Processed ParPgb:0.0-272.0 (median depth 119.0)\n",
      "[15:38:41 - Sampler] Took 0.06s to make features.\n",
      "[15:38:42 - PWorker] Processed 1 batches\n",
      "[15:38:42 - PWorker] All done, 0 remainder regions.\n",
      "[15:38:42 - Predict] Finished processing all regions.\n",
      "[15:38:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:45 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:38:45 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:38:45 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:38:45 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:38:45 - Predict] Found a GPU.\n",
      "[15:38:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:38:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:38:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdf8314dae0>\n",
      "[15:38:46 - MdlStrTF] loading weights from /tmp/tmphwjwip5u/model/variables/variables\n",
      "[15:38:46 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:38:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:38:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:46 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:38:46 - Feature] Processed ParPgb:0.0-245.0 (median depth 93.0)\n",
      "[15:38:46 - Sampler] Took 0.09s to make features.\n",
      "[15:38:46 - Sampler] Region ParPgb:0.0-245.0 (305 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:38:46 - PWorker] Processed 0 batches\n",
      "[15:38:46 - PWorker] All done, 1 remainder regions.\n",
      "[15:38:46 - Predict] Processing 1 short region(s).\n",
      "[15:38:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdef234d480>\n",
      "[15:38:47 - MdlStrTF] loading weights from /tmp/tmphwjwip5u/model/variables/variables\n",
      "[15:38:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:38:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:49 - Feature] Processed ParPgb:0.0-245.0 (median depth 93.0)\n",
      "[15:38:49 - Sampler] Took 2.24s to make features.\n",
      "[15:38:50 - PWorker] Processed 1 batches\n",
      "[15:38:50 - PWorker] All done, 0 remainder regions.\n",
      "[15:38:50 - Predict] Finished processing all regions.\n",
      "[15:38:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:38:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:38:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:38:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:38:53 - Predict] Found a GPU.\n",
      "[15:38:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:38:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:38:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0701301ae0>\n",
      "[15:38:54 - MdlStrTF] loading weights from /tmp/tmpws9beymw/model/variables/variables\n",
      "[15:38:54 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:38:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:38:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-258.\n",
      "[15:38:56 - Feature] Processed ParPgb:0.0-258.0 (median depth 220.0)\n",
      "[15:38:56 - Sampler] Took 2.00s to make features.\n",
      "[15:38:56 - Sampler] Region ParPgb:0.0-258.0 (370 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:38:56 - PWorker] Processed 0 batches\n",
      "[15:38:56 - PWorker] All done, 1 remainder regions.\n",
      "[15:38:56 - Predict] Processing 1 short region(s).\n",
      "[15:38:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:38:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f06704661a0>\n",
      "[15:38:57 - MdlStrTF] loading weights from /tmp/tmpws9beymw/model/variables/variables\n",
      "[15:38:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-259.\n",
      "[15:38:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:38:57 - Feature] Processed ParPgb:0.0-258.0 (median depth 220.0)\n",
      "[15:38:57 - Sampler] Took 0.06s to make features.\n",
      "[15:38:57 - PWorker] Processed 1 batches\n",
      "[15:38:57 - PWorker] All done, 0 remainder regions.\n",
      "[15:38:57 - Predict] Finished processing all regions.\n",
      "[15:38:59 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:38:59 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:01 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:39:01 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:39:01 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:39:01 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:39:01 - Predict] Found a GPU.\n",
      "[15:39:01 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:39:01 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:39:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efec5fc9ae0>\n",
      "[15:39:02 - MdlStrTF] loading weights from /tmp/tmp14sfvjko/model/variables/variables\n",
      "[15:39:02 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:39:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:39:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:02 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:39:02 - Feature] Processed ParPgb:0.0-251.0 (median depth 93.0)\n",
      "[15:39:02 - Sampler] Took 0.04s to make features.\n",
      "[15:39:02 - Sampler] Region ParPgb:0.0-251.0 (300 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:39:02 - PWorker] Processed 0 batches\n",
      "[15:39:02 - PWorker] All done, 1 remainder regions.\n",
      "[15:39:02 - Predict] Processing 1 short region(s).\n",
      "[15:39:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efe29111480>\n",
      "[15:39:03 - MdlStrTF] loading weights from /tmp/tmp14sfvjko/model/variables/variables\n",
      "[15:39:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:39:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:03 - Feature] Processed ParPgb:0.0-251.0 (median depth 93.0)\n",
      "[15:39:03 - Sampler] Took 0.06s to make features.\n",
      "[15:39:03 - PWorker] Processed 1 batches\n",
      "[15:39:03 - PWorker] All done, 0 remainder regions.\n",
      "[15:39:03 - Predict] Finished processing all regions.\n",
      "[15:39:05 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:05 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:07 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:39:07 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:39:07 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:39:07 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:39:07 - Predict] Found a GPU.\n",
      "[15:39:07 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:39:07 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:39:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f45e4e65a80>\n",
      "[15:39:08 - MdlStrTF] loading weights from /tmp/tmpma2vldu7/model/variables/variables\n",
      "[15:39:08 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:39:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:39:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[15:39:11 - Feature] Processed ParPgb:0.0-240.0 (median depth 47.0)\n",
      "[15:39:11 - Sampler] Took 2.41s to make features.\n",
      "[15:39:11 - Sampler] Region ParPgb:0.0-240.0 (263 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:39:11 - PWorker] Processed 0 batches\n",
      "[15:39:11 - PWorker] All done, 1 remainder regions.\n",
      "[15:39:11 - Predict] Processing 1 short region(s).\n",
      "[15:39:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f455042efb0>\n",
      "[15:39:11 - MdlStrTF] loading weights from /tmp/tmpma2vldu7/model/variables/variables\n",
      "[15:39:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[15:39:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:11 - Feature] Processed ParPgb:0.0-240.0 (median depth 47.0)\n",
      "[15:39:11 - Sampler] Took 0.04s to make features.\n",
      "[15:39:12 - PWorker] Processed 1 batches\n",
      "[15:39:12 - PWorker] All done, 0 remainder regions.\n",
      "[15:39:12 - Predict] Finished processing all regions.\n",
      "[15:39:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:39:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:39:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:39:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:39:15 - Predict] Found a GPU.\n",
      "[15:39:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:39:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:39:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe0fd195ae0>\n",
      "[15:39:16 - MdlStrTF] loading weights from /tmp/tmpc4cai3zb/model/variables/variables\n",
      "[15:39:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:39:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:39:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-217.\n",
      "[15:39:16 - Feature] Processed ParPgb:0.0-217.0 (median depth 104.0)\n",
      "[15:39:16 - Sampler] Took 0.02s to make features.\n",
      "[15:39:16 - Sampler] Region ParPgb:0.0-217.0 (281 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:39:16 - PWorker] Processed 0 batches\n",
      "[15:39:16 - PWorker] All done, 1 remainder regions.\n",
      "[15:39:16 - Predict] Processing 1 short region(s).\n",
      "[15:39:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe06c299ea0>\n",
      "[15:39:17 - MdlStrTF] loading weights from /tmp/tmpc4cai3zb/model/variables/variables\n",
      "[15:39:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-218.\n",
      "[15:39:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:17 - Feature] Processed ParPgb:0.0-217.0 (median depth 104.0)\n",
      "[15:39:17 - Sampler] Took 0.05s to make features.\n",
      "[15:39:17 - PWorker] Processed 1 batches\n",
      "[15:39:17 - PWorker] All done, 0 remainder regions.\n",
      "[15:39:17 - Predict] Finished processing all regions.\n",
      "[15:39:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:21 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:39:21 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:39:21 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:39:21 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:39:21 - Predict] Found a GPU.\n",
      "[15:39:21 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:39:21 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:39:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9c85d4dae0>\n",
      "[15:39:22 - MdlStrTF] loading weights from /tmp/tmp2_y02jka/model/variables/variables\n",
      "[15:39:22 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:39:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:39:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:22 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-202.\n",
      "[15:39:22 - Feature] Processed ParPgb:0.0-202.0 (median depth 91.0)\n",
      "[15:39:22 - Sampler] Took 0.13s to make features.\n",
      "[15:39:22 - Sampler] Region ParPgb:0.0-202.0 (256 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:39:22 - PWorker] Processed 0 batches\n",
      "[15:39:22 - PWorker] All done, 1 remainder regions.\n",
      "[15:39:22 - Predict] Processing 1 short region(s).\n",
      "[15:39:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9be8671ea0>\n",
      "[15:39:23 - MdlStrTF] loading weights from /tmp/tmp2_y02jka/model/variables/variables\n",
      "[15:39:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-203.\n",
      "[15:39:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:23 - Feature] Processed ParPgb:0.0-202.0 (median depth 91.0)\n",
      "[15:39:23 - Sampler] Took 0.04s to make features.\n",
      "[15:39:23 - PWorker] Processed 1 batches\n",
      "[15:39:23 - PWorker] All done, 0 remainder regions.\n",
      "[15:39:23 - Predict] Finished processing all regions.\n",
      "[15:39:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:27 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:39:27 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:39:27 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:39:27 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:39:27 - Predict] Found a GPU.\n",
      "[15:39:27 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:39:27 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:39:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f250ab29a80>\n",
      "[15:39:28 - MdlStrTF] loading weights from /tmp/tmpvknqlf1j/model/variables/variables\n",
      "[15:39:28 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:39:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:39:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:28 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:39:28 - Feature] Processed ParPgb:0.0-246.0 (median depth 162.0)\n",
      "[15:39:28 - Sampler] Took 0.03s to make features.\n",
      "[15:39:28 - Sampler] Region ParPgb:0.0-246.0 (318 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:39:28 - PWorker] Processed 0 batches\n",
      "[15:39:28 - PWorker] All done, 1 remainder regions.\n",
      "[15:39:28 - Predict] Processing 1 short region(s).\n",
      "[15:39:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2479d29420>\n",
      "[15:39:29 - MdlStrTF] loading weights from /tmp/tmpvknqlf1j/model/variables/variables\n",
      "[15:39:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:39:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:29 - Feature] Processed ParPgb:0.0-246.0 (median depth 162.0)\n",
      "[15:39:29 - Sampler] Took 0.10s to make features.\n",
      "[15:39:29 - PWorker] Processed 1 batches\n",
      "[15:39:29 - PWorker] All done, 0 remainder regions.\n",
      "[15:39:29 - Predict] Finished processing all regions.\n",
      "[15:39:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:33 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:39:33 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:39:33 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:39:33 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:39:33 - Predict] Found a GPU.\n",
      "[15:39:33 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:39:33 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:39:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcf56e45ae0>\n",
      "[15:39:34 - MdlStrTF] loading weights from /tmp/tmp3m93cjwt/model/variables/variables\n",
      "[15:39:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:39:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:39:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[15:39:34 - Feature] Processed ParPgb:0.0-247.0 (median depth 97.0)\n",
      "[15:39:34 - Sampler] Took 0.02s to make features.\n",
      "[15:39:34 - Sampler] Region ParPgb:0.0-247.0 (308 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:39:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:34 - PWorker] Processed 0 batches\n",
      "[15:39:34 - PWorker] All done, 1 remainder regions.\n",
      "[15:39:34 - Predict] Processing 1 short region(s).\n",
      "[15:39:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcea1e6d240>\n",
      "[15:39:35 - MdlStrTF] loading weights from /tmp/tmp3m93cjwt/model/variables/variables\n",
      "[15:39:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[15:39:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:35 - Feature] Processed ParPgb:0.0-247.0 (median depth 97.0)\n",
      "[15:39:35 - Sampler] Took 0.05s to make features.\n",
      "[15:39:35 - PWorker] Processed 1 batches\n",
      "[15:39:35 - PWorker] All done, 0 remainder regions.\n",
      "[15:39:35 - Predict] Finished processing all regions.\n",
      "[15:39:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:39 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:39:39 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:39:39 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:39:39 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:39:39 - Predict] Found a GPU.\n",
      "[15:39:39 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:39:39 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:39:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f13bbff5ae0>\n",
      "[15:39:40 - MdlStrTF] loading weights from /tmp/tmpiybkvuar/model/variables/variables\n",
      "[15:39:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:39:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:39:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:40 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:39:40 - Feature] Processed ParPgb:0.0-243.0 (median depth 100.0)\n",
      "[15:39:40 - Sampler] Took 0.03s to make features.\n",
      "[15:39:40 - Sampler] Region ParPgb:0.0-243.0 (293 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:39:40 - PWorker] Processed 0 batches\n",
      "[15:39:40 - PWorker] All done, 1 remainder regions.\n",
      "[15:39:40 - Predict] Processing 1 short region(s).\n",
      "[15:39:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f132c1d9480>\n",
      "[15:39:40 - MdlStrTF] loading weights from /tmp/tmpiybkvuar/model/variables/variables\n",
      "[15:39:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:39:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:41 - Feature] Processed ParPgb:0.0-243.0 (median depth 100.0)\n",
      "[15:39:41 - Sampler] Took 0.07s to make features.\n",
      "[15:39:41 - PWorker] Processed 1 batches\n",
      "[15:39:41 - PWorker] All done, 0 remainder regions.\n",
      "[15:39:41 - Predict] Finished processing all regions.\n",
      "[15:39:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:44 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:39:44 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:39:44 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:39:44 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:39:45 - Predict] Found a GPU.\n",
      "[15:39:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:39:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:39:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5e0b639ae0>\n",
      "[15:39:46 - MdlStrTF] loading weights from /tmp/tmpmxz31tvk/model/variables/variables\n",
      "[15:39:46 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:39:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:39:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:46 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-239.\n",
      "[15:39:46 - Feature] Processed ParPgb:0.0-239.0 (median depth 100.0)\n",
      "[15:39:46 - Sampler] Took 0.05s to make features.\n",
      "[15:39:46 - Sampler] Region ParPgb:0.0-239.0 (321 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:39:46 - PWorker] Processed 0 batches\n",
      "[15:39:46 - PWorker] All done, 1 remainder regions.\n",
      "[15:39:46 - Predict] Processing 1 short region(s).\n",
      "[15:39:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5d7a7f6f20>\n",
      "[15:39:46 - MdlStrTF] loading weights from /tmp/tmpmxz31tvk/model/variables/variables\n",
      "[15:39:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-240.\n",
      "[15:39:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:46 - Feature] Processed ParPgb:0.0-239.0 (median depth 100.0)\n",
      "[15:39:46 - Sampler] Took 0.05s to make features.\n",
      "[15:39:47 - PWorker] Processed 1 batches\n",
      "[15:39:47 - PWorker] All done, 0 remainder regions.\n",
      "[15:39:47 - Predict] Finished processing all regions.\n",
      "[15:39:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:39:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:39:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:39:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:39:50 - Predict] Found a GPU.\n",
      "[15:39:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:39:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:39:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb808425a80>\n",
      "[15:39:52 - MdlStrTF] loading weights from /tmp/tmpmddbot3m/model/variables/variables\n",
      "[15:39:52 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:39:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:39:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:52 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-279.\n",
      "[15:39:52 - Feature] Processed ParPgb:0.0-279.0 (median depth 225.0)\n",
      "[15:39:52 - Sampler] Took 0.05s to make features.\n",
      "[15:39:52 - Sampler] Region ParPgb:0.0-279.0 (396 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:39:52 - PWorker] Processed 0 batches\n",
      "[15:39:52 - PWorker] All done, 1 remainder regions.\n",
      "[15:39:52 - Predict] Processing 1 short region(s).\n",
      "[15:39:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb76925d420>\n",
      "[15:39:52 - MdlStrTF] loading weights from /tmp/tmpmddbot3m/model/variables/variables\n",
      "[15:39:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-280.\n",
      "[15:39:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:39:52 - Feature] Processed ParPgb:0.0-279.0 (median depth 225.0)\n",
      "[15:39:52 - Sampler] Took 0.05s to make features.\n",
      "[15:39:53 - PWorker] Processed 1 batches\n",
      "[15:39:53 - PWorker] All done, 0 remainder regions.\n",
      "[15:39:53 - Predict] Finished processing all regions.\n",
      "[15:39:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:39:56 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:39:56 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:39:56 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:39:56 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:39:56 - Predict] Found a GPU.\n",
      "[15:39:56 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:39:56 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:39:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:39:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcb2c6a1a80>\n",
      "[15:39:58 - MdlStrTF] loading weights from /tmp/tmpcew7129a/model/variables/variables\n",
      "[15:39:58 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:39:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:39:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:00 - Sampler] Took 1.95s to make features.\n",
      "[15:40:00 - PWorker] Processed 0 batches\n",
      "[15:40:00 - PWorker] All done, 0 remainder regions.\n",
      "[15:40:00 - Predict] Finished processing all regions.\n",
      "[15:40:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:01 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:40:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:40:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:40:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:40:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:40:03 - Predict] Found a GPU.\n",
      "[15:40:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:40:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:40:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3a2fdddae0>\n",
      "[15:40:04 - MdlStrTF] loading weights from /tmp/tmpe_jwt2al/model/variables/variables\n",
      "[15:40:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:40:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:40:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:40:04 - Feature] Processed ParPgb:0.0-245.0 (median depth 177.0)\n",
      "[15:40:04 - Sampler] Took 0.14s to make features.\n",
      "[15:40:04 - Sampler] Region ParPgb:0.0-245.0 (357 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:40:04 - PWorker] Processed 0 batches\n",
      "[15:40:04 - PWorker] All done, 1 remainder regions.\n",
      "[15:40:04 - Predict] Processing 1 short region(s).\n",
      "[15:40:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3990f9db10>\n",
      "[15:40:05 - MdlStrTF] loading weights from /tmp/tmpe_jwt2al/model/variables/variables\n",
      "[15:40:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:40:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:05 - Feature] Processed ParPgb:0.0-245.0 (median depth 177.0)\n",
      "[15:40:05 - Sampler] Took 0.22s to make features.\n",
      "[15:40:06 - PWorker] Processed 1 batches\n",
      "[15:40:06 - PWorker] All done, 0 remainder regions.\n",
      "[15:40:06 - Predict] Finished processing all regions.\n",
      "[15:40:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:40:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:40:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:40:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:40:09 - Predict] Found a GPU.\n",
      "[15:40:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:40:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:40:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff22eea9ae0>\n",
      "[15:40:10 - MdlStrTF] loading weights from /tmp/tmp_zlr40_f/model/variables/variables\n",
      "[15:40:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:40:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:40:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:10 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-256.\n",
      "[15:40:10 - Feature] Processed ParPgb:0.0-256.0 (median depth 137.0)\n",
      "[15:40:10 - Sampler] Took 0.09s to make features.\n",
      "[15:40:10 - Sampler] Region ParPgb:0.0-256.0 (346 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:40:10 - PWorker] Processed 0 batches\n",
      "[15:40:10 - PWorker] All done, 1 remainder regions.\n",
      "[15:40:10 - Predict] Processing 1 short region(s).\n",
      "[15:40:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff2104b1ff0>\n",
      "[15:40:11 - MdlStrTF] loading weights from /tmp/tmp_zlr40_f/model/variables/variables\n",
      "[15:40:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-257.\n",
      "[15:40:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:12 - Feature] Processed ParPgb:0.0-256.0 (median depth 137.0)\n",
      "[15:40:12 - Sampler] Took 0.85s to make features.\n",
      "[15:40:12 - PWorker] Processed 1 batches\n",
      "[15:40:12 - PWorker] All done, 0 remainder regions.\n",
      "[15:40:12 - Predict] Finished processing all regions.\n",
      "[15:40:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:16 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:40:16 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:40:16 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:40:16 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:40:16 - Predict] Found a GPU.\n",
      "[15:40:16 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:40:16 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:40:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efd52865a80>\n",
      "[15:40:17 - MdlStrTF] loading weights from /tmp/tmp1qoar_rj/model/variables/variables\n",
      "[15:40:17 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:40:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:40:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:40:17 - Feature] Processed ParPgb:0.0-244.0 (median depth 150.0)\n",
      "[15:40:17 - Sampler] Took 0.15s to make features.\n",
      "[15:40:17 - Sampler] Region ParPgb:0.0-244.0 (337 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:40:17 - PWorker] Processed 0 batches\n",
      "[15:40:17 - PWorker] All done, 1 remainder regions.\n",
      "[15:40:17 - Predict] Processing 1 short region(s).\n",
      "[15:40:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efcc013aec0>\n",
      "[15:40:18 - MdlStrTF] loading weights from /tmp/tmp1qoar_rj/model/variables/variables\n",
      "[15:40:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:40:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:20 - Feature] Processed ParPgb:0.0-244.0 (median depth 150.0)\n",
      "[15:40:20 - Sampler] Took 2.65s to make features.\n",
      "[15:40:21 - PWorker] Processed 1 batches\n",
      "[15:40:21 - PWorker] All done, 0 remainder regions.\n",
      "[15:40:21 - Predict] Finished processing all regions.\n",
      "[15:40:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:40:24 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:40:24 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:40:24 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:40:24 - Predict] Found a GPU.\n",
      "[15:40:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:40:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:40:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4089c39ae0>\n",
      "[15:40:26 - MdlStrTF] loading weights from /tmp/tmpqvu_1qbx/model/variables/variables\n",
      "[15:40:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:40:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:40:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[15:40:26 - Feature] Processed ParPgb:0.0-248.0 (median depth 87.0)\n",
      "[15:40:26 - Sampler] Took 0.04s to make features.\n",
      "[15:40:26 - Sampler] Region ParPgb:0.0-248.0 (297 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:40:26 - PWorker] Processed 0 batches\n",
      "[15:40:26 - PWorker] All done, 1 remainder regions.\n",
      "[15:40:26 - Predict] Processing 1 short region(s).\n",
      "[15:40:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3fe82e5480>\n",
      "[15:40:26 - MdlStrTF] loading weights from /tmp/tmpqvu_1qbx/model/variables/variables\n",
      "[15:40:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[15:40:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:26 - Feature] Processed ParPgb:0.0-248.0 (median depth 87.0)\n",
      "[15:40:26 - Sampler] Took 0.07s to make features.\n",
      "[15:40:27 - PWorker] Processed 1 batches\n",
      "[15:40:27 - PWorker] All done, 0 remainder regions.\n",
      "[15:40:27 - Predict] Finished processing all regions.\n",
      "[15:40:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:40:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:40:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:40:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:40:30 - Predict] Found a GPU.\n",
      "[15:40:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:40:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:40:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f34a19eda80>\n",
      "[15:40:32 - MdlStrTF] loading weights from /tmp/tmpqb5fs3_y/model/variables/variables\n",
      "[15:40:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:40:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:40:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:32 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-265.\n",
      "[15:40:34 - Feature] Processed ParPgb:0.0-265.0 (median depth 103.0)\n",
      "[15:40:34 - Sampler] Took 1.93s to make features.\n",
      "[15:40:34 - Sampler] Region ParPgb:0.0-265.0 (324 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:40:34 - PWorker] Processed 0 batches\n",
      "[15:40:34 - PWorker] All done, 1 remainder regions.\n",
      "[15:40:34 - Predict] Processing 1 short region(s).\n",
      "[15:40:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3410395420>\n",
      "[15:40:34 - MdlStrTF] loading weights from /tmp/tmpqb5fs3_y/model/variables/variables\n",
      "[15:40:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-266.\n",
      "[15:40:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:34 - Feature] Processed ParPgb:0.0-265.0 (median depth 103.0)\n",
      "[15:40:34 - Sampler] Took 0.06s to make features.\n",
      "[15:40:35 - PWorker] Processed 1 batches\n",
      "[15:40:35 - PWorker] All done, 0 remainder regions.\n",
      "[15:40:35 - Predict] Finished processing all regions.\n",
      "[15:40:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:40:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:40:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:40:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:40:38 - Predict] Found a GPU.\n",
      "[15:40:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:40:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:40:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc5c04bda80>\n",
      "[15:40:39 - MdlStrTF] loading weights from /tmp/tmpw0i602mo/model/variables/variables\n",
      "[15:40:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:40:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:40:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-205.\n",
      "[15:40:43 - Feature] Processed ParPgb:0.0-205.0 (median depth 160.0)\n",
      "[15:40:43 - Sampler] Took 3.49s to make features.\n",
      "[15:40:43 - Sampler] Region ParPgb:0.0-205.0 (287 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:40:43 - PWorker] Processed 0 batches\n",
      "[15:40:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:40:43 - Predict] Processing 1 short region(s).\n",
      "[15:40:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc521672140>\n",
      "[15:40:43 - MdlStrTF] loading weights from /tmp/tmpw0i602mo/model/variables/variables\n",
      "[15:40:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-206.\n",
      "[15:40:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:45 - Feature] Processed ParPgb:0.0-205.0 (median depth 160.0)\n",
      "[15:40:45 - Sampler] Took 2.09s to make features.\n",
      "[15:40:46 - PWorker] Processed 1 batches\n",
      "[15:40:46 - PWorker] All done, 0 remainder regions.\n",
      "[15:40:46 - Predict] Finished processing all regions.\n",
      "[15:40:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:49 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:40:49 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:40:49 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:40:49 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:40:49 - Predict] Found a GPU.\n",
      "[15:40:49 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:40:49 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:40:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8354785ae0>\n",
      "[15:40:51 - MdlStrTF] loading weights from /tmp/tmp3sohqca0/model/variables/variables\n",
      "[15:40:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:40:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:40:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:40:51 - Feature] Processed ParPgb:0.0-252.0 (median depth 98.0)\n",
      "[15:40:51 - Sampler] Took 0.05s to make features.\n",
      "[15:40:51 - Sampler] Region ParPgb:0.0-252.0 (320 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:40:51 - PWorker] Processed 0 batches\n",
      "[15:40:51 - PWorker] All done, 1 remainder regions.\n",
      "[15:40:51 - Predict] Processing 1 short region(s).\n",
      "[15:40:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f82c0125450>\n",
      "[15:40:51 - MdlStrTF] loading weights from /tmp/tmp3sohqca0/model/variables/variables\n",
      "[15:40:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:40:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:51 - Feature] Processed ParPgb:0.0-252.0 (median depth 98.0)\n",
      "[15:40:51 - Sampler] Took 0.05s to make features.\n",
      "[15:40:52 - PWorker] Processed 1 batches\n",
      "[15:40:52 - PWorker] All done, 0 remainder regions.\n",
      "[15:40:52 - Predict] Finished processing all regions.\n",
      "[15:40:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:40:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:40:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:40:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:40:55 - Predict] Found a GPU.\n",
      "[15:40:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:40:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:40:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:40:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faebacedae0>\n",
      "[15:40:57 - MdlStrTF] loading weights from /tmp/tmpnjbop7rl/model/variables/variables\n",
      "[15:40:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:40:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:40:57 - Sampler] Took 0.01s to make features.\n",
      "[15:40:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:40:57 - PWorker] Processed 0 batches\n",
      "[15:40:57 - PWorker] All done, 0 remainder regions.\n",
      "[15:40:57 - Predict] Finished processing all regions.\n",
      "[15:40:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:40:58 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:41:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:41:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:41:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:41:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:41:00 - Predict] Found a GPU.\n",
      "[15:41:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:41:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:41:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb652329ae0>\n",
      "[15:41:01 - MdlStrTF] loading weights from /tmp/tmpmc352ik3/model/variables/variables\n",
      "[15:41:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:41:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:41:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:41:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:41:04 - Feature] Processed ParPgb:0.0-245.0 (median depth 120.0)\n",
      "[15:41:04 - Sampler] Took 2.46s to make features.\n",
      "[15:41:04 - Sampler] Region ParPgb:0.0-245.0 (331 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:41:04 - PWorker] Processed 0 batches\n",
      "[15:41:04 - PWorker] All done, 1 remainder regions.\n",
      "[15:41:04 - Predict] Processing 1 short region(s).\n",
      "[15:41:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb5c1425ff0>\n",
      "[15:41:04 - MdlStrTF] loading weights from /tmp/tmpmc352ik3/model/variables/variables\n",
      "[15:41:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:41:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:41:06 - Feature] Processed ParPgb:0.0-245.0 (median depth 120.0)\n",
      "[15:41:06 - Sampler] Took 2.03s to make features.\n",
      "[15:41:07 - PWorker] Processed 1 batches\n",
      "[15:41:07 - PWorker] All done, 0 remainder regions.\n",
      "[15:41:07 - Predict] Finished processing all regions.\n",
      "[15:41:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:41:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:41:10 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:41:10 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:41:10 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:41:10 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:41:10 - Predict] Found a GPU.\n",
      "[15:41:10 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:41:10 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:41:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:12 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa455b55ae0>\n",
      "[15:41:12 - MdlStrTF] loading weights from /tmp/tmp9_gjojnk/model/variables/variables\n",
      "[15:41:12 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:41:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:41:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:41:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:41:17 - Feature] Processed ParPgb:0.0-244.0 (median depth 183.0)\n",
      "[15:41:17 - Sampler] Took 5.34s to make features.\n",
      "[15:41:17 - Sampler] Region ParPgb:0.0-244.0 (338 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:41:17 - PWorker] Processed 0 batches\n",
      "[15:41:17 - PWorker] All done, 1 remainder regions.\n",
      "[15:41:17 - Predict] Processing 1 short region(s).\n",
      "[15:41:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa3c0c75b10>\n",
      "[15:41:17 - MdlStrTF] loading weights from /tmp/tmp9_gjojnk/model/variables/variables\n",
      "[15:41:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:41:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:41:19 - Feature] Processed ParPgb:0.0-244.0 (median depth 183.0)\n",
      "[15:41:19 - Sampler] Took 1.34s to make features.\n",
      "[15:41:19 - PWorker] Processed 1 batches\n",
      "[15:41:19 - PWorker] All done, 0 remainder regions.\n",
      "[15:41:19 - Predict] Finished processing all regions.\n",
      "[15:41:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:41:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:41:23 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:41:23 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:41:23 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:41:23 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:41:23 - Predict] Found a GPU.\n",
      "[15:41:23 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:41:23 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:41:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb575919ae0>\n",
      "[15:41:24 - MdlStrTF] loading weights from /tmp/tmpwfkq5jja/model/variables/variables\n",
      "[15:41:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:41:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:41:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:41:24 - Sampler] Took 0.02s to make features.\n",
      "[15:41:24 - PWorker] Processed 0 batches\n",
      "[15:41:24 - PWorker] All done, 0 remainder regions.\n",
      "[15:41:24 - Predict] Finished processing all regions.\n",
      "[15:41:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:41:26 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:41:27 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:41:27 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:41:27 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:41:27 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:41:27 - Predict] Found a GPU.\n",
      "[15:41:27 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:41:27 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:41:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0a5df9dae0>\n",
      "[15:41:29 - MdlStrTF] loading weights from /tmp/tmpi9myy0d8/model/variables/variables\n",
      "[15:41:29 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:41:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:41:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:41:29 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[15:41:29 - Feature] Processed ParPgb:0.0-253.0 (median depth 93.0)\n",
      "[15:41:29 - Sampler] Took 0.47s to make features.\n",
      "[15:41:29 - Sampler] Region ParPgb:0.0-253.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:41:29 - PWorker] Processed 0 batches\n",
      "[15:41:29 - PWorker] All done, 1 remainder regions.\n",
      "[15:41:29 - Predict] Processing 1 short region(s).\n",
      "[15:41:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f09cd0d1f90>\n",
      "[15:41:30 - MdlStrTF] loading weights from /tmp/tmpi9myy0d8/model/variables/variables\n",
      "[15:41:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[15:41:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:41:30 - Feature] Processed ParPgb:0.0-253.0 (median depth 93.0)\n",
      "[15:41:30 - Sampler] Took 0.04s to make features.\n",
      "[15:41:30 - PWorker] Processed 1 batches\n",
      "[15:41:30 - PWorker] All done, 0 remainder regions.\n",
      "[15:41:30 - Predict] Finished processing all regions.\n",
      "[15:41:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:41:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:41:34 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:41:34 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:41:34 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:41:34 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:41:34 - Predict] Found a GPU.\n",
      "[15:41:34 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:41:34 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:41:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6ce7965a80>\n",
      "[15:41:35 - MdlStrTF] loading weights from /tmp/tmp9kvpjpkp/model/variables/variables\n",
      "[15:41:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:41:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:41:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:41:35 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-241.\n",
      "[15:41:37 - Feature] Processed ParPgb:0.0-241.0 (median depth 144.0)\n",
      "[15:41:37 - Sampler] Took 2.24s to make features.\n",
      "[15:41:37 - Sampler] Region ParPgb:0.0-241.0 (318 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:41:37 - PWorker] Processed 0 batches\n",
      "[15:41:37 - PWorker] All done, 1 remainder regions.\n",
      "[15:41:37 - Predict] Processing 1 short region(s).\n",
      "[15:41:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6c4833d420>\n",
      "[15:41:38 - MdlStrTF] loading weights from /tmp/tmp9kvpjpkp/model/variables/variables\n",
      "[15:41:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-242.\n",
      "[15:41:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:41:38 - Feature] Processed ParPgb:0.0-241.0 (median depth 144.0)\n",
      "[15:41:38 - Sampler] Took 0.08s to make features.\n",
      "[15:41:38 - PWorker] Processed 1 batches\n",
      "[15:41:38 - PWorker] All done, 0 remainder regions.\n",
      "[15:41:38 - Predict] Finished processing all regions.\n",
      "[15:41:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:41:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:41:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:41:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:41:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:41:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:41:42 - Predict] Found a GPU.\n",
      "[15:41:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:41:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:41:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa9ec47dae0>\n",
      "[15:41:43 - MdlStrTF] loading weights from /tmp/tmp0tyhpnzm/model/variables/variables\n",
      "[15:41:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:41:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:41:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:41:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-257.\n",
      "[15:41:51 - Feature] Processed ParPgb:0.0-257.0 (median depth 105.0)\n",
      "[15:41:51 - Sampler] Took 7.93s to make features.\n",
      "[15:41:51 - Sampler] Region ParPgb:0.0-257.0 (331 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:41:51 - PWorker] Processed 0 batches\n",
      "[15:41:51 - PWorker] All done, 1 remainder regions.\n",
      "[15:41:51 - Predict] Processing 1 short region(s).\n",
      "[15:41:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa94d56f070>\n",
      "[15:41:52 - MdlStrTF] loading weights from /tmp/tmp0tyhpnzm/model/variables/variables\n",
      "[15:41:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-258.\n",
      "[15:41:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:41:52 - Feature] Processed ParPgb:0.0-257.0 (median depth 105.0)\n",
      "[15:41:52 - Sampler] Took 0.19s to make features.\n",
      "[15:41:52 - PWorker] Processed 1 batches\n",
      "[15:41:52 - PWorker] All done, 0 remainder regions.\n",
      "[15:41:52 - Predict] Finished processing all regions.\n",
      "[15:41:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:41:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:41:56 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:41:56 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:41:56 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:41:56 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:41:56 - Predict] Found a GPU.\n",
      "[15:41:56 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:41:56 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:41:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0015c49ae0>\n",
      "[15:41:57 - MdlStrTF] loading weights from /tmp/tmpetut08ht/model/variables/variables\n",
      "[15:41:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:41:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:41:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:41:57 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[15:41:57 - Feature] Processed ParPgb:0.0-255.0 (median depth 85.0)\n",
      "[15:41:57 - Sampler] Took 0.09s to make features.\n",
      "[15:41:57 - Sampler] Region ParPgb:0.0-255.0 (306 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:41:57 - PWorker] Processed 0 batches\n",
      "[15:41:57 - PWorker] All done, 1 remainder regions.\n",
      "[15:41:57 - Predict] Processing 1 short region(s).\n",
      "[15:41:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:41:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7eff8056dfc0>\n",
      "[15:41:58 - MdlStrTF] loading weights from /tmp/tmpetut08ht/model/variables/variables\n",
      "[15:41:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[15:41:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:42:00 - Feature] Processed ParPgb:0.0-255.0 (median depth 85.0)\n",
      "[15:42:00 - Sampler] Took 2.56s to make features.\n",
      "[15:42:01 - PWorker] Processed 1 batches\n",
      "[15:42:01 - PWorker] All done, 0 remainder regions.\n",
      "[15:42:01 - Predict] Finished processing all regions.\n",
      "[15:42:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:42:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:42:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:42:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:42:04 - Predict] Found a GPU.\n",
      "[15:42:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:42:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:42:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:42:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1e460e9ae0>\n",
      "[15:42:05 - MdlStrTF] loading weights from /tmp/tmpex0t6ib2/model/variables/variables\n",
      "[15:42:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:42:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:42:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:42:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[15:42:14 - Feature] Processed ParPgb:0.0-240.0 (median depth 130.0)\n",
      "[15:42:14 - Sampler] Took 8.18s to make features.\n",
      "[15:42:14 - Sampler] Region ParPgb:0.0-240.0 (329 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:42:14 - PWorker] Processed 0 batches\n",
      "[15:42:14 - PWorker] All done, 1 remainder regions.\n",
      "[15:42:14 - Predict] Processing 1 short region(s).\n",
      "[15:42:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:42:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1da920dea0>\n",
      "[15:42:14 - MdlStrTF] loading weights from /tmp/tmpex0t6ib2/model/variables/variables\n",
      "[15:42:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[15:42:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:42:17 - Feature] Processed ParPgb:0.0-240.0 (median depth 130.0)\n",
      "[15:42:17 - Sampler] Took 3.06s to make features.\n",
      "[15:42:18 - PWorker] Processed 1 batches\n",
      "[15:42:18 - PWorker] All done, 0 remainder regions.\n",
      "[15:42:18 - Predict] Finished processing all regions.\n",
      "[15:42:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:21 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:42:21 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:42:21 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:42:21 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:42:21 - Predict] Found a GPU.\n",
      "[15:42:21 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:42:21 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:42:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:42:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f388703dae0>\n",
      "[15:42:22 - MdlStrTF] loading weights from /tmp/tmptq8vx9cx/model/variables/variables\n",
      "[15:42:23 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:42:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:42:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:42:23 - Sampler] Took 0.11s to make features.\n",
      "[15:42:23 - PWorker] Processed 0 batches\n",
      "[15:42:23 - PWorker] All done, 0 remainder regions.\n",
      "[15:42:23 - Predict] Finished processing all regions.\n",
      "[15:42:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:24 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:42:26 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:42:26 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:42:26 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:42:26 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:42:26 - Predict] Found a GPU.\n",
      "[15:42:26 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:42:26 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:42:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:42:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0ebbc49a80>\n",
      "[15:42:27 - MdlStrTF] loading weights from /tmp/tmpbzma2xsx/model/variables/variables\n",
      "[15:42:27 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:42:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:42:27 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-260.\n",
      "[15:42:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:42:27 - Feature] Processed ParPgb:0.0-260.0 (median depth 137.0)\n",
      "[15:42:27 - Sampler] Took 0.10s to make features.\n",
      "[15:42:27 - Sampler] Region ParPgb:0.0-260.0 (355 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:42:27 - PWorker] Processed 0 batches\n",
      "[15:42:27 - PWorker] All done, 1 remainder regions.\n",
      "[15:42:27 - Predict] Processing 1 short region(s).\n",
      "[15:42:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:42:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0e2ad1e2c0>\n",
      "[15:42:28 - MdlStrTF] loading weights from /tmp/tmpbzma2xsx/model/variables/variables\n",
      "[15:42:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-261.\n",
      "[15:42:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:42:31 - Feature] Processed ParPgb:0.0-260.0 (median depth 137.0)\n",
      "[15:42:31 - Sampler] Took 3.62s to make features.\n",
      "[15:42:32 - PWorker] Processed 1 batches\n",
      "[15:42:32 - PWorker] All done, 0 remainder regions.\n",
      "[15:42:32 - Predict] Finished processing all regions.\n",
      "[15:42:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:35 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:42:35 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:42:35 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:42:35 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:42:35 - Predict] Found a GPU.\n",
      "[15:42:35 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:42:35 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:42:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:42:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa0225a1ae0>\n",
      "[15:42:37 - MdlStrTF] loading weights from /tmp/tmpc2t1s37o/model/variables/variables\n",
      "[15:42:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:42:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:42:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:42:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-216.\n",
      "[15:42:38 - Feature] Processed ParPgb:0.0-216.0 (median depth 99.0)\n",
      "[15:42:38 - Sampler] Took 1.60s to make features.\n",
      "[15:42:38 - Sampler] Region ParPgb:0.0-216.0 (265 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:42:38 - PWorker] Processed 0 batches\n",
      "[15:42:38 - PWorker] All done, 1 remainder regions.\n",
      "[15:42:38 - Predict] Processing 1 short region(s).\n",
      "[15:42:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:42:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9f917c6230>\n",
      "[15:42:39 - MdlStrTF] loading weights from /tmp/tmpc2t1s37o/model/variables/variables\n",
      "[15:42:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-217.\n",
      "[15:42:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:42:39 - Feature] Processed ParPgb:0.0-216.0 (median depth 99.0)\n",
      "[15:42:39 - Sampler] Took 0.05s to make features.\n",
      "[15:42:39 - PWorker] Processed 1 batches\n",
      "[15:42:39 - PWorker] All done, 0 remainder regions.\n",
      "[15:42:39 - Predict] Finished processing all regions.\n",
      "[15:42:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:42:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:42:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:42:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:42:43 - Predict] Found a GPU.\n",
      "[15:42:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:42:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:42:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:42:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8809a85a80>\n",
      "[15:42:44 - MdlStrTF] loading weights from /tmp/tmpbngrad4w/model/variables/variables\n",
      "[15:42:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:42:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:42:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:42:44 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:42:44 - Feature] Processed ParPgb:0.0-243.0 (median depth 165.0)\n",
      "[15:42:44 - Sampler] Took 0.11s to make features.\n",
      "[15:42:44 - Sampler] Region ParPgb:0.0-243.0 (339 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:42:44 - PWorker] Processed 0 batches\n",
      "[15:42:44 - PWorker] All done, 1 remainder regions.\n",
      "[15:42:44 - Predict] Processing 1 short region(s).\n",
      "[15:42:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:42:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8778c66e90>\n",
      "[15:42:45 - MdlStrTF] loading weights from /tmp/tmpbngrad4w/model/variables/variables\n",
      "[15:42:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:42:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:42:46 - Feature] Processed ParPgb:0.0-243.0 (median depth 165.0)\n",
      "[15:42:46 - Sampler] Took 1.06s to make features.\n",
      "[15:42:46 - PWorker] Processed 1 batches\n",
      "[15:42:46 - PWorker] All done, 0 remainder regions.\n",
      "[15:42:46 - Predict] Finished processing all regions.\n",
      "[15:42:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:42:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:42:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:42:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:42:50 - Predict] Found a GPU.\n",
      "[15:42:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:42:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:42:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:42:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f25c574da80>\n",
      "[15:42:51 - MdlStrTF] loading weights from /tmp/tmpfgyd34l9/model/variables/variables\n",
      "[15:42:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:42:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:42:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:42:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-256.\n",
      "[15:42:51 - Feature] Processed ParPgb:0.0-256.0 (median depth 91.0)\n",
      "[15:42:51 - Sampler] Took 0.12s to make features.\n",
      "[15:42:51 - Sampler] Region ParPgb:0.0-256.0 (304 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:42:51 - PWorker] Processed 0 batches\n",
      "[15:42:51 - PWorker] All done, 1 remainder regions.\n",
      "[15:42:51 - Predict] Processing 1 short region(s).\n",
      "[15:42:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:42:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2530919f90>\n",
      "[15:42:52 - MdlStrTF] loading weights from /tmp/tmpfgyd34l9/model/variables/variables\n",
      "[15:42:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-257.\n",
      "[15:42:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:42:54 - Feature] Processed ParPgb:0.0-256.0 (median depth 91.0)\n",
      "[15:42:54 - Sampler] Took 2.62s to make features.\n",
      "[15:42:55 - PWorker] Processed 1 batches\n",
      "[15:42:55 - PWorker] All done, 0 remainder regions.\n",
      "[15:42:55 - Predict] Finished processing all regions.\n",
      "[15:42:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:42:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:42:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:42:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:42:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:42:58 - Predict] Found a GPU.\n",
      "[15:42:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:42:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:42:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f420ab4dae0>\n",
      "[15:43:00 - MdlStrTF] loading weights from /tmp/tmpyfld_7k6/model/variables/variables\n",
      "[15:43:00 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:43:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:43:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:00 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-215.\n",
      "[15:43:00 - Feature] Processed ParPgb:0.0-215.0 (median depth 121.0)\n",
      "[15:43:00 - Sampler] Took 0.02s to make features.\n",
      "[15:43:00 - Sampler] Region ParPgb:0.0-215.0 (292 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:43:00 - PWorker] Processed 0 batches\n",
      "[15:43:00 - PWorker] All done, 1 remainder regions.\n",
      "[15:43:00 - Predict] Processing 1 short region(s).\n",
      "[15:43:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4179d29ea0>\n",
      "[15:43:00 - MdlStrTF] loading weights from /tmp/tmpyfld_7k6/model/variables/variables\n",
      "[15:43:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-216.\n",
      "[15:43:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:03 - Feature] Processed ParPgb:0.0-215.0 (median depth 121.0)\n",
      "[15:43:03 - Sampler] Took 2.42s to make features.\n",
      "[15:43:03 - PWorker] Processed 1 batches\n",
      "[15:43:03 - PWorker] All done, 0 remainder regions.\n",
      "[15:43:03 - Predict] Finished processing all regions.\n",
      "[15:43:05 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:05 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:06 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:43:06 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:43:06 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:43:06 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:43:06 - Predict] Found a GPU.\n",
      "[15:43:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:43:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:43:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbb30eedae0>\n",
      "[15:43:08 - MdlStrTF] loading weights from /tmp/tmploh619le/model/variables/variables\n",
      "[15:43:08 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:43:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:43:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:08 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:43:08 - Feature] Processed ParPgb:0.0-244.0 (median depth 155.0)\n",
      "[15:43:08 - Sampler] Took 0.05s to make features.\n",
      "[15:43:08 - Sampler] Region ParPgb:0.0-244.0 (317 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:43:08 - PWorker] Processed 0 batches\n",
      "[15:43:08 - PWorker] All done, 1 remainder regions.\n",
      "[15:43:08 - Predict] Processing 1 short region(s).\n",
      "[15:43:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbaa00c5990>\n",
      "[15:43:08 - MdlStrTF] loading weights from /tmp/tmploh619le/model/variables/variables\n",
      "[15:43:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:43:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:08 - Feature] Processed ParPgb:0.0-244.0 (median depth 155.0)\n",
      "[15:43:08 - Sampler] Took 0.08s to make features.\n",
      "[15:43:09 - PWorker] Processed 1 batches\n",
      "[15:43:09 - PWorker] All done, 0 remainder regions.\n",
      "[15:43:09 - Predict] Finished processing all regions.\n",
      "[15:43:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:43:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:43:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:43:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:43:12 - Predict] Found a GPU.\n",
      "[15:43:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:43:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:43:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6bdad19ae0>\n",
      "[15:43:14 - MdlStrTF] loading weights from /tmp/tmp8c6ygpy4/model/variables/variables\n",
      "[15:43:14 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:43:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:43:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:43:14 - Feature] Processed ParPgb:0.0-252.0 (median depth 103.0)\n",
      "[15:43:14 - Sampler] Took 0.05s to make features.\n",
      "[15:43:14 - Sampler] Region ParPgb:0.0-252.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:43:14 - PWorker] Processed 0 batches\n",
      "[15:43:14 - PWorker] All done, 1 remainder regions.\n",
      "[15:43:14 - Predict] Processing 1 short region(s).\n",
      "[15:43:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6b49e25480>\n",
      "[15:43:14 - MdlStrTF] loading weights from /tmp/tmp8c6ygpy4/model/variables/variables\n",
      "[15:43:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:43:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:14 - Feature] Processed ParPgb:0.0-252.0 (median depth 103.0)\n",
      "[15:43:14 - Sampler] Took 0.07s to make features.\n",
      "[15:43:15 - PWorker] Processed 1 batches\n",
      "[15:43:15 - PWorker] All done, 0 remainder regions.\n",
      "[15:43:15 - Predict] Finished processing all regions.\n",
      "[15:43:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:18 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:43:18 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:43:18 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:43:18 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:43:18 - Predict] Found a GPU.\n",
      "[15:43:18 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:43:18 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:43:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8355325ae0>\n",
      "[15:43:20 - MdlStrTF] loading weights from /tmp/tmpdx0vfs_k/model/variables/variables\n",
      "[15:43:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:43:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:43:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:20 - Sampler] Took 0.04s to make features.\n",
      "[15:43:20 - PWorker] Processed 0 batches\n",
      "[15:43:20 - PWorker] All done, 0 remainder regions.\n",
      "[15:43:20 - Predict] Finished processing all regions.\n",
      "[15:43:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:21 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:43:23 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:43:23 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:43:23 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:43:23 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:43:23 - Predict] Found a GPU.\n",
      "[15:43:23 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:43:23 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:43:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbdbb879ae0>\n",
      "[15:43:24 - MdlStrTF] loading weights from /tmp/tmp72eorhwt/model/variables/variables\n",
      "[15:43:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:43:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:43:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:43:24 - Feature] Processed ParPgb:0.0-251.0 (median depth 173.0)\n",
      "[15:43:24 - Sampler] Took 0.10s to make features.\n",
      "[15:43:24 - Sampler] Region ParPgb:0.0-251.0 (328 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:43:24 - PWorker] Processed 0 batches\n",
      "[15:43:24 - PWorker] All done, 1 remainder regions.\n",
      "[15:43:24 - Predict] Processing 1 short region(s).\n",
      "[15:43:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbd2870dff0>\n",
      "[15:43:25 - MdlStrTF] loading weights from /tmp/tmp72eorhwt/model/variables/variables\n",
      "[15:43:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:43:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:25 - Feature] Processed ParPgb:0.0-251.0 (median depth 173.0)\n",
      "[15:43:25 - Sampler] Took 0.06s to make features.\n",
      "[15:43:25 - PWorker] Processed 1 batches\n",
      "[15:43:25 - PWorker] All done, 0 remainder regions.\n",
      "[15:43:25 - Predict] Finished processing all regions.\n",
      "[15:43:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:43:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:43:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:43:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:43:29 - Predict] Found a GPU.\n",
      "[15:43:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:43:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:43:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc6f3e7dae0>\n",
      "[15:43:30 - MdlStrTF] loading weights from /tmp/tmph4vxaeto/model/variables/variables\n",
      "[15:43:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:43:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:43:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:33 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:43:33 - Feature] Processed ParPgb:0.0-243.0 (median depth 111.0)\n",
      "[15:43:33 - Sampler] Took 2.44s to make features.\n",
      "[15:43:33 - Sampler] Region ParPgb:0.0-243.0 (312 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:43:33 - PWorker] Processed 0 batches\n",
      "[15:43:33 - PWorker] All done, 1 remainder regions.\n",
      "[15:43:33 - Predict] Processing 1 short region(s).\n",
      "[15:43:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc6cc102170>\n",
      "[15:43:33 - MdlStrTF] loading weights from /tmp/tmph4vxaeto/model/variables/variables\n",
      "[15:43:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:43:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:33 - Feature] Processed ParPgb:0.0-243.0 (median depth 111.0)\n",
      "[15:43:33 - Sampler] Took 0.08s to make features.\n",
      "[15:43:34 - PWorker] Processed 1 batches\n",
      "[15:43:34 - PWorker] All done, 0 remainder regions.\n",
      "[15:43:34 - Predict] Finished processing all regions.\n",
      "[15:43:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:43:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:43:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:43:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:43:37 - Predict] Found a GPU.\n",
      "[15:43:37 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:43:37 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:43:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f488bfb9ae0>\n",
      "[15:43:38 - MdlStrTF] loading weights from /tmp/tmps68nkbx2/model/variables/variables\n",
      "[15:43:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:43:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:43:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[15:43:39 - Feature] Processed ParPgb:0.0-238.0 (median depth 126.0)\n",
      "[15:43:39 - Sampler] Took 0.04s to make features.\n",
      "[15:43:39 - Sampler] Region ParPgb:0.0-238.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:43:39 - PWorker] Processed 0 batches\n",
      "[15:43:39 - PWorker] All done, 1 remainder regions.\n",
      "[15:43:39 - Predict] Processing 1 short region(s).\n",
      "[15:43:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f47fc0e1480>\n",
      "[15:43:39 - MdlStrTF] loading weights from /tmp/tmps68nkbx2/model/variables/variables\n",
      "[15:43:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[15:43:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:39 - Feature] Processed ParPgb:0.0-238.0 (median depth 126.0)\n",
      "[15:43:39 - Sampler] Took 0.13s to make features.\n",
      "[15:43:40 - PWorker] Processed 1 batches\n",
      "[15:43:40 - PWorker] All done, 0 remainder regions.\n",
      "[15:43:40 - Predict] Finished processing all regions.\n",
      "[15:43:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:43:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:43:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:43:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:43:43 - Predict] Found a GPU.\n",
      "[15:43:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:43:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:43:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0f45ab9ae0>\n",
      "[15:43:44 - MdlStrTF] loading weights from /tmp/tmp8szvettd/model/variables/variables\n",
      "[15:43:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:43:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:43:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:43:47 - Feature] Processed ParPgb:0.0-243.0 (median depth 141.0)\n",
      "[15:43:47 - Sampler] Took 3.04s to make features.\n",
      "[15:43:47 - Sampler] Region ParPgb:0.0-243.0 (329 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:43:47 - PWorker] Processed 0 batches\n",
      "[15:43:47 - PWorker] All done, 1 remainder regions.\n",
      "[15:43:47 - Predict] Processing 1 short region(s).\n",
      "[15:43:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0eb0859990>\n",
      "[15:43:48 - MdlStrTF] loading weights from /tmp/tmp8szvettd/model/variables/variables\n",
      "[15:43:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:43:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:50 - Feature] Processed ParPgb:0.0-243.0 (median depth 141.0)\n",
      "[15:43:50 - Sampler] Took 1.95s to make features.\n",
      "[15:43:50 - PWorker] Processed 1 batches\n",
      "[15:43:50 - PWorker] All done, 0 remainder regions.\n",
      "[15:43:50 - Predict] Finished processing all regions.\n",
      "[15:43:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:43:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:43:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:43:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:43:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:43:54 - Predict] Found a GPU.\n",
      "[15:43:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:43:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:43:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f02647cdae0>\n",
      "[15:43:55 - MdlStrTF] loading weights from /tmp/tmp0vze2uof/model/variables/variables\n",
      "[15:43:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:43:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:43:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-216.\n",
      "[15:43:55 - Feature] Processed ParPgb:0.0-216.0 (median depth 180.0)\n",
      "[15:43:55 - Sampler] Took 0.04s to make features.\n",
      "[15:43:55 - Sampler] Region ParPgb:0.0-216.0 (289 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:43:55 - PWorker] Processed 0 batches\n",
      "[15:43:55 - PWorker] All done, 1 remainder regions.\n",
      "[15:43:55 - Predict] Processing 1 short region(s).\n",
      "[15:43:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:43:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f01d0125480>\n",
      "[15:43:56 - MdlStrTF] loading weights from /tmp/tmp0vze2uof/model/variables/variables\n",
      "[15:43:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-217.\n",
      "[15:43:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:43:58 - Feature] Processed ParPgb:0.0-216.0 (median depth 180.0)\n",
      "[15:43:58 - Sampler] Took 2.39s to make features.\n",
      "[15:43:59 - PWorker] Processed 1 batches\n",
      "[15:43:59 - PWorker] All done, 0 remainder regions.\n",
      "[15:43:59 - Predict] Finished processing all regions.\n",
      "[15:44:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:44:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:44:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:44:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:44:02 - Predict] Found a GPU.\n",
      "[15:44:02 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:44:02 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:44:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9b72ffdae0>\n",
      "[15:44:03 - MdlStrTF] loading weights from /tmp/tmpf727wezm/model/variables/variables\n",
      "[15:44:03 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:44:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:44:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:03 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-230.\n",
      "[15:44:03 - Feature] Processed ParPgb:0.0-230.0 (median depth 101.0)\n",
      "[15:44:03 - Sampler] Took 0.09s to make features.\n",
      "[15:44:03 - Sampler] Region ParPgb:0.0-230.0 (289 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:44:03 - PWorker] Processed 0 batches\n",
      "[15:44:03 - PWorker] All done, 1 remainder regions.\n",
      "[15:44:03 - Predict] Processing 1 short region(s).\n",
      "[15:44:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9ae222d480>\n",
      "[15:44:04 - MdlStrTF] loading weights from /tmp/tmpf727wezm/model/variables/variables\n",
      "[15:44:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-231.\n",
      "[15:44:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:04 - Feature] Processed ParPgb:0.0-230.0 (median depth 101.0)\n",
      "[15:44:04 - Sampler] Took 0.06s to make features.\n",
      "[15:44:04 - PWorker] Processed 1 batches\n",
      "[15:44:04 - PWorker] All done, 0 remainder regions.\n",
      "[15:44:04 - Predict] Finished processing all regions.\n",
      "[15:44:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:44:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:44:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:44:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:44:08 - Predict] Found a GPU.\n",
      "[15:44:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:44:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:44:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fce01059ae0>\n",
      "[15:44:09 - MdlStrTF] loading weights from /tmp/tmposyr87xm/model/variables/variables\n",
      "[15:44:09 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:44:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:44:09 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-226.\n",
      "[15:44:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:09 - Feature] Processed ParPgb:0.0-226.0 (median depth 122.0)\n",
      "[15:44:09 - Sampler] Took 0.02s to make features.\n",
      "[15:44:09 - Sampler] Region ParPgb:0.0-226.0 (318 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:44:09 - PWorker] Processed 0 batches\n",
      "[15:44:09 - PWorker] All done, 1 remainder regions.\n",
      "[15:44:09 - Predict] Processing 1 short region(s).\n",
      "[15:44:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcd70222320>\n",
      "[15:44:10 - MdlStrTF] loading weights from /tmp/tmposyr87xm/model/variables/variables\n",
      "[15:44:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-227.\n",
      "[15:44:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:10 - Feature] Processed ParPgb:0.0-226.0 (median depth 122.0)\n",
      "[15:44:10 - Sampler] Took 0.54s to make features.\n",
      "[15:44:11 - PWorker] Processed 1 batches\n",
      "[15:44:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:44:11 - Predict] Finished processing all regions.\n",
      "[15:44:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:44:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:44:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:44:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:44:14 - Predict] Found a GPU.\n",
      "[15:44:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:44:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:44:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fce43409ae0>\n",
      "[15:44:15 - MdlStrTF] loading weights from /tmp/tmp9etqu7s5/model/variables/variables\n",
      "[15:44:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:44:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:44:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-258.\n",
      "[15:44:16 - Feature] Processed ParPgb:0.0-258.0 (median depth 63.0)\n",
      "[15:44:16 - Sampler] Took 0.03s to make features.\n",
      "[15:44:16 - Sampler] Region ParPgb:0.0-258.0 (280 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:44:16 - PWorker] Processed 0 batches\n",
      "[15:44:16 - PWorker] All done, 1 remainder regions.\n",
      "[15:44:16 - Predict] Processing 1 short region(s).\n",
      "[15:44:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcdb2292f20>\n",
      "[15:44:16 - MdlStrTF] loading weights from /tmp/tmp9etqu7s5/model/variables/variables\n",
      "[15:44:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-259.\n",
      "[15:44:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:18 - Feature] Processed ParPgb:0.0-258.0 (median depth 63.0)\n",
      "[15:44:18 - Sampler] Took 2.22s to make features.\n",
      "[15:44:19 - PWorker] Processed 1 batches\n",
      "[15:44:19 - PWorker] All done, 0 remainder regions.\n",
      "[15:44:19 - Predict] Finished processing all regions.\n",
      "[15:44:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:44:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:44:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:44:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:44:22 - Predict] Found a GPU.\n",
      "[15:44:22 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:44:22 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:44:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fafb27adae0>\n",
      "[15:44:24 - MdlStrTF] loading weights from /tmp/tmpirq1i7qs/model/variables/variables\n",
      "[15:44:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:44:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:44:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:44:24 - Feature] Processed ParPgb:0.0-251.0 (median depth 107.0)\n",
      "[15:44:24 - Sampler] Took 0.04s to make features.\n",
      "[15:44:24 - Sampler] Region ParPgb:0.0-251.0 (335 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:44:24 - PWorker] Processed 0 batches\n",
      "[15:44:24 - PWorker] All done, 1 remainder regions.\n",
      "[15:44:24 - Predict] Processing 1 short region(s).\n",
      "[15:44:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faf200d9480>\n",
      "[15:44:24 - MdlStrTF] loading weights from /tmp/tmpirq1i7qs/model/variables/variables\n",
      "[15:44:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:44:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:24 - Feature] Processed ParPgb:0.0-251.0 (median depth 107.0)\n",
      "[15:44:24 - Sampler] Took 0.12s to make features.\n",
      "[15:44:25 - PWorker] Processed 1 batches\n",
      "[15:44:25 - PWorker] All done, 0 remainder regions.\n",
      "[15:44:25 - Predict] Finished processing all regions.\n",
      "[15:44:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:28 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:44:28 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:44:28 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:44:28 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:44:28 - Predict] Found a GPU.\n",
      "[15:44:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:44:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:44:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8d4d131ae0>\n",
      "[15:44:29 - MdlStrTF] loading weights from /tmp/tmpd0km0p6y/model/variables/variables\n",
      "[15:44:29 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:44:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:44:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:33 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-241.\n",
      "[15:44:34 - Feature] Processed ParPgb:0.0-241.0 (median depth 183.0)\n",
      "[15:44:34 - Sampler] Took 4.03s to make features.\n",
      "[15:44:34 - Sampler] Region ParPgb:0.0-241.0 (342 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:44:34 - PWorker] Processed 0 batches\n",
      "[15:44:34 - PWorker] All done, 1 remainder regions.\n",
      "[15:44:34 - Predict] Processing 1 short region(s).\n",
      "[15:44:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8cbc299ae0>\n",
      "[15:44:34 - MdlStrTF] loading weights from /tmp/tmpd0km0p6y/model/variables/variables\n",
      "[15:44:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-242.\n",
      "[15:44:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:36 - Feature] Processed ParPgb:0.0-241.0 (median depth 183.0)\n",
      "[15:44:36 - Sampler] Took 1.99s to make features.\n",
      "[15:44:36 - PWorker] Processed 1 batches\n",
      "[15:44:36 - PWorker] All done, 0 remainder regions.\n",
      "[15:44:36 - Predict] Finished processing all regions.\n",
      "[15:44:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:44:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:44:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:44:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:44:40 - Predict] Found a GPU.\n",
      "[15:44:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:44:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:44:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f68f3349a80>\n",
      "[15:44:41 - MdlStrTF] loading weights from /tmp/tmp_b868ekp/model/variables/variables\n",
      "[15:44:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:44:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:44:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-189.\n",
      "[15:44:43 - Feature] Processed ParPgb:0.0-189.0 (median depth 2.0)\n",
      "[15:44:43 - Sampler] Took 2.11s to make features.\n",
      "[15:44:43 - Sampler] Region ParPgb:0.0-189.0 (191 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:44:43 - PWorker] Processed 0 batches\n",
      "[15:44:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:44:43 - Predict] Processing 1 short region(s).\n",
      "[15:44:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6861d262c0>\n",
      "[15:44:44 - MdlStrTF] loading weights from /tmp/tmp_b868ekp/model/variables/variables\n",
      "[15:44:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-190.\n",
      "[15:44:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:44 - Feature] Processed ParPgb:0.0-189.0 (median depth 2.0)\n",
      "[15:44:44 - Sampler] Took 0.16s to make features.\n",
      "[15:44:45 - PWorker] Processed 1 batches\n",
      "[15:44:45 - PWorker] All done, 0 remainder regions.\n",
      "[15:44:45 - Predict] Finished processing all regions.\n",
      "[15:44:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:48 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:44:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:44:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:44:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:44:48 - Predict] Found a GPU.\n",
      "[15:44:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:44:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:44:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f902d4fdae0>\n",
      "[15:44:49 - MdlStrTF] loading weights from /tmp/tmpmb3v1n9h/model/variables/variables\n",
      "[15:44:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:44:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:44:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-228.\n",
      "[15:44:49 - Feature] Processed ParPgb:0.0-228.0 (median depth 91.0)\n",
      "[15:44:49 - Sampler] Took 0.03s to make features.\n",
      "[15:44:49 - Sampler] Region ParPgb:0.0-228.0 (297 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:44:49 - PWorker] Processed 0 batches\n",
      "[15:44:49 - PWorker] All done, 1 remainder regions.\n",
      "[15:44:49 - Predict] Processing 1 short region(s).\n",
      "[15:44:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8f9c639480>\n",
      "[15:44:50 - MdlStrTF] loading weights from /tmp/tmpmb3v1n9h/model/variables/variables\n",
      "[15:44:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-229.\n",
      "[15:44:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:52 - Feature] Processed ParPgb:0.0-228.0 (median depth 91.0)\n",
      "[15:44:52 - Sampler] Took 2.11s to make features.\n",
      "[15:44:52 - PWorker] Processed 1 batches\n",
      "[15:44:52 - PWorker] All done, 0 remainder regions.\n",
      "[15:44:52 - Predict] Finished processing all regions.\n",
      "[15:44:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:44:56 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:44:56 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:44:56 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:44:56 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:44:56 - Predict] Found a GPU.\n",
      "[15:44:56 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:44:56 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:44:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fedc2fb9ae0>\n",
      "[15:44:57 - MdlStrTF] loading weights from /tmp/tmprkrfe39z/model/variables/variables\n",
      "[15:44:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:44:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:44:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:44:57 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-215.\n",
      "[15:44:57 - Feature] Processed ParPgb:0.0-215.0 (median depth 135.0)\n",
      "[15:44:57 - Sampler] Took 0.11s to make features.\n",
      "[15:44:57 - Sampler] Region ParPgb:0.0-215.0 (297 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:44:57 - PWorker] Processed 0 batches\n",
      "[15:44:57 - PWorker] All done, 1 remainder regions.\n",
      "[15:44:57 - Predict] Processing 1 short region(s).\n",
      "[15:44:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:44:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fed2077a1a0>\n",
      "[15:44:58 - MdlStrTF] loading weights from /tmp/tmprkrfe39z/model/variables/variables\n",
      "[15:44:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-216.\n",
      "[15:44:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:00 - Feature] Processed ParPgb:0.0-215.0 (median depth 135.0)\n",
      "[15:45:00 - Sampler] Took 2.08s to make features.\n",
      "[15:45:00 - PWorker] Processed 1 batches\n",
      "[15:45:00 - PWorker] All done, 0 remainder regions.\n",
      "[15:45:00 - Predict] Finished processing all regions.\n",
      "[15:45:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:45:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:45:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:45:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:45:04 - Predict] Found a GPU.\n",
      "[15:45:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:45:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:45:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9c814b1ae0>\n",
      "[15:45:05 - MdlStrTF] loading weights from /tmp/tmptxt3n6p9/model/variables/variables\n",
      "[15:45:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:45:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:45:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:45:07 - Feature] Processed ParPgb:0.0-249.0 (median depth 144.0)\n",
      "[15:45:07 - Sampler] Took 1.94s to make features.\n",
      "[15:45:07 - Sampler] Region ParPgb:0.0-249.0 (324 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:45:07 - PWorker] Processed 0 batches\n",
      "[15:45:07 - PWorker] All done, 1 remainder regions.\n",
      "[15:45:07 - Predict] Processing 1 short region(s).\n",
      "[15:45:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9be1675480>\n",
      "[15:45:08 - MdlStrTF] loading weights from /tmp/tmptxt3n6p9/model/variables/variables\n",
      "[15:45:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:45:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:10 - Feature] Processed ParPgb:0.0-249.0 (median depth 144.0)\n",
      "[15:45:10 - Sampler] Took 2.26s to make features.\n",
      "[15:45:10 - PWorker] Processed 1 batches\n",
      "[15:45:10 - PWorker] All done, 0 remainder regions.\n",
      "[15:45:10 - Predict] Finished processing all regions.\n",
      "[15:45:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:45:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:45:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:45:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:45:14 - Predict] Found a GPU.\n",
      "[15:45:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:45:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:45:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f79f9f65ae0>\n",
      "[15:45:15 - MdlStrTF] loading weights from /tmp/tmpp1v1zofg/model/variables/variables\n",
      "[15:45:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:45:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:45:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[15:45:15 - Feature] Processed ParPgb:0.0-248.0 (median depth 110.0)\n",
      "[15:45:15 - Sampler] Took 0.04s to make features.\n",
      "[15:45:15 - Sampler] Region ParPgb:0.0-248.0 (315 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:45:15 - PWorker] Processed 0 batches\n",
      "[15:45:15 - PWorker] All done, 1 remainder regions.\n",
      "[15:45:15 - Predict] Processing 1 short region(s).\n",
      "[15:45:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f79690bafe0>\n",
      "[15:45:16 - MdlStrTF] loading weights from /tmp/tmpp1v1zofg/model/variables/variables\n",
      "[15:45:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[15:45:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:16 - Feature] Processed ParPgb:0.0-248.0 (median depth 110.0)\n",
      "[15:45:16 - Sampler] Took 0.06s to make features.\n",
      "[15:45:16 - PWorker] Processed 1 batches\n",
      "[15:45:16 - PWorker] All done, 0 remainder regions.\n",
      "[15:45:16 - Predict] Finished processing all regions.\n",
      "[15:45:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:45:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:45:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:45:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:45:20 - Predict] Found a GPU.\n",
      "[15:45:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:45:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:45:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb893d2dae0>\n",
      "[15:45:21 - MdlStrTF] loading weights from /tmp/tmpn2qw_6zg/model/variables/variables\n",
      "[15:45:21 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:45:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:45:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:21 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:45:21 - Feature] Processed ParPgb:0.0-244.0 (median depth 126.0)\n",
      "[15:45:21 - Sampler] Took 0.24s to make features.\n",
      "[15:45:21 - Sampler] Region ParPgb:0.0-244.0 (330 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:45:21 - PWorker] Processed 0 batches\n",
      "[15:45:21 - PWorker] All done, 1 remainder regions.\n",
      "[15:45:21 - Predict] Processing 1 short region(s).\n",
      "[15:45:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb802b99ae0>\n",
      "[15:45:22 - MdlStrTF] loading weights from /tmp/tmpn2qw_6zg/model/variables/variables\n",
      "[15:45:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:45:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:22 - Feature] Processed ParPgb:0.0-244.0 (median depth 126.0)\n",
      "[15:45:22 - Sampler] Took 0.05s to make features.\n",
      "[15:45:22 - PWorker] Processed 1 batches\n",
      "[15:45:22 - PWorker] All done, 0 remainder regions.\n",
      "[15:45:22 - Predict] Finished processing all regions.\n",
      "[15:45:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:26 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:45:26 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:45:26 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:45:26 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:45:26 - Predict] Found a GPU.\n",
      "[15:45:26 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:45:26 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:45:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f834c6c9ae0>\n",
      "[15:45:27 - MdlStrTF] loading weights from /tmp/tmp54g5gqcu/model/variables/variables\n",
      "[15:45:27 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:45:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:45:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:27 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[15:45:28 - Feature] Processed ParPgb:0.0-247.0 (median depth 103.0)\n",
      "[15:45:28 - Sampler] Took 0.52s to make features.\n",
      "[15:45:28 - Sampler] Region ParPgb:0.0-247.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:45:28 - PWorker] Processed 0 batches\n",
      "[15:45:28 - PWorker] All done, 1 remainder regions.\n",
      "[15:45:28 - Predict] Processing 1 short region(s).\n",
      "[15:45:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f82bc095480>\n",
      "[15:45:28 - MdlStrTF] loading weights from /tmp/tmp54g5gqcu/model/variables/variables\n",
      "[15:45:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[15:45:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:28 - Feature] Processed ParPgb:0.0-247.0 (median depth 103.0)\n",
      "[15:45:28 - Sampler] Took 0.12s to make features.\n",
      "[15:45:29 - PWorker] Processed 1 batches\n",
      "[15:45:29 - PWorker] All done, 0 remainder regions.\n",
      "[15:45:29 - Predict] Finished processing all regions.\n",
      "[15:45:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:32 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:45:32 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:45:32 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:45:32 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:45:32 - Predict] Found a GPU.\n",
      "[15:45:32 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:45:32 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:45:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5e116e1ae0>\n",
      "[15:45:33 - MdlStrTF] loading weights from /tmp/tmp8r_772p1/model/variables/variables\n",
      "[15:45:33 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:45:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:45:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[15:45:34 - Feature] Processed ParPgb:0.0-255.0 (median depth 131.0)\n",
      "[15:45:34 - Sampler] Took 0.13s to make features.\n",
      "[15:45:34 - Sampler] Region ParPgb:0.0-255.0 (377 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:45:34 - PWorker] Processed 0 batches\n",
      "[15:45:34 - PWorker] All done, 1 remainder regions.\n",
      "[15:45:34 - Predict] Processing 1 short region(s).\n",
      "[15:45:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5d808c1b10>\n",
      "[15:45:34 - MdlStrTF] loading weights from /tmp/tmp8r_772p1/model/variables/variables\n",
      "[15:45:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[15:45:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:34 - Feature] Processed ParPgb:0.0-255.0 (median depth 131.0)\n",
      "[15:45:34 - Sampler] Took 0.17s to make features.\n",
      "[15:45:35 - PWorker] Processed 1 batches\n",
      "[15:45:35 - PWorker] All done, 0 remainder regions.\n",
      "[15:45:35 - Predict] Finished processing all regions.\n",
      "[15:45:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:45:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:45:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:45:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:45:38 - Predict] Found a GPU.\n",
      "[15:45:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:45:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:45:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd4f7919ae0>\n",
      "[15:45:40 - MdlStrTF] loading weights from /tmp/tmpb5x3o37p/model/variables/variables\n",
      "[15:45:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:45:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:45:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:41 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-261.\n",
      "[15:45:41 - Feature] Processed ParPgb:0.0-261.0 (median depth 135.0)\n",
      "[15:45:41 - Sampler] Took 0.95s to make features.\n",
      "[15:45:41 - Sampler] Region ParPgb:0.0-261.0 (340 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:45:41 - PWorker] Processed 0 batches\n",
      "[15:45:41 - PWorker] All done, 1 remainder regions.\n",
      "[15:45:41 - Predict] Processing 1 short region(s).\n",
      "[15:45:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd458b15b10>\n",
      "[15:45:41 - MdlStrTF] loading weights from /tmp/tmpb5x3o37p/model/variables/variables\n",
      "[15:45:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-262.\n",
      "[15:45:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:43 - Feature] Processed ParPgb:0.0-261.0 (median depth 135.0)\n",
      "[15:45:43 - Sampler] Took 2.36s to make features.\n",
      "[15:45:44 - PWorker] Processed 1 batches\n",
      "[15:45:44 - PWorker] All done, 0 remainder regions.\n",
      "[15:45:44 - Predict] Finished processing all regions.\n",
      "[15:45:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:45:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:45:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:45:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:45:47 - Predict] Found a GPU.\n",
      "[15:45:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:45:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:45:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f07edf69ae0>\n",
      "[15:45:49 - MdlStrTF] loading weights from /tmp/tmpgmx327q0/model/variables/variables\n",
      "[15:45:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:45:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:45:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[15:45:49 - Feature] Processed ParPgb:0.0-255.0 (median depth 113.0)\n",
      "[15:45:49 - Sampler] Took 0.07s to make features.\n",
      "[15:45:49 - Sampler] Region ParPgb:0.0-255.0 (315 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:45:49 - PWorker] Processed 0 batches\n",
      "[15:45:49 - PWorker] All done, 1 remainder regions.\n",
      "[15:45:49 - Predict] Processing 1 short region(s).\n",
      "[15:45:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f075d0a1ae0>\n",
      "[15:45:49 - MdlStrTF] loading weights from /tmp/tmpgmx327q0/model/variables/variables\n",
      "[15:45:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[15:45:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:49 - Feature] Processed ParPgb:0.0-255.0 (median depth 113.0)\n",
      "[15:45:49 - Sampler] Took 0.11s to make features.\n",
      "[15:45:50 - PWorker] Processed 1 batches\n",
      "[15:45:50 - PWorker] All done, 0 remainder regions.\n",
      "[15:45:50 - Predict] Finished processing all regions.\n",
      "[15:45:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:45:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:45:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:45:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:45:53 - Predict] Found a GPU.\n",
      "[15:45:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:45:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:45:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7648cd9ae0>\n",
      "[15:45:55 - MdlStrTF] loading weights from /tmp/tmpguct3r3b/model/variables/variables\n",
      "[15:45:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:45:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:45:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-229.\n",
      "[15:45:55 - Feature] Processed ParPgb:0.0-229.0 (median depth 206.5)\n",
      "[15:45:55 - Sampler] Took 0.04s to make features.\n",
      "[15:45:55 - Sampler] Region ParPgb:0.0-229.0 (342 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:45:55 - PWorker] Processed 0 batches\n",
      "[15:45:55 - PWorker] All done, 1 remainder regions.\n",
      "[15:45:55 - Predict] Processing 1 short region(s).\n",
      "[15:45:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:45:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f75a9e71480>\n",
      "[15:45:55 - MdlStrTF] loading weights from /tmp/tmpguct3r3b/model/variables/variables\n",
      "[15:45:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-230.\n",
      "[15:45:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:45:56 - Feature] Processed ParPgb:0.0-229.0 (median depth 206.5)\n",
      "[15:45:56 - Sampler] Took 0.51s to make features.\n",
      "[15:45:56 - PWorker] Processed 1 batches\n",
      "[15:45:56 - PWorker] All done, 0 remainder regions.\n",
      "[15:45:56 - Predict] Finished processing all regions.\n",
      "[15:45:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:45:59 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:46:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:46:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:46:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:46:00 - Predict] Found a GPU.\n",
      "[15:46:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:46:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:46:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3ca55cdae0>\n",
      "[15:46:01 - MdlStrTF] loading weights from /tmp/tmph3nc2_k_/model/variables/variables\n",
      "[15:46:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:46:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:46:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[15:46:01 - Feature] Processed ParPgb:0.0-248.0 (median depth 123.0)\n",
      "[15:46:01 - Sampler] Took 0.12s to make features.\n",
      "[15:46:01 - Sampler] Region ParPgb:0.0-248.0 (321 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:46:01 - PWorker] Processed 0 batches\n",
      "[15:46:01 - PWorker] All done, 1 remainder regions.\n",
      "[15:46:01 - Predict] Processing 1 short region(s).\n",
      "[15:46:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3c107c5ff0>\n",
      "[15:46:01 - MdlStrTF] loading weights from /tmp/tmph3nc2_k_/model/variables/variables\n",
      "[15:46:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[15:46:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:02 - Feature] Processed ParPgb:0.0-248.0 (median depth 123.0)\n",
      "[15:46:02 - Sampler] Took 0.06s to make features.\n",
      "[15:46:02 - PWorker] Processed 1 batches\n",
      "[15:46:02 - PWorker] All done, 0 remainder regions.\n",
      "[15:46:02 - Predict] Finished processing all regions.\n",
      "[15:46:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:46:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:46:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:46:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:46:06 - Predict] Found a GPU.\n",
      "[15:46:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:46:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:46:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fae20ce1a80>\n",
      "[15:46:07 - MdlStrTF] loading weights from /tmp/tmpid10k0wp/model/variables/variables\n",
      "[15:46:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:46:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:46:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:07 - Sampler] Took 0.09s to make features.\n",
      "[15:46:07 - PWorker] Processed 0 batches\n",
      "[15:46:07 - PWorker] All done, 0 remainder regions.\n",
      "[15:46:07 - Predict] Finished processing all regions.\n",
      "[15:46:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:09 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:46:10 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:46:10 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:46:10 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:46:10 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:46:10 - Predict] Found a GPU.\n",
      "[15:46:10 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:46:10 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:46:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:12 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8582981ae0>\n",
      "[15:46:12 - MdlStrTF] loading weights from /tmp/tmph5htgsr3/model/variables/variables\n",
      "[15:46:12 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:46:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:46:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:46:14 - Feature] Processed ParPgb:0.0-243.0 (median depth 153.0)\n",
      "[15:46:14 - Sampler] Took 2.42s to make features.\n",
      "[15:46:14 - Sampler] Region ParPgb:0.0-243.0 (345 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:46:14 - PWorker] Processed 0 batches\n",
      "[15:46:14 - PWorker] All done, 1 remainder regions.\n",
      "[15:46:14 - Predict] Processing 1 short region(s).\n",
      "[15:46:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f84f1b29450>\n",
      "[15:46:14 - MdlStrTF] loading weights from /tmp/tmph5htgsr3/model/variables/variables\n",
      "[15:46:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:46:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:14 - Feature] Processed ParPgb:0.0-243.0 (median depth 153.0)\n",
      "[15:46:14 - Sampler] Took 0.04s to make features.\n",
      "[15:46:15 - PWorker] Processed 1 batches\n",
      "[15:46:15 - PWorker] All done, 0 remainder regions.\n",
      "[15:46:15 - Predict] Finished processing all regions.\n",
      "[15:46:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:18 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:46:18 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:46:18 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:46:18 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:46:18 - Predict] Found a GPU.\n",
      "[15:46:18 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:46:18 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:46:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7bbe9edae0>\n",
      "[15:46:20 - MdlStrTF] loading weights from /tmp/tmpe91173_4/model/variables/variables\n",
      "[15:46:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:46:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:46:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[15:46:20 - Feature] Processed ParPgb:0.0-254.0 (median depth 149.0)\n",
      "[15:46:20 - Sampler] Took 0.04s to make features.\n",
      "[15:46:20 - Sampler] Region ParPgb:0.0-254.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:46:20 - PWorker] Processed 0 batches\n",
      "[15:46:20 - PWorker] All done, 1 remainder regions.\n",
      "[15:46:20 - Predict] Processing 1 short region(s).\n",
      "[15:46:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7b2daa5480>\n",
      "[15:46:20 - MdlStrTF] loading weights from /tmp/tmpe91173_4/model/variables/variables\n",
      "[15:46:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[15:46:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:20 - Feature] Processed ParPgb:0.0-254.0 (median depth 149.0)\n",
      "[15:46:20 - Sampler] Took 0.06s to make features.\n",
      "[15:46:21 - PWorker] Processed 1 batches\n",
      "[15:46:21 - PWorker] All done, 0 remainder regions.\n",
      "[15:46:21 - Predict] Finished processing all regions.\n",
      "[15:46:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:46:24 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:46:24 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:46:24 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:46:24 - Predict] Found a GPU.\n",
      "[15:46:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:46:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:46:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd0b16fda80>\n",
      "[15:46:26 - MdlStrTF] loading weights from /tmp/tmpn22rq3uq/model/variables/variables\n",
      "[15:46:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:46:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:46:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-213.\n",
      "[15:46:26 - Feature] Processed ParPgb:0.0-213.0 (median depth 70.0)\n",
      "[15:46:26 - Sampler] Took 0.16s to make features.\n",
      "[15:46:26 - Sampler] Region ParPgb:0.0-213.0 (253 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:46:26 - PWorker] Processed 0 batches\n",
      "[15:46:26 - PWorker] All done, 1 remainder regions.\n",
      "[15:46:26 - Predict] Processing 1 short region(s).\n",
      "[15:46:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd0208c9a80>\n",
      "[15:46:26 - MdlStrTF] loading weights from /tmp/tmpn22rq3uq/model/variables/variables\n",
      "[15:46:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-214.\n",
      "[15:46:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:26 - Feature] Processed ParPgb:0.0-213.0 (median depth 70.0)\n",
      "[15:46:26 - Sampler] Took 0.05s to make features.\n",
      "[15:46:27 - PWorker] Processed 1 batches\n",
      "[15:46:27 - PWorker] All done, 0 remainder regions.\n",
      "[15:46:27 - Predict] Finished processing all regions.\n",
      "[15:46:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:46:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:46:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:46:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:46:30 - Predict] Found a GPU.\n",
      "[15:46:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:46:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:46:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa5535d5ae0>\n",
      "[15:46:32 - MdlStrTF] loading weights from /tmp/tmp329za2l5/model/variables/variables\n",
      "[15:46:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:46:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:46:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:32 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:46:32 - Feature] Processed ParPgb:0.0-244.0 (median depth 92.0)\n",
      "[15:46:32 - Sampler] Took 0.04s to make features.\n",
      "[15:46:32 - Sampler] Region ParPgb:0.0-244.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:46:32 - PWorker] Processed 0 batches\n",
      "[15:46:32 - PWorker] All done, 1 remainder regions.\n",
      "[15:46:32 - Predict] Processing 1 short region(s).\n",
      "[15:46:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa4c049d450>\n",
      "[15:46:32 - MdlStrTF] loading weights from /tmp/tmp329za2l5/model/variables/variables\n",
      "[15:46:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:46:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:32 - Feature] Processed ParPgb:0.0-244.0 (median depth 92.0)\n",
      "[15:46:32 - Sampler] Took 0.04s to make features.\n",
      "[15:46:33 - PWorker] Processed 1 batches\n",
      "[15:46:33 - PWorker] All done, 0 remainder regions.\n",
      "[15:46:33 - Predict] Finished processing all regions.\n",
      "[15:46:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:36 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:46:36 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:46:36 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:46:36 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:46:36 - Predict] Found a GPU.\n",
      "[15:46:36 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:46:36 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:46:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdb0a319a80>\n",
      "[15:46:37 - MdlStrTF] loading weights from /tmp/tmpr0tuu8lh/model/variables/variables\n",
      "[15:46:38 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:46:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:46:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:38 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[15:46:38 - Feature] Processed ParPgb:0.0-248.0 (median depth 90.0)\n",
      "[15:46:38 - Sampler] Took 0.05s to make features.\n",
      "[15:46:38 - Sampler] Region ParPgb:0.0-248.0 (298 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:46:38 - PWorker] Processed 0 batches\n",
      "[15:46:38 - PWorker] All done, 1 remainder regions.\n",
      "[15:46:38 - Predict] Processing 1 short region(s).\n",
      "[15:46:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fda79429420>\n",
      "[15:46:38 - MdlStrTF] loading weights from /tmp/tmpr0tuu8lh/model/variables/variables\n",
      "[15:46:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[15:46:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:38 - Feature] Processed ParPgb:0.0-248.0 (median depth 90.0)\n",
      "[15:46:38 - Sampler] Took 0.23s to make features.\n",
      "[15:46:39 - PWorker] Processed 1 batches\n",
      "[15:46:39 - PWorker] All done, 0 remainder regions.\n",
      "[15:46:39 - Predict] Finished processing all regions.\n",
      "[15:46:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:46:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:46:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:46:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:46:42 - Predict] Found a GPU.\n",
      "[15:46:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:46:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:46:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbc878c5ae0>\n",
      "[15:46:44 - MdlStrTF] loading weights from /tmp/tmp5_kibp_r/model/variables/variables\n",
      "[15:46:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:46:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:46:44 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:46:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:44 - Feature] Processed ParPgb:0.0-246.0 (median depth 134.0)\n",
      "[15:46:44 - Sampler] Took 0.10s to make features.\n",
      "[15:46:44 - Sampler] Region ParPgb:0.0-246.0 (321 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:46:44 - PWorker] Processed 0 batches\n",
      "[15:46:44 - PWorker] All done, 1 remainder regions.\n",
      "[15:46:44 - Predict] Processing 1 short region(s).\n",
      "[15:46:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbbe8a3e380>\n",
      "[15:46:44 - MdlStrTF] loading weights from /tmp/tmp5_kibp_r/model/variables/variables\n",
      "[15:46:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:46:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:44 - Feature] Processed ParPgb:0.0-246.0 (median depth 134.0)\n",
      "[15:46:44 - Sampler] Took 0.08s to make features.\n",
      "[15:46:45 - PWorker] Processed 1 batches\n",
      "[15:46:45 - PWorker] All done, 0 remainder regions.\n",
      "[15:46:45 - Predict] Finished processing all regions.\n",
      "[15:46:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:48 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:46:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:46:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:46:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:46:48 - Predict] Found a GPU.\n",
      "[15:46:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:46:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:46:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f51a30b1ae0>\n",
      "[15:46:49 - MdlStrTF] loading weights from /tmp/tmpqxs3u6ao/model/variables/variables\n",
      "[15:46:50 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:46:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:46:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:50 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:46:50 - Feature] Processed ParPgb:0.0-252.0 (median depth 120.0)\n",
      "[15:46:50 - Sampler] Took 0.03s to make features.\n",
      "[15:46:50 - Sampler] Region ParPgb:0.0-252.0 (316 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:46:50 - PWorker] Processed 0 batches\n",
      "[15:46:50 - PWorker] All done, 1 remainder regions.\n",
      "[15:46:50 - Predict] Processing 1 short region(s).\n",
      "[15:46:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5111f3d450>\n",
      "[15:46:50 - MdlStrTF] loading weights from /tmp/tmpqxs3u6ao/model/variables/variables\n",
      "[15:46:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:46:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:50 - Feature] Processed ParPgb:0.0-252.0 (median depth 120.0)\n",
      "[15:46:50 - Sampler] Took 0.04s to make features.\n",
      "[15:46:51 - PWorker] Processed 1 batches\n",
      "[15:46:51 - PWorker] All done, 0 remainder regions.\n",
      "[15:46:51 - Predict] Finished processing all regions.\n",
      "[15:46:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:46:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:46:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:46:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:46:54 - Predict] Found a GPU.\n",
      "[15:46:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:46:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:46:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faf52339ae0>\n",
      "[15:46:55 - MdlStrTF] loading weights from /tmp/tmpzkxu19k5/model/variables/variables\n",
      "[15:46:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:46:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:46:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-235.\n",
      "[15:46:56 - Feature] Processed ParPgb:0.0-235.0 (median depth 140.0)\n",
      "[15:46:56 - Sampler] Took 0.20s to make features.\n",
      "[15:46:56 - Sampler] Region ParPgb:0.0-235.0 (304 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:46:56 - PWorker] Processed 0 batches\n",
      "[15:46:56 - PWorker] All done, 1 remainder regions.\n",
      "[15:46:56 - Predict] Processing 1 short region(s).\n",
      "[15:46:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:46:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faec1529ff0>\n",
      "[15:46:56 - MdlStrTF] loading weights from /tmp/tmpzkxu19k5/model/variables/variables\n",
      "[15:46:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-236.\n",
      "[15:46:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:46:56 - Feature] Processed ParPgb:0.0-235.0 (median depth 140.0)\n",
      "[15:46:56 - Sampler] Took 0.04s to make features.\n",
      "[15:46:57 - PWorker] Processed 1 batches\n",
      "[15:46:57 - PWorker] All done, 0 remainder regions.\n",
      "[15:46:57 - Predict] Finished processing all regions.\n",
      "[15:46:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:46:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:47:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:47:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:47:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:47:00 - Predict] Found a GPU.\n",
      "[15:47:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:47:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:47:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f24ae2b5ae0>\n",
      "[15:47:01 - MdlStrTF] loading weights from /tmp/tmpbl_pwk9b/model/variables/variables\n",
      "[15:47:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:47:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:47:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[15:47:04 - Feature] Processed ParPgb:0.0-240.0 (median depth 107.0)\n",
      "[15:47:04 - Sampler] Took 2.90s to make features.\n",
      "[15:47:04 - Sampler] Region ParPgb:0.0-240.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:47:04 - PWorker] Processed 0 batches\n",
      "[15:47:04 - PWorker] All done, 1 remainder regions.\n",
      "[15:47:04 - Predict] Processing 1 short region(s).\n",
      "[15:47:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f241c2bd450>\n",
      "[15:47:05 - MdlStrTF] loading weights from /tmp/tmpbl_pwk9b/model/variables/variables\n",
      "[15:47:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[15:47:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:05 - Feature] Processed ParPgb:0.0-240.0 (median depth 107.0)\n",
      "[15:47:05 - Sampler] Took 0.05s to make features.\n",
      "[15:47:05 - PWorker] Processed 1 batches\n",
      "[15:47:05 - PWorker] All done, 0 remainder regions.\n",
      "[15:47:05 - Predict] Finished processing all regions.\n",
      "[15:47:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:47:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:47:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:47:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:47:09 - Predict] Found a GPU.\n",
      "[15:47:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:47:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:47:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7533cedae0>\n",
      "[15:47:10 - MdlStrTF] loading weights from /tmp/tmp9o4s0sxd/model/variables/variables\n",
      "[15:47:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:47:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:47:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:10 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-222.\n",
      "[15:47:10 - Feature] Processed ParPgb:0.0-222.0 (median depth 107.0)\n",
      "[15:47:10 - Sampler] Took 0.06s to make features.\n",
      "[15:47:10 - Sampler] Region ParPgb:0.0-222.0 (275 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:47:10 - PWorker] Processed 0 batches\n",
      "[15:47:10 - PWorker] All done, 1 remainder regions.\n",
      "[15:47:10 - Predict] Processing 1 short region(s).\n",
      "[15:47:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f74a2105480>\n",
      "[15:47:11 - MdlStrTF] loading weights from /tmp/tmp9o4s0sxd/model/variables/variables\n",
      "[15:47:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-223.\n",
      "[15:47:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:11 - Feature] Processed ParPgb:0.0-222.0 (median depth 107.0)\n",
      "[15:47:11 - Sampler] Took 0.04s to make features.\n",
      "[15:47:11 - PWorker] Processed 1 batches\n",
      "[15:47:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:47:11 - Predict] Finished processing all regions.\n",
      "[15:47:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:47:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:47:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:47:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:47:15 - Predict] Found a GPU.\n",
      "[15:47:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:47:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:47:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff6169bdae0>\n",
      "[15:47:16 - MdlStrTF] loading weights from /tmp/tmp_5im061k/model/variables/variables\n",
      "[15:47:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:47:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:47:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[15:47:16 - Feature] Processed ParPgb:0.0-254.0 (median depth 164.0)\n",
      "[15:47:16 - Sampler] Took 0.14s to make features.\n",
      "[15:47:16 - Sampler] Region ParPgb:0.0-254.0 (342 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:47:16 - PWorker] Processed 0 batches\n",
      "[15:47:16 - PWorker] All done, 1 remainder regions.\n",
      "[15:47:16 - Predict] Processing 1 short region(s).\n",
      "[15:47:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff578309ae0>\n",
      "[15:47:17 - MdlStrTF] loading weights from /tmp/tmp_5im061k/model/variables/variables\n",
      "[15:47:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[15:47:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:17 - Feature] Processed ParPgb:0.0-254.0 (median depth 164.0)\n",
      "[15:47:17 - Sampler] Took 0.05s to make features.\n",
      "[15:47:17 - PWorker] Processed 1 batches\n",
      "[15:47:17 - PWorker] All done, 0 remainder regions.\n",
      "[15:47:17 - Predict] Finished processing all regions.\n",
      "[15:47:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:21 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:47:21 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:47:21 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:47:21 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:47:21 - Predict] Found a GPU.\n",
      "[15:47:21 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:47:21 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:47:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5165961ae0>\n",
      "[15:47:22 - MdlStrTF] loading weights from /tmp/tmp99fmcj09/model/variables/variables\n",
      "[15:47:22 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:47:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:47:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:22 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-195.\n",
      "[15:47:22 - Feature] Processed ParPgb:0.0-195.0 (median depth 3.0)\n",
      "[15:47:22 - Sampler] Took 0.04s to make features.\n",
      "[15:47:22 - Sampler] Region ParPgb:0.0-195.0 (196 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:47:22 - PWorker] Processed 0 batches\n",
      "[15:47:22 - PWorker] All done, 1 remainder regions.\n",
      "[15:47:22 - Predict] Processing 1 short region(s).\n",
      "[15:47:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f50d0a6dff0>\n",
      "[15:47:22 - MdlStrTF] loading weights from /tmp/tmp99fmcj09/model/variables/variables\n",
      "[15:47:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-196.\n",
      "[15:47:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:24 - Feature] Processed ParPgb:0.0-195.0 (median depth 3.0)\n",
      "[15:47:24 - Sampler] Took 1.12s to make features.\n",
      "[15:47:24 - PWorker] Processed 1 batches\n",
      "[15:47:24 - PWorker] All done, 0 remainder regions.\n",
      "[15:47:24 - Predict] Finished processing all regions.\n",
      "[15:47:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:27 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:47:27 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:47:27 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:47:27 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:47:28 - Predict] Found a GPU.\n",
      "[15:47:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:47:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:47:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f78b6b01ae0>\n",
      "[15:47:29 - MdlStrTF] loading weights from /tmp/tmp3ktl11mr/model/variables/variables\n",
      "[15:47:29 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:47:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:47:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:29 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-261.\n",
      "[15:47:29 - Feature] Processed ParPgb:0.0-261.0 (median depth 84.0)\n",
      "[15:47:29 - Sampler] Took 0.13s to make features.\n",
      "[15:47:29 - Sampler] Region ParPgb:0.0-261.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:47:29 - PWorker] Processed 0 batches\n",
      "[15:47:29 - PWorker] All done, 1 remainder regions.\n",
      "[15:47:29 - Predict] Processing 1 short region(s).\n",
      "[15:47:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7818479ff0>\n",
      "[15:47:29 - MdlStrTF] loading weights from /tmp/tmp3ktl11mr/model/variables/variables\n",
      "[15:47:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-262.\n",
      "[15:47:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:29 - Feature] Processed ParPgb:0.0-261.0 (median depth 84.0)\n",
      "[15:47:29 - Sampler] Took 0.06s to make features.\n",
      "[15:47:30 - PWorker] Processed 1 batches\n",
      "[15:47:30 - PWorker] All done, 0 remainder regions.\n",
      "[15:47:30 - Predict] Finished processing all regions.\n",
      "[15:47:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:33 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:47:33 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:47:33 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:47:33 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:47:33 - Predict] Found a GPU.\n",
      "[15:47:33 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:47:33 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:47:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbcf26bdae0>\n",
      "[15:47:35 - MdlStrTF] loading weights from /tmp/tmpahbpxnr8/model/variables/variables\n",
      "[15:47:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:47:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:47:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:35 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-218.\n",
      "[15:47:35 - Feature] Processed ParPgb:0.0-218.0 (median depth 105.0)\n",
      "[15:47:35 - Sampler] Took 0.04s to make features.\n",
      "[15:47:35 - Sampler] Region ParPgb:0.0-218.0 (275 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:47:35 - PWorker] Processed 0 batches\n",
      "[15:47:35 - PWorker] All done, 1 remainder regions.\n",
      "[15:47:35 - Predict] Processing 1 short region(s).\n",
      "[15:47:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbc610ee170>\n",
      "[15:47:35 - MdlStrTF] loading weights from /tmp/tmpahbpxnr8/model/variables/variables\n",
      "[15:47:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-219.\n",
      "[15:47:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:37 - Feature] Processed ParPgb:0.0-218.0 (median depth 105.0)\n",
      "[15:47:37 - Sampler] Took 1.54s to make features.\n",
      "[15:47:37 - PWorker] Processed 1 batches\n",
      "[15:47:37 - PWorker] All done, 0 remainder regions.\n",
      "[15:47:37 - Predict] Finished processing all regions.\n",
      "[15:47:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:47:41 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:47:41 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:47:41 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:47:41 - Predict] Found a GPU.\n",
      "[15:47:41 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:47:41 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:47:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5d9e1f5ae0>\n",
      "[15:47:42 - MdlStrTF] loading weights from /tmp/tmp853asdk8/model/variables/variables\n",
      "[15:47:42 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:47:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:47:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-219.\n",
      "[15:47:51 - Feature] Processed ParPgb:0.0-219.0 (median depth 152.0)\n",
      "[15:47:51 - Sampler] Took 9.31s to make features.\n",
      "[15:47:51 - Sampler] Region ParPgb:0.0-219.0 (305 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:47:51 - PWorker] Processed 0 batches\n",
      "[15:47:51 - PWorker] All done, 1 remainder regions.\n",
      "[15:47:51 - Predict] Processing 1 short region(s).\n",
      "[15:47:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5d0d0155a0>\n",
      "[15:47:52 - MdlStrTF] loading weights from /tmp/tmp853asdk8/model/variables/variables\n",
      "[15:47:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-220.\n",
      "[15:47:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:52 - Feature] Processed ParPgb:0.0-219.0 (median depth 152.0)\n",
      "[15:47:52 - Sampler] Took 0.13s to make features.\n",
      "[15:47:53 - PWorker] Processed 1 batches\n",
      "[15:47:53 - PWorker] All done, 0 remainder regions.\n",
      "[15:47:53 - Predict] Finished processing all regions.\n",
      "[15:47:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:47:56 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:47:56 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:47:56 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:47:56 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:47:56 - Predict] Found a GPU.\n",
      "[15:47:56 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:47:56 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:47:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6b48581ae0>\n",
      "[15:47:57 - MdlStrTF] loading weights from /tmp/tmpm_qm13pk/model/variables/variables\n",
      "[15:47:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:47:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:47:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:57 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:47:57 - Feature] Processed ParPgb:0.0-246.0 (median depth 112.0)\n",
      "[15:47:57 - Sampler] Took 0.03s to make features.\n",
      "[15:47:57 - Sampler] Region ParPgb:0.0-246.0 (328 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:47:57 - PWorker] Processed 0 batches\n",
      "[15:47:57 - PWorker] All done, 1 remainder regions.\n",
      "[15:47:57 - Predict] Processing 1 short region(s).\n",
      "[15:47:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:47:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6aa96a1480>\n",
      "[15:47:58 - MdlStrTF] loading weights from /tmp/tmpm_qm13pk/model/variables/variables\n",
      "[15:47:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:47:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:47:58 - Feature] Processed ParPgb:0.0-246.0 (median depth 112.0)\n",
      "[15:47:58 - Sampler] Took 0.04s to make features.\n",
      "[15:47:58 - PWorker] Processed 1 batches\n",
      "[15:47:58 - PWorker] All done, 0 remainder regions.\n",
      "[15:47:58 - Predict] Finished processing all regions.\n",
      "[15:48:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:48:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:48:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:48:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:48:02 - Predict] Found a GPU.\n",
      "[15:48:02 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:48:02 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:48:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f81af619ae0>\n",
      "[15:48:03 - MdlStrTF] loading weights from /tmp/tmpvc56p2hv/model/variables/variables\n",
      "[15:48:03 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:48:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:48:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:03 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:48:03 - Feature] Processed ParPgb:0.0-249.0 (median depth 121.0)\n",
      "[15:48:03 - Sampler] Took 0.09s to make features.\n",
      "[15:48:03 - Sampler] Region ParPgb:0.0-249.0 (324 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:48:03 - PWorker] Processed 0 batches\n",
      "[15:48:03 - PWorker] All done, 1 remainder regions.\n",
      "[15:48:03 - Predict] Processing 1 short region(s).\n",
      "[15:48:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f81107761a0>\n",
      "[15:48:04 - MdlStrTF] loading weights from /tmp/tmpvc56p2hv/model/variables/variables\n",
      "[15:48:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:48:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:04 - Feature] Processed ParPgb:0.0-249.0 (median depth 121.0)\n",
      "[15:48:04 - Sampler] Took 0.05s to make features.\n",
      "[15:48:04 - PWorker] Processed 1 batches\n",
      "[15:48:04 - PWorker] All done, 0 remainder regions.\n",
      "[15:48:04 - Predict] Finished processing all regions.\n",
      "[15:48:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:48:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:48:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:48:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:48:08 - Predict] Found a GPU.\n",
      "[15:48:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:48:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:48:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2bd4091a80>\n",
      "[15:48:09 - MdlStrTF] loading weights from /tmp/tmpdb9yfmho/model/variables/variables\n",
      "[15:48:09 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:48:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:48:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:09 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:48:09 - Feature] Processed ParPgb:0.0-246.0 (median depth 103.0)\n",
      "[15:48:09 - Sampler] Took 0.14s to make features.\n",
      "[15:48:09 - Sampler] Region ParPgb:0.0-246.0 (328 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:48:09 - PWorker] Processed 0 batches\n",
      "[15:48:09 - PWorker] All done, 1 remainder regions.\n",
      "[15:48:09 - Predict] Processing 1 short region(s).\n",
      "[15:48:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2b40269f90>\n",
      "[15:48:10 - MdlStrTF] loading weights from /tmp/tmpdb9yfmho/model/variables/variables\n",
      "[15:48:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:48:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:10 - Feature] Processed ParPgb:0.0-246.0 (median depth 103.0)\n",
      "[15:48:10 - Sampler] Took 0.66s to make features.\n",
      "[15:48:11 - PWorker] Processed 1 batches\n",
      "[15:48:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:48:11 - Predict] Finished processing all regions.\n",
      "[15:48:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:48:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:48:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:48:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:48:14 - Predict] Found a GPU.\n",
      "[15:48:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:48:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:48:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9244fb1ae0>\n",
      "[15:48:16 - MdlStrTF] loading weights from /tmp/tmpro_26oqb/model/variables/variables\n",
      "[15:48:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:48:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:48:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:48:20 - Feature] Processed ParPgb:0.0-251.0 (median depth 143.0)\n",
      "[15:48:20 - Sampler] Took 4.55s to make features.\n",
      "[15:48:20 - Sampler] Region ParPgb:0.0-251.0 (323 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:48:20 - PWorker] Processed 0 batches\n",
      "[15:48:20 - PWorker] All done, 1 remainder regions.\n",
      "[15:48:20 - Predict] Processing 1 short region(s).\n",
      "[15:48:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f91b0125960>\n",
      "[15:48:21 - MdlStrTF] loading weights from /tmp/tmpro_26oqb/model/variables/variables\n",
      "[15:48:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:48:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:21 - Feature] Processed ParPgb:0.0-251.0 (median depth 143.0)\n",
      "[15:48:21 - Sampler] Took 0.07s to make features.\n",
      "[15:48:21 - PWorker] Processed 1 batches\n",
      "[15:48:21 - PWorker] All done, 0 remainder regions.\n",
      "[15:48:21 - Predict] Finished processing all regions.\n",
      "[15:48:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:48:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:48:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:48:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:48:25 - Predict] Found a GPU.\n",
      "[15:48:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:48:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:48:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6bd5d7dae0>\n",
      "[15:48:26 - MdlStrTF] loading weights from /tmp/tmphdhk0gzx/model/variables/variables\n",
      "[15:48:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:48:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:48:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-260.\n",
      "[15:48:26 - Feature] Processed ParPgb:0.0-260.0 (median depth 152.0)\n",
      "[15:48:26 - Sampler] Took 0.06s to make features.\n",
      "[15:48:26 - Sampler] Region ParPgb:0.0-260.0 (360 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:48:26 - PWorker] Processed 0 batches\n",
      "[15:48:26 - PWorker] All done, 1 remainder regions.\n",
      "[15:48:26 - Predict] Processing 1 short region(s).\n",
      "[15:48:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6b40e6eef0>\n",
      "[15:48:27 - MdlStrTF] loading weights from /tmp/tmphdhk0gzx/model/variables/variables\n",
      "[15:48:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-261.\n",
      "[15:48:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:27 - Feature] Processed ParPgb:0.0-260.0 (median depth 152.0)\n",
      "[15:48:27 - Sampler] Took 0.04s to make features.\n",
      "[15:48:27 - PWorker] Processed 1 batches\n",
      "[15:48:27 - PWorker] All done, 0 remainder regions.\n",
      "[15:48:27 - Predict] Finished processing all regions.\n",
      "[15:48:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:48:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:48:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:48:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:48:31 - Predict] Found a GPU.\n",
      "[15:48:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:48:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:48:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb88dbe1ae0>\n",
      "[15:48:32 - MdlStrTF] loading weights from /tmp/tmptq1ff9sq/model/variables/variables\n",
      "[15:48:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:48:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:48:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:32 - Sampler] Took 0.23s to make features.\n",
      "[15:48:32 - PWorker] Processed 0 batches\n",
      "[15:48:32 - PWorker] All done, 0 remainder regions.\n",
      "[15:48:32 - Predict] Finished processing all regions.\n",
      "[15:48:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:34 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:48:35 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:48:35 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:48:35 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:48:35 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:48:35 - Predict] Found a GPU.\n",
      "[15:48:35 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:48:35 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:48:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fba37f3da80>\n",
      "[15:48:37 - MdlStrTF] loading weights from /tmp/tmps2dflnqp/model/variables/variables\n",
      "[15:48:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:48:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:48:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:48:37 - Feature] Processed ParPgb:0.0-244.0 (median depth 127.0)\n",
      "[15:48:37 - Sampler] Took 0.09s to make features.\n",
      "[15:48:37 - Sampler] Region ParPgb:0.0-244.0 (312 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:48:37 - PWorker] Processed 0 batches\n",
      "[15:48:37 - PWorker] All done, 1 remainder regions.\n",
      "[15:48:37 - Predict] Processing 1 short region(s).\n",
      "[15:48:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb9a80c5ab0>\n",
      "[15:48:37 - MdlStrTF] loading weights from /tmp/tmps2dflnqp/model/variables/variables\n",
      "[15:48:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:48:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:37 - Feature] Processed ParPgb:0.0-244.0 (median depth 127.0)\n",
      "[15:48:37 - Sampler] Took 0.05s to make features.\n",
      "[15:48:38 - PWorker] Processed 1 batches\n",
      "[15:48:38 - PWorker] All done, 0 remainder regions.\n",
      "[15:48:38 - Predict] Finished processing all regions.\n",
      "[15:48:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:48:41 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:48:41 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:48:41 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:48:41 - Predict] Found a GPU.\n",
      "[15:48:41 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:48:41 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:48:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f98e2079ae0>\n",
      "[15:48:43 - MdlStrTF] loading weights from /tmp/tmp6bosyrf5/model/variables/variables\n",
      "[15:48:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:48:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:48:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-224.\n",
      "[15:48:43 - Feature] Processed ParPgb:0.0-224.0 (median depth 218.0)\n",
      "[15:48:43 - Sampler] Took 0.04s to make features.\n",
      "[15:48:43 - Sampler] Region ParPgb:0.0-224.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:48:43 - PWorker] Processed 0 batches\n",
      "[15:48:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:48:43 - Predict] Processing 1 short region(s).\n",
      "[15:48:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9850f3d480>\n",
      "[15:48:43 - MdlStrTF] loading weights from /tmp/tmp6bosyrf5/model/variables/variables\n",
      "[15:48:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-225.\n",
      "[15:48:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:43 - Feature] Processed ParPgb:0.0-224.0 (median depth 218.0)\n",
      "[15:48:43 - Sampler] Took 0.06s to make features.\n",
      "[15:48:44 - PWorker] Processed 1 batches\n",
      "[15:48:44 - PWorker] All done, 0 remainder regions.\n",
      "[15:48:44 - Predict] Finished processing all regions.\n",
      "[15:48:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:48:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:48:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:48:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:48:47 - Predict] Found a GPU.\n",
      "[15:48:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:48:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:48:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa0795f1ae0>\n",
      "[15:48:49 - MdlStrTF] loading weights from /tmp/tmpnshxr2eh/model/variables/variables\n",
      "[15:48:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:48:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:48:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:51 - Sampler] Took 2.21s to make features.\n",
      "[15:48:51 - PWorker] Processed 0 batches\n",
      "[15:48:51 - PWorker] All done, 0 remainder regions.\n",
      "[15:48:51 - Predict] Finished processing all regions.\n",
      "[15:48:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:52 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:48:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:48:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:48:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:48:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:48:54 - Predict] Found a GPU.\n",
      "[15:48:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:48:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:48:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3535d11ae0>\n",
      "[15:48:55 - MdlStrTF] loading weights from /tmp/tmp13bay13o/model/variables/variables\n",
      "[15:48:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:48:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:48:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:48:55 - Feature] Processed ParPgb:0.0-246.0 (median depth 150.0)\n",
      "[15:48:55 - Sampler] Took 0.05s to make features.\n",
      "[15:48:55 - Sampler] Region ParPgb:0.0-246.0 (347 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:48:55 - PWorker] Processed 0 batches\n",
      "[15:48:55 - PWorker] All done, 1 remainder regions.\n",
      "[15:48:55 - Predict] Processing 1 short region(s).\n",
      "[15:48:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:48:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f34a0d69990>\n",
      "[15:48:56 - MdlStrTF] loading weights from /tmp/tmp13bay13o/model/variables/variables\n",
      "[15:48:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:48:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:48:56 - Feature] Processed ParPgb:0.0-246.0 (median depth 150.0)\n",
      "[15:48:56 - Sampler] Took 0.05s to make features.\n",
      "[15:48:57 - PWorker] Processed 1 batches\n",
      "[15:48:57 - PWorker] All done, 0 remainder regions.\n",
      "[15:48:57 - Predict] Finished processing all regions.\n",
      "[15:48:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:48:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:49:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:49:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:49:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:49:00 - Predict] Found a GPU.\n",
      "[15:49:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:49:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:49:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7e2ff89a80>\n",
      "[15:49:01 - MdlStrTF] loading weights from /tmp/tmp4o3p2a0r/model/variables/variables\n",
      "[15:49:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:49:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:49:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:02 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-192.\n",
      "[15:49:02 - Feature] Processed ParPgb:0.0-192.0 (median depth 1.0)\n",
      "[15:49:02 - Sampler] Took 0.29s to make features.\n",
      "[15:49:02 - Sampler] Region ParPgb:0.0-192.0 (193 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:49:02 - PWorker] Processed 0 batches\n",
      "[15:49:02 - PWorker] All done, 1 remainder regions.\n",
      "[15:49:02 - Predict] Processing 1 short region(s).\n",
      "[15:49:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7da00c21d0>\n",
      "[15:49:02 - MdlStrTF] loading weights from /tmp/tmp4o3p2a0r/model/variables/variables\n",
      "[15:49:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-193.\n",
      "[15:49:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:02 - Feature] Processed ParPgb:0.0-192.0 (median depth 1.0)\n",
      "[15:49:02 - Sampler] Took 0.04s to make features.\n",
      "[15:49:03 - PWorker] Processed 1 batches\n",
      "[15:49:03 - PWorker] All done, 0 remainder regions.\n",
      "[15:49:03 - Predict] Finished processing all regions.\n",
      "[15:49:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:06 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:49:06 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:49:06 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:49:06 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:49:06 - Predict] Found a GPU.\n",
      "[15:49:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:49:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:49:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0af9d3da80>\n",
      "[15:49:07 - MdlStrTF] loading weights from /tmp/tmp1vk8efhu/model/variables/variables\n",
      "[15:49:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:49:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:49:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-192.\n",
      "[15:49:07 - Feature] Processed ParPgb:0.0-192.0 (median depth 1.0)\n",
      "[15:49:07 - Sampler] Took 0.05s to make features.\n",
      "[15:49:07 - Sampler] Region ParPgb:0.0-192.0 (194 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:49:07 - PWorker] Processed 0 batches\n",
      "[15:49:07 - PWorker] All done, 1 remainder regions.\n",
      "[15:49:07 - Predict] Processing 1 short region(s).\n",
      "[15:49:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0a68ebefb0>\n",
      "[15:49:08 - MdlStrTF] loading weights from /tmp/tmp1vk8efhu/model/variables/variables\n",
      "[15:49:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-193.\n",
      "[15:49:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:08 - Feature] Processed ParPgb:0.0-192.0 (median depth 1.0)\n",
      "[15:49:08 - Sampler] Took 0.05s to make features.\n",
      "[15:49:08 - PWorker] Processed 1 batches\n",
      "[15:49:08 - PWorker] All done, 0 remainder regions.\n",
      "[15:49:08 - Predict] Finished processing all regions.\n",
      "[15:49:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:49:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:49:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:49:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:49:12 - Predict] Found a GPU.\n",
      "[15:49:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:49:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:49:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f94a9689ae0>\n",
      "[15:49:13 - MdlStrTF] loading weights from /tmp/tmpuzl4pu5t/model/variables/variables\n",
      "[15:49:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:49:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:49:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:13 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-280.\n",
      "[15:49:13 - Feature] Processed ParPgb:0.0-280.0 (median depth 187.0)\n",
      "[15:49:13 - Sampler] Took 0.11s to make features.\n",
      "[15:49:13 - Sampler] Region ParPgb:0.0-280.0 (375 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:49:13 - PWorker] Processed 0 batches\n",
      "[15:49:13 - PWorker] All done, 1 remainder regions.\n",
      "[15:49:13 - Predict] Processing 1 short region(s).\n",
      "[15:49:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f94180c1480>\n",
      "[15:49:14 - MdlStrTF] loading weights from /tmp/tmpuzl4pu5t/model/variables/variables\n",
      "[15:49:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-281.\n",
      "[15:49:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:14 - Feature] Processed ParPgb:0.0-280.0 (median depth 187.0)\n",
      "[15:49:14 - Sampler] Took 0.06s to make features.\n",
      "[15:49:14 - PWorker] Processed 1 batches\n",
      "[15:49:14 - PWorker] All done, 0 remainder regions.\n",
      "[15:49:14 - Predict] Finished processing all regions.\n",
      "[15:49:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:18 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:49:18 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:49:18 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:49:18 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:49:18 - Predict] Found a GPU.\n",
      "[15:49:18 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:49:18 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:49:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3f1ddd9a80>\n",
      "[15:49:19 - MdlStrTF] loading weights from /tmp/tmpqlki9_qx/model/variables/variables\n",
      "[15:49:19 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:49:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:49:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:49:20 - Feature] Processed ParPgb:0.0-252.0 (median depth 175.0)\n",
      "[15:49:20 - Sampler] Took 0.74s to make features.\n",
      "[15:49:20 - Sampler] Region ParPgb:0.0-252.0 (344 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:49:20 - PWorker] Processed 0 batches\n",
      "[15:49:20 - PWorker] All done, 1 remainder regions.\n",
      "[15:49:20 - Predict] Processing 1 short region(s).\n",
      "[15:49:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3e8cfa5ab0>\n",
      "[15:49:20 - MdlStrTF] loading weights from /tmp/tmpqlki9_qx/model/variables/variables\n",
      "[15:49:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:49:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:27 - Feature] Processed ParPgb:0.0-252.0 (median depth 175.0)\n",
      "[15:49:27 - Sampler] Took 6.29s to make features.\n",
      "[15:49:27 - PWorker] Batches in cache: 1.\n",
      "[15:49:27 - PWorker] Processed 1 batches\n",
      "[15:49:27 - PWorker] All done, 0 remainder regions.\n",
      "[15:49:27 - Predict] Finished processing all regions.\n",
      "[15:49:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:49:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:49:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:49:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:49:31 - Predict] Found a GPU.\n",
      "[15:49:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:49:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:49:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f45258bdae0>\n",
      "[15:49:32 - MdlStrTF] loading weights from /tmp/tmpcnub5c2t/model/variables/variables\n",
      "[15:49:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:49:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:49:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:32 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[15:49:32 - Feature] Processed ParPgb:0.0-250.0 (median depth 200.0)\n",
      "[15:49:32 - Sampler] Took 0.04s to make features.\n",
      "[15:49:32 - Sampler] Region ParPgb:0.0-250.0 (378 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:49:32 - PWorker] Processed 0 batches\n",
      "[15:49:32 - PWorker] All done, 1 remainder regions.\n",
      "[15:49:32 - Predict] Processing 1 short region(s).\n",
      "[15:49:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4490a91480>\n",
      "[15:49:32 - MdlStrTF] loading weights from /tmp/tmpcnub5c2t/model/variables/variables\n",
      "[15:49:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[15:49:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:32 - Feature] Processed ParPgb:0.0-250.0 (median depth 200.0)\n",
      "[15:49:32 - Sampler] Took 0.04s to make features.\n",
      "[15:49:33 - PWorker] Processed 1 batches\n",
      "[15:49:33 - PWorker] All done, 0 remainder regions.\n",
      "[15:49:33 - Predict] Finished processing all regions.\n",
      "[15:49:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:36 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:49:36 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:49:36 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:49:36 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:49:36 - Predict] Found a GPU.\n",
      "[15:49:36 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:49:36 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:49:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fce0b4fdae0>\n",
      "[15:49:38 - MdlStrTF] loading weights from /tmp/tmpp_jy0i7d/model/variables/variables\n",
      "[15:49:38 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:49:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:49:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:38 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[15:49:38 - Feature] Processed ParPgb:0.0-240.0 (median depth 156.0)\n",
      "[15:49:38 - Sampler] Took 0.04s to make features.\n",
      "[15:49:38 - Sampler] Region ParPgb:0.0-240.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:49:38 - PWorker] Processed 0 batches\n",
      "[15:49:38 - PWorker] All done, 1 remainder regions.\n",
      "[15:49:38 - Predict] Processing 1 short region(s).\n",
      "[15:49:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcd7a649960>\n",
      "[15:49:38 - MdlStrTF] loading weights from /tmp/tmpp_jy0i7d/model/variables/variables\n",
      "[15:49:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[15:49:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:38 - Feature] Processed ParPgb:0.0-240.0 (median depth 156.0)\n",
      "[15:49:38 - Sampler] Took 0.07s to make features.\n",
      "[15:49:39 - PWorker] Processed 1 batches\n",
      "[15:49:39 - PWorker] All done, 0 remainder regions.\n",
      "[15:49:39 - Predict] Finished processing all regions.\n",
      "[15:49:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:49:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:49:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:49:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:49:42 - Predict] Found a GPU.\n",
      "[15:49:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:49:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:49:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f33cf59dae0>\n",
      "[15:49:44 - MdlStrTF] loading weights from /tmp/tmpoq2r_8l9/model/variables/variables\n",
      "[15:49:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:49:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:49:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:44 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-264.\n",
      "[15:49:44 - Feature] Processed ParPgb:0.0-264.0 (median depth 79.0)\n",
      "[15:49:44 - Sampler] Took 0.03s to make features.\n",
      "[15:49:44 - Sampler] Region ParPgb:0.0-264.0 (312 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:49:44 - PWorker] Processed 0 batches\n",
      "[15:49:44 - PWorker] All done, 1 remainder regions.\n",
      "[15:49:44 - Predict] Processing 1 short region(s).\n",
      "[15:49:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f33306a1480>\n",
      "[15:49:44 - MdlStrTF] loading weights from /tmp/tmpoq2r_8l9/model/variables/variables\n",
      "[15:49:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-265.\n",
      "[15:49:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:44 - Feature] Processed ParPgb:0.0-264.0 (median depth 79.0)\n",
      "[15:49:44 - Sampler] Took 0.05s to make features.\n",
      "[15:49:45 - PWorker] Processed 1 batches\n",
      "[15:49:45 - PWorker] All done, 0 remainder regions.\n",
      "[15:49:45 - Predict] Finished processing all regions.\n",
      "[15:49:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:48 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:49:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:49:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:49:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:49:48 - Predict] Found a GPU.\n",
      "[15:49:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:49:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:49:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f42d0a09ae0>\n",
      "[15:49:50 - MdlStrTF] loading weights from /tmp/tmpuqoo0hmf/model/variables/variables\n",
      "[15:49:50 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:49:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:49:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:50 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[15:49:50 - Feature] Processed ParPgb:0.0-242.0 (median depth 206.0)\n",
      "[15:49:50 - Sampler] Took 0.22s to make features.\n",
      "[15:49:50 - Sampler] Region ParPgb:0.0-242.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:49:50 - PWorker] Processed 0 batches\n",
      "[15:49:50 - PWorker] All done, 1 remainder regions.\n",
      "[15:49:50 - Predict] Processing 1 short region(s).\n",
      "[15:49:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f42403661a0>\n",
      "[15:49:50 - MdlStrTF] loading weights from /tmp/tmpuqoo0hmf/model/variables/variables\n",
      "[15:49:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[15:49:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:50 - Feature] Processed ParPgb:0.0-242.0 (median depth 206.0)\n",
      "[15:49:50 - Sampler] Took 0.04s to make features.\n",
      "[15:49:51 - PWorker] Processed 1 batches\n",
      "[15:49:51 - PWorker] All done, 0 remainder regions.\n",
      "[15:49:51 - Predict] Finished processing all regions.\n",
      "[15:49:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:49:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:49:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:49:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:49:54 - Predict] Found a GPU.\n",
      "[15:49:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:49:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:49:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f34840c9ae0>\n",
      "[15:49:56 - MdlStrTF] loading weights from /tmp/tmpf4s_uy52/model/variables/variables\n",
      "[15:49:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:49:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:49:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-264.\n",
      "[15:49:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:56 - Feature] Processed ParPgb:0.0-264.0 (median depth 114.0)\n",
      "[15:49:56 - Sampler] Took 0.09s to make features.\n",
      "[15:49:56 - Sampler] Region ParPgb:0.0-264.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:49:56 - PWorker] Processed 0 batches\n",
      "[15:49:56 - PWorker] All done, 1 remainder regions.\n",
      "[15:49:56 - Predict] Processing 1 short region(s).\n",
      "[15:49:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:49:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f33c6da62f0>\n",
      "[15:49:56 - MdlStrTF] loading weights from /tmp/tmpf4s_uy52/model/variables/variables\n",
      "[15:49:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-265.\n",
      "[15:49:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:49:56 - Feature] Processed ParPgb:0.0-264.0 (median depth 114.0)\n",
      "[15:49:56 - Sampler] Took 0.15s to make features.\n",
      "[15:49:57 - PWorker] Processed 1 batches\n",
      "[15:49:57 - PWorker] All done, 0 remainder regions.\n",
      "[15:49:57 - Predict] Finished processing all regions.\n",
      "[15:49:59 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:49:59 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:50:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:50:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:50:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:50:00 - Predict] Found a GPU.\n",
      "[15:50:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:50:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:50:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fddf6d41ae0>\n",
      "[15:50:02 - MdlStrTF] loading weights from /tmp/tmpi08q2mhe/model/variables/variables\n",
      "[15:50:02 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:50:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:50:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:02 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-218.\n",
      "[15:50:02 - Feature] Processed ParPgb:0.0-218.0 (median depth 108.0)\n",
      "[15:50:02 - Sampler] Took 0.12s to make features.\n",
      "[15:50:02 - Sampler] Region ParPgb:0.0-218.0 (288 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:50:02 - PWorker] Processed 0 batches\n",
      "[15:50:02 - PWorker] All done, 1 remainder regions.\n",
      "[15:50:02 - Predict] Processing 1 short region(s).\n",
      "[15:50:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdd5876dae0>\n",
      "[15:50:02 - MdlStrTF] loading weights from /tmp/tmpi08q2mhe/model/variables/variables\n",
      "[15:50:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-219.\n",
      "[15:50:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:05 - Feature] Processed ParPgb:0.0-218.0 (median depth 108.0)\n",
      "[15:50:05 - Sampler] Took 2.47s to make features.\n",
      "[15:50:05 - PWorker] Processed 1 batches\n",
      "[15:50:05 - PWorker] All done, 0 remainder regions.\n",
      "[15:50:05 - Predict] Finished processing all regions.\n",
      "[15:50:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:50:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:50:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:50:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:50:09 - Predict] Found a GPU.\n",
      "[15:50:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:50:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:50:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fde55de5a80>\n",
      "[15:50:10 - MdlStrTF] loading weights from /tmp/tmpx2o3e447/model/variables/variables\n",
      "[15:50:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:50:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:50:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:10 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-257.\n",
      "[15:50:10 - Feature] Processed ParPgb:0.0-257.0 (median depth 115.0)\n",
      "[15:50:10 - Sampler] Took 0.02s to make features.\n",
      "[15:50:10 - Sampler] Region ParPgb:0.0-257.0 (319 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:50:10 - PWorker] Processed 0 batches\n",
      "[15:50:10 - PWorker] All done, 1 remainder regions.\n",
      "[15:50:10 - Predict] Processing 1 short region(s).\n",
      "[15:50:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fddb8f11420>\n",
      "[15:50:11 - MdlStrTF] loading weights from /tmp/tmpx2o3e447/model/variables/variables\n",
      "[15:50:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-258.\n",
      "[15:50:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:11 - Feature] Processed ParPgb:0.0-257.0 (median depth 115.0)\n",
      "[15:50:11 - Sampler] Took 0.15s to make features.\n",
      "[15:50:11 - PWorker] Processed 1 batches\n",
      "[15:50:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:50:11 - Predict] Finished processing all regions.\n",
      "[15:50:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:50:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:50:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:50:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:50:15 - Predict] Found a GPU.\n",
      "[15:50:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:50:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:50:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f15e3bcdae0>\n",
      "[15:50:16 - MdlStrTF] loading weights from /tmp/tmpm2qdosp3/model/variables/variables\n",
      "[15:50:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:50:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:50:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:50:16 - Feature] Processed ParPgb:0.0-251.0 (median depth 138.0)\n",
      "[15:50:16 - Sampler] Took 0.04s to make features.\n",
      "[15:50:16 - Sampler] Region ParPgb:0.0-251.0 (331 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:50:16 - PWorker] Processed 0 batches\n",
      "[15:50:16 - PWorker] All done, 1 remainder regions.\n",
      "[15:50:16 - Predict] Processing 1 short region(s).\n",
      "[15:50:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1552d4d480>\n",
      "[15:50:17 - MdlStrTF] loading weights from /tmp/tmpm2qdosp3/model/variables/variables\n",
      "[15:50:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:50:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:17 - Feature] Processed ParPgb:0.0-251.0 (median depth 138.0)\n",
      "[15:50:17 - Sampler] Took 0.10s to make features.\n",
      "[15:50:17 - PWorker] Processed 1 batches\n",
      "[15:50:17 - PWorker] All done, 0 remainder regions.\n",
      "[15:50:17 - Predict] Finished processing all regions.\n",
      "[15:50:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:21 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:50:21 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:50:21 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:50:21 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:50:21 - Predict] Found a GPU.\n",
      "[15:50:21 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:50:21 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:50:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0df4f71ae0>\n",
      "[15:50:22 - MdlStrTF] loading weights from /tmp/tmpwmij387c/model/variables/variables\n",
      "[15:50:22 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:50:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:50:22 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:50:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:22 - Feature] Processed ParPgb:0.0-252.0 (median depth 121.0)\n",
      "[15:50:22 - Sampler] Took 0.13s to make features.\n",
      "[15:50:22 - Sampler] Region ParPgb:0.0-252.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:50:22 - PWorker] Processed 0 batches\n",
      "[15:50:22 - PWorker] All done, 1 remainder regions.\n",
      "[15:50:22 - Predict] Processing 1 short region(s).\n",
      "[15:50:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0d6091a3b0>\n",
      "[15:50:23 - MdlStrTF] loading weights from /tmp/tmpwmij387c/model/variables/variables\n",
      "[15:50:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:50:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:23 - Feature] Processed ParPgb:0.0-252.0 (median depth 121.0)\n",
      "[15:50:23 - Sampler] Took 0.03s to make features.\n",
      "[15:50:23 - PWorker] Processed 1 batches\n",
      "[15:50:23 - PWorker] All done, 0 remainder regions.\n",
      "[15:50:23 - Predict] Finished processing all regions.\n",
      "[15:50:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:26 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:50:27 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:50:27 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:50:27 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:50:27 - Predict] Found a GPU.\n",
      "[15:50:27 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:50:27 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:50:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd654fb1ae0>\n",
      "[15:50:28 - MdlStrTF] loading weights from /tmp/tmp3uig7v76/model/variables/variables\n",
      "[15:50:28 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:50:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:50:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:28 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[15:50:28 - Feature] Processed ParPgb:0.0-250.0 (median depth 67.0)\n",
      "[15:50:28 - Sampler] Took 0.04s to make features.\n",
      "[15:50:28 - Sampler] Region ParPgb:0.0-250.0 (279 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:50:28 - PWorker] Processed 0 batches\n",
      "[15:50:28 - PWorker] All done, 1 remainder regions.\n",
      "[15:50:28 - Predict] Processing 1 short region(s).\n",
      "[15:50:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd5c0151ff0>\n",
      "[15:50:28 - MdlStrTF] loading weights from /tmp/tmp3uig7v76/model/variables/variables\n",
      "[15:50:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[15:50:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:28 - Feature] Processed ParPgb:0.0-250.0 (median depth 67.0)\n",
      "[15:50:28 - Sampler] Took 0.04s to make features.\n",
      "[15:50:29 - PWorker] Processed 1 batches\n",
      "[15:50:29 - PWorker] All done, 0 remainder regions.\n",
      "[15:50:29 - Predict] Finished processing all regions.\n",
      "[15:50:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:32 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:50:32 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:50:32 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:50:32 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:50:32 - Predict] Found a GPU.\n",
      "[15:50:32 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:50:32 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:50:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc9d1895ae0>\n",
      "[15:50:34 - MdlStrTF] loading weights from /tmp/tmpe40cr5jg/model/variables/variables\n",
      "[15:50:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:50:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:50:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-257.\n",
      "[15:50:34 - Feature] Processed ParPgb:0.0-257.0 (median depth 139.0)\n",
      "[15:50:34 - Sampler] Took 0.22s to make features.\n",
      "[15:50:34 - Sampler] Region ParPgb:0.0-257.0 (344 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:50:34 - PWorker] Processed 0 batches\n",
      "[15:50:34 - PWorker] All done, 1 remainder regions.\n",
      "[15:50:34 - Predict] Processing 1 short region(s).\n",
      "[15:50:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc940709ff0>\n",
      "[15:50:34 - MdlStrTF] loading weights from /tmp/tmpe40cr5jg/model/variables/variables\n",
      "[15:50:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-258.\n",
      "[15:50:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:36 - Feature] Processed ParPgb:0.0-257.0 (median depth 139.0)\n",
      "[15:50:36 - Sampler] Took 1.93s to make features.\n",
      "[15:50:37 - PWorker] Processed 1 batches\n",
      "[15:50:37 - PWorker] All done, 0 remainder regions.\n",
      "[15:50:37 - Predict] Finished processing all regions.\n",
      "[15:50:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:50:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:50:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:50:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:50:40 - Predict] Found a GPU.\n",
      "[15:50:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:50:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:50:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff3c607dae0>\n",
      "[15:50:42 - MdlStrTF] loading weights from /tmp/tmpeq21d01t/model/variables/variables\n",
      "[15:50:42 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:50:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:50:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:42 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-237.\n",
      "[15:50:42 - Feature] Processed ParPgb:0.0-237.0 (median depth 110.0)\n",
      "[15:50:42 - Sampler] Took 0.32s to make features.\n",
      "[15:50:42 - Sampler] Region ParPgb:0.0-237.0 (284 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:50:42 - PWorker] Processed 0 batches\n",
      "[15:50:42 - PWorker] All done, 1 remainder regions.\n",
      "[15:50:42 - Predict] Processing 1 short region(s).\n",
      "[15:50:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff329211ff0>\n",
      "[15:50:42 - MdlStrTF] loading weights from /tmp/tmpeq21d01t/model/variables/variables\n",
      "[15:50:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-238.\n",
      "[15:50:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:43 - Feature] Processed ParPgb:0.0-237.0 (median depth 110.0)\n",
      "[15:50:43 - Sampler] Took 0.13s to make features.\n",
      "[15:50:43 - PWorker] Processed 1 batches\n",
      "[15:50:43 - PWorker] All done, 0 remainder regions.\n",
      "[15:50:43 - Predict] Finished processing all regions.\n",
      "[15:50:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:50:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:50:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:50:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:50:47 - Predict] Found a GPU.\n",
      "[15:50:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:50:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:50:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd587495ae0>\n",
      "[15:50:48 - MdlStrTF] loading weights from /tmp/tmp7z_cgrh1/model/variables/variables\n",
      "[15:50:48 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:50:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:50:48 - Sampler] Took 0.01s to make features.\n",
      "[15:50:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:48 - PWorker] Processed 0 batches\n",
      "[15:50:48 - PWorker] All done, 0 remainder regions.\n",
      "[15:50:48 - Predict] Finished processing all regions.\n",
      "[15:50:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:50 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:50:51 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:50:51 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:50:51 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:50:51 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:50:51 - Predict] Found a GPU.\n",
      "[15:50:51 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:50:51 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:50:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9ba5335a80>\n",
      "[15:50:53 - MdlStrTF] loading weights from /tmp/tmp1dvyd44u/model/variables/variables\n",
      "[15:50:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:50:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:50:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:50:53 - Feature] Processed ParPgb:0.0-246.0 (median depth 43.0)\n",
      "[15:50:53 - Sampler] Took 0.03s to make features.\n",
      "[15:50:53 - Sampler] Region ParPgb:0.0-246.0 (280 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:50:53 - PWorker] Processed 0 batches\n",
      "[15:50:53 - PWorker] All done, 1 remainder regions.\n",
      "[15:50:53 - Predict] Processing 1 short region(s).\n",
      "[15:50:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9ae026e2c0>\n",
      "[15:50:53 - MdlStrTF] loading weights from /tmp/tmp1dvyd44u/model/variables/variables\n",
      "[15:50:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:50:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:53 - Feature] Processed ParPgb:0.0-246.0 (median depth 43.0)\n",
      "[15:50:53 - Sampler] Took 0.05s to make features.\n",
      "[15:50:54 - PWorker] Processed 1 batches\n",
      "[15:50:54 - PWorker] All done, 0 remainder regions.\n",
      "[15:50:54 - Predict] Finished processing all regions.\n",
      "[15:50:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:50:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:50:57 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:50:57 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:50:57 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:50:57 - Predict] Found a GPU.\n",
      "[15:50:57 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:50:57 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:50:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7facad4b5ae0>\n",
      "[15:50:58 - MdlStrTF] loading weights from /tmp/tmp9l1d3v78/model/variables/variables\n",
      "[15:50:58 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:50:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:50:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-235.\n",
      "[15:50:59 - Feature] Processed ParPgb:0.0-235.0 (median depth 66.0)\n",
      "[15:50:59 - Sampler] Took 0.09s to make features.\n",
      "[15:50:59 - Sampler] Region ParPgb:0.0-235.0 (282 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:50:59 - PWorker] Processed 0 batches\n",
      "[15:50:59 - PWorker] All done, 1 remainder regions.\n",
      "[15:50:59 - Predict] Processing 1 short region(s).\n",
      "[15:50:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:50:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fac1c566170>\n",
      "[15:50:59 - MdlStrTF] loading weights from /tmp/tmp9l1d3v78/model/variables/variables\n",
      "[15:50:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-236.\n",
      "[15:50:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:50:59 - Feature] Processed ParPgb:0.0-235.0 (median depth 66.0)\n",
      "[15:50:59 - Sampler] Took 0.05s to make features.\n",
      "[15:51:00 - PWorker] Processed 1 batches\n",
      "[15:51:00 - PWorker] All done, 0 remainder regions.\n",
      "[15:51:00 - Predict] Finished processing all regions.\n",
      "[15:51:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:51:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:51:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:51:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:51:03 - Predict] Found a GPU.\n",
      "[15:51:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:51:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:51:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f211c1a1ae0>\n",
      "[15:51:04 - MdlStrTF] loading weights from /tmp/tmph2f_sekx/model/variables/variables\n",
      "[15:51:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:51:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:51:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-263.\n",
      "[15:51:04 - Feature] Processed ParPgb:0.0-263.0 (median depth 125.0)\n",
      "[15:51:04 - Sampler] Took 0.04s to make features.\n",
      "[15:51:04 - Sampler] Region ParPgb:0.0-263.0 (342 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:51:04 - PWorker] Processed 0 batches\n",
      "[15:51:04 - PWorker] All done, 1 remainder regions.\n",
      "[15:51:04 - Predict] Processing 1 short region(s).\n",
      "[15:51:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f207d001480>\n",
      "[15:51:05 - MdlStrTF] loading weights from /tmp/tmph2f_sekx/model/variables/variables\n",
      "[15:51:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-264.\n",
      "[15:51:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:05 - Feature] Processed ParPgb:0.0-263.0 (median depth 125.0)\n",
      "[15:51:05 - Sampler] Took 0.39s to make features.\n",
      "[15:51:06 - PWorker] Processed 1 batches\n",
      "[15:51:06 - PWorker] All done, 0 remainder regions.\n",
      "[15:51:06 - Predict] Finished processing all regions.\n",
      "[15:51:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:51:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:51:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:51:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:51:09 - Predict] Found a GPU.\n",
      "[15:51:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:51:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:51:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0ec01cdae0>\n",
      "[15:51:11 - MdlStrTF] loading weights from /tmp/tmphpn5dcim/model/variables/variables\n",
      "[15:51:11 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:51:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:51:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-213.\n",
      "[15:51:11 - Feature] Processed ParPgb:0.0-213.0 (median depth 78.0)\n",
      "[15:51:11 - Sampler] Took 0.04s to make features.\n",
      "[15:51:11 - Sampler] Region ParPgb:0.0-213.0 (257 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:51:11 - PWorker] Processed 0 batches\n",
      "[15:51:11 - PWorker] All done, 1 remainder regions.\n",
      "[15:51:11 - Predict] Processing 1 short region(s).\n",
      "[15:51:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0e21341480>\n",
      "[15:51:11 - MdlStrTF] loading weights from /tmp/tmphpn5dcim/model/variables/variables\n",
      "[15:51:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-214.\n",
      "[15:51:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:11 - Feature] Processed ParPgb:0.0-213.0 (median depth 78.0)\n",
      "[15:51:11 - Sampler] Took 0.05s to make features.\n",
      "[15:51:12 - PWorker] Processed 1 batches\n",
      "[15:51:12 - PWorker] All done, 0 remainder regions.\n",
      "[15:51:12 - Predict] Finished processing all regions.\n",
      "[15:51:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:51:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:51:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:51:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:51:15 - Predict] Found a GPU.\n",
      "[15:51:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:51:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:51:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9da3e5dae0>\n",
      "[15:51:16 - MdlStrTF] loading weights from /tmp/tmp7t4bynvz/model/variables/variables\n",
      "[15:51:17 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:51:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:51:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-258.\n",
      "[15:51:23 - Feature] Processed ParPgb:0.0-258.0 (median depth 130.0)\n",
      "[15:51:23 - Sampler] Took 6.57s to make features.\n",
      "[15:51:23 - Sampler] Region ParPgb:0.0-258.0 (318 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:51:23 - PWorker] Processed 0 batches\n",
      "[15:51:23 - PWorker] All done, 1 remainder regions.\n",
      "[15:51:23 - Predict] Processing 1 short region(s).\n",
      "[15:51:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9d7c131480>\n",
      "[15:51:23 - MdlStrTF] loading weights from /tmp/tmp7t4bynvz/model/variables/variables\n",
      "[15:51:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-259.\n",
      "[15:51:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:24 - Feature] Processed ParPgb:0.0-258.0 (median depth 130.0)\n",
      "[15:51:24 - Sampler] Took 0.06s to make features.\n",
      "[15:51:24 - PWorker] Processed 1 batches\n",
      "[15:51:24 - PWorker] All done, 0 remainder regions.\n",
      "[15:51:24 - Predict] Finished processing all regions.\n",
      "[15:51:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:27 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:51:28 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:51:28 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:51:28 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:51:28 - Predict] Found a GPU.\n",
      "[15:51:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:51:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:51:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa49cad9a80>\n",
      "[15:51:29 - MdlStrTF] loading weights from /tmp/tmp6ypwl96n/model/variables/variables\n",
      "[15:51:29 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:51:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:51:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:29 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-214.\n",
      "[15:51:29 - Feature] Processed ParPgb:0.0-214.0 (median depth 123.0)\n",
      "[15:51:29 - Sampler] Took 0.08s to make features.\n",
      "[15:51:29 - Sampler] Region ParPgb:0.0-214.0 (293 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:51:29 - PWorker] Processed 0 batches\n",
      "[15:51:29 - PWorker] All done, 1 remainder regions.\n",
      "[15:51:29 - Predict] Processing 1 short region(s).\n",
      "[15:51:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa40c4413f0>\n",
      "[15:51:29 - MdlStrTF] loading weights from /tmp/tmp6ypwl96n/model/variables/variables\n",
      "[15:51:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-215.\n",
      "[15:51:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:30 - Feature] Processed ParPgb:0.0-214.0 (median depth 123.0)\n",
      "[15:51:30 - Sampler] Took 0.39s to make features.\n",
      "[15:51:30 - PWorker] Processed 1 batches\n",
      "[15:51:30 - PWorker] All done, 0 remainder regions.\n",
      "[15:51:30 - Predict] Finished processing all regions.\n",
      "[15:51:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:34 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:51:34 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:51:34 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:51:34 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:51:34 - Predict] Found a GPU.\n",
      "[15:51:34 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:51:34 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:51:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f68fd415ae0>\n",
      "[15:51:35 - MdlStrTF] loading weights from /tmp/tmp_zfh7cbk/model/variables/variables\n",
      "[15:51:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:51:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:51:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:35 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-237.\n",
      "[15:51:35 - Feature] Processed ParPgb:0.0-237.0 (median depth 157.0)\n",
      "[15:51:35 - Sampler] Took 0.03s to make features.\n",
      "[15:51:35 - Sampler] Region ParPgb:0.0-237.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:51:35 - PWorker] Processed 0 batches\n",
      "[15:51:35 - PWorker] All done, 1 remainder regions.\n",
      "[15:51:35 - Predict] Processing 1 short region(s).\n",
      "[15:51:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f686c229b10>\n",
      "[15:51:36 - MdlStrTF] loading weights from /tmp/tmp_zfh7cbk/model/variables/variables\n",
      "[15:51:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-238.\n",
      "[15:51:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:36 - Feature] Processed ParPgb:0.0-237.0 (median depth 157.0)\n",
      "[15:51:36 - Sampler] Took 0.03s to make features.\n",
      "[15:51:36 - PWorker] Processed 1 batches\n",
      "[15:51:36 - PWorker] All done, 0 remainder regions.\n",
      "[15:51:36 - Predict] Finished processing all regions.\n",
      "[15:51:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:51:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:51:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:51:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:51:40 - Predict] Found a GPU.\n",
      "[15:51:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:51:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:51:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff0c9eddae0>\n",
      "[15:51:41 - MdlStrTF] loading weights from /tmp/tmp6q90ox4d/model/variables/variables\n",
      "[15:51:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:51:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:51:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:41 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-260.\n",
      "[15:51:41 - Feature] Processed ParPgb:0.0-260.0 (median depth 117.0)\n",
      "[15:51:41 - Sampler] Took 0.04s to make features.\n",
      "[15:51:41 - Sampler] Region ParPgb:0.0-260.0 (333 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:51:41 - PWorker] Processed 0 batches\n",
      "[15:51:41 - PWorker] All done, 1 remainder regions.\n",
      "[15:51:41 - Predict] Processing 1 short region(s).\n",
      "[15:51:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff0390beec0>\n",
      "[15:51:41 - MdlStrTF] loading weights from /tmp/tmp6q90ox4d/model/variables/variables\n",
      "[15:51:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-261.\n",
      "[15:51:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:42 - Feature] Processed ParPgb:0.0-260.0 (median depth 117.0)\n",
      "[15:51:42 - Sampler] Took 0.07s to make features.\n",
      "[15:51:42 - PWorker] Processed 1 batches\n",
      "[15:51:42 - PWorker] All done, 0 remainder regions.\n",
      "[15:51:42 - Predict] Finished processing all regions.\n",
      "[15:51:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:45 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:51:45 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:51:45 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:51:45 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:51:46 - Predict] Found a GPU.\n",
      "[15:51:46 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:51:46 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:51:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2311a3dae0>\n",
      "[15:51:47 - MdlStrTF] loading weights from /tmp/tmpzq5f7kwc/model/variables/variables\n",
      "[15:51:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:51:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:51:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-260.\n",
      "[15:51:49 - Feature] Processed ParPgb:0.0-260.0 (median depth 140.0)\n",
      "[15:51:49 - Sampler] Took 2.09s to make features.\n",
      "[15:51:49 - Sampler] Region ParPgb:0.0-260.0 (351 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:51:49 - PWorker] Processed 0 batches\n",
      "[15:51:49 - PWorker] All done, 1 remainder regions.\n",
      "[15:51:49 - Predict] Processing 1 short region(s).\n",
      "[15:51:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f228038e1a0>\n",
      "[15:51:49 - MdlStrTF] loading weights from /tmp/tmpzq5f7kwc/model/variables/variables\n",
      "[15:51:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-261.\n",
      "[15:51:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:51 - Feature] Processed ParPgb:0.0-260.0 (median depth 140.0)\n",
      "[15:51:51 - Sampler] Took 1.60s to make features.\n",
      "[15:51:52 - PWorker] Processed 1 batches\n",
      "[15:51:52 - PWorker] All done, 0 remainder regions.\n",
      "[15:51:52 - Predict] Finished processing all regions.\n",
      "[15:51:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:51:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:51:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:51:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:51:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:51:55 - Predict] Found a GPU.\n",
      "[15:51:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:51:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:51:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fddbd0a5ae0>\n",
      "[15:51:56 - MdlStrTF] loading weights from /tmp/tmp_mo_hin5/model/variables/variables\n",
      "[15:51:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:51:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:51:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:51:59 - Feature] Processed ParPgb:0.0-246.0 (median depth 87.0)\n",
      "[15:51:59 - Sampler] Took 2.26s to make features.\n",
      "[15:51:59 - Sampler] Region ParPgb:0.0-246.0 (297 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:51:59 - PWorker] Processed 0 batches\n",
      "[15:51:59 - PWorker] All done, 1 remainder regions.\n",
      "[15:51:59 - Predict] Processing 1 short region(s).\n",
      "[15:51:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:51:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdd2c199480>\n",
      "[15:51:59 - MdlStrTF] loading weights from /tmp/tmp_mo_hin5/model/variables/variables\n",
      "[15:51:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:51:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:51:59 - Feature] Processed ParPgb:0.0-246.0 (median depth 87.0)\n",
      "[15:51:59 - Sampler] Took 0.11s to make features.\n",
      "[15:52:00 - PWorker] Processed 1 batches\n",
      "[15:52:00 - PWorker] All done, 0 remainder regions.\n",
      "[15:52:00 - Predict] Finished processing all regions.\n",
      "[15:52:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:52:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:52:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:52:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:52:03 - Predict] Found a GPU.\n",
      "[15:52:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:52:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:52:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f07a9165a80>\n",
      "[15:52:04 - MdlStrTF] loading weights from /tmp/tmp4ifkhwa5/model/variables/variables\n",
      "[15:52:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:52:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:52:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:52:05 - Feature] Processed ParPgb:0.0-249.0 (median depth 136.0)\n",
      "[15:52:05 - Sampler] Took 0.08s to make features.\n",
      "[15:52:05 - Sampler] Region ParPgb:0.0-249.0 (323 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:52:05 - PWorker] Processed 0 batches\n",
      "[15:52:05 - PWorker] All done, 1 remainder regions.\n",
      "[15:52:05 - Predict] Processing 1 short region(s).\n",
      "[15:52:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0718365420>\n",
      "[15:52:05 - MdlStrTF] loading weights from /tmp/tmp4ifkhwa5/model/variables/variables\n",
      "[15:52:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:52:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:05 - Feature] Processed ParPgb:0.0-249.0 (median depth 136.0)\n",
      "[15:52:05 - Sampler] Took 0.06s to make features.\n",
      "[15:52:06 - PWorker] Processed 1 batches\n",
      "[15:52:06 - PWorker] All done, 0 remainder regions.\n",
      "[15:52:06 - Predict] Finished processing all regions.\n",
      "[15:52:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:52:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:52:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:52:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:52:09 - Predict] Found a GPU.\n",
      "[15:52:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:52:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:52:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4122b55ae0>\n",
      "[15:52:10 - MdlStrTF] loading weights from /tmp/tmp8a4f803o/model/variables/variables\n",
      "[15:52:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:52:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:52:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:10 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-230.\n",
      "[15:52:10 - Feature] Processed ParPgb:0.0-230.0 (median depth 129.0)\n",
      "[15:52:10 - Sampler] Took 0.03s to make features.\n",
      "[15:52:10 - Sampler] Region ParPgb:0.0-230.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:52:10 - PWorker] Processed 0 batches\n",
      "[15:52:10 - PWorker] All done, 1 remainder regions.\n",
      "[15:52:10 - Predict] Processing 1 short region(s).\n",
      "[15:52:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4091525ff0>\n",
      "[15:52:11 - MdlStrTF] loading weights from /tmp/tmp8a4f803o/model/variables/variables\n",
      "[15:52:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-231.\n",
      "[15:52:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:13 - Feature] Processed ParPgb:0.0-230.0 (median depth 129.0)\n",
      "[15:52:13 - Sampler] Took 2.36s to make features.\n",
      "[15:52:14 - PWorker] Processed 1 batches\n",
      "[15:52:14 - PWorker] All done, 0 remainder regions.\n",
      "[15:52:14 - Predict] Finished processing all regions.\n",
      "[15:52:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:17 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:52:17 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:52:17 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:52:17 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:52:17 - Predict] Found a GPU.\n",
      "[15:52:17 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:52:17 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:52:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdc157c9ae0>\n",
      "[15:52:18 - MdlStrTF] loading weights from /tmp/tmpoae27ukj/model/variables/variables\n",
      "[15:52:19 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:52:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:52:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:19 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-228.\n",
      "[15:52:19 - Feature] Processed ParPgb:0.0-228.0 (median depth 105.0)\n",
      "[15:52:19 - Sampler] Took 0.05s to make features.\n",
      "[15:52:19 - Sampler] Region ParPgb:0.0-228.0 (296 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:52:19 - PWorker] Processed 0 batches\n",
      "[15:52:19 - PWorker] All done, 1 remainder regions.\n",
      "[15:52:19 - Predict] Processing 1 short region(s).\n",
      "[15:52:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdb805fd480>\n",
      "[15:52:19 - MdlStrTF] loading weights from /tmp/tmpoae27ukj/model/variables/variables\n",
      "[15:52:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-229.\n",
      "[15:52:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:21 - Feature] Processed ParPgb:0.0-228.0 (median depth 105.0)\n",
      "[15:52:21 - Sampler] Took 2.06s to make features.\n",
      "[15:52:22 - PWorker] Processed 1 batches\n",
      "[15:52:22 - PWorker] All done, 0 remainder regions.\n",
      "[15:52:22 - Predict] Finished processing all regions.\n",
      "[15:52:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:52:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:52:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:52:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:52:25 - Predict] Found a GPU.\n",
      "[15:52:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:52:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:52:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fef5d685ae0>\n",
      "[15:52:26 - MdlStrTF] loading weights from /tmp/tmphoj_sb85/model/variables/variables\n",
      "[15:52:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:52:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:52:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:52:26 - Feature] Processed ParPgb:0.0-246.0 (median depth 139.0)\n",
      "[15:52:26 - Sampler] Took 0.03s to make features.\n",
      "[15:52:26 - Sampler] Region ParPgb:0.0-246.0 (347 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:52:26 - PWorker] Processed 0 batches\n",
      "[15:52:26 - PWorker] All done, 1 remainder regions.\n",
      "[15:52:26 - Predict] Processing 1 short region(s).\n",
      "[15:52:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7feecc8a5480>\n",
      "[15:52:27 - MdlStrTF] loading weights from /tmp/tmphoj_sb85/model/variables/variables\n",
      "[15:52:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:52:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:27 - Feature] Processed ParPgb:0.0-246.0 (median depth 139.0)\n",
      "[15:52:27 - Sampler] Took 0.05s to make features.\n",
      "[15:52:27 - PWorker] Processed 1 batches\n",
      "[15:52:27 - PWorker] All done, 0 remainder regions.\n",
      "[15:52:27 - Predict] Finished processing all regions.\n",
      "[15:52:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:52:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:52:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:52:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:52:31 - Predict] Found a GPU.\n",
      "[15:52:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:52:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:52:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efc8b9c1ae0>\n",
      "[15:52:32 - MdlStrTF] loading weights from /tmp/tmpqpvmgxpw/model/variables/variables\n",
      "[15:52:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:52:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:52:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:35 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[15:52:35 - Feature] Processed ParPgb:0.0-243.0 (median depth 151.0)\n",
      "[15:52:35 - Sampler] Took 2.78s to make features.\n",
      "[15:52:35 - Sampler] Region ParPgb:0.0-243.0 (329 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:52:35 - PWorker] Processed 0 batches\n",
      "[15:52:35 - PWorker] All done, 1 remainder regions.\n",
      "[15:52:35 - Predict] Processing 1 short region(s).\n",
      "[15:52:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efbfab221a0>\n",
      "[15:52:35 - MdlStrTF] loading weights from /tmp/tmpqpvmgxpw/model/variables/variables\n",
      "[15:52:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[15:52:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:35 - Feature] Processed ParPgb:0.0-243.0 (median depth 151.0)\n",
      "[15:52:35 - Sampler] Took 0.03s to make features.\n",
      "[15:52:36 - PWorker] Processed 1 batches\n",
      "[15:52:36 - PWorker] All done, 0 remainder regions.\n",
      "[15:52:36 - Predict] Finished processing all regions.\n",
      "[15:52:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:39 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:52:39 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:52:39 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:52:39 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:52:39 - Predict] Found a GPU.\n",
      "[15:52:39 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:52:39 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:52:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fea93fa9ae0>\n",
      "[15:52:41 - MdlStrTF] loading weights from /tmp/tmpoo7xwski/model/variables/variables\n",
      "[15:52:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:52:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:52:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:41 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[15:52:41 - Feature] Processed ParPgb:0.0-253.0 (median depth 172.0)\n",
      "[15:52:41 - Sampler] Took 0.05s to make features.\n",
      "[15:52:41 - Sampler] Region ParPgb:0.0-253.0 (382 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:52:41 - PWorker] Processed 0 batches\n",
      "[15:52:41 - PWorker] All done, 1 remainder regions.\n",
      "[15:52:41 - Predict] Processing 1 short region(s).\n",
      "[15:52:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fea6c29e1a0>\n",
      "[15:52:41 - MdlStrTF] loading weights from /tmp/tmpoo7xwski/model/variables/variables\n",
      "[15:52:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[15:52:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:43 - Feature] Processed ParPgb:0.0-253.0 (median depth 172.0)\n",
      "[15:52:43 - Sampler] Took 2.06s to make features.\n",
      "[15:52:44 - PWorker] Processed 1 batches\n",
      "[15:52:44 - PWorker] All done, 0 remainder regions.\n",
      "[15:52:44 - Predict] Finished processing all regions.\n",
      "[15:52:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:52:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:52:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:52:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:52:47 - Predict] Found a GPU.\n",
      "[15:52:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:52:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:52:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efce23d5a80>\n",
      "[15:52:49 - MdlStrTF] loading weights from /tmp/tmpm7glkhjl/model/variables/variables\n",
      "[15:52:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:52:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:52:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[15:52:49 - Feature] Processed ParPgb:0.0-250.0 (median depth 148.0)\n",
      "[15:52:49 - Sampler] Took 0.05s to make features.\n",
      "[15:52:49 - Sampler] Region ParPgb:0.0-250.0 (338 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:52:49 - PWorker] Processed 0 batches\n",
      "[15:52:49 - PWorker] All done, 1 remainder regions.\n",
      "[15:52:49 - Predict] Processing 1 short region(s).\n",
      "[15:52:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efc515c5420>\n",
      "[15:52:49 - MdlStrTF] loading weights from /tmp/tmpm7glkhjl/model/variables/variables\n",
      "[15:52:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[15:52:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:49 - Feature] Processed ParPgb:0.0-250.0 (median depth 148.0)\n",
      "[15:52:49 - Sampler] Took 0.06s to make features.\n",
      "[15:52:50 - PWorker] Processed 1 batches\n",
      "[15:52:50 - PWorker] All done, 0 remainder regions.\n",
      "[15:52:50 - Predict] Finished processing all regions.\n",
      "[15:52:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:52:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:52:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:52:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:52:53 - Predict] Found a GPU.\n",
      "[15:52:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:52:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:52:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdc4f329ae0>\n",
      "[15:52:54 - MdlStrTF] loading weights from /tmp/tmpq4fy19hs/model/variables/variables\n",
      "[15:52:54 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:52:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:52:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:55 - Sampler] Took 0.01s to make features.\n",
      "[15:52:55 - PWorker] Processed 0 batches\n",
      "[15:52:55 - PWorker] All done, 0 remainder regions.\n",
      "[15:52:55 - Predict] Finished processing all regions.\n",
      "[15:52:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:52:56 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:52:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:52:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:52:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:52:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:52:58 - Predict] Found a GPU.\n",
      "[15:52:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:52:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:52:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:52:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3fd4015a80>\n",
      "[15:52:59 - MdlStrTF] loading weights from /tmp/tmpulnsqoo2/model/variables/variables\n",
      "[15:52:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:52:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:52:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:52:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:52:59 - Feature] Processed ParPgb:0.0-203.0 (median depth 109.0)\n",
      "[15:52:59 - Sampler] Took 0.18s to make features.\n",
      "[15:52:59 - Sampler] Region ParPgb:0.0-203.0 (249 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:52:59 - PWorker] Processed 0 batches\n",
      "[15:52:59 - PWorker] All done, 1 remainder regions.\n",
      "[15:52:59 - Predict] Processing 1 short region(s).\n",
      "[15:52:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3fac36df90>\n",
      "[15:53:00 - MdlStrTF] loading weights from /tmp/tmpulnsqoo2/model/variables/variables\n",
      "[15:53:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:53:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:02 - Feature] Processed ParPgb:0.0-203.0 (median depth 109.0)\n",
      "[15:53:02 - Sampler] Took 2.21s to make features.\n",
      "[15:53:02 - PWorker] Processed 1 batches\n",
      "[15:53:02 - PWorker] All done, 0 remainder regions.\n",
      "[15:53:02 - Predict] Finished processing all regions.\n",
      "[15:53:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:06 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:53:06 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:53:06 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:53:06 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:53:06 - Predict] Found a GPU.\n",
      "[15:53:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:53:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:53:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2d59f3dae0>\n",
      "[15:53:07 - MdlStrTF] loading weights from /tmp/tmp65zy82c0/model/variables/variables\n",
      "[15:53:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:53:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:53:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:53:07 - Feature] Processed ParPgb:0.0-249.0 (median depth 50.0)\n",
      "[15:53:07 - Sampler] Took 0.04s to make features.\n",
      "[15:53:07 - Sampler] Region ParPgb:0.0-249.0 (307 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:53:07 - PWorker] Processed 0 batches\n",
      "[15:53:07 - PWorker] All done, 1 remainder regions.\n",
      "[15:53:07 - Predict] Processing 1 short region(s).\n",
      "[15:53:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2cc90c1480>\n",
      "[15:53:08 - MdlStrTF] loading weights from /tmp/tmp65zy82c0/model/variables/variables\n",
      "[15:53:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:53:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:08 - Feature] Processed ParPgb:0.0-249.0 (median depth 50.0)\n",
      "[15:53:08 - Sampler] Took 0.04s to make features.\n",
      "[15:53:08 - PWorker] Processed 1 batches\n",
      "[15:53:08 - PWorker] All done, 0 remainder regions.\n",
      "[15:53:08 - Predict] Finished processing all regions.\n",
      "[15:53:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:53:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:53:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:53:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:53:12 - Predict] Found a GPU.\n",
      "[15:53:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:53:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:53:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f835e3e9ae0>\n",
      "[15:53:13 - MdlStrTF] loading weights from /tmp/tmpibamo998/model/variables/variables\n",
      "[15:53:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:53:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:53:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-233.\n",
      "[15:53:14 - Feature] Processed ParPgb:0.0-233.0 (median depth 102.0)\n",
      "[15:53:14 - Sampler] Took 0.73s to make features.\n",
      "[15:53:14 - Sampler] Region ParPgb:0.0-233.0 (285 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:53:14 - PWorker] Processed 0 batches\n",
      "[15:53:14 - PWorker] All done, 1 remainder regions.\n",
      "[15:53:14 - Predict] Processing 1 short region(s).\n",
      "[15:53:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f83401e1ff0>\n",
      "[15:53:14 - MdlStrTF] loading weights from /tmp/tmpibamo998/model/variables/variables\n",
      "[15:53:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-234.\n",
      "[15:53:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:14 - Feature] Processed ParPgb:0.0-233.0 (median depth 102.0)\n",
      "[15:53:14 - Sampler] Took 0.13s to make features.\n",
      "[15:53:15 - PWorker] Processed 1 batches\n",
      "[15:53:15 - PWorker] All done, 0 remainder regions.\n",
      "[15:53:15 - Predict] Finished processing all regions.\n",
      "[15:53:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:18 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:53:18 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:53:18 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:53:18 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:53:18 - Predict] Found a GPU.\n",
      "[15:53:18 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:53:18 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:53:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f08cfa8dae0>\n",
      "[15:53:20 - MdlStrTF] loading weights from /tmp/tmp59ka4j8h/model/variables/variables\n",
      "[15:53:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:53:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:53:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:53:20 - Feature] Processed ParPgb:0.0-203.0 (median depth 53.0)\n",
      "[15:53:20 - Sampler] Took 0.08s to make features.\n",
      "[15:53:20 - Sampler] Region ParPgb:0.0-203.0 (231 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:53:20 - PWorker] Processed 0 batches\n",
      "[15:53:20 - PWorker] All done, 1 remainder regions.\n",
      "[15:53:20 - Predict] Processing 1 short region(s).\n",
      "[15:53:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0830c15b10>\n",
      "[15:53:20 - MdlStrTF] loading weights from /tmp/tmp59ka4j8h/model/variables/variables\n",
      "[15:53:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:53:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:20 - Feature] Processed ParPgb:0.0-203.0 (median depth 53.0)\n",
      "[15:53:20 - Sampler] Took 0.05s to make features.\n",
      "[15:53:21 - PWorker] Processed 1 batches\n",
      "[15:53:21 - PWorker] All done, 0 remainder regions.\n",
      "[15:53:21 - Predict] Finished processing all regions.\n",
      "[15:53:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:53:24 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:53:24 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:53:24 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:53:24 - Predict] Found a GPU.\n",
      "[15:53:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:53:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:53:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9f1b205ae0>\n",
      "[15:53:26 - MdlStrTF] loading weights from /tmp/tmpt6sbyylr/model/variables/variables\n",
      "[15:53:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:53:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:53:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:53:26 - Feature] Processed ParPgb:0.0-245.0 (median depth 81.0)\n",
      "[15:53:26 - Sampler] Took 0.02s to make features.\n",
      "[15:53:26 - Sampler] Region ParPgb:0.0-245.0 (297 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:53:26 - PWorker] Processed 0 batches\n",
      "[15:53:26 - PWorker] All done, 1 remainder regions.\n",
      "[15:53:26 - Predict] Processing 1 short region(s).\n",
      "[15:53:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9e8a429450>\n",
      "[15:53:26 - MdlStrTF] loading weights from /tmp/tmpt6sbyylr/model/variables/variables\n",
      "[15:53:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:53:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:26 - Feature] Processed ParPgb:0.0-245.0 (median depth 81.0)\n",
      "[15:53:26 - Sampler] Took 0.09s to make features.\n",
      "[15:53:27 - PWorker] Processed 1 batches\n",
      "[15:53:27 - PWorker] All done, 0 remainder regions.\n",
      "[15:53:27 - Predict] Finished processing all regions.\n",
      "[15:53:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:53:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:53:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:53:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:53:30 - Predict] Found a GPU.\n",
      "[15:53:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:53:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:53:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5d7d329a80>\n",
      "[15:53:32 - MdlStrTF] loading weights from /tmp/tmpaogrka5g/model/variables/variables\n",
      "[15:53:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:53:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:53:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:32 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-205.\n",
      "[15:53:32 - Feature] Processed ParPgb:0.0-205.0 (median depth 47.0)\n",
      "[15:53:32 - Sampler] Took 0.03s to make features.\n",
      "[15:53:32 - Sampler] Region ParPgb:0.0-205.0 (230 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:53:32 - PWorker] Processed 0 batches\n",
      "[15:53:32 - PWorker] All done, 1 remainder regions.\n",
      "[15:53:32 - Predict] Processing 1 short region(s).\n",
      "[15:53:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5cec535420>\n",
      "[15:53:32 - MdlStrTF] loading weights from /tmp/tmpaogrka5g/model/variables/variables\n",
      "[15:53:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-206.\n",
      "[15:53:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:34 - Feature] Processed ParPgb:0.0-205.0 (median depth 47.0)\n",
      "[15:53:34 - Sampler] Took 1.99s to make features.\n",
      "[15:53:35 - PWorker] Processed 1 batches\n",
      "[15:53:35 - PWorker] All done, 0 remainder regions.\n",
      "[15:53:35 - Predict] Finished processing all regions.\n",
      "[15:53:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:53:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:53:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:53:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:53:38 - Predict] Found a GPU.\n",
      "[15:53:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:53:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:53:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f38d7209ae0>\n",
      "[15:53:39 - MdlStrTF] loading weights from /tmp/tmpyczk_z_u/model/variables/variables\n",
      "[15:53:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:53:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:53:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:53:39 - Feature] Processed ParPgb:0.0-251.0 (median depth 118.0)\n",
      "[15:53:39 - Sampler] Took 0.02s to make features.\n",
      "[15:53:39 - Sampler] Region ParPgb:0.0-251.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:53:39 - PWorker] Processed 0 batches\n",
      "[15:53:39 - PWorker] All done, 1 remainder regions.\n",
      "[15:53:39 - Predict] Processing 1 short region(s).\n",
      "[15:53:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3838379480>\n",
      "[15:53:40 - MdlStrTF] loading weights from /tmp/tmpyczk_z_u/model/variables/variables\n",
      "[15:53:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:53:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:40 - Feature] Processed ParPgb:0.0-251.0 (median depth 118.0)\n",
      "[15:53:40 - Sampler] Took 0.03s to make features.\n",
      "[15:53:40 - PWorker] Processed 1 batches\n",
      "[15:53:40 - PWorker] All done, 0 remainder regions.\n",
      "[15:53:40 - Predict] Finished processing all regions.\n",
      "[15:53:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:44 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:53:44 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:53:44 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:53:44 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:53:44 - Predict] Found a GPU.\n",
      "[15:53:44 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:53:44 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:53:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8c581c9ae0>\n",
      "[15:53:45 - MdlStrTF] loading weights from /tmp/tmp2tuh3veq/model/variables/variables\n",
      "[15:53:45 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:53:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:53:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-264.\n",
      "[15:53:47 - Feature] Processed ParPgb:0.0-264.0 (median depth 75.0)\n",
      "[15:53:47 - Sampler] Took 1.84s to make features.\n",
      "[15:53:47 - Sampler] Region ParPgb:0.0-264.0 (327 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:53:47 - PWorker] Processed 0 batches\n",
      "[15:53:47 - PWorker] All done, 1 remainder regions.\n",
      "[15:53:47 - Predict] Processing 1 short region(s).\n",
      "[15:53:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8bb9315ff0>\n",
      "[15:53:48 - MdlStrTF] loading weights from /tmp/tmp2tuh3veq/model/variables/variables\n",
      "[15:53:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-265.\n",
      "[15:53:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:49 - Feature] Processed ParPgb:0.0-264.0 (median depth 75.0)\n",
      "[15:53:49 - Sampler] Took 1.94s to make features.\n",
      "[15:53:50 - PWorker] Processed 1 batches\n",
      "[15:53:50 - PWorker] All done, 0 remainder regions.\n",
      "[15:53:50 - Predict] Finished processing all regions.\n",
      "[15:53:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:53:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:53:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:53:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:53:53 - Predict] Found a GPU.\n",
      "[15:53:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:53:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:53:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4450491ae0>\n",
      "[15:53:55 - MdlStrTF] loading weights from /tmp/tmpekd6pga0/model/variables/variables\n",
      "[15:53:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:53:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:53:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-258.\n",
      "[15:53:55 - Feature] Processed ParPgb:0.0-258.0 (median depth 93.0)\n",
      "[15:53:55 - Sampler] Took 0.11s to make features.\n",
      "[15:53:55 - Sampler] Region ParPgb:0.0-258.0 (305 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:53:55 - PWorker] Processed 0 batches\n",
      "[15:53:55 - PWorker] All done, 1 remainder regions.\n",
      "[15:53:55 - Predict] Processing 1 short region(s).\n",
      "[15:53:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:53:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f43b166e1a0>\n",
      "[15:53:55 - MdlStrTF] loading weights from /tmp/tmpekd6pga0/model/variables/variables\n",
      "[15:53:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-259.\n",
      "[15:53:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:53:55 - Feature] Processed ParPgb:0.0-258.0 (median depth 93.0)\n",
      "[15:53:55 - Sampler] Took 0.04s to make features.\n",
      "[15:53:56 - PWorker] Processed 1 batches\n",
      "[15:53:56 - PWorker] All done, 0 remainder regions.\n",
      "[15:53:56 - Predict] Finished processing all regions.\n",
      "[15:53:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:53:59 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:53:59 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:53:59 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:53:59 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:53:59 - Predict] Found a GPU.\n",
      "[15:53:59 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:53:59 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:53:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6ec9fddae0>\n",
      "[15:54:01 - MdlStrTF] loading weights from /tmp/tmp7zbr7wp4/model/variables/variables\n",
      "[15:54:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:54:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:54:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-229.\n",
      "[15:54:01 - Feature] Processed ParPgb:0.0-229.0 (median depth 221.0)\n",
      "[15:54:01 - Sampler] Took 0.09s to make features.\n",
      "[15:54:01 - Sampler] Region ParPgb:0.0-229.0 (348 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:54:01 - PWorker] Processed 0 batches\n",
      "[15:54:01 - PWorker] All done, 1 remainder regions.\n",
      "[15:54:01 - Predict] Processing 1 short region(s).\n",
      "[15:54:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6e3922a1a0>\n",
      "[15:54:01 - MdlStrTF] loading weights from /tmp/tmp7zbr7wp4/model/variables/variables\n",
      "[15:54:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-230.\n",
      "[15:54:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:04 - Feature] Processed ParPgb:0.0-229.0 (median depth 221.0)\n",
      "[15:54:04 - Sampler] Took 2.37s to make features.\n",
      "[15:54:04 - PWorker] Processed 1 batches\n",
      "[15:54:04 - PWorker] All done, 0 remainder regions.\n",
      "[15:54:04 - Predict] Finished processing all regions.\n",
      "[15:54:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:07 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:54:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:54:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:54:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:54:08 - Predict] Found a GPU.\n",
      "[15:54:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:54:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:54:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc28bf05ae0>\n",
      "[15:54:09 - MdlStrTF] loading weights from /tmp/tmposoi7qu5/model/variables/variables\n",
      "[15:54:09 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:54:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:54:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:09 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:54:09 - Feature] Processed ParPgb:0.0-249.0 (median depth 65.0)\n",
      "[15:54:09 - Sampler] Took 0.05s to make features.\n",
      "[15:54:09 - Sampler] Region ParPgb:0.0-249.0 (280 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:54:09 - PWorker] Processed 0 batches\n",
      "[15:54:09 - PWorker] All done, 1 remainder regions.\n",
      "[15:54:09 - Predict] Processing 1 short region(s).\n",
      "[15:54:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc1fc0d9450>\n",
      "[15:54:09 - MdlStrTF] loading weights from /tmp/tmposoi7qu5/model/variables/variables\n",
      "[15:54:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:54:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:10 - Feature] Processed ParPgb:0.0-249.0 (median depth 65.0)\n",
      "[15:54:10 - Sampler] Took 0.18s to make features.\n",
      "[15:54:10 - PWorker] Processed 1 batches\n",
      "[15:54:10 - PWorker] All done, 0 remainder regions.\n",
      "[15:54:10 - Predict] Finished processing all regions.\n",
      "[15:54:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:13 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:54:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:54:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:54:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:54:14 - Predict] Found a GPU.\n",
      "[15:54:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:54:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:54:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3d6e211ae0>\n",
      "[15:54:15 - MdlStrTF] loading weights from /tmp/tmplzb3l0a5/model/variables/variables\n",
      "[15:54:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:54:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:54:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-204.\n",
      "[15:54:18 - Feature] Processed ParPgb:0.0-204.0 (median depth 60.0)\n",
      "[15:54:18 - Sampler] Took 2.65s to make features.\n",
      "[15:54:18 - Sampler] Region ParPgb:0.0-204.0 (248 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:54:18 - PWorker] Processed 0 batches\n",
      "[15:54:18 - PWorker] All done, 1 remainder regions.\n",
      "[15:54:18 - Predict] Processing 1 short region(s).\n",
      "[15:54:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3cdd2a5480>\n",
      "[15:54:18 - MdlStrTF] loading weights from /tmp/tmplzb3l0a5/model/variables/variables\n",
      "[15:54:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-205.\n",
      "[15:54:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:18 - Feature] Processed ParPgb:0.0-204.0 (median depth 60.0)\n",
      "[15:54:18 - Sampler] Took 0.05s to make features.\n",
      "[15:54:19 - PWorker] Processed 1 batches\n",
      "[15:54:19 - PWorker] All done, 0 remainder regions.\n",
      "[15:54:19 - Predict] Finished processing all regions.\n",
      "[15:54:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:54:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:54:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:54:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:54:22 - Predict] Found a GPU.\n",
      "[15:54:22 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:54:22 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:54:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0805dadae0>\n",
      "[15:54:23 - MdlStrTF] loading weights from /tmp/tmpnxu3zcs5/model/variables/variables\n",
      "[15:54:23 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:54:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:54:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:23 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-201.\n",
      "[15:54:23 - Feature] Processed ParPgb:0.0-201.0 (median depth 138.0)\n",
      "[15:54:23 - Sampler] Took 0.03s to make features.\n",
      "[15:54:23 - Sampler] Region ParPgb:0.0-201.0 (300 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:54:23 - PWorker] Processed 0 batches\n",
      "[15:54:23 - PWorker] All done, 1 remainder regions.\n",
      "[15:54:23 - Predict] Processing 1 short region(s).\n",
      "[15:54:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0768f11450>\n",
      "[15:54:24 - MdlStrTF] loading weights from /tmp/tmpnxu3zcs5/model/variables/variables\n",
      "[15:54:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-202.\n",
      "[15:54:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:29 - Feature] Processed ParPgb:0.0-201.0 (median depth 138.0)\n",
      "[15:54:29 - Sampler] Took 5.05s to make features.\n",
      "[15:54:29 - PWorker] Batches in cache: 1.\n",
      "[15:54:30 - PWorker] Processed 1 batches\n",
      "[15:54:30 - PWorker] All done, 0 remainder regions.\n",
      "[15:54:30 - Predict] Finished processing all regions.\n",
      "[15:54:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:33 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:54:33 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:54:33 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:54:33 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:54:33 - Predict] Found a GPU.\n",
      "[15:54:33 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:54:33 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:54:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4abf49da80>\n",
      "[15:54:34 - MdlStrTF] loading weights from /tmp/tmpknq_jdpu/model/variables/variables\n",
      "[15:54:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:54:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:54:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[15:54:34 - Feature] Processed ParPgb:0.0-252.0 (median depth 73.0)\n",
      "[15:54:34 - Sampler] Took 0.06s to make features.\n",
      "[15:54:34 - Sampler] Region ParPgb:0.0-252.0 (276 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:54:34 - PWorker] Processed 0 batches\n",
      "[15:54:34 - PWorker] All done, 1 remainder regions.\n",
      "[15:54:34 - Predict] Processing 1 short region(s).\n",
      "[15:54:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4a20679420>\n",
      "[15:54:35 - MdlStrTF] loading weights from /tmp/tmpknq_jdpu/model/variables/variables\n",
      "[15:54:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[15:54:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:36 - Feature] Processed ParPgb:0.0-252.0 (median depth 73.0)\n",
      "[15:54:36 - Sampler] Took 1.10s to make features.\n",
      "[15:54:36 - PWorker] Processed 1 batches\n",
      "[15:54:36 - PWorker] All done, 0 remainder regions.\n",
      "[15:54:36 - Predict] Finished processing all regions.\n",
      "[15:54:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:54:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:54:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:54:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:54:40 - Predict] Found a GPU.\n",
      "[15:54:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:54:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:54:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9740135ae0>\n",
      "[15:54:41 - MdlStrTF] loading weights from /tmp/tmpc6ejpt2f/model/variables/variables\n",
      "[15:54:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:54:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:54:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:41 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-233.\n",
      "[15:54:41 - Feature] Processed ParPgb:0.0-233.0 (median depth 75.0)\n",
      "[15:54:41 - Sampler] Took 0.17s to make features.\n",
      "[15:54:41 - Sampler] Region ParPgb:0.0-233.0 (272 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:54:41 - PWorker] Processed 0 batches\n",
      "[15:54:41 - PWorker] All done, 1 remainder regions.\n",
      "[15:54:41 - Predict] Processing 1 short region(s).\n",
      "[15:54:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f96a0ffdea0>\n",
      "[15:54:42 - MdlStrTF] loading weights from /tmp/tmpc6ejpt2f/model/variables/variables\n",
      "[15:54:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-234.\n",
      "[15:54:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:42 - Feature] Processed ParPgb:0.0-233.0 (median depth 75.0)\n",
      "[15:54:42 - Sampler] Took 0.05s to make features.\n",
      "[15:54:42 - PWorker] Processed 1 batches\n",
      "[15:54:42 - PWorker] All done, 0 remainder regions.\n",
      "[15:54:42 - Predict] Finished processing all regions.\n",
      "[15:54:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:46 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:54:46 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:54:46 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:54:46 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:54:46 - Predict] Found a GPU.\n",
      "[15:54:46 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:54:46 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:54:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe922319a80>\n",
      "[15:54:47 - MdlStrTF] loading weights from /tmp/tmp6n_gxzp3/model/variables/variables\n",
      "[15:54:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:54:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:54:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:54:47 - Feature] Processed ParPgb:0.0-244.0 (median depth 92.0)\n",
      "[15:54:47 - Sampler] Took 0.10s to make features.\n",
      "[15:54:47 - Sampler] Region ParPgb:0.0-244.0 (320 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:54:47 - PWorker] Processed 0 batches\n",
      "[15:54:47 - PWorker] All done, 1 remainder regions.\n",
      "[15:54:47 - Predict] Processing 1 short region(s).\n",
      "[15:54:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe891456140>\n",
      "[15:54:48 - MdlStrTF] loading weights from /tmp/tmp6n_gxzp3/model/variables/variables\n",
      "[15:54:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:54:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:48 - Feature] Processed ParPgb:0.0-244.0 (median depth 92.0)\n",
      "[15:54:48 - Sampler] Took 0.19s to make features.\n",
      "[15:54:49 - PWorker] Processed 1 batches\n",
      "[15:54:49 - PWorker] All done, 0 remainder regions.\n",
      "[15:54:49 - Predict] Finished processing all regions.\n",
      "[15:54:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:52 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:54:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:54:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:54:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:54:52 - Predict] Found a GPU.\n",
      "[15:54:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:54:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:54:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f65dfe85ae0>\n",
      "[15:54:53 - MdlStrTF] loading weights from /tmp/tmp6_0g9hd5/model/variables/variables\n",
      "[15:54:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:54:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:54:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-208.\n",
      "[15:54:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:53 - Feature] Processed ParPgb:0.0-208.0 (median depth 185.0)\n",
      "[15:54:53 - Sampler] Took 0.07s to make features.\n",
      "[15:54:53 - Sampler] Region ParPgb:0.0-208.0 (317 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:54:53 - PWorker] Processed 0 batches\n",
      "[15:54:53 - PWorker] All done, 1 remainder regions.\n",
      "[15:54:53 - Predict] Processing 1 short region(s).\n",
      "[15:54:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6540fa22c0>\n",
      "[15:54:54 - MdlStrTF] loading weights from /tmp/tmp6_0g9hd5/model/variables/variables\n",
      "[15:54:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-209.\n",
      "[15:54:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:54 - Feature] Processed ParPgb:0.0-208.0 (median depth 185.0)\n",
      "[15:54:54 - Sampler] Took 0.05s to make features.\n",
      "[15:54:54 - PWorker] Processed 1 batches\n",
      "[15:54:54 - PWorker] All done, 0 remainder regions.\n",
      "[15:54:54 - Predict] Finished processing all regions.\n",
      "[15:54:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:54:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:54:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:54:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:54:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:54:58 - Predict] Found a GPU.\n",
      "[15:54:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:54:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:54:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:54:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd0d0539a80>\n",
      "[15:54:59 - MdlStrTF] loading weights from /tmp/tmptmqjl7w2/model/variables/variables\n",
      "[15:54:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:54:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:54:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:54:59 - Sampler] Took 0.19s to make features.\n",
      "[15:54:59 - PWorker] Processed 0 batches\n",
      "[15:54:59 - PWorker] All done, 0 remainder regions.\n",
      "[15:54:59 - Predict] Finished processing all regions.\n",
      "[15:55:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:01 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:55:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:55:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:55:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:55:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:55:03 - Predict] Found a GPU.\n",
      "[15:55:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:55:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:55:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5add8bda80>\n",
      "[15:55:04 - MdlStrTF] loading weights from /tmp/tmpk0vgepgu/model/variables/variables\n",
      "[15:55:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:55:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:55:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[15:55:05 - Feature] Processed ParPgb:0.0-245.0 (median depth 197.0)\n",
      "[15:55:05 - Sampler] Took 0.72s to make features.\n",
      "[15:55:05 - Sampler] Region ParPgb:0.0-245.0 (362 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:55:05 - PWorker] Processed 0 batches\n",
      "[15:55:05 - PWorker] All done, 1 remainder regions.\n",
      "[15:55:05 - Predict] Processing 1 short region(s).\n",
      "[15:55:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5a4c6b93f0>\n",
      "[15:55:05 - MdlStrTF] loading weights from /tmp/tmpk0vgepgu/model/variables/variables\n",
      "[15:55:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[15:55:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:05 - Feature] Processed ParPgb:0.0-245.0 (median depth 197.0)\n",
      "[15:55:05 - Sampler] Took 0.07s to make features.\n",
      "[15:55:06 - PWorker] Processed 1 batches\n",
      "[15:55:06 - PWorker] All done, 0 remainder regions.\n",
      "[15:55:06 - Predict] Finished processing all regions.\n",
      "[15:55:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:55:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:55:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:55:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:55:09 - Predict] Found a GPU.\n",
      "[15:55:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:55:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:55:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2466249a80>\n",
      "[15:55:11 - MdlStrTF] loading weights from /tmp/tmpnk0wg4e7/model/variables/variables\n",
      "[15:55:11 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:55:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:55:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-213.\n",
      "[15:55:11 - Feature] Processed ParPgb:0.0-213.0 (median depth 24.0)\n",
      "[15:55:11 - Sampler] Took 0.03s to make features.\n",
      "[15:55:11 - Sampler] Region ParPgb:0.0-213.0 (225 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:55:11 - PWorker] Processed 0 batches\n",
      "[15:55:11 - PWorker] All done, 1 remainder regions.\n",
      "[15:55:11 - Predict] Processing 1 short region(s).\n",
      "[15:55:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f23c9372140>\n",
      "[15:55:11 - MdlStrTF] loading weights from /tmp/tmpnk0wg4e7/model/variables/variables\n",
      "[15:55:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-214.\n",
      "[15:55:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:14 - Feature] Processed ParPgb:0.0-213.0 (median depth 24.0)\n",
      "[15:55:14 - Sampler] Took 3.30s to make features.\n",
      "[15:55:15 - PWorker] Processed 1 batches\n",
      "[15:55:15 - PWorker] All done, 0 remainder regions.\n",
      "[15:55:15 - Predict] Finished processing all regions.\n",
      "[15:55:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:18 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:55:18 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:55:18 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:55:18 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:55:18 - Predict] Found a GPU.\n",
      "[15:55:18 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:55:18 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:55:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f61e543dae0>\n",
      "[15:55:20 - MdlStrTF] loading weights from /tmp/tmpanojccd1/model/variables/variables\n",
      "[15:55:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:55:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:55:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-228.\n",
      "[15:55:20 - Feature] Processed ParPgb:0.0-228.0 (median depth 61.0)\n",
      "[15:55:20 - Sampler] Took 0.18s to make features.\n",
      "[15:55:20 - Sampler] Region ParPgb:0.0-228.0 (271 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:55:20 - PWorker] Processed 0 batches\n",
      "[15:55:20 - PWorker] All done, 1 remainder regions.\n",
      "[15:55:20 - Predict] Processing 1 short region(s).\n",
      "[15:55:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f612036e170>\n",
      "[15:55:20 - MdlStrTF] loading weights from /tmp/tmpanojccd1/model/variables/variables\n",
      "[15:55:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-229.\n",
      "[15:55:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:20 - Feature] Processed ParPgb:0.0-228.0 (median depth 61.0)\n",
      "[15:55:20 - Sampler] Took 0.17s to make features.\n",
      "[15:55:21 - PWorker] Processed 1 batches\n",
      "[15:55:21 - PWorker] All done, 0 remainder regions.\n",
      "[15:55:21 - Predict] Finished processing all regions.\n",
      "[15:55:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:55:24 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:55:24 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:55:24 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:55:24 - Predict] Found a GPU.\n",
      "[15:55:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:55:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:55:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4e7ea8dae0>\n",
      "[15:55:26 - MdlStrTF] loading weights from /tmp/tmp454gelu7/model/variables/variables\n",
      "[15:55:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:55:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:55:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[15:55:26 - Feature] Processed ParPgb:0.0-238.0 (median depth 79.0)\n",
      "[15:55:26 - Sampler] Took 0.15s to make features.\n",
      "[15:55:26 - Sampler] Region ParPgb:0.0-238.0 (288 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:55:26 - PWorker] Processed 0 batches\n",
      "[15:55:26 - PWorker] All done, 1 remainder regions.\n",
      "[15:55:26 - Predict] Processing 1 short region(s).\n",
      "[15:55:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4dedba5ab0>\n",
      "[15:55:26 - MdlStrTF] loading weights from /tmp/tmp454gelu7/model/variables/variables\n",
      "[15:55:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[15:55:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:30 - Feature] Processed ParPgb:0.0-238.0 (median depth 79.0)\n",
      "[15:55:30 - Sampler] Took 3.66s to make features.\n",
      "[15:55:31 - PWorker] Processed 1 batches\n",
      "[15:55:31 - PWorker] All done, 0 remainder regions.\n",
      "[15:55:31 - Predict] Finished processing all regions.\n",
      "[15:55:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:34 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:55:34 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:55:34 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:55:34 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:55:34 - Predict] Found a GPU.\n",
      "[15:55:34 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:55:34 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:55:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3e084ddae0>\n",
      "[15:55:35 - MdlStrTF] loading weights from /tmp/tmpyifc4ili/model/variables/variables\n",
      "[15:55:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:55:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:55:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-265.\n",
      "[15:55:37 - Feature] Processed ParPgb:0.0-265.0 (median depth 116.0)\n",
      "[15:55:37 - Sampler] Took 1.91s to make features.\n",
      "[15:55:37 - Sampler] Region ParPgb:0.0-265.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:55:37 - PWorker] Processed 0 batches\n",
      "[15:55:37 - PWorker] All done, 1 remainder regions.\n",
      "[15:55:37 - Predict] Processing 1 short region(s).\n",
      "[15:55:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3d69679990>\n",
      "[15:55:38 - MdlStrTF] loading weights from /tmp/tmpyifc4ili/model/variables/variables\n",
      "[15:55:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-266.\n",
      "[15:55:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:41 - Feature] Processed ParPgb:0.0-265.0 (median depth 116.0)\n",
      "[15:55:41 - Sampler] Took 2.79s to make features.\n",
      "[15:55:41 - PWorker] Processed 1 batches\n",
      "[15:55:41 - PWorker] All done, 0 remainder regions.\n",
      "[15:55:41 - Predict] Finished processing all regions.\n",
      "[15:55:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:44 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:55:44 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:55:44 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:55:44 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:55:45 - Predict] Found a GPU.\n",
      "[15:55:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:55:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:55:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8b9d6c9ae0>\n",
      "[15:55:46 - MdlStrTF] loading weights from /tmp/tmpcegzk2x1/model/variables/variables\n",
      "[15:55:46 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:55:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:55:46 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:55:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:46 - Feature] Processed ParPgb:0.0-249.0 (median depth 89.0)\n",
      "[15:55:46 - Sampler] Took 0.07s to make features.\n",
      "[15:55:46 - Sampler] Region ParPgb:0.0-249.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:55:46 - PWorker] Processed 0 batches\n",
      "[15:55:46 - PWorker] All done, 1 remainder regions.\n",
      "[15:55:46 - Predict] Processing 1 short region(s).\n",
      "[15:55:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8b0c8aa320>\n",
      "[15:55:46 - MdlStrTF] loading weights from /tmp/tmpcegzk2x1/model/variables/variables\n",
      "[15:55:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:55:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:46 - Feature] Processed ParPgb:0.0-249.0 (median depth 89.0)\n",
      "[15:55:46 - Sampler] Took 0.04s to make features.\n",
      "[15:55:47 - PWorker] Processed 1 batches\n",
      "[15:55:47 - PWorker] All done, 0 remainder regions.\n",
      "[15:55:47 - Predict] Finished processing all regions.\n",
      "[15:55:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:55:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:55:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:55:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:55:50 - Predict] Found a GPU.\n",
      "[15:55:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:55:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:55:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbce25e5ae0>\n",
      "[15:55:52 - MdlStrTF] loading weights from /tmp/tmp9h53f794/model/variables/variables\n",
      "[15:55:52 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:55:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:55:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:52 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-204.\n",
      "[15:55:52 - Feature] Processed ParPgb:0.0-204.0 (median depth 112.0)\n",
      "[15:55:52 - Sampler] Took 0.10s to make features.\n",
      "[15:55:52 - Sampler] Region ParPgb:0.0-204.0 (266 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:55:52 - PWorker] Processed 0 batches\n",
      "[15:55:52 - PWorker] All done, 1 remainder regions.\n",
      "[15:55:52 - Predict] Processing 1 short region(s).\n",
      "[15:55:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbc517cef20>\n",
      "[15:55:52 - MdlStrTF] loading weights from /tmp/tmp9h53f794/model/variables/variables\n",
      "[15:55:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-205.\n",
      "[15:55:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:54 - Feature] Processed ParPgb:0.0-204.0 (median depth 112.0)\n",
      "[15:55:54 - Sampler] Took 1.31s to make features.\n",
      "[15:55:54 - PWorker] Processed 1 batches\n",
      "[15:55:54 - PWorker] All done, 0 remainder regions.\n",
      "[15:55:54 - Predict] Finished processing all regions.\n",
      "[15:55:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:55:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:55:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:55:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:55:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:55:58 - Predict] Found a GPU.\n",
      "[15:55:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:55:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:55:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5501885a80>\n",
      "[15:55:59 - MdlStrTF] loading weights from /tmp/tmpmies3lz7/model/variables/variables\n",
      "[15:55:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:55:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:55:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-270.\n",
      "[15:55:59 - Feature] Processed ParPgb:0.0-270.0 (median depth 161.0)\n",
      "[15:55:59 - Sampler] Took 0.04s to make features.\n",
      "[15:55:59 - Sampler] Region ParPgb:0.0-270.0 (359 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:55:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:59 - PWorker] Processed 0 batches\n",
      "[15:55:59 - PWorker] All done, 1 remainder regions.\n",
      "[15:55:59 - Predict] Processing 1 short region(s).\n",
      "[15:55:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:55:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f54706f9ba0>\n",
      "[15:55:59 - MdlStrTF] loading weights from /tmp/tmpmies3lz7/model/variables/variables\n",
      "[15:55:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-271.\n",
      "[15:55:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:55:59 - Feature] Processed ParPgb:0.0-270.0 (median depth 161.0)\n",
      "[15:55:59 - Sampler] Took 0.05s to make features.\n",
      "[15:56:00 - PWorker] Processed 1 batches\n",
      "[15:56:00 - PWorker] All done, 0 remainder regions.\n",
      "[15:56:00 - Predict] Finished processing all regions.\n",
      "[15:56:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:56:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:56:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:56:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:56:03 - Predict] Found a GPU.\n",
      "[15:56:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:56:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:56:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f55b51cdae0>\n",
      "[15:56:05 - MdlStrTF] loading weights from /tmp/tmpuu9g1aj8/model/variables/variables\n",
      "[15:56:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:56:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:56:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-232.\n",
      "[15:56:05 - Feature] Processed ParPgb:0.0-232.0 (median depth 74.0)\n",
      "[15:56:05 - Sampler] Took 0.11s to make features.\n",
      "[15:56:05 - Sampler] Region ParPgb:0.0-232.0 (285 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:56:05 - PWorker] Processed 0 batches\n",
      "[15:56:05 - PWorker] All done, 1 remainder regions.\n",
      "[15:56:05 - Predict] Processing 1 short region(s).\n",
      "[15:56:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f55203661a0>\n",
      "[15:56:05 - MdlStrTF] loading weights from /tmp/tmpuu9g1aj8/model/variables/variables\n",
      "[15:56:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-233.\n",
      "[15:56:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:05 - Feature] Processed ParPgb:0.0-232.0 (median depth 74.0)\n",
      "[15:56:05 - Sampler] Took 0.09s to make features.\n",
      "[15:56:06 - PWorker] Processed 1 batches\n",
      "[15:56:06 - PWorker] All done, 0 remainder regions.\n",
      "[15:56:06 - Predict] Finished processing all regions.\n",
      "[15:56:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:56:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:56:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:56:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:56:09 - Predict] Found a GPU.\n",
      "[15:56:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:56:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:56:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7e63c65a80>\n",
      "[15:56:11 - MdlStrTF] loading weights from /tmp/tmpp7d08rjk/model/variables/variables\n",
      "[15:56:11 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:56:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:56:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:56:11 - Feature] Processed ParPgb:0.0-249.0 (median depth 78.0)\n",
      "[15:56:11 - Sampler] Took 0.04s to make features.\n",
      "[15:56:11 - Sampler] Region ParPgb:0.0-249.0 (298 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:56:11 - PWorker] Processed 0 batches\n",
      "[15:56:11 - PWorker] All done, 1 remainder regions.\n",
      "[15:56:11 - Predict] Processing 1 short region(s).\n",
      "[15:56:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7dd2d25420>\n",
      "[15:56:11 - MdlStrTF] loading weights from /tmp/tmpp7d08rjk/model/variables/variables\n",
      "[15:56:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:56:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:11 - Feature] Processed ParPgb:0.0-249.0 (median depth 78.0)\n",
      "[15:56:11 - Sampler] Took 0.05s to make features.\n",
      "[15:56:12 - PWorker] Processed 1 batches\n",
      "[15:56:12 - PWorker] All done, 0 remainder regions.\n",
      "[15:56:12 - Predict] Finished processing all regions.\n",
      "[15:56:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:56:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:56:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:56:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:56:15 - Predict] Found a GPU.\n",
      "[15:56:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:56:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:56:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff16e1a5ae0>\n",
      "[15:56:17 - MdlStrTF] loading weights from /tmp/tmpt7e9h5ei/model/variables/variables\n",
      "[15:56:17 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:56:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:56:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[15:56:17 - Feature] Processed ParPgb:0.0-250.0 (median depth 59.0)\n",
      "[15:56:17 - Sampler] Took 0.09s to make features.\n",
      "[15:56:17 - Sampler] Region ParPgb:0.0-250.0 (300 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:56:17 - PWorker] Processed 0 batches\n",
      "[15:56:17 - PWorker] All done, 1 remainder regions.\n",
      "[15:56:17 - Predict] Processing 1 short region(s).\n",
      "[15:56:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff0dc1e1b10>\n",
      "[15:56:17 - MdlStrTF] loading weights from /tmp/tmpt7e9h5ei/model/variables/variables\n",
      "[15:56:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[15:56:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:18 - Feature] Processed ParPgb:0.0-250.0 (median depth 59.0)\n",
      "[15:56:18 - Sampler] Took 1.17s to make features.\n",
      "[15:56:19 - PWorker] Processed 1 batches\n",
      "[15:56:19 - PWorker] All done, 0 remainder regions.\n",
      "[15:56:19 - Predict] Finished processing all regions.\n",
      "[15:56:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:56:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:56:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:56:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:56:22 - Predict] Found a GPU.\n",
      "[15:56:22 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:56:22 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:56:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa37e839ae0>\n",
      "[15:56:24 - MdlStrTF] loading weights from /tmp/tmphmtze4q6/model/variables/variables\n",
      "[15:56:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:56:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:56:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:29 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-201.\n",
      "[15:56:29 - Feature] Processed ParPgb:0.0-201.0 (median depth 133.0)\n",
      "[15:56:29 - Sampler] Took 4.92s to make features.\n",
      "[15:56:29 - Sampler] Region ParPgb:0.0-201.0 (248 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:56:29 - PWorker] Processed 0 batches\n",
      "[15:56:29 - PWorker] All done, 1 remainder regions.\n",
      "[15:56:29 - Predict] Processing 1 short region(s).\n",
      "[15:56:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa2ed9a9ae0>\n",
      "[15:56:29 - MdlStrTF] loading weights from /tmp/tmphmtze4q6/model/variables/variables\n",
      "[15:56:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-202.\n",
      "[15:56:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:29 - Feature] Processed ParPgb:0.0-201.0 (median depth 133.0)\n",
      "[15:56:29 - Sampler] Took 0.05s to make features.\n",
      "[15:56:30 - PWorker] Processed 1 batches\n",
      "[15:56:30 - PWorker] All done, 0 remainder regions.\n",
      "[15:56:30 - Predict] Finished processing all regions.\n",
      "[15:56:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:33 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:56:33 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:56:33 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:56:33 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:56:33 - Predict] Found a GPU.\n",
      "[15:56:33 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:56:33 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:56:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe1dc8c9ae0>\n",
      "[15:56:34 - MdlStrTF] loading weights from /tmp/tmp4owvw91o/model/variables/variables\n",
      "[15:56:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:56:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:56:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:36 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[15:56:36 - Feature] Processed ParPgb:0.0-247.0 (median depth 79.0)\n",
      "[15:56:36 - Sampler] Took 1.17s to make features.\n",
      "[15:56:36 - Sampler] Region ParPgb:0.0-247.0 (287 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:56:36 - PWorker] Processed 0 batches\n",
      "[15:56:36 - PWorker] All done, 1 remainder regions.\n",
      "[15:56:36 - Predict] Processing 1 short region(s).\n",
      "[15:56:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe14c199480>\n",
      "[15:56:36 - MdlStrTF] loading weights from /tmp/tmp4owvw91o/model/variables/variables\n",
      "[15:56:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[15:56:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:36 - Feature] Processed ParPgb:0.0-247.0 (median depth 79.0)\n",
      "[15:56:36 - Sampler] Took 0.04s to make features.\n",
      "[15:56:37 - PWorker] Processed 1 batches\n",
      "[15:56:37 - PWorker] All done, 0 remainder regions.\n",
      "[15:56:37 - Predict] Finished processing all regions.\n",
      "[15:56:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:56:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:56:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:56:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:56:40 - Predict] Found a GPU.\n",
      "[15:56:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:56:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:56:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f821d335ae0>\n",
      "[15:56:41 - MdlStrTF] loading weights from /tmp/tmp2hyz7mny/model/variables/variables\n",
      "[15:56:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:56:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:56:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:41 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:56:41 - Feature] Processed ParPgb:0.0-203.0 (median depth 69.0)\n",
      "[15:56:41 - Sampler] Took 0.03s to make features.\n",
      "[15:56:41 - Sampler] Region ParPgb:0.0-203.0 (231 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:56:41 - PWorker] Processed 0 batches\n",
      "[15:56:41 - PWorker] All done, 1 remainder regions.\n",
      "[15:56:41 - Predict] Processing 1 short region(s).\n",
      "[15:56:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f818c3c5480>\n",
      "[15:56:42 - MdlStrTF] loading weights from /tmp/tmp2hyz7mny/model/variables/variables\n",
      "[15:56:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:56:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:42 - Feature] Processed ParPgb:0.0-203.0 (median depth 69.0)\n",
      "[15:56:42 - Sampler] Took 0.05s to make features.\n",
      "[15:56:43 - PWorker] Processed 1 batches\n",
      "[15:56:43 - PWorker] All done, 0 remainder regions.\n",
      "[15:56:43 - Predict] Finished processing all regions.\n",
      "[15:56:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:46 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:56:46 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:56:46 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:56:46 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:56:46 - Predict] Found a GPU.\n",
      "[15:56:46 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:56:46 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:56:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd3d0c79ae0>\n",
      "[15:56:47 - MdlStrTF] loading weights from /tmp/tmpnt9lj7rk/model/variables/variables\n",
      "[15:56:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:56:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:56:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[15:56:47 - Feature] Processed ParPgb:0.0-244.0 (median depth 85.0)\n",
      "[15:56:47 - Sampler] Took 0.12s to make features.\n",
      "[15:56:47 - Sampler] Region ParPgb:0.0-244.0 (324 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:56:47 - PWorker] Processed 0 batches\n",
      "[15:56:47 - PWorker] All done, 1 remainder regions.\n",
      "[15:56:47 - Predict] Processing 1 short region(s).\n",
      "[15:56:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd331d69ff0>\n",
      "[15:56:48 - MdlStrTF] loading weights from /tmp/tmpnt9lj7rk/model/variables/variables\n",
      "[15:56:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[15:56:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:48 - Feature] Processed ParPgb:0.0-244.0 (median depth 85.0)\n",
      "[15:56:48 - Sampler] Took 0.25s to make features.\n",
      "[15:56:49 - PWorker] Processed 1 batches\n",
      "[15:56:49 - PWorker] All done, 0 remainder regions.\n",
      "[15:56:49 - Predict] Finished processing all regions.\n",
      "[15:56:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:52 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:56:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:56:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:56:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:56:52 - Predict] Found a GPU.\n",
      "[15:56:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:56:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:56:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc659805ae0>\n",
      "[15:56:53 - MdlStrTF] loading weights from /tmp/tmp81_xg2v9/model/variables/variables\n",
      "[15:56:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:56:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:56:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-257.\n",
      "[15:56:55 - Feature] Processed ParPgb:0.0-257.0 (median depth 121.0)\n",
      "[15:56:55 - Sampler] Took 1.76s to make features.\n",
      "[15:56:55 - Sampler] Region ParPgb:0.0-257.0 (353 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:56:55 - PWorker] Processed 0 batches\n",
      "[15:56:55 - PWorker] All done, 1 remainder regions.\n",
      "[15:56:55 - Predict] Processing 1 short region(s).\n",
      "[15:56:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:56:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc5c8a21480>\n",
      "[15:56:56 - MdlStrTF] loading weights from /tmp/tmp81_xg2v9/model/variables/variables\n",
      "[15:56:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-258.\n",
      "[15:56:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:56:56 - Feature] Processed ParPgb:0.0-257.0 (median depth 121.0)\n",
      "[15:56:56 - Sampler] Took 0.04s to make features.\n",
      "[15:56:56 - PWorker] Processed 1 batches\n",
      "[15:56:56 - PWorker] All done, 0 remainder regions.\n",
      "[15:56:56 - Predict] Finished processing all regions.\n",
      "[15:56:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:56:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:57:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:57:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:57:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:57:00 - Predict] Found a GPU.\n",
      "[15:57:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:57:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:57:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7230059ae0>\n",
      "[15:57:01 - MdlStrTF] loading weights from /tmp/tmpxlpj6d71/model/variables/variables\n",
      "[15:57:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:57:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:57:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-216.\n",
      "[15:57:01 - Feature] Processed ParPgb:0.0-216.0 (median depth 90.0)\n",
      "[15:57:01 - Sampler] Took 0.04s to make features.\n",
      "[15:57:01 - Sampler] Region ParPgb:0.0-216.0 (290 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:57:01 - PWorker] Processed 0 batches\n",
      "[15:57:01 - PWorker] All done, 1 remainder regions.\n",
      "[15:57:01 - Predict] Processing 1 short region(s).\n",
      "[15:57:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f71a01c61a0>\n",
      "[15:57:01 - MdlStrTF] loading weights from /tmp/tmpxlpj6d71/model/variables/variables\n",
      "[15:57:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-217.\n",
      "[15:57:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:01 - Feature] Processed ParPgb:0.0-216.0 (median depth 90.0)\n",
      "[15:57:01 - Sampler] Took 0.07s to make features.\n",
      "[15:57:02 - PWorker] Processed 1 batches\n",
      "[15:57:02 - PWorker] All done, 0 remainder regions.\n",
      "[15:57:02 - Predict] Finished processing all regions.\n",
      "[15:57:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:57:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:57:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:57:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:57:06 - Predict] Found a GPU.\n",
      "[15:57:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:57:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:57:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4cf4905ae0>\n",
      "[15:57:07 - MdlStrTF] loading weights from /tmp/tmpvb6btq05/model/variables/variables\n",
      "[15:57:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:57:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:57:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:08 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-214.\n",
      "[15:57:10 - Feature] Processed ParPgb:0.0-214.0 (median depth 74.0)\n",
      "[15:57:10 - Sampler] Took 2.95s to make features.\n",
      "[15:57:10 - Sampler] Region ParPgb:0.0-214.0 (262 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:57:10 - PWorker] Processed 0 batches\n",
      "[15:57:10 - PWorker] All done, 1 remainder regions.\n",
      "[15:57:10 - Predict] Processing 1 short region(s).\n",
      "[15:57:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4c603661a0>\n",
      "[15:57:10 - MdlStrTF] loading weights from /tmp/tmpvb6btq05/model/variables/variables\n",
      "[15:57:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-215.\n",
      "[15:57:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:10 - Feature] Processed ParPgb:0.0-214.0 (median depth 74.0)\n",
      "[15:57:10 - Sampler] Took 0.07s to make features.\n",
      "[15:57:11 - PWorker] Processed 1 batches\n",
      "[15:57:11 - PWorker] All done, 0 remainder regions.\n",
      "[15:57:11 - Predict] Finished processing all regions.\n",
      "[15:57:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:57:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:57:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:57:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:57:14 - Predict] Found a GPU.\n",
      "[15:57:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:57:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:57:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f515c191ae0>\n",
      "[15:57:16 - MdlStrTF] loading weights from /tmp/tmpwmn4j45b/model/variables/variables\n",
      "[15:57:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:57:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:57:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:18 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[15:57:18 - Feature] Processed ParPgb:0.0-251.0 (median depth 83.0)\n",
      "[15:57:18 - Sampler] Took 2.15s to make features.\n",
      "[15:57:18 - Sampler] Region ParPgb:0.0-251.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:57:18 - PWorker] Processed 0 batches\n",
      "[15:57:18 - PWorker] All done, 1 remainder regions.\n",
      "[15:57:18 - Predict] Processing 1 short region(s).\n",
      "[15:57:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f50bd319450>\n",
      "[15:57:18 - MdlStrTF] loading weights from /tmp/tmpwmn4j45b/model/variables/variables\n",
      "[15:57:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[15:57:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:18 - Feature] Processed ParPgb:0.0-251.0 (median depth 83.0)\n",
      "[15:57:18 - Sampler] Took 0.09s to make features.\n",
      "[15:57:19 - PWorker] Processed 1 batches\n",
      "[15:57:19 - PWorker] All done, 0 remainder regions.\n",
      "[15:57:19 - Predict] Finished processing all regions.\n",
      "[15:57:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:57:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:57:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:57:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:57:22 - Predict] Found a GPU.\n",
      "[15:57:22 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:57:22 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:57:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd608b01ae0>\n",
      "[15:57:24 - MdlStrTF] loading weights from /tmp/tmpqlt67x7q/model/variables/variables\n",
      "[15:57:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:57:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:57:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-236.\n",
      "[15:57:24 - Feature] Processed ParPgb:0.0-236.0 (median depth 60.0)\n",
      "[15:57:24 - Sampler] Took 0.02s to make features.\n",
      "[15:57:24 - Sampler] Region ParPgb:0.0-236.0 (264 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:57:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:24 - PWorker] Processed 0 batches\n",
      "[15:57:24 - PWorker] All done, 1 remainder regions.\n",
      "[15:57:24 - Predict] Processing 1 short region(s).\n",
      "[15:57:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd578492ec0>\n",
      "[15:57:24 - MdlStrTF] loading weights from /tmp/tmpqlt67x7q/model/variables/variables\n",
      "[15:57:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-237.\n",
      "[15:57:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:26 - Feature] Processed ParPgb:0.0-236.0 (median depth 60.0)\n",
      "[15:57:26 - Sampler] Took 2.25s to make features.\n",
      "[15:57:27 - PWorker] Processed 1 batches\n",
      "[15:57:27 - PWorker] All done, 0 remainder regions.\n",
      "[15:57:27 - Predict] Finished processing all regions.\n",
      "[15:57:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:57:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:57:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:57:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:57:30 - Predict] Found a GPU.\n",
      "[15:57:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:57:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:57:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1a62035ae0>\n",
      "[15:57:32 - MdlStrTF] loading weights from /tmp/tmp4lo65j_b/model/variables/variables\n",
      "[15:57:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:57:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:57:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:32 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[15:57:32 - Feature] Processed ParPgb:0.0-254.0 (median depth 67.0)\n",
      "[15:57:32 - Sampler] Took 0.05s to make features.\n",
      "[15:57:32 - Sampler] Region ParPgb:0.0-254.0 (288 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:57:32 - PWorker] Processed 0 batches\n",
      "[15:57:32 - PWorker] All done, 1 remainder regions.\n",
      "[15:57:32 - Predict] Processing 1 short region(s).\n",
      "[15:57:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f19d122e350>\n",
      "[15:57:32 - MdlStrTF] loading weights from /tmp/tmp4lo65j_b/model/variables/variables\n",
      "[15:57:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[15:57:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:32 - Feature] Processed ParPgb:0.0-254.0 (median depth 67.0)\n",
      "[15:57:32 - Sampler] Took 0.03s to make features.\n",
      "[15:57:33 - PWorker] Processed 1 batches\n",
      "[15:57:33 - PWorker] All done, 0 remainder regions.\n",
      "[15:57:33 - Predict] Finished processing all regions.\n",
      "[15:57:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:36 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:57:36 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:57:36 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:57:36 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:57:36 - Predict] Found a GPU.\n",
      "[15:57:36 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:57:36 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:57:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fceb4e7dae0>\n",
      "[15:57:38 - MdlStrTF] loading weights from /tmp/tmpxss9w4g3/model/variables/variables\n",
      "[15:57:38 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:57:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:57:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:38 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-239.\n",
      "[15:57:38 - Feature] Processed ParPgb:0.0-239.0 (median depth 86.0)\n",
      "[15:57:38 - Sampler] Took 0.28s to make features.\n",
      "[15:57:38 - Sampler] Region ParPgb:0.0-239.0 (283 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:57:38 - PWorker] Processed 0 batches\n",
      "[15:57:38 - PWorker] All done, 1 remainder regions.\n",
      "[15:57:38 - Predict] Processing 1 short region(s).\n",
      "[15:57:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcdeff9d450>\n",
      "[15:57:38 - MdlStrTF] loading weights from /tmp/tmpxss9w4g3/model/variables/variables\n",
      "[15:57:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-240.\n",
      "[15:57:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:38 - Feature] Processed ParPgb:0.0-239.0 (median depth 86.0)\n",
      "[15:57:38 - Sampler] Took 0.19s to make features.\n",
      "[15:57:39 - PWorker] Processed 1 batches\n",
      "[15:57:39 - PWorker] All done, 0 remainder regions.\n",
      "[15:57:39 - Predict] Finished processing all regions.\n",
      "[15:57:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:57:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:57:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:57:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:57:42 - Predict] Found a GPU.\n",
      "[15:57:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:57:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:57:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4f90a61ae0>\n",
      "[15:57:44 - MdlStrTF] loading weights from /tmp/tmpxng10a6x/model/variables/variables\n",
      "[15:57:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:57:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:57:44 - Sampler] Took 0.01s to make features.\n",
      "[15:57:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:44 - PWorker] Processed 0 batches\n",
      "[15:57:44 - PWorker] All done, 0 remainder regions.\n",
      "[15:57:44 - Predict] Finished processing all regions.\n",
      "[15:57:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:45 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:57:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:57:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:57:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:57:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:57:47 - Predict] Found a GPU.\n",
      "[15:57:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:57:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:57:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff4782e9ae0>\n",
      "[15:57:48 - MdlStrTF] loading weights from /tmp/tmpsbgu8z0b/model/variables/variables\n",
      "[15:57:48 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:57:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:57:48 - Sampler] Took 0.01s to make features.\n",
      "[15:57:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:48 - PWorker] Processed 0 batches\n",
      "[15:57:48 - PWorker] All done, 0 remainder regions.\n",
      "[15:57:48 - Predict] Finished processing all regions.\n",
      "[15:57:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:50 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[15:57:52 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:57:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:57:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:57:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:57:52 - Predict] Found a GPU.\n",
      "[15:57:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:57:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:57:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f40189d9ae0>\n",
      "[15:57:53 - MdlStrTF] loading weights from /tmp/tmpbcy7ts3_/model/variables/variables\n",
      "[15:57:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:57:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:57:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:57:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:53 - Feature] Processed ParPgb:0.0-246.0 (median depth 76.0)\n",
      "[15:57:53 - Sampler] Took 0.10s to make features.\n",
      "[15:57:53 - Sampler] Region ParPgb:0.0-246.0 (288 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:57:53 - PWorker] Processed 0 batches\n",
      "[15:57:53 - PWorker] All done, 1 remainder regions.\n",
      "[15:57:53 - Predict] Processing 1 short region(s).\n",
      "[15:57:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3f88392320>\n",
      "[15:57:54 - MdlStrTF] loading weights from /tmp/tmpbcy7ts3_/model/variables/variables\n",
      "[15:57:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:57:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:57:54 - Feature] Processed ParPgb:0.0-246.0 (median depth 76.0)\n",
      "[15:57:54 - Sampler] Took 0.04s to make features.\n",
      "[15:57:54 - PWorker] Processed 1 batches\n",
      "[15:57:54 - PWorker] All done, 0 remainder regions.\n",
      "[15:57:54 - Predict] Finished processing all regions.\n",
      "[15:57:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:57:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:57:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:57:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:57:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:57:58 - Predict] Found a GPU.\n",
      "[15:57:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:57:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:57:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:57:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f05d0835a80>\n",
      "[15:57:59 - MdlStrTF] loading weights from /tmp/tmpaalya8q5/model/variables/variables\n",
      "[15:57:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:57:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:57:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:00 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[15:58:02 - Feature] Processed ParPgb:0.0-249.0 (median depth 21.0)\n",
      "[15:58:02 - Sampler] Took 2.71s to make features.\n",
      "[15:58:02 - Sampler] Region ParPgb:0.0-249.0 (264 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:58:02 - PWorker] Processed 0 batches\n",
      "[15:58:02 - PWorker] All done, 1 remainder regions.\n",
      "[15:58:02 - Predict] Processing 1 short region(s).\n",
      "[15:58:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f05402261a0>\n",
      "[15:58:02 - MdlStrTF] loading weights from /tmp/tmpaalya8q5/model/variables/variables\n",
      "[15:58:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[15:58:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:02 - Feature] Processed ParPgb:0.0-249.0 (median depth 21.0)\n",
      "[15:58:02 - Sampler] Took 0.09s to make features.\n",
      "[15:58:03 - PWorker] Processed 1 batches\n",
      "[15:58:03 - PWorker] All done, 0 remainder regions.\n",
      "[15:58:03 - Predict] Finished processing all regions.\n",
      "[15:58:05 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:05 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:06 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:58:06 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:58:06 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:58:06 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:58:06 - Predict] Found a GPU.\n",
      "[15:58:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:58:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:58:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff7331c1ae0>\n",
      "[15:58:07 - MdlStrTF] loading weights from /tmp/tmpqig9my_2/model/variables/variables\n",
      "[15:58:08 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:58:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:58:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:08 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-265.\n",
      "[15:58:08 - Feature] Processed ParPgb:0.0-265.0 (median depth 65.0)\n",
      "[15:58:08 - Sampler] Took 0.07s to make features.\n",
      "[15:58:08 - Sampler] Region ParPgb:0.0-265.0 (315 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:58:08 - PWorker] Processed 0 batches\n",
      "[15:58:08 - PWorker] All done, 1 remainder regions.\n",
      "[15:58:08 - Predict] Processing 1 short region(s).\n",
      "[15:58:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff6a0261480>\n",
      "[15:58:08 - MdlStrTF] loading weights from /tmp/tmpqig9my_2/model/variables/variables\n",
      "[15:58:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-266.\n",
      "[15:58:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:09 - Feature] Processed ParPgb:0.0-265.0 (median depth 65.0)\n",
      "[15:58:09 - Sampler] Took 0.73s to make features.\n",
      "[15:58:09 - PWorker] Processed 1 batches\n",
      "[15:58:09 - PWorker] All done, 0 remainder regions.\n",
      "[15:58:09 - Predict] Finished processing all regions.\n",
      "[15:58:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:13 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:58:13 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:58:13 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:58:13 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:58:13 - Predict] Found a GPU.\n",
      "[15:58:13 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:58:13 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:58:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6d63cd9ae0>\n",
      "[15:58:14 - MdlStrTF] loading weights from /tmp/tmp4fkkgxlz/model/variables/variables\n",
      "[15:58:14 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:58:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:58:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-201.\n",
      "[15:58:14 - Feature] Processed ParPgb:0.0-201.0 (median depth 64.0)\n",
      "[15:58:14 - Sampler] Took 0.03s to make features.\n",
      "[15:58:14 - Sampler] Region ParPgb:0.0-201.0 (263 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:58:14 - PWorker] Processed 0 batches\n",
      "[15:58:14 - PWorker] All done, 1 remainder regions.\n",
      "[15:58:14 - Predict] Processing 1 short region(s).\n",
      "[15:58:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6cd2621480>\n",
      "[15:58:15 - MdlStrTF] loading weights from /tmp/tmp4fkkgxlz/model/variables/variables\n",
      "[15:58:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-202.\n",
      "[15:58:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:15 - Feature] Processed ParPgb:0.0-201.0 (median depth 64.0)\n",
      "[15:58:15 - Sampler] Took 0.05s to make features.\n",
      "[15:58:15 - PWorker] Processed 1 batches\n",
      "[15:58:15 - PWorker] All done, 0 remainder regions.\n",
      "[15:58:15 - Predict] Finished processing all regions.\n",
      "[15:58:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:58:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:58:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:58:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:58:19 - Predict] Found a GPU.\n",
      "[15:58:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:58:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:58:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe26feedae0>\n",
      "[15:58:20 - MdlStrTF] loading weights from /tmp/tmpemeur0gh/model/variables/variables\n",
      "[15:58:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:58:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:58:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:22 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[15:58:22 - Feature] Processed ParPgb:0.0-203.0 (median depth 106.0)\n",
      "[15:58:22 - Sampler] Took 1.98s to make features.\n",
      "[15:58:22 - Sampler] Region ParPgb:0.0-203.0 (277 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:58:22 - PWorker] Processed 0 batches\n",
      "[15:58:22 - PWorker] All done, 1 remainder regions.\n",
      "[15:58:22 - Predict] Processing 1 short region(s).\n",
      "[15:58:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe1e00ee350>\n",
      "[15:58:22 - MdlStrTF] loading weights from /tmp/tmpemeur0gh/model/variables/variables\n",
      "[15:58:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[15:58:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:22 - Feature] Processed ParPgb:0.0-203.0 (median depth 106.0)\n",
      "[15:58:22 - Sampler] Took 0.08s to make features.\n",
      "[15:58:23 - PWorker] Processed 1 batches\n",
      "[15:58:23 - PWorker] All done, 0 remainder regions.\n",
      "[15:58:23 - Predict] Finished processing all regions.\n",
      "[15:58:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:26 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:58:26 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:58:26 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:58:26 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:58:26 - Predict] Found a GPU.\n",
      "[15:58:26 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:58:26 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:58:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f27d212dae0>\n",
      "[15:58:28 - MdlStrTF] loading weights from /tmp/tmph04j5a51/model/variables/variables\n",
      "[15:58:28 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:58:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:58:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:28 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-256.\n",
      "[15:58:28 - Feature] Processed ParPgb:0.0-256.0 (median depth 81.0)\n",
      "[15:58:28 - Sampler] Took 0.08s to make features.\n",
      "[15:58:28 - Sampler] Region ParPgb:0.0-256.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:58:28 - PWorker] Processed 0 batches\n",
      "[15:58:28 - PWorker] All done, 1 remainder regions.\n",
      "[15:58:28 - Predict] Processing 1 short region(s).\n",
      "[15:58:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2741329480>\n",
      "[15:58:28 - MdlStrTF] loading weights from /tmp/tmph04j5a51/model/variables/variables\n",
      "[15:58:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-257.\n",
      "[15:58:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:28 - Feature] Processed ParPgb:0.0-256.0 (median depth 81.0)\n",
      "[15:58:28 - Sampler] Took 0.06s to make features.\n",
      "[15:58:29 - PWorker] Processed 1 batches\n",
      "[15:58:29 - PWorker] All done, 0 remainder regions.\n",
      "[15:58:29 - Predict] Finished processing all regions.\n",
      "[15:58:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:32 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:58:32 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:58:32 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:58:32 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:58:32 - Predict] Found a GPU.\n",
      "[15:58:32 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:58:32 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:58:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7b8ac55ae0>\n",
      "[15:58:34 - MdlStrTF] loading weights from /tmp/tmpcsfy7y7j/model/variables/variables\n",
      "[15:58:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:58:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:58:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:36 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-215.\n",
      "[15:58:36 - Feature] Processed ParPgb:0.0-215.0 (median depth 66.0)\n",
      "[15:58:36 - Sampler] Took 1.94s to make features.\n",
      "[15:58:36 - Sampler] Region ParPgb:0.0-215.0 (252 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:58:36 - PWorker] Processed 0 batches\n",
      "[15:58:36 - PWorker] All done, 1 remainder regions.\n",
      "[15:58:36 - Predict] Processing 1 short region(s).\n",
      "[15:58:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7af9d55480>\n",
      "[15:58:36 - MdlStrTF] loading weights from /tmp/tmpcsfy7y7j/model/variables/variables\n",
      "[15:58:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-216.\n",
      "[15:58:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:36 - Feature] Processed ParPgb:0.0-215.0 (median depth 66.0)\n",
      "[15:58:36 - Sampler] Took 0.06s to make features.\n",
      "[15:58:37 - PWorker] Processed 1 batches\n",
      "[15:58:37 - PWorker] All done, 0 remainder regions.\n",
      "[15:58:37 - Predict] Finished processing all regions.\n",
      "[15:58:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:58:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:58:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:58:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:58:40 - Predict] Found a GPU.\n",
      "[15:58:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:58:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:58:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe075f99ae0>\n",
      "[15:58:42 - MdlStrTF] loading weights from /tmp/tmp4wg35ywc/model/variables/variables\n",
      "[15:58:42 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:58:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:58:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:42 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-259.\n",
      "[15:58:42 - Feature] Processed ParPgb:0.0-259.0 (median depth 84.0)\n",
      "[15:58:42 - Sampler] Took 0.03s to make features.\n",
      "[15:58:42 - Sampler] Region ParPgb:0.0-259.0 (307 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:58:42 - PWorker] Processed 0 batches\n",
      "[15:58:42 - PWorker] All done, 1 remainder regions.\n",
      "[15:58:42 - Predict] Processing 1 short region(s).\n",
      "[15:58:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdfd9111480>\n",
      "[15:58:42 - MdlStrTF] loading weights from /tmp/tmp4wg35ywc/model/variables/variables\n",
      "[15:58:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-260.\n",
      "[15:58:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:45 - Feature] Processed ParPgb:0.0-259.0 (median depth 84.0)\n",
      "[15:58:45 - Sampler] Took 2.68s to make features.\n",
      "[15:58:45 - PWorker] Processed 1 batches\n",
      "[15:58:45 - PWorker] All done, 0 remainder regions.\n",
      "[15:58:45 - Predict] Finished processing all regions.\n",
      "[15:58:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:49 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:58:49 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:58:49 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:58:49 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:58:49 - Predict] Found a GPU.\n",
      "[15:58:49 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:58:49 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:58:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4361e05ae0>\n",
      "[15:58:50 - MdlStrTF] loading weights from /tmp/tmpuzo_z1df/model/variables/variables\n",
      "[15:58:50 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:58:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:58:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:50 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-202.\n",
      "[15:58:50 - Feature] Processed ParPgb:0.0-202.0 (median depth 151.0)\n",
      "[15:58:50 - Sampler] Took 0.11s to make features.\n",
      "[15:58:50 - Sampler] Region ParPgb:0.0-202.0 (316 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:58:50 - PWorker] Processed 0 batches\n",
      "[15:58:50 - PWorker] All done, 1 remainder regions.\n",
      "[15:58:50 - Predict] Processing 1 short region(s).\n",
      "[15:58:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f42d0fe6ef0>\n",
      "[15:58:51 - MdlStrTF] loading weights from /tmp/tmpuzo_z1df/model/variables/variables\n",
      "[15:58:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-203.\n",
      "[15:58:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:58:52 - Feature] Processed ParPgb:0.0-202.0 (median depth 151.0)\n",
      "[15:58:52 - Sampler] Took 1.85s to make features.\n",
      "[15:58:53 - PWorker] Processed 1 batches\n",
      "[15:58:53 - PWorker] All done, 0 remainder regions.\n",
      "[15:58:53 - Predict] Finished processing all regions.\n",
      "[15:58:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:58:56 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:58:56 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:58:56 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:58:56 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:58:56 - Predict] Found a GPU.\n",
      "[15:58:56 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:58:56 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:58:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:58:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f02a6515ae0>\n",
      "[15:58:58 - MdlStrTF] loading weights from /tmp/tmpky7p6qbe/model/variables/variables\n",
      "[15:58:58 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:58:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:58:58 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-266.\n",
      "[15:58:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:00 - Feature] Processed ParPgb:0.0-266.0 (median depth 61.0)\n",
      "[15:59:00 - Sampler] Took 2.59s to make features.\n",
      "[15:59:00 - Sampler] Region ParPgb:0.0-266.0 (321 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:59:00 - PWorker] Processed 0 batches\n",
      "[15:59:00 - PWorker] All done, 1 remainder regions.\n",
      "[15:59:00 - Predict] Processing 1 short region(s).\n",
      "[15:59:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f020969e320>\n",
      "[15:59:01 - MdlStrTF] loading weights from /tmp/tmpky7p6qbe/model/variables/variables\n",
      "[15:59:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-267.\n",
      "[15:59:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:06 - Feature] Processed ParPgb:0.0-266.0 (median depth 61.0)\n",
      "[15:59:06 - Sampler] Took 4.93s to make features.\n",
      "[15:59:06 - PWorker] Batches in cache: 1.\n",
      "[15:59:06 - PWorker] Processed 1 batches\n",
      "[15:59:06 - PWorker] All done, 0 remainder regions.\n",
      "[15:59:06 - Predict] Finished processing all regions.\n",
      "[15:59:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:10 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:59:10 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:59:10 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:59:10 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:59:10 - Predict] Found a GPU.\n",
      "[15:59:10 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:59:10 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:59:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fab29465ae0>\n",
      "[15:59:11 - MdlStrTF] loading weights from /tmp/tmpsu6pnpf8/model/variables/variables\n",
      "[15:59:11 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:59:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:59:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-266.\n",
      "[15:59:11 - Feature] Processed ParPgb:0.0-266.0 (median depth 131.0)\n",
      "[15:59:11 - Sampler] Took 0.03s to make features.\n",
      "[15:59:11 - Sampler] Region ParPgb:0.0-266.0 (336 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:59:11 - PWorker] Processed 0 batches\n",
      "[15:59:11 - PWorker] All done, 1 remainder regions.\n",
      "[15:59:11 - Predict] Processing 1 short region(s).\n",
      "[15:59:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faa88556170>\n",
      "[15:59:11 - MdlStrTF] loading weights from /tmp/tmpsu6pnpf8/model/variables/variables\n",
      "[15:59:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-267.\n",
      "[15:59:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:12 - Feature] Processed ParPgb:0.0-266.0 (median depth 131.0)\n",
      "[15:59:12 - Sampler] Took 0.06s to make features.\n",
      "[15:59:12 - PWorker] Processed 1 batches\n",
      "[15:59:12 - PWorker] All done, 0 remainder regions.\n",
      "[15:59:12 - Predict] Finished processing all regions.\n",
      "[15:59:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:59:16 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:59:16 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:59:16 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:59:16 - Predict] Found a GPU.\n",
      "[15:59:16 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:59:16 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:59:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3e7a345ae0>\n",
      "[15:59:17 - MdlStrTF] loading weights from /tmp/tmpc_q0rxkv/model/variables/variables\n",
      "[15:59:17 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:59:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:59:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-204.\n",
      "[15:59:17 - Feature] Processed ParPgb:0.0-204.0 (median depth 70.0)\n",
      "[15:59:17 - Sampler] Took 0.21s to make features.\n",
      "[15:59:17 - Sampler] Region ParPgb:0.0-204.0 (239 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:59:17 - PWorker] Processed 0 batches\n",
      "[15:59:17 - PWorker] All done, 1 remainder regions.\n",
      "[15:59:17 - Predict] Processing 1 short region(s).\n",
      "[15:59:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3de952af20>\n",
      "[15:59:18 - MdlStrTF] loading weights from /tmp/tmpc_q0rxkv/model/variables/variables\n",
      "[15:59:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-205.\n",
      "[15:59:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:20 - Feature] Processed ParPgb:0.0-204.0 (median depth 70.0)\n",
      "[15:59:20 - Sampler] Took 2.36s to make features.\n",
      "[15:59:20 - PWorker] Processed 1 batches\n",
      "[15:59:20 - PWorker] All done, 0 remainder regions.\n",
      "[15:59:20 - Predict] Finished processing all regions.\n",
      "[15:59:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:59:24 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:59:24 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:59:24 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:59:24 - Predict] Found a GPU.\n",
      "[15:59:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:59:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:59:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f88c4b9da80>\n",
      "[15:59:25 - MdlStrTF] loading weights from /tmp/tmpwc1m45kb/model/variables/variables\n",
      "[15:59:25 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:59:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:59:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:25 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-200.\n",
      "[15:59:25 - Feature] Processed ParPgb:0.0-200.0 (median depth 175.0)\n",
      "[15:59:25 - Sampler] Took 0.04s to make features.\n",
      "[15:59:25 - Sampler] Region ParPgb:0.0-200.0 (304 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:59:25 - PWorker] Processed 0 batches\n",
      "[15:59:25 - PWorker] All done, 1 remainder regions.\n",
      "[15:59:25 - Predict] Processing 1 short region(s).\n",
      "[15:59:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8801d92f80>\n",
      "[15:59:26 - MdlStrTF] loading weights from /tmp/tmpwc1m45kb/model/variables/variables\n",
      "[15:59:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-201.\n",
      "[15:59:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:26 - Feature] Processed ParPgb:0.0-200.0 (median depth 175.0)\n",
      "[15:59:26 - Sampler] Took 0.18s to make features.\n",
      "[15:59:26 - PWorker] Processed 1 batches\n",
      "[15:59:26 - PWorker] All done, 0 remainder regions.\n",
      "[15:59:26 - Predict] Finished processing all regions.\n",
      "[15:59:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:59:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:59:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:59:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:59:30 - Predict] Found a GPU.\n",
      "[15:59:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:59:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:59:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fba25245ae0>\n",
      "[15:59:31 - MdlStrTF] loading weights from /tmp/tmpw1v7znxq/model/variables/variables\n",
      "[15:59:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:59:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:59:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-262.\n",
      "[15:59:31 - Feature] Processed ParPgb:0.0-262.0 (median depth 73.0)\n",
      "[15:59:31 - Sampler] Took 0.07s to make features.\n",
      "[15:59:31 - Sampler] Region ParPgb:0.0-262.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:59:31 - PWorker] Processed 0 batches\n",
      "[15:59:31 - PWorker] All done, 1 remainder regions.\n",
      "[15:59:31 - Predict] Processing 1 short region(s).\n",
      "[15:59:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb9904621a0>\n",
      "[15:59:32 - MdlStrTF] loading weights from /tmp/tmpw1v7znxq/model/variables/variables\n",
      "[15:59:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-263.\n",
      "[15:59:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:32 - Feature] Processed ParPgb:0.0-262.0 (median depth 73.0)\n",
      "[15:59:32 - Sampler] Took 0.05s to make features.\n",
      "[15:59:32 - PWorker] Processed 1 batches\n",
      "[15:59:32 - PWorker] All done, 0 remainder regions.\n",
      "[15:59:32 - Predict] Finished processing all regions.\n",
      "[15:59:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:36 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:59:36 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:59:36 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:59:36 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:59:36 - Predict] Found a GPU.\n",
      "[15:59:36 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:59:36 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:59:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fed1e879ae0>\n",
      "[15:59:37 - MdlStrTF] loading weights from /tmp/tmpkcowga9i/model/variables/variables\n",
      "[15:59:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:59:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:59:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-265.\n",
      "[15:59:37 - Feature] Processed ParPgb:0.0-265.0 (median depth 63.0)\n",
      "[15:59:37 - Sampler] Took 0.04s to make features.\n",
      "[15:59:37 - Sampler] Region ParPgb:0.0-265.0 (333 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:59:37 - PWorker] Processed 0 batches\n",
      "[15:59:37 - PWorker] All done, 1 remainder regions.\n",
      "[15:59:37 - Predict] Processing 1 short region(s).\n",
      "[15:59:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fec8c76ae30>\n",
      "[15:59:38 - MdlStrTF] loading weights from /tmp/tmpkcowga9i/model/variables/variables\n",
      "[15:59:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-266.\n",
      "[15:59:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:38 - Feature] Processed ParPgb:0.0-265.0 (median depth 63.0)\n",
      "[15:59:38 - Sampler] Took 0.06s to make features.\n",
      "[15:59:38 - PWorker] Processed 1 batches\n",
      "[15:59:38 - PWorker] All done, 0 remainder regions.\n",
      "[15:59:38 - Predict] Finished processing all regions.\n",
      "[15:59:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:59:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:59:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:59:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:59:42 - Predict] Found a GPU.\n",
      "[15:59:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:59:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:59:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6b46029ae0>\n",
      "[15:59:43 - MdlStrTF] loading weights from /tmp/tmps92fh_p9/model/variables/variables\n",
      "[15:59:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:59:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:59:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-194.\n",
      "[15:59:43 - Feature] Processed ParPgb:0.0-194.0 (median depth 1.0)\n",
      "[15:59:43 - Sampler] Took 0.09s to make features.\n",
      "[15:59:43 - Sampler] Region ParPgb:0.0-194.0 (195 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:59:43 - PWorker] Processed 0 batches\n",
      "[15:59:43 - PWorker] All done, 1 remainder regions.\n",
      "[15:59:43 - Predict] Processing 1 short region(s).\n",
      "[15:59:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6aa9211e70>\n",
      "[15:59:43 - MdlStrTF] loading weights from /tmp/tmps92fh_p9/model/variables/variables\n",
      "[15:59:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-195.\n",
      "[15:59:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:44 - Feature] Processed ParPgb:0.0-194.0 (median depth 1.0)\n",
      "[15:59:44 - Sampler] Took 0.08s to make features.\n",
      "[15:59:44 - PWorker] Processed 1 batches\n",
      "[15:59:44 - PWorker] All done, 0 remainder regions.\n",
      "[15:59:44 - Predict] Finished processing all regions.\n",
      "[15:59:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:59:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:59:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:59:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:59:48 - Predict] Found a GPU.\n",
      "[15:59:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:59:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:59:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8afa201ae0>\n",
      "[15:59:49 - MdlStrTF] loading weights from /tmp/tmp9cyqhx6n/model/variables/variables\n",
      "[15:59:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:59:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:59:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[15:59:51 - Feature] Processed ParPgb:0.0-246.0 (median depth 102.0)\n",
      "[15:59:51 - Sampler] Took 2.52s to make features.\n",
      "[15:59:51 - Sampler] Region ParPgb:0.0-246.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:59:51 - PWorker] Processed 0 batches\n",
      "[15:59:51 - PWorker] All done, 1 remainder regions.\n",
      "[15:59:51 - Predict] Processing 1 short region(s).\n",
      "[15:59:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8a6932aec0>\n",
      "[15:59:52 - MdlStrTF] loading weights from /tmp/tmp9cyqhx6n/model/variables/variables\n",
      "[15:59:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[15:59:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:54 - Feature] Processed ParPgb:0.0-246.0 (median depth 102.0)\n",
      "[15:59:54 - Sampler] Took 2.08s to make features.\n",
      "[15:59:54 - PWorker] Processed 1 batches\n",
      "[15:59:54 - PWorker] All done, 0 remainder regions.\n",
      "[15:59:54 - Predict] Finished processing all regions.\n",
      "[15:59:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[15:59:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[15:59:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[15:59:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[15:59:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[15:59:58 - Predict] Found a GPU.\n",
      "[15:59:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[15:59:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[15:59:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[15:59:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4feff55ae0>\n",
      "[15:59:59 - MdlStrTF] loading weights from /tmp/tmp5r3_9jf6/model/variables/variables\n",
      "[15:59:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[15:59:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[15:59:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[15:59:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-225.\n",
      "[15:59:59 - Feature] Processed ParPgb:0.0-225.0 (median depth 200.0)\n",
      "[15:59:59 - Sampler] Took 0.03s to make features.\n",
      "[15:59:59 - Sampler] Region ParPgb:0.0-225.0 (343 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[15:59:59 - PWorker] Processed 0 batches\n",
      "[15:59:59 - PWorker] All done, 1 remainder regions.\n",
      "[15:59:59 - Predict] Processing 1 short region(s).\n",
      "[15:59:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4f600c9480>\n",
      "[16:00:00 - MdlStrTF] loading weights from /tmp/tmp5r3_9jf6/model/variables/variables\n",
      "[16:00:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-226.\n",
      "[16:00:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:00 - Feature] Processed ParPgb:0.0-225.0 (median depth 200.0)\n",
      "[16:00:00 - Sampler] Took 0.04s to make features.\n",
      "[16:00:00 - PWorker] Processed 1 batches\n",
      "[16:00:00 - PWorker] All done, 0 remainder regions.\n",
      "[16:00:00 - Predict] Finished processing all regions.\n",
      "[16:00:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:00:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:00:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:00:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:00:04 - Predict] Found a GPU.\n",
      "[16:00:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:00:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:00:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5ad2e6dae0>\n",
      "[16:00:05 - MdlStrTF] loading weights from /tmp/tmprv3i42r9/model/variables/variables\n",
      "[16:00:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:00:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:00:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:00:05 - Feature] Processed ParPgb:0.0-248.0 (median depth 133.0)\n",
      "[16:00:05 - Sampler] Took 0.03s to make features.\n",
      "[16:00:05 - Sampler] Region ParPgb:0.0-248.0 (324 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:00:05 - PWorker] Processed 0 batches\n",
      "[16:00:05 - PWorker] All done, 1 remainder regions.\n",
      "[16:00:05 - Predict] Processing 1 short region(s).\n",
      "[16:00:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5a30459420>\n",
      "[16:00:06 - MdlStrTF] loading weights from /tmp/tmprv3i42r9/model/variables/variables\n",
      "[16:00:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:00:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:06 - Feature] Processed ParPgb:0.0-248.0 (median depth 133.0)\n",
      "[16:00:06 - Sampler] Took 0.05s to make features.\n",
      "[16:00:06 - PWorker] Processed 1 batches\n",
      "[16:00:06 - PWorker] All done, 0 remainder regions.\n",
      "[16:00:06 - Predict] Finished processing all regions.\n",
      "[16:00:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:10 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:00:10 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:00:10 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:00:10 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:00:10 - Predict] Found a GPU.\n",
      "[16:00:10 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:00:10 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:00:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f81d08d1ae0>\n",
      "[16:00:11 - MdlStrTF] loading weights from /tmp/tmphdypdfyl/model/variables/variables\n",
      "[16:00:11 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:00:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:00:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[16:00:11 - Feature] Processed ParPgb:0.0-254.0 (median depth 100.0)\n",
      "[16:00:11 - Sampler] Took 0.12s to make features.\n",
      "[16:00:11 - Sampler] Region ParPgb:0.0-254.0 (331 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:00:11 - PWorker] Processed 0 batches\n",
      "[16:00:11 - PWorker] All done, 1 remainder regions.\n",
      "[16:00:11 - Predict] Processing 1 short region(s).\n",
      "[16:00:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:12 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8140225b10>\n",
      "[16:00:12 - MdlStrTF] loading weights from /tmp/tmphdypdfyl/model/variables/variables\n",
      "[16:00:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[16:00:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:12 - Feature] Processed ParPgb:0.0-254.0 (median depth 100.0)\n",
      "[16:00:12 - Sampler] Took 0.05s to make features.\n",
      "[16:00:12 - PWorker] Processed 1 batches\n",
      "[16:00:12 - PWorker] All done, 0 remainder regions.\n",
      "[16:00:12 - Predict] Finished processing all regions.\n",
      "[16:00:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:00:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:00:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:00:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:00:16 - Predict] Found a GPU.\n",
      "[16:00:16 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:00:16 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:00:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff5a02edae0>\n",
      "[16:00:17 - MdlStrTF] loading weights from /tmp/tmpcj7clonk/model/variables/variables\n",
      "[16:00:17 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:00:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:00:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-190.\n",
      "[16:00:17 - Feature] Processed ParPgb:0.0-190.0 (median depth 1.0)\n",
      "[16:00:17 - Sampler] Took 0.04s to make features.\n",
      "[16:00:17 - Sampler] Region ParPgb:0.0-190.0 (192 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:00:17 - PWorker] Processed 0 batches\n",
      "[16:00:17 - PWorker] All done, 1 remainder regions.\n",
      "[16:00:17 - Predict] Processing 1 short region(s).\n",
      "[16:00:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff501442ef0>\n",
      "[16:00:17 - MdlStrTF] loading weights from /tmp/tmpcj7clonk/model/variables/variables\n",
      "[16:00:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-191.\n",
      "[16:00:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:17 - Feature] Processed ParPgb:0.0-190.0 (median depth 1.0)\n",
      "[16:00:17 - Sampler] Took 0.05s to make features.\n",
      "[16:00:18 - PWorker] Processed 1 batches\n",
      "[16:00:18 - PWorker] All done, 0 remainder regions.\n",
      "[16:00:18 - Predict] Finished processing all regions.\n",
      "[16:00:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:21 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:00:21 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:00:21 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:00:21 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:00:21 - Predict] Found a GPU.\n",
      "[16:00:21 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:00:21 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:00:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f66b26d5ae0>\n",
      "[16:00:23 - MdlStrTF] loading weights from /tmp/tmp_0wlywfa/model/variables/variables\n",
      "[16:00:23 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:00:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:00:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:25 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-264.\n",
      "[16:00:25 - Feature] Processed ParPgb:0.0-264.0 (median depth 55.0)\n",
      "[16:00:25 - Sampler] Took 2.21s to make features.\n",
      "[16:00:25 - Sampler] Region ParPgb:0.0-264.0 (306 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:00:25 - PWorker] Processed 0 batches\n",
      "[16:00:25 - PWorker] All done, 1 remainder regions.\n",
      "[16:00:25 - Predict] Processing 1 short region(s).\n",
      "[16:00:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f66218c5480>\n",
      "[16:00:25 - MdlStrTF] loading weights from /tmp/tmp_0wlywfa/model/variables/variables\n",
      "[16:00:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-265.\n",
      "[16:00:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:25 - Feature] Processed ParPgb:0.0-264.0 (median depth 55.0)\n",
      "[16:00:25 - Sampler] Took 0.04s to make features.\n",
      "[16:00:26 - PWorker] Processed 1 batches\n",
      "[16:00:26 - PWorker] All done, 0 remainder regions.\n",
      "[16:00:26 - Predict] Finished processing all regions.\n",
      "[16:00:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:00:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:00:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:00:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:00:29 - Predict] Found a GPU.\n",
      "[16:00:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:00:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:00:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb8cb611ae0>\n",
      "[16:00:31 - MdlStrTF] loading weights from /tmp/tmpsehsy8ai/model/variables/variables\n",
      "[16:00:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:00:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:00:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:33 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-208.\n",
      "[16:00:33 - Feature] Processed ParPgb:0.0-208.0 (median depth 120.0)\n",
      "[16:00:33 - Sampler] Took 2.32s to make features.\n",
      "[16:00:33 - Sampler] Region ParPgb:0.0-208.0 (291 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:00:33 - PWorker] Processed 0 batches\n",
      "[16:00:33 - PWorker] All done, 1 remainder regions.\n",
      "[16:00:33 - Predict] Processing 1 short region(s).\n",
      "[16:00:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb83a7c5480>\n",
      "[16:00:33 - MdlStrTF] loading weights from /tmp/tmpsehsy8ai/model/variables/variables\n",
      "[16:00:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-209.\n",
      "[16:00:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:36 - Feature] Processed ParPgb:0.0-208.0 (median depth 120.0)\n",
      "[16:00:36 - Sampler] Took 2.55s to make features.\n",
      "[16:00:37 - PWorker] Processed 1 batches\n",
      "[16:00:37 - PWorker] All done, 0 remainder regions.\n",
      "[16:00:37 - Predict] Finished processing all regions.\n",
      "[16:00:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:00:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:00:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:00:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:00:40 - Predict] Found a GPU.\n",
      "[16:00:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:00:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:00:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f59ce5f9ae0>\n",
      "[16:00:41 - MdlStrTF] loading weights from /tmp/tmpcgj988bx/model/variables/variables\n",
      "[16:00:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:00:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:00:41 - Sampler] Took 0.01s to make features.\n",
      "[16:00:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:41 - PWorker] Processed 0 batches\n",
      "[16:00:41 - PWorker] All done, 0 remainder regions.\n",
      "[16:00:41 - Predict] Finished processing all regions.\n",
      "[16:00:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:43 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:00:44 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:00:45 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:00:45 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:00:45 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:00:45 - Predict] Found a GPU.\n",
      "[16:00:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:00:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:00:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fccb1de1a80>\n",
      "[16:00:46 - MdlStrTF] loading weights from /tmp/tmpc9htyqno/model/variables/variables\n",
      "[16:00:46 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:00:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:00:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:46 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-203.\n",
      "[16:00:46 - Feature] Processed ParPgb:0.0-203.0 (median depth 87.0)\n",
      "[16:00:46 - Sampler] Took 0.05s to make features.\n",
      "[16:00:46 - Sampler] Region ParPgb:0.0-203.0 (263 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:00:46 - PWorker] Processed 0 batches\n",
      "[16:00:46 - PWorker] All done, 1 remainder regions.\n",
      "[16:00:46 - Predict] Processing 1 short region(s).\n",
      "[16:00:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcc20fbd420>\n",
      "[16:00:46 - MdlStrTF] loading weights from /tmp/tmpc9htyqno/model/variables/variables\n",
      "[16:00:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-204.\n",
      "[16:00:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:48 - Feature] Processed ParPgb:0.0-203.0 (median depth 87.0)\n",
      "[16:00:48 - Sampler] Took 1.16s to make features.\n",
      "[16:00:48 - PWorker] Processed 1 batches\n",
      "[16:00:48 - PWorker] All done, 0 remainder regions.\n",
      "[16:00:48 - Predict] Finished processing all regions.\n",
      "[16:00:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:51 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:00:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:00:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:00:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:00:52 - Predict] Found a GPU.\n",
      "[16:00:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:00:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:00:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f82307b1ae0>\n",
      "[16:00:53 - MdlStrTF] loading weights from /tmp/tmpg4kns3bu/model/variables/variables\n",
      "[16:00:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:00:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:00:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-258.\n",
      "[16:00:53 - Feature] Processed ParPgb:0.0-258.0 (median depth 46.0)\n",
      "[16:00:53 - Sampler] Took 0.05s to make features.\n",
      "[16:00:53 - Sampler] Region ParPgb:0.0-258.0 (299 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:00:53 - PWorker] Processed 0 batches\n",
      "[16:00:53 - PWorker] All done, 1 remainder regions.\n",
      "[16:00:53 - Predict] Processing 1 short region(s).\n",
      "[16:00:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f81a01c5480>\n",
      "[16:00:53 - MdlStrTF] loading weights from /tmp/tmpg4kns3bu/model/variables/variables\n",
      "[16:00:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-259.\n",
      "[16:00:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:53 - Feature] Processed ParPgb:0.0-258.0 (median depth 46.0)\n",
      "[16:00:53 - Sampler] Took 0.04s to make features.\n",
      "[16:00:54 - PWorker] Processed 1 batches\n",
      "[16:00:54 - PWorker] All done, 0 remainder regions.\n",
      "[16:00:54 - Predict] Finished processing all regions.\n",
      "[16:00:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:00:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:00:57 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:00:57 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:00:57 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:00:57 - Predict] Found a GPU.\n",
      "[16:00:57 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:00:57 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:00:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0d1a9d5ae0>\n",
      "[16:00:59 - MdlStrTF] loading weights from /tmp/tmp6f7cdxix/model/variables/variables\n",
      "[16:00:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:00:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:00:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:00:59 - Feature] Processed ParPgb:0.0-246.0 (median depth 81.0)\n",
      "[16:00:59 - Sampler] Took 0.04s to make features.\n",
      "[16:00:59 - Sampler] Region ParPgb:0.0-246.0 (299 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:00:59 - PWorker] Processed 0 batches\n",
      "[16:00:59 - PWorker] All done, 1 remainder regions.\n",
      "[16:00:59 - Predict] Processing 1 short region(s).\n",
      "[16:00:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:00:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0c89b29450>\n",
      "[16:00:59 - MdlStrTF] loading weights from /tmp/tmp6f7cdxix/model/variables/variables\n",
      "[16:00:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:00:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:00:59 - Feature] Processed ParPgb:0.0-246.0 (median depth 81.0)\n",
      "[16:00:59 - Sampler] Took 0.04s to make features.\n",
      "[16:01:00 - PWorker] Processed 1 batches\n",
      "[16:01:00 - PWorker] All done, 0 remainder regions.\n",
      "[16:01:00 - Predict] Finished processing all regions.\n",
      "[16:01:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:01:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:01:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:01:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:01:03 - Predict] Found a GPU.\n",
      "[16:01:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:01:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:01:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff994afdae0>\n",
      "[16:01:05 - MdlStrTF] loading weights from /tmp/tmphctvmglo/model/variables/variables\n",
      "[16:01:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:01:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:01:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-264.\n",
      "[16:01:05 - Feature] Processed ParPgb:0.0-264.0 (median depth 88.0)\n",
      "[16:01:05 - Sampler] Took 0.03s to make features.\n",
      "[16:01:05 - Sampler] Region ParPgb:0.0-264.0 (345 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:01:05 - PWorker] Processed 0 batches\n",
      "[16:01:05 - PWorker] All done, 1 remainder regions.\n",
      "[16:01:05 - Predict] Processing 1 short region(s).\n",
      "[16:01:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff8d0239450>\n",
      "[16:01:05 - MdlStrTF] loading weights from /tmp/tmphctvmglo/model/variables/variables\n",
      "[16:01:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-265.\n",
      "[16:01:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:05 - Feature] Processed ParPgb:0.0-264.0 (median depth 88.0)\n",
      "[16:01:05 - Sampler] Took 0.08s to make features.\n",
      "[16:01:06 - PWorker] Processed 1 batches\n",
      "[16:01:06 - PWorker] All done, 0 remainder regions.\n",
      "[16:01:06 - Predict] Finished processing all regions.\n",
      "[16:01:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:01:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:01:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:01:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:01:09 - Predict] Found a GPU.\n",
      "[16:01:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:01:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:01:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f54a4769ae0>\n",
      "[16:01:11 - MdlStrTF] loading weights from /tmp/tmpaeq6cfkv/model/variables/variables\n",
      "[16:01:11 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:01:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:01:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[16:01:11 - Feature] Processed ParPgb:0.0-254.0 (median depth 54.0)\n",
      "[16:01:11 - Sampler] Took 0.05s to make features.\n",
      "[16:01:11 - Sampler] Region ParPgb:0.0-254.0 (284 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:01:11 - PWorker] Processed 0 batches\n",
      "[16:01:11 - PWorker] All done, 1 remainder regions.\n",
      "[16:01:11 - Predict] Processing 1 short region(s).\n",
      "[16:01:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5410126f20>\n",
      "[16:01:11 - MdlStrTF] loading weights from /tmp/tmpaeq6cfkv/model/variables/variables\n",
      "[16:01:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[16:01:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:11 - Feature] Processed ParPgb:0.0-254.0 (median depth 54.0)\n",
      "[16:01:11 - Sampler] Took 0.03s to make features.\n",
      "[16:01:12 - PWorker] Processed 1 batches\n",
      "[16:01:12 - PWorker] All done, 0 remainder regions.\n",
      "[16:01:12 - Predict] Finished processing all regions.\n",
      "[16:01:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:01:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:01:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:01:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:01:15 - Predict] Found a GPU.\n",
      "[16:01:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:01:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:01:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4a3c451ae0>\n",
      "[16:01:16 - MdlStrTF] loading weights from /tmp/tmpbuew8wmj/model/variables/variables\n",
      "[16:01:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:01:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:01:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[16:01:16 - Feature] Processed ParPgb:0.0-247.0 (median depth 98.0)\n",
      "[16:01:16 - Sampler] Took 0.05s to make features.\n",
      "[16:01:16 - Sampler] Region ParPgb:0.0-247.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:01:16 - PWorker] Processed 0 batches\n",
      "[16:01:16 - PWorker] All done, 1 remainder regions.\n",
      "[16:01:16 - Predict] Processing 1 short region(s).\n",
      "[16:01:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f499c391480>\n",
      "[16:01:17 - MdlStrTF] loading weights from /tmp/tmpbuew8wmj/model/variables/variables\n",
      "[16:01:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[16:01:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:19 - Feature] Processed ParPgb:0.0-247.0 (median depth 98.0)\n",
      "[16:01:19 - Sampler] Took 2.47s to make features.\n",
      "[16:01:20 - PWorker] Processed 1 batches\n",
      "[16:01:20 - PWorker] All done, 0 remainder regions.\n",
      "[16:01:20 - Predict] Finished processing all regions.\n",
      "[16:01:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:23 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:01:23 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:01:23 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:01:23 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:01:23 - Predict] Found a GPU.\n",
      "[16:01:23 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:01:23 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:01:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1e2e119ae0>\n",
      "[16:01:25 - MdlStrTF] loading weights from /tmp/tmp2abdthos/model/variables/variables\n",
      "[16:01:25 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:01:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:01:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:25 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-200.\n",
      "[16:01:25 - Feature] Processed ParPgb:0.0-200.0 (median depth 67.0)\n",
      "[16:01:25 - Sampler] Took 0.03s to make features.\n",
      "[16:01:25 - Sampler] Region ParPgb:0.0-200.0 (241 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:01:25 - PWorker] Processed 0 batches\n",
      "[16:01:25 - PWorker] All done, 1 remainder regions.\n",
      "[16:01:25 - Predict] Processing 1 short region(s).\n",
      "[16:01:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1d9d2a1480>\n",
      "[16:01:25 - MdlStrTF] loading weights from /tmp/tmp2abdthos/model/variables/variables\n",
      "[16:01:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-201.\n",
      "[16:01:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:27 - Feature] Processed ParPgb:0.0-200.0 (median depth 67.0)\n",
      "[16:01:27 - Sampler] Took 2.29s to make features.\n",
      "[16:01:28 - PWorker] Processed 1 batches\n",
      "[16:01:28 - PWorker] All done, 0 remainder regions.\n",
      "[16:01:28 - Predict] Finished processing all regions.\n",
      "[16:01:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:01:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:01:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:01:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:01:31 - Predict] Found a GPU.\n",
      "[16:01:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:01:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:01:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8e0ba1dae0>\n",
      "[16:01:33 - MdlStrTF] loading weights from /tmp/tmp6u9eyo3z/model/variables/variables\n",
      "[16:01:33 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:01:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:01:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:33 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-260.\n",
      "[16:01:33 - Feature] Processed ParPgb:0.0-260.0 (median depth 147.0)\n",
      "[16:01:33 - Sampler] Took 0.08s to make features.\n",
      "[16:01:33 - Sampler] Region ParPgb:0.0-260.0 (349 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:01:33 - PWorker] Processed 0 batches\n",
      "[16:01:33 - PWorker] All done, 1 remainder regions.\n",
      "[16:01:33 - Predict] Processing 1 short region(s).\n",
      "[16:01:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8d781ed480>\n",
      "[16:01:33 - MdlStrTF] loading weights from /tmp/tmp6u9eyo3z/model/variables/variables\n",
      "[16:01:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-261.\n",
      "[16:01:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:33 - Feature] Processed ParPgb:0.0-260.0 (median depth 147.0)\n",
      "[16:01:33 - Sampler] Took 0.13s to make features.\n",
      "[16:01:34 - PWorker] Processed 1 batches\n",
      "[16:01:34 - PWorker] All done, 0 remainder regions.\n",
      "[16:01:34 - Predict] Finished processing all regions.\n",
      "[16:01:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:01:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:01:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:01:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:01:37 - Predict] Found a GPU.\n",
      "[16:01:37 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:01:37 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:01:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6912c25ae0>\n",
      "[16:01:39 - MdlStrTF] loading weights from /tmp/tmpdhjhmqpf/model/variables/variables\n",
      "[16:01:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:01:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:01:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:01:39 - Feature] Processed ParPgb:0.0-246.0 (median depth 63.0)\n",
      "[16:01:39 - Sampler] Took 0.11s to make features.\n",
      "[16:01:39 - Sampler] Region ParPgb:0.0-246.0 (289 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:01:39 - PWorker] Processed 0 batches\n",
      "[16:01:39 - PWorker] All done, 1 remainder regions.\n",
      "[16:01:39 - Predict] Processing 1 short region(s).\n",
      "[16:01:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6881d55ff0>\n",
      "[16:01:39 - MdlStrTF] loading weights from /tmp/tmpdhjhmqpf/model/variables/variables\n",
      "[16:01:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:01:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:39 - Feature] Processed ParPgb:0.0-246.0 (median depth 63.0)\n",
      "[16:01:39 - Sampler] Took 0.04s to make features.\n",
      "[16:01:40 - PWorker] Processed 1 batches\n",
      "[16:01:40 - PWorker] All done, 0 remainder regions.\n",
      "[16:01:40 - Predict] Finished processing all regions.\n",
      "[16:01:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:01:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:01:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:01:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:01:43 - Predict] Found a GPU.\n",
      "[16:01:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:01:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:01:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f33bab69ae0>\n",
      "[16:01:45 - MdlStrTF] loading weights from /tmp/tmp4ix1p4d5/model/variables/variables\n",
      "[16:01:45 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:01:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:01:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-224.\n",
      "[16:01:45 - Feature] Processed ParPgb:0.0-224.0 (median depth 39.0)\n",
      "[16:01:45 - Sampler] Took 0.07s to make features.\n",
      "[16:01:45 - Sampler] Region ParPgb:0.0-224.0 (260 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:01:45 - PWorker] Processed 0 batches\n",
      "[16:01:45 - PWorker] All done, 1 remainder regions.\n",
      "[16:01:45 - Predict] Processing 1 short region(s).\n",
      "[16:01:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3329d25ea0>\n",
      "[16:01:45 - MdlStrTF] loading weights from /tmp/tmp4ix1p4d5/model/variables/variables\n",
      "[16:01:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-225.\n",
      "[16:01:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:47 - Feature] Processed ParPgb:0.0-224.0 (median depth 39.0)\n",
      "[16:01:47 - Sampler] Took 2.13s to make features.\n",
      "[16:01:48 - PWorker] Processed 1 batches\n",
      "[16:01:48 - PWorker] All done, 0 remainder regions.\n",
      "[16:01:48 - Predict] Finished processing all regions.\n",
      "[16:01:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:51 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:01:51 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:01:51 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:01:51 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:01:51 - Predict] Found a GPU.\n",
      "[16:01:51 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:01:51 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:01:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6297571ae0>\n",
      "[16:01:53 - MdlStrTF] loading weights from /tmp/tmpl8xgco4z/model/variables/variables\n",
      "[16:01:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:01:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:01:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[16:01:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:53 - Feature] Processed ParPgb:0.0-245.0 (median depth 70.0)\n",
      "[16:01:53 - Sampler] Took 0.08s to make features.\n",
      "[16:01:53 - Sampler] Region ParPgb:0.0-245.0 (288 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:01:53 - PWorker] Processed 0 batches\n",
      "[16:01:53 - PWorker] All done, 1 remainder regions.\n",
      "[16:01:53 - Predict] Processing 1 short region(s).\n",
      "[16:01:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f61f87762f0>\n",
      "[16:01:53 - MdlStrTF] loading weights from /tmp/tmpl8xgco4z/model/variables/variables\n",
      "[16:01:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[16:01:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:53 - Feature] Processed ParPgb:0.0-245.0 (median depth 70.0)\n",
      "[16:01:53 - Sampler] Took 0.14s to make features.\n",
      "[16:01:54 - PWorker] Processed 1 batches\n",
      "[16:01:54 - PWorker] All done, 0 remainder regions.\n",
      "[16:01:54 - Predict] Finished processing all regions.\n",
      "[16:01:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:01:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:01:57 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:01:57 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:01:57 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:01:57 - Predict] Found a GPU.\n",
      "[16:01:57 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:01:57 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:01:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3940019ae0>\n",
      "[16:01:59 - MdlStrTF] loading weights from /tmp/tmpkqv3827w/model/variables/variables\n",
      "[16:01:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:01:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:01:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:01:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-201.\n",
      "[16:01:59 - Feature] Processed ParPgb:0.0-201.0 (median depth 73.0)\n",
      "[16:01:59 - Sampler] Took 0.22s to make features.\n",
      "[16:01:59 - Sampler] Region ParPgb:0.0-201.0 (250 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:01:59 - PWorker] Processed 0 batches\n",
      "[16:01:59 - PWorker] All done, 1 remainder regions.\n",
      "[16:01:59 - Predict] Processing 1 short region(s).\n",
      "[16:01:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:01:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f38b01c6170>\n",
      "[16:01:59 - MdlStrTF] loading weights from /tmp/tmpkqv3827w/model/variables/variables\n",
      "[16:01:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-202.\n",
      "[16:01:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:01 - Feature] Processed ParPgb:0.0-201.0 (median depth 73.0)\n",
      "[16:02:01 - Sampler] Took 2.14s to make features.\n",
      "[16:02:02 - PWorker] Processed 1 batches\n",
      "[16:02:02 - PWorker] All done, 0 remainder regions.\n",
      "[16:02:02 - Predict] Finished processing all regions.\n",
      "[16:02:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:02:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:02:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:02:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:02:05 - Predict] Found a GPU.\n",
      "[16:02:05 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:02:05 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:02:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3a990cdae0>\n",
      "[16:02:07 - MdlStrTF] loading weights from /tmp/tmphxg6qm1x/model/variables/variables\n",
      "[16:02:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:02:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:02:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-191.\n",
      "[16:02:07 - Feature] Processed ParPgb:0.0-191.0 (median depth 1.0)\n",
      "[16:02:07 - Sampler] Took 0.03s to make features.\n",
      "[16:02:07 - Sampler] Region ParPgb:0.0-191.0 (194 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:02:07 - PWorker] Processed 0 batches\n",
      "[16:02:07 - PWorker] All done, 1 remainder regions.\n",
      "[16:02:07 - Predict] Processing 1 short region(s).\n",
      "[16:02:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3a08221b10>\n",
      "[16:02:07 - MdlStrTF] loading weights from /tmp/tmphxg6qm1x/model/variables/variables\n",
      "[16:02:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-192.\n",
      "[16:02:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:10 - Feature] Processed ParPgb:0.0-191.0 (median depth 1.0)\n",
      "[16:02:10 - Sampler] Took 2.47s to make features.\n",
      "[16:02:10 - PWorker] Processed 1 batches\n",
      "[16:02:10 - PWorker] All done, 0 remainder regions.\n",
      "[16:02:10 - Predict] Finished processing all regions.\n",
      "[16:02:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:02:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:02:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:02:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:02:14 - Predict] Found a GPU.\n",
      "[16:02:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:02:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:02:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbd440c5ae0>\n",
      "[16:02:15 - MdlStrTF] loading weights from /tmp/tmpjs72b80c/model/variables/variables\n",
      "[16:02:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:02:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:02:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[16:02:15 - Feature] Processed ParPgb:0.0-251.0 (median depth 78.0)\n",
      "[16:02:15 - Sampler] Took 0.08s to make features.\n",
      "[16:02:15 - Sampler] Region ParPgb:0.0-251.0 (318 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:02:15 - PWorker] Processed 0 batches\n",
      "[16:02:15 - PWorker] All done, 1 remainder regions.\n",
      "[16:02:15 - Predict] Processing 1 short region(s).\n",
      "[16:02:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbcb02921a0>\n",
      "[16:02:15 - MdlStrTF] loading weights from /tmp/tmpjs72b80c/model/variables/variables\n",
      "[16:02:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[16:02:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:16 - Feature] Processed ParPgb:0.0-251.0 (median depth 78.0)\n",
      "[16:02:16 - Sampler] Took 0.04s to make features.\n",
      "[16:02:16 - PWorker] Processed 1 batches\n",
      "[16:02:16 - PWorker] All done, 0 remainder regions.\n",
      "[16:02:16 - Predict] Finished processing all regions.\n",
      "[16:02:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:02:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:02:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:02:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:02:20 - Predict] Found a GPU.\n",
      "[16:02:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:02:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:02:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa4e91ddae0>\n",
      "[16:02:21 - MdlStrTF] loading weights from /tmp/tmpn110dccl/model/variables/variables\n",
      "[16:02:21 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:02:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:02:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:21 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[16:02:21 - Feature] Processed ParPgb:0.0-242.0 (median depth 134.0)\n",
      "[16:02:21 - Sampler] Took 0.06s to make features.\n",
      "[16:02:21 - Sampler] Region ParPgb:0.0-242.0 (317 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:02:21 - PWorker] Processed 0 batches\n",
      "[16:02:21 - PWorker] All done, 1 remainder regions.\n",
      "[16:02:21 - Predict] Processing 1 short region(s).\n",
      "[16:02:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa458366f20>\n",
      "[16:02:21 - MdlStrTF] loading weights from /tmp/tmpn110dccl/model/variables/variables\n",
      "[16:02:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[16:02:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:21 - Feature] Processed ParPgb:0.0-242.0 (median depth 134.0)\n",
      "[16:02:21 - Sampler] Took 0.05s to make features.\n",
      "[16:02:22 - PWorker] Processed 1 batches\n",
      "[16:02:22 - PWorker] All done, 0 remainder regions.\n",
      "[16:02:22 - Predict] Finished processing all regions.\n",
      "[16:02:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:02:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:02:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:02:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:02:25 - Predict] Found a GPU.\n",
      "[16:02:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:02:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:02:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efd68c35ae0>\n",
      "[16:02:27 - MdlStrTF] loading weights from /tmp/tmphdtt1vmq/model/variables/variables\n",
      "[16:02:27 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:02:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:02:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:27 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[16:02:28 - Feature] Processed ParPgb:0.0-249.0 (median depth 52.0)\n",
      "[16:02:28 - Sampler] Took 1.71s to make features.\n",
      "[16:02:28 - Sampler] Region ParPgb:0.0-249.0 (281 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:02:28 - PWorker] Processed 0 batches\n",
      "[16:02:28 - PWorker] All done, 1 remainder regions.\n",
      "[16:02:28 - Predict] Processing 1 short region(s).\n",
      "[16:02:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efcc9d6ee90>\n",
      "[16:02:29 - MdlStrTF] loading weights from /tmp/tmphdtt1vmq/model/variables/variables\n",
      "[16:02:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[16:02:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:29 - Feature] Processed ParPgb:0.0-249.0 (median depth 52.0)\n",
      "[16:02:29 - Sampler] Took 0.11s to make features.\n",
      "[16:02:30 - PWorker] Processed 1 batches\n",
      "[16:02:30 - PWorker] All done, 0 remainder regions.\n",
      "[16:02:30 - Predict] Finished processing all regions.\n",
      "[16:02:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:33 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:02:33 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:02:33 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:02:33 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:02:33 - Predict] Found a GPU.\n",
      "[16:02:33 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:02:33 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:02:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9303b7dae0>\n",
      "[16:02:34 - MdlStrTF] loading weights from /tmp/tmp813shxlc/model/variables/variables\n",
      "[16:02:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:02:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:02:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-257.\n",
      "[16:02:34 - Feature] Processed ParPgb:0.0-257.0 (median depth 77.0)\n",
      "[16:02:34 - Sampler] Took 0.11s to make features.\n",
      "[16:02:34 - Sampler] Region ParPgb:0.0-257.0 (312 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:02:34 - PWorker] Processed 0 batches\n",
      "[16:02:34 - PWorker] All done, 1 remainder regions.\n",
      "[16:02:34 - Predict] Processing 1 short region(s).\n",
      "[16:02:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9272d26f20>\n",
      "[16:02:35 - MdlStrTF] loading weights from /tmp/tmp813shxlc/model/variables/variables\n",
      "[16:02:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-258.\n",
      "[16:02:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:37 - Feature] Processed ParPgb:0.0-257.0 (median depth 77.0)\n",
      "[16:02:37 - Sampler] Took 2.35s to make features.\n",
      "[16:02:38 - PWorker] Processed 1 batches\n",
      "[16:02:38 - PWorker] All done, 0 remainder regions.\n",
      "[16:02:38 - Predict] Finished processing all regions.\n",
      "[16:02:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:02:41 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:02:41 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:02:41 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:02:41 - Predict] Found a GPU.\n",
      "[16:02:41 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:02:41 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:02:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa935989a80>\n",
      "[16:02:43 - MdlStrTF] loading weights from /tmp/tmpq7zme0i7/model/variables/variables\n",
      "[16:02:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:02:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:02:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-267.\n",
      "[16:02:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:43 - Feature] Processed ParPgb:0.0-267.0 (median depth 163.0)\n",
      "[16:02:43 - Sampler] Took 0.12s to make features.\n",
      "[16:02:43 - Sampler] Region ParPgb:0.0-267.0 (390 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:02:43 - PWorker] Processed 0 batches\n",
      "[16:02:43 - PWorker] All done, 1 remainder regions.\n",
      "[16:02:43 - Predict] Processing 1 short region(s).\n",
      "[16:02:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa8a026e320>\n",
      "[16:02:43 - MdlStrTF] loading weights from /tmp/tmpq7zme0i7/model/variables/variables\n",
      "[16:02:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-268.\n",
      "[16:02:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:43 - Feature] Processed ParPgb:0.0-267.0 (median depth 163.0)\n",
      "[16:02:43 - Sampler] Took 0.07s to make features.\n",
      "[16:02:44 - PWorker] Processed 1 batches\n",
      "[16:02:44 - PWorker] All done, 0 remainder regions.\n",
      "[16:02:44 - Predict] Finished processing all regions.\n",
      "[16:02:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:02:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:02:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:02:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:02:47 - Predict] Found a GPU.\n",
      "[16:02:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:02:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:02:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1e1adcdae0>\n",
      "[16:02:49 - MdlStrTF] loading weights from /tmp/tmp0iwts_wx/model/variables/variables\n",
      "[16:02:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:02:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:02:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-202.\n",
      "[16:02:49 - Feature] Processed ParPgb:0.0-202.0 (median depth 70.0)\n",
      "[16:02:49 - Sampler] Took 0.05s to make features.\n",
      "[16:02:49 - Sampler] Region ParPgb:0.0-202.0 (233 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:02:49 - PWorker] Processed 0 batches\n",
      "[16:02:49 - PWorker] All done, 1 remainder regions.\n",
      "[16:02:49 - Predict] Processing 1 short region(s).\n",
      "[16:02:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1d89fce1a0>\n",
      "[16:02:49 - MdlStrTF] loading weights from /tmp/tmp0iwts_wx/model/variables/variables\n",
      "[16:02:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-203.\n",
      "[16:02:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:49 - Feature] Processed ParPgb:0.0-202.0 (median depth 70.0)\n",
      "[16:02:49 - Sampler] Took 0.04s to make features.\n",
      "[16:02:50 - PWorker] Processed 1 batches\n",
      "[16:02:50 - PWorker] All done, 0 remainder regions.\n",
      "[16:02:50 - Predict] Finished processing all regions.\n",
      "[16:02:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:02:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:02:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:02:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:02:53 - Predict] Found a GPU.\n",
      "[16:02:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:02:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:02:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f59fbccdae0>\n",
      "[16:02:54 - MdlStrTF] loading weights from /tmp/tmpqj0n5lna/model/variables/variables\n",
      "[16:02:54 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:02:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:02:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[16:02:55 - Feature] Processed ParPgb:0.0-253.0 (median depth 143.0)\n",
      "[16:02:55 - Sampler] Took 0.12s to make features.\n",
      "[16:02:55 - Sampler] Region ParPgb:0.0-253.0 (328 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:02:55 - PWorker] Processed 0 batches\n",
      "[16:02:55 - PWorker] All done, 1 remainder regions.\n",
      "[16:02:55 - Predict] Processing 1 short region(s).\n",
      "[16:02:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:02:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f595ce69b10>\n",
      "[16:02:55 - MdlStrTF] loading weights from /tmp/tmpqj0n5lna/model/variables/variables\n",
      "[16:02:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[16:02:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:02:55 - Feature] Processed ParPgb:0.0-253.0 (median depth 143.0)\n",
      "[16:02:55 - Sampler] Took 0.04s to make features.\n",
      "[16:02:56 - PWorker] Processed 1 batches\n",
      "[16:02:56 - PWorker] All done, 0 remainder regions.\n",
      "[16:02:56 - Predict] Finished processing all regions.\n",
      "[16:02:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:02:59 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:02:59 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:02:59 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:02:59 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:02:59 - Predict] Found a GPU.\n",
      "[16:02:59 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:02:59 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:02:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0e90735ae0>\n",
      "[16:03:00 - MdlStrTF] loading weights from /tmp/tmpow4u1c3a/model/variables/variables\n",
      "[16:03:00 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:03:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:03:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:00 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-265.\n",
      "[16:03:00 - Feature] Processed ParPgb:0.0-265.0 (median depth 74.0)\n",
      "[16:03:00 - Sampler] Took 0.02s to make features.\n",
      "[16:03:00 - Sampler] Region ParPgb:0.0-265.0 (316 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:03:00 - PWorker] Processed 0 batches\n",
      "[16:03:00 - PWorker] All done, 1 remainder regions.\n",
      "[16:03:00 - Predict] Processing 1 short region(s).\n",
      "[16:03:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0e000c1ab0>\n",
      "[16:03:01 - MdlStrTF] loading weights from /tmp/tmpow4u1c3a/model/variables/variables\n",
      "[16:03:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-266.\n",
      "[16:03:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:01 - Feature] Processed ParPgb:0.0-265.0 (median depth 74.0)\n",
      "[16:03:01 - Sampler] Took 0.04s to make features.\n",
      "[16:03:01 - PWorker] Processed 1 batches\n",
      "[16:03:01 - PWorker] All done, 0 remainder regions.\n",
      "[16:03:01 - Predict] Finished processing all regions.\n",
      "[16:03:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:03:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:03:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:03:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:03:05 - Predict] Found a GPU.\n",
      "[16:03:05 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:03:05 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:03:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f448a22da80>\n",
      "[16:03:06 - MdlStrTF] loading weights from /tmp/tmp1faydp4w/model/variables/variables\n",
      "[16:03:06 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:03:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:03:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:06 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[16:03:06 - Feature] Processed ParPgb:0.0-250.0 (median depth 135.0)\n",
      "[16:03:06 - Sampler] Took 0.06s to make features.\n",
      "[16:03:06 - Sampler] Region ParPgb:0.0-250.0 (328 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:03:06 - PWorker] Processed 0 batches\n",
      "[16:03:06 - PWorker] All done, 1 remainder regions.\n",
      "[16:03:06 - Predict] Processing 1 short region(s).\n",
      "[16:03:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f43f8339e10>\n",
      "[16:03:07 - MdlStrTF] loading weights from /tmp/tmp1faydp4w/model/variables/variables\n",
      "[16:03:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[16:03:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:07 - Feature] Processed ParPgb:0.0-250.0 (median depth 135.0)\n",
      "[16:03:07 - Sampler] Took 0.05s to make features.\n",
      "[16:03:07 - PWorker] Processed 1 batches\n",
      "[16:03:07 - PWorker] All done, 0 remainder regions.\n",
      "[16:03:07 - Predict] Finished processing all regions.\n",
      "[16:03:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:11 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:03:11 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:03:11 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:03:11 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:03:11 - Predict] Found a GPU.\n",
      "[16:03:11 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:03:11 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:03:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:12 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd529355ae0>\n",
      "[16:03:12 - MdlStrTF] loading weights from /tmp/tmpxfphsg6u/model/variables/variables\n",
      "[16:03:12 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:03:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:03:12 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[16:03:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:14 - Feature] Processed ParPgb:0.0-244.0 (median depth 89.0)\n",
      "[16:03:14 - Sampler] Took 2.21s to make features.\n",
      "[16:03:14 - Sampler] Region ParPgb:0.0-244.0 (290 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:03:14 - PWorker] Processed 0 batches\n",
      "[16:03:14 - PWorker] All done, 1 remainder regions.\n",
      "[16:03:14 - Predict] Processing 1 short region(s).\n",
      "[16:03:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd49858e3b0>\n",
      "[16:03:15 - MdlStrTF] loading weights from /tmp/tmpxfphsg6u/model/variables/variables\n",
      "[16:03:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[16:03:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:15 - Feature] Processed ParPgb:0.0-244.0 (median depth 89.0)\n",
      "[16:03:15 - Sampler] Took 0.08s to make features.\n",
      "[16:03:15 - PWorker] Processed 1 batches\n",
      "[16:03:15 - PWorker] All done, 0 remainder regions.\n",
      "[16:03:15 - Predict] Finished processing all regions.\n",
      "[16:03:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:03:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:03:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:03:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:03:19 - Predict] Found a GPU.\n",
      "[16:03:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:03:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:03:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd270b91ae0>\n",
      "[16:03:20 - MdlStrTF] loading weights from /tmp/tmps56f6ukb/model/variables/variables\n",
      "[16:03:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:03:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:03:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:22 - Sampler] Took 1.77s to make features.\n",
      "[16:03:22 - PWorker] Processed 0 batches\n",
      "[16:03:22 - PWorker] All done, 0 remainder regions.\n",
      "[16:03:22 - Predict] Finished processing all regions.\n",
      "[16:03:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:24 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:03:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:03:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:03:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:03:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:03:25 - Predict] Found a GPU.\n",
      "[16:03:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:03:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:03:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f803550dae0>\n",
      "[16:03:27 - MdlStrTF] loading weights from /tmp/tmp5_zdolvs/model/variables/variables\n",
      "[16:03:27 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:03:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:03:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:27 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-234.\n",
      "[16:03:27 - Feature] Processed ParPgb:0.0-234.0 (median depth 36.0)\n",
      "[16:03:27 - Sampler] Took 0.09s to make features.\n",
      "[16:03:27 - Sampler] Region ParPgb:0.0-234.0 (254 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:03:27 - PWorker] Processed 0 batches\n",
      "[16:03:27 - PWorker] All done, 1 remainder regions.\n",
      "[16:03:27 - Predict] Processing 1 short region(s).\n",
      "[16:03:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7fa022dea0>\n",
      "[16:03:27 - MdlStrTF] loading weights from /tmp/tmp5_zdolvs/model/variables/variables\n",
      "[16:03:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-235.\n",
      "[16:03:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:27 - Feature] Processed ParPgb:0.0-234.0 (median depth 36.0)\n",
      "[16:03:27 - Sampler] Took 0.11s to make features.\n",
      "[16:03:28 - PWorker] Processed 1 batches\n",
      "[16:03:28 - PWorker] All done, 0 remainder regions.\n",
      "[16:03:28 - Predict] Finished processing all regions.\n",
      "[16:03:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:03:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:03:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:03:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:03:31 - Predict] Found a GPU.\n",
      "[16:03:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:03:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:03:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc35f181ae0>\n",
      "[16:03:33 - MdlStrTF] loading weights from /tmp/tmptr62mj6s/model/variables/variables\n",
      "[16:03:33 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:03:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:03:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:33 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[16:03:33 - Feature] Processed ParPgb:0.0-244.0 (median depth 41.0)\n",
      "[16:03:33 - Sampler] Took 0.13s to make features.\n",
      "[16:03:33 - Sampler] Region ParPgb:0.0-244.0 (273 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:03:33 - PWorker] Processed 0 batches\n",
      "[16:03:33 - PWorker] All done, 1 remainder regions.\n",
      "[16:03:33 - Predict] Processing 1 short region(s).\n",
      "[16:03:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc2cd7c9480>\n",
      "[16:03:33 - MdlStrTF] loading weights from /tmp/tmptr62mj6s/model/variables/variables\n",
      "[16:03:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[16:03:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:33 - Feature] Processed ParPgb:0.0-244.0 (median depth 41.0)\n",
      "[16:03:33 - Sampler] Took 0.10s to make features.\n",
      "[16:03:34 - PWorker] Processed 1 batches\n",
      "[16:03:34 - PWorker] All done, 0 remainder regions.\n",
      "[16:03:34 - Predict] Finished processing all regions.\n",
      "[16:03:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:03:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:03:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:03:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:03:37 - Predict] Found a GPU.\n",
      "[16:03:37 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:03:37 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:03:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb793115a80>\n",
      "[16:03:39 - MdlStrTF] loading weights from /tmp/tmphc81j4x7/model/variables/variables\n",
      "[16:03:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:03:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:03:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[16:03:39 - Feature] Processed ParPgb:0.0-244.0 (median depth 86.0)\n",
      "[16:03:39 - Sampler] Took 0.03s to make features.\n",
      "[16:03:39 - Sampler] Region ParPgb:0.0-244.0 (302 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:03:39 - PWorker] Processed 0 batches\n",
      "[16:03:39 - PWorker] All done, 1 remainder regions.\n",
      "[16:03:39 - Predict] Processing 1 short region(s).\n",
      "[16:03:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb702329420>\n",
      "[16:03:39 - MdlStrTF] loading weights from /tmp/tmphc81j4x7/model/variables/variables\n",
      "[16:03:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[16:03:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:39 - Feature] Processed ParPgb:0.0-244.0 (median depth 86.0)\n",
      "[16:03:39 - Sampler] Took 0.06s to make features.\n",
      "[16:03:40 - PWorker] Processed 1 batches\n",
      "[16:03:40 - PWorker] All done, 0 remainder regions.\n",
      "[16:03:40 - Predict] Finished processing all regions.\n",
      "[16:03:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:03:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:03:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:03:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:03:43 - Predict] Found a GPU.\n",
      "[16:03:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:03:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:03:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa2e3e8dae0>\n",
      "[16:03:44 - MdlStrTF] loading weights from /tmp/tmplvbw5xn7/model/variables/variables\n",
      "[16:03:45 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:03:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:03:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-231.\n",
      "[16:03:45 - Feature] Processed ParPgb:0.0-231.0 (median depth 135.0)\n",
      "[16:03:45 - Sampler] Took 0.10s to make features.\n",
      "[16:03:45 - Sampler] Region ParPgb:0.0-231.0 (320 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:03:45 - PWorker] Processed 0 batches\n",
      "[16:03:45 - PWorker] All done, 1 remainder regions.\n",
      "[16:03:45 - Predict] Processing 1 short region(s).\n",
      "[16:03:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa2bc201480>\n",
      "[16:03:45 - MdlStrTF] loading weights from /tmp/tmplvbw5xn7/model/variables/variables\n",
      "[16:03:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-232.\n",
      "[16:03:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:48 - Feature] Processed ParPgb:0.0-231.0 (median depth 135.0)\n",
      "[16:03:48 - Sampler] Took 2.54s to make features.\n",
      "[16:03:48 - PWorker] Processed 1 batches\n",
      "[16:03:48 - PWorker] All done, 0 remainder regions.\n",
      "[16:03:48 - Predict] Finished processing all regions.\n",
      "[16:03:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:51 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:03:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:03:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:03:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:03:52 - Predict] Found a GPU.\n",
      "[16:03:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:03:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:03:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f27d278dae0>\n",
      "[16:03:53 - MdlStrTF] loading weights from /tmp/tmpyzpp26z1/model/variables/variables\n",
      "[16:03:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:03:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:03:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-207.\n",
      "[16:03:53 - Feature] Processed ParPgb:0.0-207.0 (median depth 70.0)\n",
      "[16:03:53 - Sampler] Took 0.04s to make features.\n",
      "[16:03:53 - Sampler] Region ParPgb:0.0-207.0 (240 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:03:53 - PWorker] Processed 0 batches\n",
      "[16:03:53 - PWorker] All done, 1 remainder regions.\n",
      "[16:03:53 - Predict] Processing 1 short region(s).\n",
      "[16:03:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f27418c1480>\n",
      "[16:03:53 - MdlStrTF] loading weights from /tmp/tmpyzpp26z1/model/variables/variables\n",
      "[16:03:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-208.\n",
      "[16:03:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:03:53 - Feature] Processed ParPgb:0.0-207.0 (median depth 70.0)\n",
      "[16:03:53 - Sampler] Took 0.05s to make features.\n",
      "[16:03:54 - PWorker] Processed 1 batches\n",
      "[16:03:54 - PWorker] All done, 0 remainder regions.\n",
      "[16:03:54 - Predict] Finished processing all regions.\n",
      "[16:03:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:03:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:03:57 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:03:57 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:03:57 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:03:57 - Predict] Found a GPU.\n",
      "[16:03:57 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:03:57 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:03:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:03:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5572295ae0>\n",
      "[16:03:59 - MdlStrTF] loading weights from /tmp/tmpkesl0df9/model/variables/variables\n",
      "[16:03:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:03:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:03:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-264.\n",
      "[16:04:01 - Feature] Processed ParPgb:0.0-264.0 (median depth 113.5)\n",
      "[16:04:01 - Sampler] Took 2.66s to make features.\n",
      "[16:04:01 - Sampler] Region ParPgb:0.0-264.0 (318 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:04:01 - PWorker] Processed 0 batches\n",
      "[16:04:01 - PWorker] All done, 1 remainder regions.\n",
      "[16:04:01 - Predict] Processing 1 short region(s).\n",
      "[16:04:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f54e142e170>\n",
      "[16:04:02 - MdlStrTF] loading weights from /tmp/tmpkesl0df9/model/variables/variables\n",
      "[16:04:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-265.\n",
      "[16:04:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:04 - Feature] Processed ParPgb:0.0-264.0 (median depth 113.5)\n",
      "[16:04:04 - Sampler] Took 2.12s to make features.\n",
      "[16:04:05 - PWorker] Processed 1 batches\n",
      "[16:04:05 - PWorker] All done, 0 remainder regions.\n",
      "[16:04:05 - Predict] Finished processing all regions.\n",
      "[16:04:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:04:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:04:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:04:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:04:08 - Predict] Found a GPU.\n",
      "[16:04:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:04:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:04:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f37cf3edae0>\n",
      "[16:04:09 - MdlStrTF] loading weights from /tmp/tmphvlhqgdu/model/variables/variables\n",
      "[16:04:09 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:04:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:04:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:09 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-215.\n",
      "[16:04:09 - Feature] Processed ParPgb:0.0-215.0 (median depth 64.0)\n",
      "[16:04:09 - Sampler] Took 0.03s to make features.\n",
      "[16:04:09 - Sampler] Region ParPgb:0.0-215.0 (248 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:04:09 - PWorker] Processed 0 batches\n",
      "[16:04:09 - PWorker] All done, 1 remainder regions.\n",
      "[16:04:09 - Predict] Processing 1 short region(s).\n",
      "[16:04:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f373c21dea0>\n",
      "[16:04:10 - MdlStrTF] loading weights from /tmp/tmphvlhqgdu/model/variables/variables\n",
      "[16:04:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-216.\n",
      "[16:04:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:10 - Feature] Processed ParPgb:0.0-215.0 (median depth 64.0)\n",
      "[16:04:10 - Sampler] Took 0.07s to make features.\n",
      "[16:04:10 - PWorker] Processed 1 batches\n",
      "[16:04:10 - PWorker] All done, 0 remainder regions.\n",
      "[16:04:10 - Predict] Finished processing all regions.\n",
      "[16:04:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:04:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:04:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:04:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:04:14 - Predict] Found a GPU.\n",
      "[16:04:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:04:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:04:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1a1b765ae0>\n",
      "[16:04:15 - MdlStrTF] loading weights from /tmp/tmpz9cg685d/model/variables/variables\n",
      "[16:04:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:04:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:04:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:04:15 - Feature] Processed ParPgb:0.0-240.0 (median depth 119.0)\n",
      "[16:04:15 - Sampler] Took 0.04s to make features.\n",
      "[16:04:15 - Sampler] Region ParPgb:0.0-240.0 (303 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:04:15 - PWorker] Processed 0 batches\n",
      "[16:04:15 - PWorker] All done, 1 remainder regions.\n",
      "[16:04:15 - Predict] Processing 1 short region(s).\n",
      "[16:04:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f198a8c9480>\n",
      "[16:04:16 - MdlStrTF] loading weights from /tmp/tmpz9cg685d/model/variables/variables\n",
      "[16:04:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:04:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:16 - Feature] Processed ParPgb:0.0-240.0 (median depth 119.0)\n",
      "[16:04:16 - Sampler] Took 0.12s to make features.\n",
      "[16:04:16 - PWorker] Processed 1 batches\n",
      "[16:04:16 - PWorker] All done, 0 remainder regions.\n",
      "[16:04:16 - Predict] Finished processing all regions.\n",
      "[16:04:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:04:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:04:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:04:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:04:20 - Predict] Found a GPU.\n",
      "[16:04:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:04:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:04:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc62bbe1a80>\n",
      "[16:04:21 - MdlStrTF] loading weights from /tmp/tmpq_vy6v6e/model/variables/variables\n",
      "[16:04:21 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:04:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:04:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:21 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[16:04:21 - Feature] Processed ParPgb:0.0-242.0 (median depth 89.0)\n",
      "[16:04:21 - Sampler] Took 0.12s to make features.\n",
      "[16:04:21 - Sampler] Region ParPgb:0.0-242.0 (288 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:04:21 - PWorker] Processed 0 batches\n",
      "[16:04:21 - PWorker] All done, 1 remainder regions.\n",
      "[16:04:21 - Predict] Processing 1 short region(s).\n",
      "[16:04:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc59ad1e140>\n",
      "[16:04:22 - MdlStrTF] loading weights from /tmp/tmpq_vy6v6e/model/variables/variables\n",
      "[16:04:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[16:04:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:22 - Feature] Processed ParPgb:0.0-242.0 (median depth 89.0)\n",
      "[16:04:22 - Sampler] Took 0.03s to make features.\n",
      "[16:04:22 - PWorker] Processed 1 batches\n",
      "[16:04:22 - PWorker] All done, 0 remainder regions.\n",
      "[16:04:22 - Predict] Finished processing all regions.\n",
      "[16:04:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:26 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:04:26 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:04:26 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:04:26 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:04:26 - Predict] Found a GPU.\n",
      "[16:04:26 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:04:26 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:04:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f762adbdae0>\n",
      "[16:04:27 - MdlStrTF] loading weights from /tmp/tmp6h_vckbi/model/variables/variables\n",
      "[16:04:27 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:04:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:04:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:27 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[16:04:27 - Feature] Processed ParPgb:0.0-245.0 (median depth 115.0)\n",
      "[16:04:27 - Sampler] Took 0.20s to make features.\n",
      "[16:04:27 - Sampler] Region ParPgb:0.0-245.0 (341 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:04:27 - PWorker] Processed 0 batches\n",
      "[16:04:27 - PWorker] All done, 1 remainder regions.\n",
      "[16:04:27 - Predict] Processing 1 short region(s).\n",
      "[16:04:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7599fca1a0>\n",
      "[16:04:28 - MdlStrTF] loading weights from /tmp/tmp6h_vckbi/model/variables/variables\n",
      "[16:04:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[16:04:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:28 - Feature] Processed ParPgb:0.0-245.0 (median depth 115.0)\n",
      "[16:04:28 - Sampler] Took 0.06s to make features.\n",
      "[16:04:28 - PWorker] Processed 1 batches\n",
      "[16:04:28 - PWorker] All done, 0 remainder regions.\n",
      "[16:04:28 - Predict] Finished processing all regions.\n",
      "[16:04:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:32 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:04:32 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:04:32 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:04:32 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:04:32 - Predict] Found a GPU.\n",
      "[16:04:32 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:04:32 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:04:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7feb511d1a80>\n",
      "[16:04:33 - MdlStrTF] loading weights from /tmp/tmp9_h1v3q1/model/variables/variables\n",
      "[16:04:33 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:04:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:04:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:33 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-213.\n",
      "[16:04:33 - Feature] Processed ParPgb:0.0-213.0 (median depth 91.0)\n",
      "[16:04:33 - Sampler] Took 0.04s to make features.\n",
      "[16:04:33 - Sampler] Region ParPgb:0.0-213.0 (283 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:04:33 - PWorker] Processed 0 batches\n",
      "[16:04:33 - PWorker] All done, 1 remainder regions.\n",
      "[16:04:33 - Predict] Processing 1 short region(s).\n",
      "[16:04:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7feac0362fb0>\n",
      "[16:04:33 - MdlStrTF] loading weights from /tmp/tmp9_h1v3q1/model/variables/variables\n",
      "[16:04:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-214.\n",
      "[16:04:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:34 - Feature] Processed ParPgb:0.0-213.0 (median depth 91.0)\n",
      "[16:04:34 - Sampler] Took 0.04s to make features.\n",
      "[16:04:34 - PWorker] Processed 1 batches\n",
      "[16:04:34 - PWorker] All done, 0 remainder regions.\n",
      "[16:04:34 - Predict] Finished processing all regions.\n",
      "[16:04:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:04:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:04:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:04:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:04:38 - Predict] Found a GPU.\n",
      "[16:04:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:04:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:04:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb8daab1ae0>\n",
      "[16:04:39 - MdlStrTF] loading weights from /tmp/tmpjpoha63d/model/variables/variables\n",
      "[16:04:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:04:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:04:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[16:04:41 - Feature] Processed ParPgb:0.0-247.0 (median depth 78.0)\n",
      "[16:04:41 - Sampler] Took 1.92s to make features.\n",
      "[16:04:41 - Sampler] Region ParPgb:0.0-247.0 (296 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:04:41 - PWorker] Processed 0 batches\n",
      "[16:04:41 - PWorker] All done, 1 remainder regions.\n",
      "[16:04:41 - Predict] Processing 1 short region(s).\n",
      "[16:04:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb84821af20>\n",
      "[16:04:41 - MdlStrTF] loading weights from /tmp/tmpjpoha63d/model/variables/variables\n",
      "[16:04:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[16:04:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:41 - Feature] Processed ParPgb:0.0-247.0 (median depth 78.0)\n",
      "[16:04:41 - Sampler] Took 0.06s to make features.\n",
      "[16:04:42 - PWorker] Processed 1 batches\n",
      "[16:04:42 - PWorker] All done, 0 remainder regions.\n",
      "[16:04:42 - Predict] Finished processing all regions.\n",
      "[16:04:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:45 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:04:45 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:04:45 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:04:45 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:04:45 - Predict] Found a GPU.\n",
      "[16:04:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:04:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:04:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f04a908da80>\n",
      "[16:04:47 - MdlStrTF] loading weights from /tmp/tmp7tjhnd_e/model/variables/variables\n",
      "[16:04:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:04:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:04:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:04:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:47 - Feature] Processed ParPgb:0.0-240.0 (median depth 106.0)\n",
      "[16:04:47 - Sampler] Took 0.16s to make features.\n",
      "[16:04:47 - Sampler] Region ParPgb:0.0-240.0 (305 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:04:47 - PWorker] Processed 0 batches\n",
      "[16:04:47 - PWorker] All done, 1 remainder regions.\n",
      "[16:04:47 - Predict] Processing 1 short region(s).\n",
      "[16:04:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0418226290>\n",
      "[16:04:47 - MdlStrTF] loading weights from /tmp/tmp7tjhnd_e/model/variables/variables\n",
      "[16:04:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:04:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:47 - Feature] Processed ParPgb:0.0-240.0 (median depth 106.0)\n",
      "[16:04:47 - Sampler] Took 0.05s to make features.\n",
      "[16:04:48 - PWorker] Processed 1 batches\n",
      "[16:04:48 - PWorker] All done, 0 remainder regions.\n",
      "[16:04:48 - Predict] Finished processing all regions.\n",
      "[16:04:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:51 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:04:51 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:04:51 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:04:51 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:04:51 - Predict] Found a GPU.\n",
      "[16:04:51 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:04:51 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:04:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f43e5eb1ae0>\n",
      "[16:04:53 - MdlStrTF] loading weights from /tmp/tmpf5dimk_q/model/variables/variables\n",
      "[16:04:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:04:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:04:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[16:04:53 - Feature] Processed ParPgb:0.0-255.0 (median depth 132.0)\n",
      "[16:04:53 - Sampler] Took 0.04s to make features.\n",
      "[16:04:53 - Sampler] Region ParPgb:0.0-255.0 (348 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:04:53 - PWorker] Processed 0 batches\n",
      "[16:04:53 - PWorker] All done, 1 remainder regions.\n",
      "[16:04:53 - Predict] Processing 1 short region(s).\n",
      "[16:04:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4349011480>\n",
      "[16:04:53 - MdlStrTF] loading weights from /tmp/tmpf5dimk_q/model/variables/variables\n",
      "[16:04:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[16:04:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:53 - Feature] Processed ParPgb:0.0-255.0 (median depth 132.0)\n",
      "[16:04:53 - Sampler] Took 0.05s to make features.\n",
      "[16:04:54 - PWorker] Processed 1 batches\n",
      "[16:04:54 - PWorker] All done, 0 remainder regions.\n",
      "[16:04:54 - Predict] Finished processing all regions.\n",
      "[16:04:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:04:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:04:57 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:04:57 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:04:57 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:04:57 - Predict] Found a GPU.\n",
      "[16:04:57 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:04:57 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:04:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff45dbddae0>\n",
      "[16:04:58 - MdlStrTF] loading weights from /tmp/tmpdi2k8uti/model/variables/variables\n",
      "[16:04:58 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:04:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:04:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:58 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:04:58 - Feature] Processed ParPgb:0.0-240.0 (median depth 101.0)\n",
      "[16:04:59 - Sampler] Took 0.05s to make features.\n",
      "[16:04:59 - Sampler] Region ParPgb:0.0-240.0 (330 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:04:59 - PWorker] Processed 0 batches\n",
      "[16:04:59 - PWorker] All done, 1 remainder regions.\n",
      "[16:04:59 - Predict] Processing 1 short region(s).\n",
      "[16:04:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:04:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff3cc53a1a0>\n",
      "[16:04:59 - MdlStrTF] loading weights from /tmp/tmpdi2k8uti/model/variables/variables\n",
      "[16:04:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:04:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:04:59 - Feature] Processed ParPgb:0.0-240.0 (median depth 101.0)\n",
      "[16:04:59 - Sampler] Took 0.06s to make features.\n",
      "[16:05:00 - PWorker] Processed 1 batches\n",
      "[16:05:00 - PWorker] All done, 0 remainder regions.\n",
      "[16:05:00 - Predict] Finished processing all regions.\n",
      "[16:05:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:05:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:05:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:05:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:05:03 - Predict] Found a GPU.\n",
      "[16:05:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:05:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:05:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe68b211ae0>\n",
      "[16:05:04 - MdlStrTF] loading weights from /tmp/tmpiyv1mn3n/model/variables/variables\n",
      "[16:05:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:05:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:05:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-268.\n",
      "[16:05:04 - Feature] Processed ParPgb:0.0-268.0 (median depth 97.0)\n",
      "[16:05:04 - Sampler] Took 0.04s to make features.\n",
      "[16:05:04 - Sampler] Region ParPgb:0.0-268.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:05:04 - PWorker] Processed 0 batches\n",
      "[16:05:04 - PWorker] All done, 1 remainder regions.\n",
      "[16:05:04 - Predict] Processing 1 short region(s).\n",
      "[16:05:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe5fa351480>\n",
      "[16:05:05 - MdlStrTF] loading weights from /tmp/tmpiyv1mn3n/model/variables/variables\n",
      "[16:05:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-269.\n",
      "[16:05:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:06 - Feature] Processed ParPgb:0.0-268.0 (median depth 97.0)\n",
      "[16:05:06 - Sampler] Took 1.23s to make features.\n",
      "[16:05:07 - PWorker] Processed 1 batches\n",
      "[16:05:07 - PWorker] All done, 0 remainder regions.\n",
      "[16:05:07 - Predict] Finished processing all regions.\n",
      "[16:05:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:10 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:05:10 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:05:10 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:05:10 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:05:10 - Predict] Found a GPU.\n",
      "[16:05:10 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:05:10 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:05:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff6ecc65ae0>\n",
      "[16:05:11 - MdlStrTF] loading weights from /tmp/tmpcycspsgn/model/variables/variables\n",
      "[16:05:11 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:05:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:05:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:05:11 - Feature] Processed ParPgb:0.0-240.0 (median depth 107.0)\n",
      "[16:05:11 - Sampler] Took 0.05s to make features.\n",
      "[16:05:11 - Sampler] Region ParPgb:0.0-240.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:05:11 - PWorker] Processed 0 batches\n",
      "[16:05:11 - PWorker] All done, 1 remainder regions.\n",
      "[16:05:11 - Predict] Processing 1 short region(s).\n",
      "[16:05:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:12 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff64dc75480>\n",
      "[16:05:12 - MdlStrTF] loading weights from /tmp/tmpcycspsgn/model/variables/variables\n",
      "[16:05:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:05:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:12 - Feature] Processed ParPgb:0.0-240.0 (median depth 107.0)\n",
      "[16:05:12 - Sampler] Took 0.05s to make features.\n",
      "[16:05:12 - PWorker] Processed 1 batches\n",
      "[16:05:12 - PWorker] All done, 0 remainder regions.\n",
      "[16:05:12 - Predict] Finished processing all regions.\n",
      "[16:05:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:16 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:05:16 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:05:16 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:05:16 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:05:16 - Predict] Found a GPU.\n",
      "[16:05:16 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:05:16 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:05:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2a85d01ae0>\n",
      "[16:05:17 - MdlStrTF] loading weights from /tmp/tmpyvyb3vis/model/variables/variables\n",
      "[16:05:17 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:05:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:05:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-204.\n",
      "[16:05:17 - Feature] Processed ParPgb:0.0-204.0 (median depth 152.0)\n",
      "[16:05:17 - Sampler] Took 0.07s to make features.\n",
      "[16:05:17 - Sampler] Region ParPgb:0.0-204.0 (274 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:05:17 - PWorker] Processed 0 batches\n",
      "[16:05:17 - PWorker] All done, 1 remainder regions.\n",
      "[16:05:17 - Predict] Processing 1 short region(s).\n",
      "[16:05:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f29f0d75480>\n",
      "[16:05:18 - MdlStrTF] loading weights from /tmp/tmpyvyb3vis/model/variables/variables\n",
      "[16:05:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-205.\n",
      "[16:05:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:18 - Feature] Processed ParPgb:0.0-204.0 (median depth 152.0)\n",
      "[16:05:18 - Sampler] Took 0.17s to make features.\n",
      "[16:05:18 - PWorker] Processed 1 batches\n",
      "[16:05:18 - PWorker] All done, 0 remainder regions.\n",
      "[16:05:18 - Predict] Finished processing all regions.\n",
      "[16:05:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:05:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:05:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:05:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:05:22 - Predict] Found a GPU.\n",
      "[16:05:22 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:05:22 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:05:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f965f571ae0>\n",
      "[16:05:23 - MdlStrTF] loading weights from /tmp/tmptwgwi8re/model/variables/variables\n",
      "[16:05:23 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:05:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:05:23 - Sampler] Took 0.01s to make features.\n",
      "[16:05:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:23 - PWorker] Processed 0 batches\n",
      "[16:05:23 - PWorker] All done, 0 remainder regions.\n",
      "[16:05:23 - Predict] Finished processing all regions.\n",
      "[16:05:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:25 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:05:26 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:05:26 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:05:26 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:05:26 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:05:27 - Predict] Found a GPU.\n",
      "[16:05:27 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:05:27 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:05:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f640fed5ae0>\n",
      "[16:05:28 - MdlStrTF] loading weights from /tmp/tmp12nzv68f/model/variables/variables\n",
      "[16:05:28 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:05:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:05:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:28 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-207.\n",
      "[16:05:28 - Feature] Processed ParPgb:0.0-207.0 (median depth 100.0)\n",
      "[16:05:28 - Sampler] Took 0.05s to make features.\n",
      "[16:05:28 - Sampler] Region ParPgb:0.0-207.0 (286 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:05:28 - PWorker] Processed 0 batches\n",
      "[16:05:28 - PWorker] All done, 1 remainder regions.\n",
      "[16:05:28 - Predict] Processing 1 short region(s).\n",
      "[16:05:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f63800c5450>\n",
      "[16:05:28 - MdlStrTF] loading weights from /tmp/tmp12nzv68f/model/variables/variables\n",
      "[16:05:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-208.\n",
      "[16:05:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:28 - Feature] Processed ParPgb:0.0-207.0 (median depth 100.0)\n",
      "[16:05:28 - Sampler] Took 0.11s to make features.\n",
      "[16:05:29 - PWorker] Processed 1 batches\n",
      "[16:05:29 - PWorker] All done, 0 remainder regions.\n",
      "[16:05:29 - Predict] Finished processing all regions.\n",
      "[16:05:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:32 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:05:32 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:05:32 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:05:32 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:05:32 - Predict] Found a GPU.\n",
      "[16:05:32 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:05:32 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:05:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fafa4599ae0>\n",
      "[16:05:34 - MdlStrTF] loading weights from /tmp/tmp8hdctwfq/model/variables/variables\n",
      "[16:05:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:05:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:05:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[16:05:34 - Feature] Processed ParPgb:0.0-253.0 (median depth 67.0)\n",
      "[16:05:34 - Sampler] Took 0.04s to make features.\n",
      "[16:05:34 - Sampler] Region ParPgb:0.0-253.0 (293 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:05:34 - PWorker] Processed 0 batches\n",
      "[16:05:34 - PWorker] All done, 1 remainder regions.\n",
      "[16:05:34 - Predict] Processing 1 short region(s).\n",
      "[16:05:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faee7771ff0>\n",
      "[16:05:34 - MdlStrTF] loading weights from /tmp/tmp8hdctwfq/model/variables/variables\n",
      "[16:05:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[16:05:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:34 - Feature] Processed ParPgb:0.0-253.0 (median depth 67.0)\n",
      "[16:05:34 - Sampler] Took 0.07s to make features.\n",
      "[16:05:35 - PWorker] Processed 1 batches\n",
      "[16:05:35 - PWorker] All done, 0 remainder regions.\n",
      "[16:05:35 - Predict] Finished processing all regions.\n",
      "[16:05:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:05:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:05:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:05:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:05:38 - Predict] Found a GPU.\n",
      "[16:05:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:05:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:05:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff2e3e7dae0>\n",
      "[16:05:40 - MdlStrTF] loading weights from /tmp/tmpd6e76lw6/model/variables/variables\n",
      "[16:05:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:05:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:05:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:42 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[16:05:42 - Feature] Processed ParPgb:0.0-250.0 (median depth 82.0)\n",
      "[16:05:42 - Sampler] Took 1.88s to make features.\n",
      "[16:05:42 - Sampler] Region ParPgb:0.0-250.0 (306 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:05:42 - PWorker] Processed 0 batches\n",
      "[16:05:42 - PWorker] All done, 1 remainder regions.\n",
      "[16:05:42 - Predict] Processing 1 short region(s).\n",
      "[16:05:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff2bc206fb0>\n",
      "[16:05:42 - MdlStrTF] loading weights from /tmp/tmpd6e76lw6/model/variables/variables\n",
      "[16:05:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[16:05:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:42 - Feature] Processed ParPgb:0.0-250.0 (median depth 82.0)\n",
      "[16:05:42 - Sampler] Took 0.09s to make features.\n",
      "[16:05:43 - PWorker] Processed 1 batches\n",
      "[16:05:43 - PWorker] All done, 0 remainder regions.\n",
      "[16:05:43 - Predict] Finished processing all regions.\n",
      "[16:05:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:46 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:05:46 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:05:46 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:05:46 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:05:46 - Predict] Found a GPU.\n",
      "[16:05:46 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:05:46 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:05:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5997329ae0>\n",
      "[16:05:47 - MdlStrTF] loading weights from /tmp/tmp_0em_3sh/model/variables/variables\n",
      "[16:05:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:05:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:05:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-268.\n",
      "[16:05:48 - Feature] Processed ParPgb:0.0-268.0 (median depth 125.0)\n",
      "[16:05:48 - Sampler] Took 0.04s to make features.\n",
      "[16:05:48 - Sampler] Region ParPgb:0.0-268.0 (346 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:05:48 - PWorker] Processed 0 batches\n",
      "[16:05:48 - PWorker] All done, 1 remainder regions.\n",
      "[16:05:48 - Predict] Processing 1 short region(s).\n",
      "[16:05:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f58f84a1480>\n",
      "[16:05:48 - MdlStrTF] loading weights from /tmp/tmp_0em_3sh/model/variables/variables\n",
      "[16:05:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-269.\n",
      "[16:05:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:52 - Feature] Processed ParPgb:0.0-268.0 (median depth 125.0)\n",
      "[16:05:52 - Sampler] Took 4.06s to make features.\n",
      "[16:05:53 - PWorker] Processed 1 batches\n",
      "[16:05:53 - PWorker] All done, 0 remainder regions.\n",
      "[16:05:53 - Predict] Finished processing all regions.\n",
      "[16:05:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:05:56 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:05:56 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:05:56 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:05:56 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:05:56 - Predict] Found a GPU.\n",
      "[16:05:56 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:05:56 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:05:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2f21eddae0>\n",
      "[16:05:57 - MdlStrTF] loading weights from /tmp/tmpc7crp8tk/model/variables/variables\n",
      "[16:05:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:05:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:05:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:57 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-220.\n",
      "[16:05:57 - Feature] Processed ParPgb:0.0-220.0 (median depth 39.0)\n",
      "[16:05:57 - Sampler] Took 0.04s to make features.\n",
      "[16:05:57 - Sampler] Region ParPgb:0.0-220.0 (242 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:05:57 - PWorker] Processed 0 batches\n",
      "[16:05:57 - PWorker] All done, 1 remainder regions.\n",
      "[16:05:57 - Predict] Processing 1 short region(s).\n",
      "[16:05:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:05:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2e910bd480>\n",
      "[16:05:58 - MdlStrTF] loading weights from /tmp/tmpc7crp8tk/model/variables/variables\n",
      "[16:05:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-221.\n",
      "[16:05:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:05:58 - Feature] Processed ParPgb:0.0-220.0 (median depth 39.0)\n",
      "[16:05:58 - Sampler] Took 0.03s to make features.\n",
      "[16:05:58 - PWorker] Processed 1 batches\n",
      "[16:05:58 - PWorker] All done, 0 remainder regions.\n",
      "[16:05:58 - Predict] Finished processing all regions.\n",
      "[16:06:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:06:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:06:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:06:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:06:02 - Predict] Found a GPU.\n",
      "[16:06:02 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:06:02 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:06:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb960a45ae0>\n",
      "[16:06:03 - MdlStrTF] loading weights from /tmp/tmpyxofvwjy/model/variables/variables\n",
      "[16:06:03 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:06:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:06:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:03 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[16:06:03 - Feature] Processed ParPgb:0.0-250.0 (median depth 57.0)\n",
      "[16:06:03 - Sampler] Took 0.04s to make features.\n",
      "[16:06:03 - Sampler] Region ParPgb:0.0-250.0 (292 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:06:03 - PWorker] Processed 0 batches\n",
      "[16:06:03 - PWorker] All done, 1 remainder regions.\n",
      "[16:06:03 - Predict] Processing 1 short region(s).\n",
      "[16:06:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb8d0391480>\n",
      "[16:06:04 - MdlStrTF] loading weights from /tmp/tmpyxofvwjy/model/variables/variables\n",
      "[16:06:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[16:06:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:07 - Feature] Processed ParPgb:0.0-250.0 (median depth 57.0)\n",
      "[16:06:07 - Sampler] Took 3.77s to make features.\n",
      "[16:06:08 - PWorker] Processed 1 batches\n",
      "[16:06:08 - PWorker] All done, 0 remainder regions.\n",
      "[16:06:08 - Predict] Finished processing all regions.\n",
      "[16:06:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:11 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:06:11 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:06:11 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:06:11 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:06:11 - Predict] Found a GPU.\n",
      "[16:06:11 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:06:11 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:06:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f42544bdae0>\n",
      "[16:06:13 - MdlStrTF] loading weights from /tmp/tmpnu6g0kot/model/variables/variables\n",
      "[16:06:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:06:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:06:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:13 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-210.\n",
      "[16:06:15 - Feature] Processed ParPgb:0.0-210.0 (median depth 101.0)\n",
      "[16:06:15 - Sampler] Took 2.08s to make features.\n",
      "[16:06:15 - Sampler] Region ParPgb:0.0-210.0 (259 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:06:15 - PWorker] Processed 0 batches\n",
      "[16:06:15 - PWorker] All done, 1 remainder regions.\n",
      "[16:06:15 - Predict] Processing 1 short region(s).\n",
      "[16:06:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4196e75e70>\n",
      "[16:06:15 - MdlStrTF] loading weights from /tmp/tmpnu6g0kot/model/variables/variables\n",
      "[16:06:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-211.\n",
      "[16:06:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:15 - Feature] Processed ParPgb:0.0-210.0 (median depth 101.0)\n",
      "[16:06:15 - Sampler] Took 0.11s to make features.\n",
      "[16:06:16 - PWorker] Processed 1 batches\n",
      "[16:06:16 - PWorker] All done, 0 remainder regions.\n",
      "[16:06:16 - Predict] Finished processing all regions.\n",
      "[16:06:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:06:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:06:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:06:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:06:19 - Predict] Found a GPU.\n",
      "[16:06:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:06:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:06:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7bb0049ae0>\n",
      "[16:06:21 - MdlStrTF] loading weights from /tmp/tmphdj2g0ia/model/variables/variables\n",
      "[16:06:21 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:06:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:06:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:21 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:06:21 - Feature] Processed ParPgb:0.0-248.0 (median depth 120.0)\n",
      "[16:06:21 - Sampler] Took 0.13s to make features.\n",
      "[16:06:21 - Sampler] Region ParPgb:0.0-248.0 (355 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:06:21 - PWorker] Processed 0 batches\n",
      "[16:06:21 - PWorker] All done, 1 remainder regions.\n",
      "[16:06:21 - Predict] Processing 1 short region(s).\n",
      "[16:06:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7b201c6170>\n",
      "[16:06:21 - MdlStrTF] loading weights from /tmp/tmphdj2g0ia/model/variables/variables\n",
      "[16:06:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:06:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:21 - Feature] Processed ParPgb:0.0-248.0 (median depth 120.0)\n",
      "[16:06:21 - Sampler] Took 0.04s to make features.\n",
      "[16:06:22 - PWorker] Processed 1 batches\n",
      "[16:06:22 - PWorker] All done, 0 remainder regions.\n",
      "[16:06:22 - Predict] Finished processing all regions.\n",
      "[16:06:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:06:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:06:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:06:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:06:25 - Predict] Found a GPU.\n",
      "[16:06:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:06:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:06:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fed71f2dae0>\n",
      "[16:06:27 - MdlStrTF] loading weights from /tmp/tmpv_x7ho9n/model/variables/variables\n",
      "[16:06:27 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:06:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:06:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:27 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-261.\n",
      "[16:06:27 - Feature] Processed ParPgb:0.0-261.0 (median depth 73.0)\n",
      "[16:06:27 - Sampler] Took 0.03s to make features.\n",
      "[16:06:27 - Sampler] Region ParPgb:0.0-261.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:06:27 - PWorker] Processed 0 batches\n",
      "[16:06:27 - PWorker] All done, 1 remainder regions.\n",
      "[16:06:27 - Predict] Processing 1 short region(s).\n",
      "[16:06:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fece10bd480>\n",
      "[16:06:27 - MdlStrTF] loading weights from /tmp/tmpv_x7ho9n/model/variables/variables\n",
      "[16:06:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-262.\n",
      "[16:06:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:30 - Feature] Processed ParPgb:0.0-261.0 (median depth 73.0)\n",
      "[16:06:30 - Sampler] Took 2.47s to make features.\n",
      "[16:06:30 - PWorker] Processed 1 batches\n",
      "[16:06:30 - PWorker] All done, 0 remainder regions.\n",
      "[16:06:30 - Predict] Finished processing all regions.\n",
      "[16:06:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:33 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:06:34 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:06:34 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:06:34 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:06:34 - Predict] Found a GPU.\n",
      "[16:06:34 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:06:34 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:06:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efd137bdae0>\n",
      "[16:06:35 - MdlStrTF] loading weights from /tmp/tmpq83oubbx/model/variables/variables\n",
      "[16:06:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:06:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:06:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:35 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[16:06:35 - Feature] Processed ParPgb:0.0-249.0 (median depth 123.0)\n",
      "[16:06:35 - Sampler] Took 0.04s to make features.\n",
      "[16:06:35 - Sampler] Region ParPgb:0.0-249.0 (352 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:06:35 - PWorker] Processed 0 batches\n",
      "[16:06:35 - PWorker] All done, 1 remainder regions.\n",
      "[16:06:35 - Predict] Processing 1 short region(s).\n",
      "[16:06:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efc8291d480>\n",
      "[16:06:35 - MdlStrTF] loading weights from /tmp/tmpq83oubbx/model/variables/variables\n",
      "[16:06:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[16:06:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:38 - Feature] Processed ParPgb:0.0-249.0 (median depth 123.0)\n",
      "[16:06:38 - Sampler] Took 2.18s to make features.\n",
      "[16:06:38 - PWorker] Processed 1 batches\n",
      "[16:06:38 - PWorker] All done, 0 remainder regions.\n",
      "[16:06:38 - Predict] Finished processing all regions.\n",
      "[16:06:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:06:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:06:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:06:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:06:42 - Predict] Found a GPU.\n",
      "[16:06:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:06:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:06:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f71f0151ae0>\n",
      "[16:06:43 - MdlStrTF] loading weights from /tmp/tmper11k7fy/model/variables/variables\n",
      "[16:06:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:06:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:06:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-264.\n",
      "[16:06:43 - Feature] Processed ParPgb:0.0-264.0 (median depth 174.0)\n",
      "[16:06:43 - Sampler] Took 0.02s to make features.\n",
      "[16:06:43 - Sampler] Region ParPgb:0.0-264.0 (333 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:06:43 - PWorker] Processed 0 batches\n",
      "[16:06:43 - PWorker] All done, 1 remainder regions.\n",
      "[16:06:43 - Predict] Processing 1 short region(s).\n",
      "[16:06:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7160351480>\n",
      "[16:06:43 - MdlStrTF] loading weights from /tmp/tmper11k7fy/model/variables/variables\n",
      "[16:06:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-265.\n",
      "[16:06:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:43 - Feature] Processed ParPgb:0.0-264.0 (median depth 174.0)\n",
      "[16:06:43 - Sampler] Took 0.04s to make features.\n",
      "[16:06:44 - PWorker] Processed 1 batches\n",
      "[16:06:44 - PWorker] All done, 0 remainder regions.\n",
      "[16:06:44 - Predict] Finished processing all regions.\n",
      "[16:06:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:06:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:06:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:06:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:06:47 - Predict] Found a GPU.\n",
      "[16:06:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:06:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:06:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f43e3491ae0>\n",
      "[16:06:49 - MdlStrTF] loading weights from /tmp/tmp6xu1a8_h/model/variables/variables\n",
      "[16:06:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:06:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:06:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[16:06:49 - Feature] Processed ParPgb:0.0-245.0 (median depth 117.0)\n",
      "[16:06:49 - Sampler] Took 0.05s to make features.\n",
      "[16:06:49 - Sampler] Region ParPgb:0.0-245.0 (323 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:06:49 - PWorker] Processed 0 batches\n",
      "[16:06:49 - PWorker] All done, 1 remainder regions.\n",
      "[16:06:49 - Predict] Processing 1 short region(s).\n",
      "[16:06:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4352625480>\n",
      "[16:06:49 - MdlStrTF] loading weights from /tmp/tmp6xu1a8_h/model/variables/variables\n",
      "[16:06:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[16:06:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:49 - Feature] Processed ParPgb:0.0-245.0 (median depth 117.0)\n",
      "[16:06:49 - Sampler] Took 0.06s to make features.\n",
      "[16:06:50 - PWorker] Processed 1 batches\n",
      "[16:06:50 - PWorker] All done, 0 remainder regions.\n",
      "[16:06:50 - Predict] Finished processing all regions.\n",
      "[16:06:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:06:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:06:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:06:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:06:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:06:53 - Predict] Found a GPU.\n",
      "[16:06:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:06:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:06:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4e4ea29ae0>\n",
      "[16:06:55 - MdlStrTF] loading weights from /tmp/tmpjri76gmp/model/variables/variables\n",
      "[16:06:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:06:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:06:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[16:06:55 - Feature] Processed ParPgb:0.0-243.0 (median depth 79.0)\n",
      "[16:06:55 - Sampler] Took 0.04s to make features.\n",
      "[16:06:55 - Sampler] Region ParPgb:0.0-243.0 (299 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:06:55 - PWorker] Processed 0 batches\n",
      "[16:06:55 - PWorker] All done, 1 remainder regions.\n",
      "[16:06:55 - Predict] Processing 1 short region(s).\n",
      "[16:06:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:06:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4dbd13d480>\n",
      "[16:06:55 - MdlStrTF] loading weights from /tmp/tmpjri76gmp/model/variables/variables\n",
      "[16:06:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[16:06:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:06:58 - Feature] Processed ParPgb:0.0-243.0 (median depth 79.0)\n",
      "[16:06:58 - Sampler] Took 2.53s to make features.\n",
      "[16:06:58 - PWorker] Processed 1 batches\n",
      "[16:06:58 - PWorker] All done, 0 remainder regions.\n",
      "[16:06:58 - Predict] Finished processing all regions.\n",
      "[16:07:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:07:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:07:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:07:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:07:02 - Predict] Found a GPU.\n",
      "[16:07:02 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:07:02 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:07:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f51f70adae0>\n",
      "[16:07:03 - MdlStrTF] loading weights from /tmp/tmpoejao6s4/model/variables/variables\n",
      "[16:07:03 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:07:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:07:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:03 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[16:07:03 - Feature] Processed ParPgb:0.0-245.0 (median depth 50.0)\n",
      "[16:07:03 - Sampler] Took 0.13s to make features.\n",
      "[16:07:03 - Sampler] Region ParPgb:0.0-245.0 (272 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:07:03 - PWorker] Processed 0 batches\n",
      "[16:07:03 - PWorker] All done, 1 remainder regions.\n",
      "[16:07:03 - Predict] Processing 1 short region(s).\n",
      "[16:07:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5158211ea0>\n",
      "[16:07:04 - MdlStrTF] loading weights from /tmp/tmpoejao6s4/model/variables/variables\n",
      "[16:07:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[16:07:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:04 - Feature] Processed ParPgb:0.0-245.0 (median depth 50.0)\n",
      "[16:07:04 - Sampler] Took 0.04s to make features.\n",
      "[16:07:04 - PWorker] Processed 1 batches\n",
      "[16:07:04 - PWorker] All done, 0 remainder regions.\n",
      "[16:07:04 - Predict] Finished processing all regions.\n",
      "[16:07:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:07:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:07:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:07:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:07:08 - Predict] Found a GPU.\n",
      "[16:07:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:07:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:07:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1450c81a80>\n",
      "[16:07:09 - MdlStrTF] loading weights from /tmp/tmp7vep8mdu/model/variables/variables\n",
      "[16:07:09 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:07:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:07:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:09 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-210.\n",
      "[16:07:09 - Feature] Processed ParPgb:0.0-210.0 (median depth 166.0)\n",
      "[16:07:09 - Sampler] Took 0.16s to make features.\n",
      "[16:07:09 - Sampler] Region ParPgb:0.0-210.0 (319 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:07:11 - PWorker] Processed 0 batches\n",
      "[16:07:11 - PWorker] All done, 1 remainder regions.\n",
      "[16:07:11 - Predict] Processing 1 short region(s).\n",
      "[16:07:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:12 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f13b1a85420>\n",
      "[16:07:12 - MdlStrTF] loading weights from /tmp/tmp7vep8mdu/model/variables/variables\n",
      "[16:07:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-211.\n",
      "[16:07:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:12 - Feature] Processed ParPgb:0.0-210.0 (median depth 166.0)\n",
      "[16:07:12 - Sampler] Took 0.10s to make features.\n",
      "[16:07:12 - PWorker] Processed 1 batches\n",
      "[16:07:12 - PWorker] All done, 0 remainder regions.\n",
      "[16:07:12 - Predict] Finished processing all regions.\n",
      "[16:07:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:16 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:07:16 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:07:16 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:07:16 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:07:16 - Predict] Found a GPU.\n",
      "[16:07:16 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:07:16 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:07:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3481c7dae0>\n",
      "[16:07:17 - MdlStrTF] loading weights from /tmp/tmpjc3e9zaq/model/variables/variables\n",
      "[16:07:17 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:07:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:07:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:07:17 - Feature] Processed ParPgb:0.0-248.0 (median depth 69.0)\n",
      "[16:07:17 - Sampler] Took 0.04s to make features.\n",
      "[16:07:17 - Sampler] Region ParPgb:0.0-248.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:07:17 - PWorker] Processed 0 batches\n",
      "[16:07:17 - PWorker] All done, 1 remainder regions.\n",
      "[16:07:17 - Predict] Processing 1 short region(s).\n",
      "[16:07:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f33f0db9990>\n",
      "[16:07:18 - MdlStrTF] loading weights from /tmp/tmpjc3e9zaq/model/variables/variables\n",
      "[16:07:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:07:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:18 - Feature] Processed ParPgb:0.0-248.0 (median depth 69.0)\n",
      "[16:07:18 - Sampler] Took 0.04s to make features.\n",
      "[16:07:18 - PWorker] Processed 1 batches\n",
      "[16:07:18 - PWorker] All done, 0 remainder regions.\n",
      "[16:07:18 - Predict] Finished processing all regions.\n",
      "[16:07:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:07:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:07:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:07:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:07:22 - Predict] Found a GPU.\n",
      "[16:07:22 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:07:22 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:07:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff0219ddae0>\n",
      "[16:07:23 - MdlStrTF] loading weights from /tmp/tmplethgmt5/model/variables/variables\n",
      "[16:07:23 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:07:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:07:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:23 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[16:07:23 - Feature] Processed ParPgb:0.0-243.0 (median depth 106.0)\n",
      "[16:07:23 - Sampler] Took 0.03s to make features.\n",
      "[16:07:23 - Sampler] Region ParPgb:0.0-243.0 (289 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:07:23 - PWorker] Processed 0 batches\n",
      "[16:07:23 - PWorker] All done, 1 remainder regions.\n",
      "[16:07:23 - Predict] Processing 1 short region(s).\n",
      "[16:07:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fef90b91480>\n",
      "[16:07:23 - MdlStrTF] loading weights from /tmp/tmplethgmt5/model/variables/variables\n",
      "[16:07:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[16:07:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:24 - Feature] Processed ParPgb:0.0-243.0 (median depth 106.0)\n",
      "[16:07:24 - Sampler] Took 0.09s to make features.\n",
      "[16:07:24 - PWorker] Processed 1 batches\n",
      "[16:07:24 - PWorker] All done, 0 remainder regions.\n",
      "[16:07:24 - Predict] Finished processing all regions.\n",
      "[16:07:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:27 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:07:28 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:07:28 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:07:28 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:07:28 - Predict] Found a GPU.\n",
      "[16:07:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:07:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:07:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9fbb64dae0>\n",
      "[16:07:29 - MdlStrTF] loading weights from /tmp/tmpy26tjl10/model/variables/variables\n",
      "[16:07:29 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:07:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:07:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:29 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-266.\n",
      "[16:07:29 - Feature] Processed ParPgb:0.0-266.0 (median depth 123.0)\n",
      "[16:07:29 - Sampler] Took 0.03s to make features.\n",
      "[16:07:29 - Sampler] Region ParPgb:0.0-266.0 (334 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:07:29 - PWorker] Processed 0 batches\n",
      "[16:07:29 - PWorker] All done, 1 remainder regions.\n",
      "[16:07:29 - Predict] Processing 1 short region(s).\n",
      "[16:07:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9f284a1ff0>\n",
      "[16:07:29 - MdlStrTF] loading weights from /tmp/tmpy26tjl10/model/variables/variables\n",
      "[16:07:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-267.\n",
      "[16:07:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:29 - Feature] Processed ParPgb:0.0-266.0 (median depth 123.0)\n",
      "[16:07:29 - Sampler] Took 0.12s to make features.\n",
      "[16:07:30 - PWorker] Processed 1 batches\n",
      "[16:07:30 - PWorker] All done, 0 remainder regions.\n",
      "[16:07:30 - Predict] Finished processing all regions.\n",
      "[16:07:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:33 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:07:33 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:07:33 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:07:33 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:07:33 - Predict] Found a GPU.\n",
      "[16:07:33 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:07:33 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:07:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9a52765ae0>\n",
      "[16:07:35 - MdlStrTF] loading weights from /tmp/tmp4eumczcy/model/variables/variables\n",
      "[16:07:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:07:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:07:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:35 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[16:07:35 - Feature] Processed ParPgb:0.0-249.0 (median depth 123.0)\n",
      "[16:07:35 - Sampler] Took 0.03s to make features.\n",
      "[16:07:35 - Sampler] Region ParPgb:0.0-249.0 (315 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:07:35 - PWorker] Processed 0 batches\n",
      "[16:07:35 - PWorker] All done, 1 remainder regions.\n",
      "[16:07:35 - Predict] Processing 1 short region(s).\n",
      "[16:07:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f99c18c5480>\n",
      "[16:07:35 - MdlStrTF] loading weights from /tmp/tmp4eumczcy/model/variables/variables\n",
      "[16:07:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[16:07:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:35 - Feature] Processed ParPgb:0.0-249.0 (median depth 123.0)\n",
      "[16:07:35 - Sampler] Took 0.05s to make features.\n",
      "[16:07:36 - PWorker] Processed 1 batches\n",
      "[16:07:36 - PWorker] All done, 0 remainder regions.\n",
      "[16:07:36 - Predict] Finished processing all regions.\n",
      "[16:07:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:39 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:07:39 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:07:39 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:07:39 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:07:39 - Predict] Found a GPU.\n",
      "[16:07:39 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:07:39 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:07:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fea6d4b5ae0>\n",
      "[16:07:41 - MdlStrTF] loading weights from /tmp/tmpb4f6om6t/model/variables/variables\n",
      "[16:07:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:07:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:07:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:41 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-200.\n",
      "[16:07:41 - Feature] Processed ParPgb:0.0-200.0 (median depth 60.0)\n",
      "[16:07:41 - Sampler] Took 0.10s to make features.\n",
      "[16:07:41 - Sampler] Region ParPgb:0.0-200.0 (246 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:07:41 - PWorker] Processed 0 batches\n",
      "[16:07:41 - PWorker] All done, 1 remainder regions.\n",
      "[16:07:41 - Predict] Processing 1 short region(s).\n",
      "[16:07:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe9dc666fb0>\n",
      "[16:07:41 - MdlStrTF] loading weights from /tmp/tmpb4f6om6t/model/variables/variables\n",
      "[16:07:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-201.\n",
      "[16:07:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:41 - Feature] Processed ParPgb:0.0-200.0 (median depth 60.0)\n",
      "[16:07:41 - Sampler] Took 0.07s to make features.\n",
      "[16:07:42 - PWorker] Processed 1 batches\n",
      "[16:07:42 - PWorker] All done, 0 remainder regions.\n",
      "[16:07:42 - Predict] Finished processing all regions.\n",
      "[16:07:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:45 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:07:45 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:07:45 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:07:45 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:07:45 - Predict] Found a GPU.\n",
      "[16:07:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:07:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:07:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f38eff6dae0>\n",
      "[16:07:47 - MdlStrTF] loading weights from /tmp/tmpr8e_m58y/model/variables/variables\n",
      "[16:07:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:07:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:07:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-220.\n",
      "[16:07:47 - Feature] Processed ParPgb:0.0-220.0 (median depth 82.0)\n",
      "[16:07:47 - Sampler] Took 0.26s to make features.\n",
      "[16:07:47 - Sampler] Region ParPgb:0.0-220.0 (283 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:07:47 - PWorker] Processed 0 batches\n",
      "[16:07:47 - PWorker] All done, 1 remainder regions.\n",
      "[16:07:47 - Predict] Processing 1 short region(s).\n",
      "[16:07:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f38600c1ff0>\n",
      "[16:07:47 - MdlStrTF] loading weights from /tmp/tmpr8e_m58y/model/variables/variables\n",
      "[16:07:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-221.\n",
      "[16:07:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:49 - Feature] Processed ParPgb:0.0-220.0 (median depth 82.0)\n",
      "[16:07:49 - Sampler] Took 2.13s to make features.\n",
      "[16:07:50 - PWorker] Processed 1 batches\n",
      "[16:07:50 - PWorker] All done, 0 remainder regions.\n",
      "[16:07:50 - Predict] Finished processing all regions.\n",
      "[16:07:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:07:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:07:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:07:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:07:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:07:53 - Predict] Found a GPU.\n",
      "[16:07:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:07:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:07:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1a73a7dae0>\n",
      "[16:07:55 - MdlStrTF] loading weights from /tmp/tmpo_3inw7j/model/variables/variables\n",
      "[16:07:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:07:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:07:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[16:07:56 - Feature] Processed ParPgb:0.0-244.0 (median depth 117.0)\n",
      "[16:07:56 - Sampler] Took 1.54s to make features.\n",
      "[16:07:56 - Sampler] Region ParPgb:0.0-244.0 (318 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:07:56 - PWorker] Processed 0 batches\n",
      "[16:07:56 - PWorker] All done, 1 remainder regions.\n",
      "[16:07:56 - Predict] Processing 1 short region(s).\n",
      "[16:07:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:07:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f19e2c4d480>\n",
      "[16:07:57 - MdlStrTF] loading weights from /tmp/tmpo_3inw7j/model/variables/variables\n",
      "[16:07:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[16:07:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:07:59 - Feature] Processed ParPgb:0.0-244.0 (median depth 117.0)\n",
      "[16:07:59 - Sampler] Took 2.03s to make features.\n",
      "[16:07:59 - PWorker] Processed 1 batches\n",
      "[16:07:59 - PWorker] All done, 0 remainder regions.\n",
      "[16:07:59 - Predict] Finished processing all regions.\n",
      "[16:08:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:08:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:08:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:08:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:08:03 - Predict] Found a GPU.\n",
      "[16:08:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:08:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:08:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efe01cd5ae0>\n",
      "[16:08:04 - MdlStrTF] loading weights from /tmp/tmpj0b74rh6/model/variables/variables\n",
      "[16:08:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:08:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:08:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:08:04 - Feature] Processed ParPgb:0.0-240.0 (median depth 117.0)\n",
      "[16:08:04 - Sampler] Took 0.04s to make features.\n",
      "[16:08:04 - Sampler] Region ParPgb:0.0-240.0 (316 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:08:04 - PWorker] Processed 0 batches\n",
      "[16:08:04 - PWorker] All done, 1 remainder regions.\n",
      "[16:08:04 - Predict] Processing 1 short region(s).\n",
      "[16:08:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efd70ebd450>\n",
      "[16:08:05 - MdlStrTF] loading weights from /tmp/tmpj0b74rh6/model/variables/variables\n",
      "[16:08:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:08:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:05 - Feature] Processed ParPgb:0.0-240.0 (median depth 117.0)\n",
      "[16:08:05 - Sampler] Took 0.06s to make features.\n",
      "[16:08:05 - PWorker] Processed 1 batches\n",
      "[16:08:05 - PWorker] All done, 0 remainder regions.\n",
      "[16:08:05 - Predict] Finished processing all regions.\n",
      "[16:08:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:08:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:08:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:08:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:08:09 - Predict] Found a GPU.\n",
      "[16:08:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:08:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:08:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efe5374dae0>\n",
      "[16:08:10 - MdlStrTF] loading weights from /tmp/tmpc1kidj_1/model/variables/variables\n",
      "[16:08:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:08:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:08:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-266.\n",
      "[16:08:15 - Feature] Processed ParPgb:0.0-266.0 (median depth 122.0)\n",
      "[16:08:15 - Sampler] Took 4.94s to make features.\n",
      "[16:08:15 - Sampler] Region ParPgb:0.0-266.0 (350 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:08:15 - PWorker] Processed 0 batches\n",
      "[16:08:15 - PWorker] All done, 1 remainder regions.\n",
      "[16:08:15 - Predict] Processing 1 short region(s).\n",
      "[16:08:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efdc28f5480>\n",
      "[16:08:15 - MdlStrTF] loading weights from /tmp/tmpc1kidj_1/model/variables/variables\n",
      "[16:08:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-267.\n",
      "[16:08:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:15 - Feature] Processed ParPgb:0.0-266.0 (median depth 122.0)\n",
      "[16:08:15 - Sampler] Took 0.03s to make features.\n",
      "[16:08:16 - PWorker] Processed 1 batches\n",
      "[16:08:16 - PWorker] All done, 0 remainder regions.\n",
      "[16:08:16 - Predict] Finished processing all regions.\n",
      "[16:08:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:08:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:08:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:08:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:08:19 - Predict] Found a GPU.\n",
      "[16:08:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:08:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:08:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5a398b9ae0>\n",
      "[16:08:21 - MdlStrTF] loading weights from /tmp/tmpglom96h5/model/variables/variables\n",
      "[16:08:21 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:08:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:08:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:23 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-239.\n",
      "[16:08:23 - Feature] Processed ParPgb:0.0-239.0 (median depth 98.0)\n",
      "[16:08:23 - Sampler] Took 2.23s to make features.\n",
      "[16:08:23 - Sampler] Region ParPgb:0.0-239.0 (293 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:08:23 - PWorker] Processed 0 batches\n",
      "[16:08:23 - PWorker] All done, 1 remainder regions.\n",
      "[16:08:23 - Predict] Processing 1 short region(s).\n",
      "[16:08:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f59a8a49ff0>\n",
      "[16:08:23 - MdlStrTF] loading weights from /tmp/tmpglom96h5/model/variables/variables\n",
      "[16:08:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-240.\n",
      "[16:08:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:23 - Feature] Processed ParPgb:0.0-239.0 (median depth 98.0)\n",
      "[16:08:23 - Sampler] Took 0.06s to make features.\n",
      "[16:08:24 - PWorker] Processed 1 batches\n",
      "[16:08:24 - PWorker] All done, 0 remainder regions.\n",
      "[16:08:24 - Predict] Finished processing all regions.\n",
      "[16:08:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:27 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:08:27 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:08:27 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:08:27 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:08:28 - Predict] Found a GPU.\n",
      "[16:08:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:08:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:08:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f73fe1d1ae0>\n",
      "[16:08:29 - MdlStrTF] loading weights from /tmp/tmp659jsvai/model/variables/variables\n",
      "[16:08:29 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:08:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:08:29 - Sampler] Took 0.02s to make features.\n",
      "[16:08:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:29 - PWorker] Processed 0 batches\n",
      "[16:08:29 - PWorker] All done, 0 remainder regions.\n",
      "[16:08:29 - Predict] Finished processing all regions.\n",
      "[16:08:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:31 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:08:32 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:08:32 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:08:32 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:08:32 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:08:32 - Predict] Found a GPU.\n",
      "[16:08:32 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:08:32 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:08:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f74529e5ae0>\n",
      "[16:08:33 - MdlStrTF] loading weights from /tmp/tmppvvw_8mr/model/variables/variables\n",
      "[16:08:33 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:08:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:08:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:33 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-208.\n",
      "[16:08:33 - Feature] Processed ParPgb:0.0-208.0 (median depth 82.0)\n",
      "[16:08:33 - Sampler] Took 0.02s to make features.\n",
      "[16:08:33 - Sampler] Region ParPgb:0.0-208.0 (262 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:08:34 - PWorker] Processed 0 batches\n",
      "[16:08:34 - PWorker] All done, 1 remainder regions.\n",
      "[16:08:34 - Predict] Processing 1 short region(s).\n",
      "[16:08:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f73c1b29b10>\n",
      "[16:08:34 - MdlStrTF] loading weights from /tmp/tmppvvw_8mr/model/variables/variables\n",
      "[16:08:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-209.\n",
      "[16:08:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:36 - Feature] Processed ParPgb:0.0-208.0 (median depth 82.0)\n",
      "[16:08:36 - Sampler] Took 2.13s to make features.\n",
      "[16:08:37 - PWorker] Processed 1 batches\n",
      "[16:08:37 - PWorker] All done, 0 remainder regions.\n",
      "[16:08:37 - Predict] Finished processing all regions.\n",
      "[16:08:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:08:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:08:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:08:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:08:40 - Predict] Found a GPU.\n",
      "[16:08:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:08:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:08:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd86fb41ae0>\n",
      "[16:08:41 - MdlStrTF] loading weights from /tmp/tmpjn5lsg6u/model/variables/variables\n",
      "[16:08:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:08:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:08:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:41 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:08:44 - Feature] Processed ParPgb:0.0-246.0 (median depth 104.0)\n",
      "[16:08:44 - Sampler] Took 2.31s to make features.\n",
      "[16:08:44 - Sampler] Region ParPgb:0.0-246.0 (327 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:08:44 - PWorker] Processed 0 batches\n",
      "[16:08:44 - PWorker] All done, 1 remainder regions.\n",
      "[16:08:44 - Predict] Processing 1 short region(s).\n",
      "[16:08:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd7d0435480>\n",
      "[16:08:44 - MdlStrTF] loading weights from /tmp/tmpjn5lsg6u/model/variables/variables\n",
      "[16:08:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:08:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:44 - Feature] Processed ParPgb:0.0-246.0 (median depth 104.0)\n",
      "[16:08:44 - Sampler] Took 0.06s to make features.\n",
      "[16:08:45 - PWorker] Processed 1 batches\n",
      "[16:08:45 - PWorker] All done, 0 remainder regions.\n",
      "[16:08:45 - Predict] Finished processing all regions.\n",
      "[16:08:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:48 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:08:48 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:08:48 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:08:48 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:08:48 - Predict] Found a GPU.\n",
      "[16:08:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:08:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:08:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2a69f45ae0>\n",
      "[16:08:50 - MdlStrTF] loading weights from /tmp/tmpq0wlar6y/model/variables/variables\n",
      "[16:08:50 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:08:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:08:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:50 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[16:08:50 - Feature] Processed ParPgb:0.0-252.0 (median depth 42.0)\n",
      "[16:08:50 - Sampler] Took 0.10s to make features.\n",
      "[16:08:50 - Sampler] Region ParPgb:0.0-252.0 (283 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:08:50 - PWorker] Processed 0 batches\n",
      "[16:08:50 - PWorker] All done, 1 remainder regions.\n",
      "[16:08:50 - Predict] Processing 1 short region(s).\n",
      "[16:08:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f29d90e9ff0>\n",
      "[16:08:50 - MdlStrTF] loading weights from /tmp/tmpq0wlar6y/model/variables/variables\n",
      "[16:08:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[16:08:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:50 - Feature] Processed ParPgb:0.0-252.0 (median depth 42.0)\n",
      "[16:08:50 - Sampler] Took 0.07s to make features.\n",
      "[16:08:51 - PWorker] Processed 1 batches\n",
      "[16:08:51 - PWorker] All done, 0 remainder regions.\n",
      "[16:08:51 - Predict] Finished processing all regions.\n",
      "[16:08:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:08:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:08:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:08:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:08:54 - Predict] Found a GPU.\n",
      "[16:08:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:08:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:08:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa11371dae0>\n",
      "[16:08:55 - MdlStrTF] loading weights from /tmp/tmprmlyy268/model/variables/variables\n",
      "[16:08:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:08:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:08:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[16:08:56 - Feature] Processed ParPgb:0.0-242.0 (median depth 84.0)\n",
      "[16:08:56 - Sampler] Took 0.12s to make features.\n",
      "[16:08:56 - Sampler] Region ParPgb:0.0-242.0 (283 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:08:56 - PWorker] Processed 0 batches\n",
      "[16:08:56 - PWorker] All done, 1 remainder regions.\n",
      "[16:08:56 - Predict] Processing 1 short region(s).\n",
      "[16:08:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:08:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa0828ca1a0>\n",
      "[16:08:56 - MdlStrTF] loading weights from /tmp/tmprmlyy268/model/variables/variables\n",
      "[16:08:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[16:08:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:08:56 - Feature] Processed ParPgb:0.0-242.0 (median depth 84.0)\n",
      "[16:08:56 - Sampler] Took 0.03s to make features.\n",
      "[16:08:57 - PWorker] Processed 1 batches\n",
      "[16:08:57 - PWorker] All done, 0 remainder regions.\n",
      "[16:08:57 - Predict] Finished processing all regions.\n",
      "[16:08:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:08:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:09:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:09:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:09:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:09:00 - Predict] Found a GPU.\n",
      "[16:09:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:09:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:09:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc3d8b31ae0>\n",
      "[16:09:01 - MdlStrTF] loading weights from /tmp/tmpvcv69by4/model/variables/variables\n",
      "[16:09:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:09:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:09:01 - Sampler] Took 0.01s to make features.\n",
      "[16:09:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:01 - PWorker] Processed 0 batches\n",
      "[16:09:01 - PWorker] All done, 0 remainder regions.\n",
      "[16:09:01 - Predict] Finished processing all regions.\n",
      "[16:09:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:03 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:09:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:09:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:09:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:09:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:09:05 - Predict] Found a GPU.\n",
      "[16:09:05 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:09:05 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:09:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb61b821ae0>\n",
      "[16:09:06 - MdlStrTF] loading weights from /tmp/tmp_5ybskjz/model/variables/variables\n",
      "[16:09:06 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:09:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:09:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:09 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-207.\n",
      "[16:09:09 - Feature] Processed ParPgb:0.0-207.0 (median depth 68.0)\n",
      "[16:09:09 - Sampler] Took 2.47s to make features.\n",
      "[16:09:09 - Sampler] Region ParPgb:0.0-207.0 (244 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:09:09 - PWorker] Processed 0 batches\n",
      "[16:09:09 - PWorker] All done, 1 remainder regions.\n",
      "[16:09:09 - Predict] Processing 1 short region(s).\n",
      "[16:09:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb58a629ff0>\n",
      "[16:09:09 - MdlStrTF] loading weights from /tmp/tmp_5ybskjz/model/variables/variables\n",
      "[16:09:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-208.\n",
      "[16:09:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:09 - Feature] Processed ParPgb:0.0-207.0 (median depth 68.0)\n",
      "[16:09:09 - Sampler] Took 0.04s to make features.\n",
      "[16:09:10 - PWorker] Processed 1 batches\n",
      "[16:09:10 - PWorker] All done, 0 remainder regions.\n",
      "[16:09:10 - Predict] Finished processing all regions.\n",
      "[16:09:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:13 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:09:13 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:09:13 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:09:13 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:09:13 - Predict] Found a GPU.\n",
      "[16:09:13 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:09:13 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:09:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f768a2edae0>\n",
      "[16:09:14 - MdlStrTF] loading weights from /tmp/tmpzc6dobgn/model/variables/variables\n",
      "[16:09:14 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:09:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:09:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[16:09:14 - Feature] Processed ParPgb:0.0-250.0 (median depth 97.0)\n",
      "[16:09:14 - Sampler] Took 0.06s to make features.\n",
      "[16:09:14 - Sampler] Region ParPgb:0.0-250.0 (305 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:09:14 - PWorker] Processed 0 batches\n",
      "[16:09:14 - PWorker] All done, 1 remainder regions.\n",
      "[16:09:14 - Predict] Processing 1 short region(s).\n",
      "[16:09:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f75f9111ea0>\n",
      "[16:09:15 - MdlStrTF] loading weights from /tmp/tmpzc6dobgn/model/variables/variables\n",
      "[16:09:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[16:09:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:15 - Feature] Processed ParPgb:0.0-250.0 (median depth 97.0)\n",
      "[16:09:15 - Sampler] Took 0.08s to make features.\n",
      "[16:09:15 - PWorker] Processed 1 batches\n",
      "[16:09:15 - PWorker] All done, 0 remainder regions.\n",
      "[16:09:15 - Predict] Finished processing all regions.\n",
      "[16:09:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:09:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:09:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:09:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:09:19 - Predict] Found a GPU.\n",
      "[16:09:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:09:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:09:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb51c825ae0>\n",
      "[16:09:20 - MdlStrTF] loading weights from /tmp/tmpetk_fnf6/model/variables/variables\n",
      "[16:09:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:09:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:09:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:20 - Sampler] Took 0.02s to make features.\n",
      "[16:09:20 - PWorker] Processed 0 batches\n",
      "[16:09:20 - PWorker] All done, 0 remainder regions.\n",
      "[16:09:20 - Predict] Finished processing all regions.\n",
      "[16:09:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:22 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:09:23 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:09:23 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:09:23 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:09:23 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:09:24 - Predict] Found a GPU.\n",
      "[16:09:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:09:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:09:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6367865ae0>\n",
      "[16:09:25 - MdlStrTF] loading weights from /tmp/tmp5uhixyma/model/variables/variables\n",
      "[16:09:25 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:09:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:09:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:25 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[16:09:25 - Feature] Processed ParPgb:0.0-243.0 (median depth 66.0)\n",
      "[16:09:25 - Sampler] Took 0.03s to make features.\n",
      "[16:09:25 - Sampler] Region ParPgb:0.0-243.0 (294 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:09:25 - PWorker] Processed 0 batches\n",
      "[16:09:25 - PWorker] All done, 1 remainder regions.\n",
      "[16:09:25 - Predict] Processing 1 short region(s).\n",
      "[16:09:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f62c8a3eef0>\n",
      "[16:09:25 - MdlStrTF] loading weights from /tmp/tmp5uhixyma/model/variables/variables\n",
      "[16:09:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[16:09:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:25 - Feature] Processed ParPgb:0.0-243.0 (median depth 66.0)\n",
      "[16:09:25 - Sampler] Took 0.06s to make features.\n",
      "[16:09:26 - PWorker] Processed 1 batches\n",
      "[16:09:26 - PWorker] All done, 0 remainder regions.\n",
      "[16:09:26 - Predict] Finished processing all regions.\n",
      "[16:09:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:09:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:09:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:09:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:09:29 - Predict] Found a GPU.\n",
      "[16:09:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:09:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:09:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe1df1c9ae0>\n",
      "[16:09:31 - MdlStrTF] loading weights from /tmp/tmp0psroykb/model/variables/variables\n",
      "[16:09:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:09:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:09:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-209.\n",
      "[16:09:31 - Feature] Processed ParPgb:0.0-209.0 (median depth 114.0)\n",
      "[16:09:31 - Sampler] Took 0.09s to make features.\n",
      "[16:09:31 - Sampler] Region ParPgb:0.0-209.0 (269 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:09:31 - PWorker] Processed 0 batches\n",
      "[16:09:31 - PWorker] All done, 1 remainder regions.\n",
      "[16:09:31 - Predict] Processing 1 short region(s).\n",
      "[16:09:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe14e2e5ff0>\n",
      "[16:09:31 - MdlStrTF] loading weights from /tmp/tmp0psroykb/model/variables/variables\n",
      "[16:09:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-210.\n",
      "[16:09:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:36 - Feature] Processed ParPgb:0.0-209.0 (median depth 114.0)\n",
      "[16:09:36 - Sampler] Took 4.83s to make features.\n",
      "[16:09:37 - PWorker] Batches in cache: 1.\n",
      "[16:09:37 - PWorker] Processed 1 batches\n",
      "[16:09:37 - PWorker] All done, 0 remainder regions.\n",
      "[16:09:37 - Predict] Finished processing all regions.\n",
      "[16:09:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:09:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:09:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:09:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:09:40 - Predict] Found a GPU.\n",
      "[16:09:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:09:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:09:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7422a1da80>\n",
      "[16:09:42 - MdlStrTF] loading weights from /tmp/tmpgydh9q_1/model/variables/variables\n",
      "[16:09:42 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:09:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:09:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[16:09:45 - Feature] Processed ParPgb:0.0-243.0 (median depth 88.0)\n",
      "[16:09:45 - Sampler] Took 3.41s to make features.\n",
      "[16:09:45 - Sampler] Region ParPgb:0.0-243.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:09:45 - PWorker] Processed 0 batches\n",
      "[16:09:45 - PWorker] All done, 1 remainder regions.\n",
      "[16:09:45 - Predict] Processing 1 short region(s).\n",
      "[16:09:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f739033d420>\n",
      "[16:09:45 - MdlStrTF] loading weights from /tmp/tmpgydh9q_1/model/variables/variables\n",
      "[16:09:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[16:09:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:48 - Feature] Processed ParPgb:0.0-243.0 (median depth 88.0)\n",
      "[16:09:48 - Sampler] Took 2.53s to make features.\n",
      "[16:09:48 - PWorker] Processed 1 batches\n",
      "[16:09:48 - PWorker] All done, 0 remainder regions.\n",
      "[16:09:48 - Predict] Finished processing all regions.\n",
      "[16:09:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:52 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:09:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:09:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:09:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:09:52 - Predict] Found a GPU.\n",
      "[16:09:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:09:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:09:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f29e98f1ae0>\n",
      "[16:09:53 - MdlStrTF] loading weights from /tmp/tmp7j21y6xc/model/variables/variables\n",
      "[16:09:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:09:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:09:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[16:09:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:53 - Feature] Processed ParPgb:0.0-244.0 (median depth 43.0)\n",
      "[16:09:53 - Sampler] Took 0.11s to make features.\n",
      "[16:09:53 - Sampler] Region ParPgb:0.0-244.0 (273 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:09:53 - PWorker] Processed 0 batches\n",
      "[16:09:53 - PWorker] All done, 1 remainder regions.\n",
      "[16:09:53 - Predict] Processing 1 short region(s).\n",
      "[16:09:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2958222320>\n",
      "[16:09:54 - MdlStrTF] loading weights from /tmp/tmp7j21y6xc/model/variables/variables\n",
      "[16:09:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[16:09:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:54 - Feature] Processed ParPgb:0.0-244.0 (median depth 43.0)\n",
      "[16:09:54 - Sampler] Took 0.04s to make features.\n",
      "[16:09:54 - PWorker] Processed 1 batches\n",
      "[16:09:54 - PWorker] All done, 0 remainder regions.\n",
      "[16:09:54 - Predict] Finished processing all regions.\n",
      "[16:09:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:09:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:09:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:09:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:09:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:09:58 - Predict] Found a GPU.\n",
      "[16:09:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:09:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:09:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:09:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcd1e4cdae0>\n",
      "[16:09:59 - MdlStrTF] loading weights from /tmp/tmpat10b69u/model/variables/variables\n",
      "[16:09:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:09:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:09:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:09:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-236.\n",
      "[16:09:59 - Feature] Processed ParPgb:0.0-236.0 (median depth 117.0)\n",
      "[16:09:59 - Sampler] Took 0.04s to make features.\n",
      "[16:09:59 - Sampler] Region ParPgb:0.0-236.0 (295 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:09:59 - PWorker] Processed 0 batches\n",
      "[16:09:59 - PWorker] All done, 1 remainder regions.\n",
      "[16:09:59 - Predict] Processing 1 short region(s).\n",
      "[16:09:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcd002b5b10>\n",
      "[16:10:00 - MdlStrTF] loading weights from /tmp/tmpat10b69u/model/variables/variables\n",
      "[16:10:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-237.\n",
      "[16:10:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:00 - Feature] Processed ParPgb:0.0-236.0 (median depth 117.0)\n",
      "[16:10:00 - Sampler] Took 0.15s to make features.\n",
      "[16:10:00 - PWorker] Processed 1 batches\n",
      "[16:10:00 - PWorker] All done, 0 remainder regions.\n",
      "[16:10:00 - Predict] Finished processing all regions.\n",
      "[16:10:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:10:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:10:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:10:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:10:04 - Predict] Found a GPU.\n",
      "[16:10:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:10:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:10:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb783e21ae0>\n",
      "[16:10:05 - MdlStrTF] loading weights from /tmp/tmp7fonneq6/model/variables/variables\n",
      "[16:10:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:10:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:10:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-241.\n",
      "[16:10:05 - Feature] Processed ParPgb:0.0-241.0 (median depth 118.0)\n",
      "[16:10:05 - Sampler] Took 0.05s to make features.\n",
      "[16:10:05 - Sampler] Region ParPgb:0.0-241.0 (320 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:10:05 - PWorker] Processed 0 batches\n",
      "[16:10:05 - PWorker] All done, 1 remainder regions.\n",
      "[16:10:05 - Predict] Processing 1 short region(s).\n",
      "[16:10:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb75c109480>\n",
      "[16:10:06 - MdlStrTF] loading weights from /tmp/tmp7fonneq6/model/variables/variables\n",
      "[16:10:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-242.\n",
      "[16:10:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:07 - Feature] Processed ParPgb:0.0-241.0 (median depth 118.0)\n",
      "[16:10:07 - Sampler] Took 1.54s to make features.\n",
      "[16:10:08 - PWorker] Processed 1 batches\n",
      "[16:10:08 - PWorker] All done, 0 remainder regions.\n",
      "[16:10:08 - Predict] Finished processing all regions.\n",
      "[16:10:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:11 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:10:11 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:10:11 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:10:11 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:10:11 - Predict] Found a GPU.\n",
      "[16:10:11 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:10:11 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:10:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f45bcfa9ae0>\n",
      "[16:10:13 - MdlStrTF] loading weights from /tmp/tmph3vb6dwn/model/variables/variables\n",
      "[16:10:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:10:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:10:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-204.\n",
      "[16:10:15 - Feature] Processed ParPgb:0.0-204.0 (median depth 26.0)\n",
      "[16:10:15 - Sampler] Took 2.29s to make features.\n",
      "[16:10:15 - Sampler] Region ParPgb:0.0-204.0 (222 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:10:15 - PWorker] Processed 0 batches\n",
      "[16:10:15 - PWorker] All done, 1 remainder regions.\n",
      "[16:10:15 - Predict] Processing 1 short region(s).\n",
      "[16:10:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f452c195480>\n",
      "[16:10:15 - MdlStrTF] loading weights from /tmp/tmph3vb6dwn/model/variables/variables\n",
      "[16:10:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-205.\n",
      "[16:10:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:15 - Feature] Processed ParPgb:0.0-204.0 (median depth 26.0)\n",
      "[16:10:15 - Sampler] Took 0.15s to make features.\n",
      "[16:10:16 - PWorker] Processed 1 batches\n",
      "[16:10:16 - PWorker] All done, 0 remainder regions.\n",
      "[16:10:16 - Predict] Finished processing all regions.\n",
      "[16:10:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:10:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:10:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:10:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:10:19 - Predict] Found a GPU.\n",
      "[16:10:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:10:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:10:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa15e1a5ae0>\n",
      "[16:10:21 - MdlStrTF] loading weights from /tmp/tmp9ym0rsth/model/variables/variables\n",
      "[16:10:21 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:10:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:10:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:23 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[16:10:23 - Feature] Processed ParPgb:0.0-238.0 (median depth 98.0)\n",
      "[16:10:23 - Sampler] Took 2.16s to make features.\n",
      "[16:10:23 - Sampler] Region ParPgb:0.0-238.0 (321 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:10:23 - PWorker] Processed 0 batches\n",
      "[16:10:23 - PWorker] All done, 1 remainder regions.\n",
      "[16:10:23 - Predict] Processing 1 short region(s).\n",
      "[16:10:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa0cd2d1fc0>\n",
      "[16:10:23 - MdlStrTF] loading weights from /tmp/tmp9ym0rsth/model/variables/variables\n",
      "[16:10:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[16:10:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:27 - Feature] Processed ParPgb:0.0-238.0 (median depth 98.0)\n",
      "[16:10:27 - Sampler] Took 3.26s to make features.\n",
      "[16:10:27 - PWorker] Processed 1 batches\n",
      "[16:10:27 - PWorker] All done, 0 remainder regions.\n",
      "[16:10:27 - Predict] Finished processing all regions.\n",
      "[16:10:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:10:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:10:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:10:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:10:31 - Predict] Found a GPU.\n",
      "[16:10:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:10:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:10:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd6045cda80>\n",
      "[16:10:32 - MdlStrTF] loading weights from /tmp/tmpsksawx_z/model/variables/variables\n",
      "[16:10:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:10:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:10:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[16:10:34 - Feature] Processed ParPgb:0.0-251.0 (median depth 138.0)\n",
      "[16:10:34 - Sampler] Took 2.00s to make features.\n",
      "[16:10:34 - Sampler] Region ParPgb:0.0-251.0 (334 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:10:34 - PWorker] Processed 0 batches\n",
      "[16:10:34 - PWorker] All done, 1 remainder regions.\n",
      "[16:10:34 - Predict] Processing 1 short region(s).\n",
      "[16:10:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd547771420>\n",
      "[16:10:34 - MdlStrTF] loading weights from /tmp/tmpsksawx_z/model/variables/variables\n",
      "[16:10:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[16:10:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:34 - Feature] Processed ParPgb:0.0-251.0 (median depth 138.0)\n",
      "[16:10:34 - Sampler] Took 0.05s to make features.\n",
      "[16:10:35 - PWorker] Processed 1 batches\n",
      "[16:10:35 - PWorker] All done, 0 remainder regions.\n",
      "[16:10:35 - Predict] Finished processing all regions.\n",
      "[16:10:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:10:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:10:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:10:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:10:38 - Predict] Found a GPU.\n",
      "[16:10:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:10:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:10:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5fe7299ae0>\n",
      "[16:10:40 - MdlStrTF] loading weights from /tmp/tmpgseiy9hb/model/variables/variables\n",
      "[16:10:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:10:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:10:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:40 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-225.\n",
      "[16:10:40 - Feature] Processed ParPgb:0.0-225.0 (median depth 126.0)\n",
      "[16:10:40 - Sampler] Took 0.08s to make features.\n",
      "[16:10:40 - Sampler] Region ParPgb:0.0-225.0 (313 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:10:40 - PWorker] Processed 0 batches\n",
      "[16:10:40 - PWorker] All done, 1 remainder regions.\n",
      "[16:10:40 - Predict] Processing 1 short region(s).\n",
      "[16:10:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5f4837a1a0>\n",
      "[16:10:40 - MdlStrTF] loading weights from /tmp/tmpgseiy9hb/model/variables/variables\n",
      "[16:10:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-226.\n",
      "[16:10:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:40 - Feature] Processed ParPgb:0.0-225.0 (median depth 126.0)\n",
      "[16:10:40 - Sampler] Took 0.02s to make features.\n",
      "[16:10:41 - PWorker] Processed 1 batches\n",
      "[16:10:41 - PWorker] All done, 0 remainder regions.\n",
      "[16:10:41 - Predict] Finished processing all regions.\n",
      "[16:10:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:44 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:10:44 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:10:44 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:10:44 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:10:44 - Predict] Found a GPU.\n",
      "[16:10:44 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:10:44 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:10:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe0641e5a80>\n",
      "[16:10:46 - MdlStrTF] loading weights from /tmp/tmpetdcwslm/model/variables/variables\n",
      "[16:10:46 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:10:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:10:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:46 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:10:46 - Feature] Processed ParPgb:0.0-248.0 (median depth 141.0)\n",
      "[16:10:46 - Sampler] Took 0.03s to make features.\n",
      "[16:10:46 - Sampler] Region ParPgb:0.0-248.0 (317 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:10:46 - PWorker] Processed 0 batches\n",
      "[16:10:46 - PWorker] All done, 1 remainder regions.\n",
      "[16:10:46 - Predict] Processing 1 short region(s).\n",
      "[16:10:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdfa7311420>\n",
      "[16:10:46 - MdlStrTF] loading weights from /tmp/tmpetdcwslm/model/variables/variables\n",
      "[16:10:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:10:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:46 - Feature] Processed ParPgb:0.0-248.0 (median depth 141.0)\n",
      "[16:10:46 - Sampler] Took 0.05s to make features.\n",
      "[16:10:47 - PWorker] Processed 1 batches\n",
      "[16:10:47 - PWorker] All done, 0 remainder regions.\n",
      "[16:10:47 - Predict] Finished processing all regions.\n",
      "[16:10:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:10:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:10:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:10:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:10:50 - Predict] Found a GPU.\n",
      "[16:10:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:10:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:10:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f68e541dae0>\n",
      "[16:10:51 - MdlStrTF] loading weights from /tmp/tmpuuvg97c8/model/variables/variables\n",
      "[16:10:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:10:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:10:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:54 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-259.\n",
      "[16:10:54 - Feature] Processed ParPgb:0.0-259.0 (median depth 119.0)\n",
      "[16:10:54 - Sampler] Took 2.48s to make features.\n",
      "[16:10:54 - Sampler] Region ParPgb:0.0-259.0 (342 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:10:54 - PWorker] Processed 0 batches\n",
      "[16:10:54 - PWorker] All done, 1 remainder regions.\n",
      "[16:10:54 - Predict] Processing 1 short region(s).\n",
      "[16:10:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:10:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6820485fc0>\n",
      "[16:10:54 - MdlStrTF] loading weights from /tmp/tmpuuvg97c8/model/variables/variables\n",
      "[16:10:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-260.\n",
      "[16:10:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:10:55 - Feature] Processed ParPgb:0.0-259.0 (median depth 119.0)\n",
      "[16:10:55 - Sampler] Took 0.21s to make features.\n",
      "[16:10:55 - PWorker] Processed 1 batches\n",
      "[16:10:55 - PWorker] All done, 0 remainder regions.\n",
      "[16:10:55 - Predict] Finished processing all regions.\n",
      "[16:10:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:10:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:10:59 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:10:59 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:10:59 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:10:59 - Predict] Found a GPU.\n",
      "[16:10:59 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:10:59 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:10:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f623b59dae0>\n",
      "[16:11:00 - MdlStrTF] loading weights from /tmp/tmpx8n4dv97/model/variables/variables\n",
      "[16:11:00 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:11:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:11:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:00 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-237.\n",
      "[16:11:00 - Feature] Processed ParPgb:0.0-237.0 (median depth 100.0)\n",
      "[16:11:00 - Sampler] Took 0.03s to make features.\n",
      "[16:11:00 - Sampler] Region ParPgb:0.0-237.0 (305 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:11:00 - PWorker] Processed 0 batches\n",
      "[16:11:00 - PWorker] All done, 1 remainder regions.\n",
      "[16:11:00 - Predict] Processing 1 short region(s).\n",
      "[16:11:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f61a9c9a170>\n",
      "[16:11:00 - MdlStrTF] loading weights from /tmp/tmpx8n4dv97/model/variables/variables\n",
      "[16:11:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-238.\n",
      "[16:11:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:00 - Feature] Processed ParPgb:0.0-237.0 (median depth 100.0)\n",
      "[16:11:00 - Sampler] Took 0.06s to make features.\n",
      "[16:11:01 - PWorker] Processed 1 batches\n",
      "[16:11:01 - PWorker] All done, 0 remainder regions.\n",
      "[16:11:01 - Predict] Finished processing all regions.\n",
      "[16:11:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:11:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:11:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:11:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:11:04 - Predict] Found a GPU.\n",
      "[16:11:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:11:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:11:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f647c075ae0>\n",
      "[16:11:06 - MdlStrTF] loading weights from /tmp/tmps5vkc5xq/model/variables/variables\n",
      "[16:11:06 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:11:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:11:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:06 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[16:11:06 - Feature] Processed ParPgb:0.0-250.0 (median depth 32.0)\n",
      "[16:11:06 - Sampler] Took 0.12s to make features.\n",
      "[16:11:06 - Sampler] Region ParPgb:0.0-250.0 (278 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:11:06 - PWorker] Processed 0 batches\n",
      "[16:11:06 - PWorker] All done, 1 remainder regions.\n",
      "[16:11:06 - Predict] Processing 1 short region(s).\n",
      "[16:11:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f63ec1d9480>\n",
      "[16:11:06 - MdlStrTF] loading weights from /tmp/tmps5vkc5xq/model/variables/variables\n",
      "[16:11:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[16:11:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:06 - Feature] Processed ParPgb:0.0-250.0 (median depth 32.0)\n",
      "[16:11:06 - Sampler] Took 0.06s to make features.\n",
      "[16:11:07 - PWorker] Processed 1 batches\n",
      "[16:11:07 - PWorker] All done, 0 remainder regions.\n",
      "[16:11:07 - Predict] Finished processing all regions.\n",
      "[16:11:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:10 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:11:10 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:11:10 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:11:10 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:11:10 - Predict] Found a GPU.\n",
      "[16:11:10 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:11:10 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:11:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:12 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f30682c1ae0>\n",
      "[16:11:12 - MdlStrTF] loading weights from /tmp/tmpkfh72ejz/model/variables/variables\n",
      "[16:11:12 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:11:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:11:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:13 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-211.\n",
      "[16:11:13 - Feature] Processed ParPgb:0.0-211.0 (median depth 141.0)\n",
      "[16:11:13 - Sampler] Took 1.19s to make features.\n",
      "[16:11:13 - Sampler] Region ParPgb:0.0-211.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:11:13 - PWorker] Processed 0 batches\n",
      "[16:11:13 - PWorker] All done, 1 remainder regions.\n",
      "[16:11:13 - Predict] Processing 1 short region(s).\n",
      "[16:11:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2fc9415480>\n",
      "[16:11:13 - MdlStrTF] loading weights from /tmp/tmpkfh72ejz/model/variables/variables\n",
      "[16:11:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-212.\n",
      "[16:11:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:14 - Feature] Processed ParPgb:0.0-211.0 (median depth 141.0)\n",
      "[16:11:14 - Sampler] Took 0.19s to make features.\n",
      "[16:11:14 - PWorker] Processed 1 batches\n",
      "[16:11:14 - PWorker] All done, 0 remainder regions.\n",
      "[16:11:14 - Predict] Finished processing all regions.\n",
      "[16:11:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:17 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:11:18 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:11:18 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:11:18 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:11:18 - Predict] Found a GPU.\n",
      "[16:11:18 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:11:18 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:11:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6ec70f5ae0>\n",
      "[16:11:19 - MdlStrTF] loading weights from /tmp/tmpc9iar8at/model/variables/variables\n",
      "[16:11:19 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:11:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:11:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:19 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:11:19 - Feature] Processed ParPgb:0.0-248.0 (median depth 110.0)\n",
      "[16:11:19 - Sampler] Took 0.17s to make features.\n",
      "[16:11:19 - Sampler] Region ParPgb:0.0-248.0 (311 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:11:19 - PWorker] Processed 0 batches\n",
      "[16:11:19 - PWorker] All done, 1 remainder regions.\n",
      "[16:11:19 - Predict] Processing 1 short region(s).\n",
      "[16:11:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6e2830a080>\n",
      "[16:11:20 - MdlStrTF] loading weights from /tmp/tmpc9iar8at/model/variables/variables\n",
      "[16:11:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:11:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:20 - Feature] Processed ParPgb:0.0-248.0 (median depth 110.0)\n",
      "[16:11:20 - Sampler] Took 0.05s to make features.\n",
      "[16:11:20 - PWorker] Processed 1 batches\n",
      "[16:11:20 - PWorker] All done, 0 remainder regions.\n",
      "[16:11:20 - Predict] Finished processing all regions.\n",
      "[16:11:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:23 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:11:23 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:11:23 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:11:23 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:11:24 - Predict] Found a GPU.\n",
      "[16:11:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:11:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:11:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f14fbfe1ae0>\n",
      "[16:11:25 - MdlStrTF] loading weights from /tmp/tmpejbuo0mr/model/variables/variables\n",
      "[16:11:25 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:11:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:11:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:25 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-212.\n",
      "[16:11:25 - Feature] Processed ParPgb:0.0-212.0 (median depth 100.0)\n",
      "[16:11:25 - Sampler] Took 0.04s to make features.\n",
      "[16:11:25 - Sampler] Region ParPgb:0.0-212.0 (269 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:11:25 - PWorker] Processed 0 batches\n",
      "[16:11:25 - PWorker] All done, 1 remainder regions.\n",
      "[16:11:25 - Predict] Processing 1 short region(s).\n",
      "[16:11:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f146c205480>\n",
      "[16:11:25 - MdlStrTF] loading weights from /tmp/tmpejbuo0mr/model/variables/variables\n",
      "[16:11:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-213.\n",
      "[16:11:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:25 - Feature] Processed ParPgb:0.0-212.0 (median depth 100.0)\n",
      "[16:11:25 - Sampler] Took 0.03s to make features.\n",
      "[16:11:26 - PWorker] Processed 1 batches\n",
      "[16:11:26 - PWorker] All done, 0 remainder regions.\n",
      "[16:11:26 - Predict] Finished processing all regions.\n",
      "[16:11:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:11:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:11:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:11:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:11:29 - Predict] Found a GPU.\n",
      "[16:11:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:11:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:11:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2680845ae0>\n",
      "[16:11:31 - MdlStrTF] loading weights from /tmp/tmp_fg045zm/model/variables/variables\n",
      "[16:11:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:11:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:11:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[16:11:31 - Feature] Processed ParPgb:0.0-247.0 (median depth 99.0)\n",
      "[16:11:31 - Sampler] Took 0.13s to make features.\n",
      "[16:11:31 - Sampler] Region ParPgb:0.0-247.0 (309 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:11:31 - PWorker] Processed 0 batches\n",
      "[16:11:31 - PWorker] All done, 1 remainder regions.\n",
      "[16:11:31 - Predict] Processing 1 short region(s).\n",
      "[16:11:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f25f0225480>\n",
      "[16:11:31 - MdlStrTF] loading weights from /tmp/tmp_fg045zm/model/variables/variables\n",
      "[16:11:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[16:11:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:31 - Feature] Processed ParPgb:0.0-247.0 (median depth 99.0)\n",
      "[16:11:31 - Sampler] Took 0.10s to make features.\n",
      "[16:11:32 - PWorker] Processed 1 batches\n",
      "[16:11:32 - PWorker] All done, 0 remainder regions.\n",
      "[16:11:32 - Predict] Finished processing all regions.\n",
      "[16:11:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:35 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:11:35 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:11:35 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:11:35 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:11:35 - Predict] Found a GPU.\n",
      "[16:11:35 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:11:35 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:11:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd6eeee5ae0>\n",
      "[16:11:37 - MdlStrTF] loading weights from /tmp/tmpx5di4obw/model/variables/variables\n",
      "[16:11:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:11:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:11:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:38 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-261.\n",
      "[16:11:38 - Feature] Processed ParPgb:0.0-261.0 (median depth 114.0)\n",
      "[16:11:38 - Sampler] Took 1.58s to make features.\n",
      "[16:11:38 - Sampler] Region ParPgb:0.0-261.0 (333 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:11:38 - PWorker] Processed 0 batches\n",
      "[16:11:38 - PWorker] All done, 1 remainder regions.\n",
      "[16:11:38 - Predict] Processing 1 short region(s).\n",
      "[16:11:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd6d01b6170>\n",
      "[16:11:39 - MdlStrTF] loading weights from /tmp/tmpx5di4obw/model/variables/variables\n",
      "[16:11:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-262.\n",
      "[16:11:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:41 - Feature] Processed ParPgb:0.0-261.0 (median depth 114.0)\n",
      "[16:11:41 - Sampler] Took 2.48s to make features.\n",
      "[16:11:42 - PWorker] Processed 1 batches\n",
      "[16:11:42 - PWorker] All done, 0 remainder regions.\n",
      "[16:11:42 - Predict] Finished processing all regions.\n",
      "[16:11:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:45 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:11:45 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:11:45 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:11:45 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:11:45 - Predict] Found a GPU.\n",
      "[16:11:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:11:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:11:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f23c9c69ae0>\n",
      "[16:11:47 - MdlStrTF] loading weights from /tmp/tmpbiseylur/model/variables/variables\n",
      "[16:11:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:11:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:11:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[16:11:47 - Feature] Processed ParPgb:0.0-247.0 (median depth 134.0)\n",
      "[16:11:47 - Sampler] Took 0.02s to make features.\n",
      "[16:11:47 - Sampler] Region ParPgb:0.0-247.0 (330 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:11:47 - PWorker] Processed 0 batches\n",
      "[16:11:47 - PWorker] All done, 1 remainder regions.\n",
      "[16:11:47 - Predict] Processing 1 short region(s).\n",
      "[16:11:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f232835e170>\n",
      "[16:11:47 - MdlStrTF] loading weights from /tmp/tmpbiseylur/model/variables/variables\n",
      "[16:11:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[16:11:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:50 - Feature] Processed ParPgb:0.0-247.0 (median depth 134.0)\n",
      "[16:11:50 - Sampler] Took 2.59s to make features.\n",
      "[16:11:50 - PWorker] Processed 1 batches\n",
      "[16:11:50 - PWorker] All done, 0 remainder regions.\n",
      "[16:11:50 - Predict] Finished processing all regions.\n",
      "[16:11:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:11:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:11:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:11:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:11:54 - Predict] Found a GPU.\n",
      "[16:11:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:11:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:11:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f965bd99a80>\n",
      "[16:11:55 - MdlStrTF] loading weights from /tmp/tmpto7jxft5/model/variables/variables\n",
      "[16:11:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:11:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:11:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-241.\n",
      "[16:11:55 - Feature] Processed ParPgb:0.0-241.0 (median depth 70.0)\n",
      "[16:11:55 - Sampler] Took 0.05s to make features.\n",
      "[16:11:55 - Sampler] Region ParPgb:0.0-241.0 (288 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:11:55 - PWorker] Processed 0 batches\n",
      "[16:11:55 - PWorker] All done, 1 remainder regions.\n",
      "[16:11:55 - Predict] Processing 1 short region(s).\n",
      "[16:11:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:11:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f95bce95930>\n",
      "[16:11:56 - MdlStrTF] loading weights from /tmp/tmpto7jxft5/model/variables/variables\n",
      "[16:11:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-242.\n",
      "[16:11:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:11:56 - Feature] Processed ParPgb:0.0-241.0 (median depth 70.0)\n",
      "[16:11:56 - Sampler] Took 0.15s to make features.\n",
      "[16:11:56 - PWorker] Processed 1 batches\n",
      "[16:11:56 - PWorker] All done, 0 remainder regions.\n",
      "[16:11:56 - Predict] Finished processing all regions.\n",
      "[16:11:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:11:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:12:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:12:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:12:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:12:00 - Predict] Found a GPU.\n",
      "[16:12:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:12:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:12:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f309b9e5ae0>\n",
      "[16:12:01 - MdlStrTF] loading weights from /tmp/tmpnsrf7y4p/model/variables/variables\n",
      "[16:12:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:12:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:12:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:12:01 - Feature] Processed ParPgb:0.0-248.0 (median depth 102.0)\n",
      "[16:12:01 - Sampler] Took 0.04s to make features.\n",
      "[16:12:01 - Sampler] Region ParPgb:0.0-248.0 (317 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:12:01 - PWorker] Processed 0 batches\n",
      "[16:12:01 - PWorker] All done, 1 remainder regions.\n",
      "[16:12:01 - Predict] Processing 1 short region(s).\n",
      "[16:12:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f300ab25480>\n",
      "[16:12:01 - MdlStrTF] loading weights from /tmp/tmpnsrf7y4p/model/variables/variables\n",
      "[16:12:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:12:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:02 - Feature] Processed ParPgb:0.0-248.0 (median depth 102.0)\n",
      "[16:12:02 - Sampler] Took 0.03s to make features.\n",
      "[16:12:02 - PWorker] Processed 1 batches\n",
      "[16:12:02 - PWorker] All done, 0 remainder regions.\n",
      "[16:12:02 - Predict] Finished processing all regions.\n",
      "[16:12:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:12:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:12:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:12:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:12:06 - Predict] Found a GPU.\n",
      "[16:12:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:12:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:12:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0199565ae0>\n",
      "[16:12:07 - MdlStrTF] loading weights from /tmp/tmpkkbrs8ts/model/variables/variables\n",
      "[16:12:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:12:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:12:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-210.\n",
      "[16:12:07 - Feature] Processed ParPgb:0.0-210.0 (median depth 69.0)\n",
      "[16:12:07 - Sampler] Took 0.03s to make features.\n",
      "[16:12:07 - Sampler] Region ParPgb:0.0-210.0 (265 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:12:07 - PWorker] Processed 0 batches\n",
      "[16:12:07 - PWorker] All done, 1 remainder regions.\n",
      "[16:12:07 - Predict] Processing 1 short region(s).\n",
      "[16:12:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f00f8625480>\n",
      "[16:12:07 - MdlStrTF] loading weights from /tmp/tmpkkbrs8ts/model/variables/variables\n",
      "[16:12:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-211.\n",
      "[16:12:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:09 - Feature] Processed ParPgb:0.0-210.0 (median depth 69.0)\n",
      "[16:12:09 - Sampler] Took 1.92s to make features.\n",
      "[16:12:10 - PWorker] Processed 1 batches\n",
      "[16:12:10 - PWorker] All done, 0 remainder regions.\n",
      "[16:12:10 - Predict] Finished processing all regions.\n",
      "[16:12:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:13 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:12:13 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:12:13 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:12:13 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:12:13 - Predict] Found a GPU.\n",
      "[16:12:13 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:12:13 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:12:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff844275ae0>\n",
      "[16:12:15 - MdlStrTF] loading weights from /tmp/tmpuginckoa/model/variables/variables\n",
      "[16:12:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:12:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:12:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-256.\n",
      "[16:12:15 - Feature] Processed ParPgb:0.0-256.0 (median depth 171.0)\n",
      "[16:12:15 - Sampler] Took 0.03s to make features.\n",
      "[16:12:15 - Sampler] Region ParPgb:0.0-256.0 (367 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:12:15 - PWorker] Processed 0 batches\n",
      "[16:12:15 - PWorker] All done, 1 remainder regions.\n",
      "[16:12:15 - Predict] Processing 1 short region(s).\n",
      "[16:12:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff787475480>\n",
      "[16:12:15 - MdlStrTF] loading weights from /tmp/tmpuginckoa/model/variables/variables\n",
      "[16:12:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-257.\n",
      "[16:12:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:15 - Feature] Processed ParPgb:0.0-256.0 (median depth 171.0)\n",
      "[16:12:15 - Sampler] Took 0.04s to make features.\n",
      "[16:12:16 - PWorker] Processed 1 batches\n",
      "[16:12:16 - PWorker] All done, 0 remainder regions.\n",
      "[16:12:16 - Predict] Finished processing all regions.\n",
      "[16:12:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:12:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:12:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:12:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:12:19 - Predict] Found a GPU.\n",
      "[16:12:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:12:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:12:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f112cc89ae0>\n",
      "[16:12:20 - MdlStrTF] loading weights from /tmp/tmpcgl7mp4q/model/variables/variables\n",
      "[16:12:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:12:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:12:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[16:12:21 - Feature] Processed ParPgb:0.0-252.0 (median depth 62.0)\n",
      "[16:12:21 - Sampler] Took 0.14s to make features.\n",
      "[16:12:21 - Sampler] Region ParPgb:0.0-252.0 (292 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:12:21 - PWorker] Processed 0 batches\n",
      "[16:12:21 - PWorker] All done, 1 remainder regions.\n",
      "[16:12:21 - Predict] Processing 1 short region(s).\n",
      "[16:12:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f108dd75ae0>\n",
      "[16:12:21 - MdlStrTF] loading weights from /tmp/tmpcgl7mp4q/model/variables/variables\n",
      "[16:12:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[16:12:21 - Feature] Processed ParPgb:0.0-252.0 (median depth 62.0)\n",
      "[16:12:21 - Sampler] Took 0.04s to make features.\n",
      "[16:12:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:22 - PWorker] Processed 1 batches\n",
      "[16:12:22 - PWorker] All done, 0 remainder regions.\n",
      "[16:12:22 - Predict] Finished processing all regions.\n",
      "[16:12:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:12:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:12:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:12:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:12:25 - Predict] Found a GPU.\n",
      "[16:12:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:12:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:12:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f764ff1dae0>\n",
      "[16:12:26 - MdlStrTF] loading weights from /tmp/tmp4t0v4tn8/model/variables/variables\n",
      "[16:12:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:12:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:12:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:12:26 - Feature] Processed ParPgb:0.0-246.0 (median depth 80.0)\n",
      "[16:12:26 - Sampler] Took 0.08s to make features.\n",
      "[16:12:26 - Sampler] Region ParPgb:0.0-246.0 (303 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:12:26 - PWorker] Processed 0 batches\n",
      "[16:12:26 - PWorker] All done, 1 remainder regions.\n",
      "[16:12:26 - Predict] Processing 1 short region(s).\n",
      "[16:12:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f75c00c9b10>\n",
      "[16:12:27 - MdlStrTF] loading weights from /tmp/tmp4t0v4tn8/model/variables/variables\n",
      "[16:12:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:12:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:27 - Feature] Processed ParPgb:0.0-246.0 (median depth 80.0)\n",
      "[16:12:27 - Sampler] Took 0.04s to make features.\n",
      "[16:12:27 - PWorker] Processed 1 batches\n",
      "[16:12:27 - PWorker] All done, 0 remainder regions.\n",
      "[16:12:27 - Predict] Finished processing all regions.\n",
      "[16:12:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:12:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:12:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:12:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:12:31 - Predict] Found a GPU.\n",
      "[16:12:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:12:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:12:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f58bc631ae0>\n",
      "[16:12:32 - MdlStrTF] loading weights from /tmp/tmp6h_b7kz5/model/variables/variables\n",
      "[16:12:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:12:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:12:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:32 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[16:12:32 - Feature] Processed ParPgb:0.0-247.0 (median depth 81.0)\n",
      "[16:12:32 - Sampler] Took 0.05s to make features.\n",
      "[16:12:32 - Sampler] Region ParPgb:0.0-247.0 (290 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:12:32 - PWorker] Processed 0 batches\n",
      "[16:12:32 - PWorker] All done, 1 remainder regions.\n",
      "[16:12:32 - Predict] Processing 1 short region(s).\n",
      "[16:12:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f581d799480>\n",
      "[16:12:33 - MdlStrTF] loading weights from /tmp/tmp6h_b7kz5/model/variables/variables\n",
      "[16:12:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[16:12:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:33 - Feature] Processed ParPgb:0.0-247.0 (median depth 81.0)\n",
      "[16:12:33 - Sampler] Took 0.03s to make features.\n",
      "[16:12:33 - PWorker] Processed 1 batches\n",
      "[16:12:33 - PWorker] All done, 0 remainder regions.\n",
      "[16:12:33 - Predict] Finished processing all regions.\n",
      "[16:12:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:12:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:12:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:12:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:12:37 - Predict] Found a GPU.\n",
      "[16:12:37 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:12:37 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:12:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbca53d5ae0>\n",
      "[16:12:38 - MdlStrTF] loading weights from /tmp/tmpt5_1hv55/model/variables/variables\n",
      "[16:12:38 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:12:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:12:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:38 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[16:12:38 - Feature] Processed ParPgb:0.0-243.0 (median depth 95.0)\n",
      "[16:12:38 - Sampler] Took 0.15s to make features.\n",
      "[16:12:38 - Sampler] Region ParPgb:0.0-243.0 (318 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:12:38 - PWorker] Processed 0 batches\n",
      "[16:12:38 - PWorker] All done, 1 remainder regions.\n",
      "[16:12:38 - Predict] Processing 1 short region(s).\n",
      "[16:12:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbc105edb10>\n",
      "[16:12:39 - MdlStrTF] loading weights from /tmp/tmpt5_1hv55/model/variables/variables\n",
      "[16:12:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[16:12:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:39 - Feature] Processed ParPgb:0.0-243.0 (median depth 95.0)\n",
      "[16:12:39 - Sampler] Took 0.10s to make features.\n",
      "[16:12:39 - PWorker] Processed 1 batches\n",
      "[16:12:39 - PWorker] All done, 0 remainder regions.\n",
      "[16:12:39 - Predict] Finished processing all regions.\n",
      "[16:12:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:12:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:12:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:12:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:12:43 - Predict] Found a GPU.\n",
      "[16:12:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:12:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:12:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd35952dae0>\n",
      "[16:12:44 - MdlStrTF] loading weights from /tmp/tmp2hie4byg/model/variables/variables\n",
      "[16:12:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:12:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:12:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-270.\n",
      "[16:12:45 - Feature] Processed ParPgb:0.0-270.0 (median depth 125.0)\n",
      "[16:12:45 - Sampler] Took 1.38s to make features.\n",
      "[16:12:45 - Sampler] Region ParPgb:0.0-270.0 (330 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:12:46 - PWorker] Processed 0 batches\n",
      "[16:12:46 - PWorker] All done, 1 remainder regions.\n",
      "[16:12:46 - Predict] Processing 1 short region(s).\n",
      "[16:12:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd2b8f09450>\n",
      "[16:12:46 - MdlStrTF] loading weights from /tmp/tmp2hie4byg/model/variables/variables\n",
      "[16:12:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-271.\n",
      "[16:12:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:46 - Feature] Processed ParPgb:0.0-270.0 (median depth 125.0)\n",
      "[16:12:46 - Sampler] Took 0.04s to make features.\n",
      "[16:12:47 - PWorker] Processed 1 batches\n",
      "[16:12:47 - PWorker] All done, 0 remainder regions.\n",
      "[16:12:47 - Predict] Finished processing all regions.\n",
      "[16:12:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:12:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:12:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:12:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:12:50 - Predict] Found a GPU.\n",
      "[16:12:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:12:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:12:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9736679ae0>\n",
      "[16:12:51 - MdlStrTF] loading weights from /tmp/tmpb5rkm1my/model/variables/variables\n",
      "[16:12:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:12:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:12:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-236.\n",
      "[16:12:51 - Feature] Processed ParPgb:0.0-236.0 (median depth 139.0)\n",
      "[16:12:51 - Sampler] Took 0.05s to make features.\n",
      "[16:12:51 - Sampler] Region ParPgb:0.0-236.0 (312 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:12:51 - PWorker] Processed 0 batches\n",
      "[16:12:51 - PWorker] All done, 1 remainder regions.\n",
      "[16:12:51 - Predict] Processing 1 short region(s).\n",
      "[16:12:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9681671450>\n",
      "[16:12:52 - MdlStrTF] loading weights from /tmp/tmpb5rkm1my/model/variables/variables\n",
      "[16:12:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-237.\n",
      "[16:12:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:52 - Feature] Processed ParPgb:0.0-236.0 (median depth 139.0)\n",
      "[16:12:52 - Sampler] Took 0.07s to make features.\n",
      "[16:12:52 - PWorker] Processed 1 batches\n",
      "[16:12:52 - PWorker] All done, 0 remainder regions.\n",
      "[16:12:52 - Predict] Finished processing all regions.\n",
      "[16:12:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:12:56 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:12:56 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:12:56 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:12:56 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:12:56 - Predict] Found a GPU.\n",
      "[16:12:56 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:12:56 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:12:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa31de75ae0>\n",
      "[16:12:57 - MdlStrTF] loading weights from /tmp/tmpag1kzh4f/model/variables/variables\n",
      "[16:12:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:12:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:12:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:12:57 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[16:12:57 - Feature] Processed ParPgb:0.0-243.0 (median depth 91.0)\n",
      "[16:12:57 - Sampler] Took 0.10s to make features.\n",
      "[16:12:57 - Sampler] Region ParPgb:0.0-243.0 (286 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:12:57 - PWorker] Processed 0 batches\n",
      "[16:12:57 - PWorker] All done, 1 remainder regions.\n",
      "[16:12:57 - Predict] Processing 1 short region(s).\n",
      "[16:12:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:12:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa28cc79480>\n",
      "[16:12:58 - MdlStrTF] loading weights from /tmp/tmpag1kzh4f/model/variables/variables\n",
      "[16:12:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[16:12:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:00 - Feature] Processed ParPgb:0.0-243.0 (median depth 91.0)\n",
      "[16:13:00 - Sampler] Took 2.31s to make features.\n",
      "[16:13:01 - PWorker] Processed 1 batches\n",
      "[16:13:01 - PWorker] All done, 0 remainder regions.\n",
      "[16:13:01 - Predict] Finished processing all regions.\n",
      "[16:13:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:13:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:13:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:13:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:13:04 - Predict] Found a GPU.\n",
      "[16:13:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:13:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:13:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff959071ae0>\n",
      "[16:13:05 - MdlStrTF] loading weights from /tmp/tmp60tyd7u5/model/variables/variables\n",
      "[16:13:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:13:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:13:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:13:05 - Feature] Processed ParPgb:0.0-248.0 (median depth 60.0)\n",
      "[16:13:05 - Sampler] Took 0.12s to make features.\n",
      "[16:13:05 - Sampler] Region ParPgb:0.0-248.0 (288 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:13:05 - PWorker] Processed 0 batches\n",
      "[16:13:05 - PWorker] All done, 1 remainder regions.\n",
      "[16:13:05 - Predict] Processing 1 short region(s).\n",
      "[16:13:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff8c8225ff0>\n",
      "[16:13:06 - MdlStrTF] loading weights from /tmp/tmp60tyd7u5/model/variables/variables\n",
      "[16:13:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:13:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:06 - Feature] Processed ParPgb:0.0-248.0 (median depth 60.0)\n",
      "[16:13:06 - Sampler] Took 0.05s to make features.\n",
      "[16:13:07 - PWorker] Processed 1 batches\n",
      "[16:13:07 - PWorker] All done, 0 remainder regions.\n",
      "[16:13:07 - Predict] Finished processing all regions.\n",
      "[16:13:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:10 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:13:10 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:13:10 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:13:10 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:13:10 - Predict] Found a GPU.\n",
      "[16:13:10 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:13:10 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:13:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd0e5c0dae0>\n",
      "[16:13:11 - MdlStrTF] loading weights from /tmp/tmpng3a0bv6/model/variables/variables\n",
      "[16:13:11 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:13:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:13:11 - Sampler] Took 0.01s to make features.\n",
      "[16:13:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:11 - PWorker] Processed 0 batches\n",
      "[16:13:11 - PWorker] All done, 0 remainder regions.\n",
      "[16:13:11 - Predict] Finished processing all regions.\n",
      "[16:13:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:13 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:13:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:13:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:13:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:13:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:13:15 - Predict] Found a GPU.\n",
      "[16:13:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:13:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:13:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fde133c1ae0>\n",
      "[16:13:16 - MdlStrTF] loading weights from /tmp/tmpjoycmeul/model/variables/variables\n",
      "[16:13:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:13:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:13:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[16:13:18 - Feature] Processed ParPgb:0.0-247.0 (median depth 112.0)\n",
      "[16:13:18 - Sampler] Took 2.16s to make features.\n",
      "[16:13:18 - Sampler] Region ParPgb:0.0-247.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:13:18 - PWorker] Processed 0 batches\n",
      "[16:13:18 - PWorker] All done, 1 remainder regions.\n",
      "[16:13:18 - Predict] Processing 1 short region(s).\n",
      "[16:13:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdd82289480>\n",
      "[16:13:18 - MdlStrTF] loading weights from /tmp/tmpjoycmeul/model/variables/variables\n",
      "[16:13:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[16:13:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:19 - Feature] Processed ParPgb:0.0-247.0 (median depth 112.0)\n",
      "[16:13:19 - Sampler] Took 0.04s to make features.\n",
      "[16:13:19 - PWorker] Processed 1 batches\n",
      "[16:13:19 - PWorker] All done, 0 remainder regions.\n",
      "[16:13:19 - Predict] Finished processing all regions.\n",
      "[16:13:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:13:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:13:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:13:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:13:23 - Predict] Found a GPU.\n",
      "[16:13:23 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:13:23 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:13:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa3a6f05a80>\n",
      "[16:13:24 - MdlStrTF] loading weights from /tmp/tmpmb1pxi0y/model/variables/variables\n",
      "[16:13:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:13:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:13:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-262.\n",
      "[16:13:24 - Feature] Processed ParPgb:0.0-262.0 (median depth 125.0)\n",
      "[16:13:24 - Sampler] Took 0.04s to make features.\n",
      "[16:13:24 - Sampler] Region ParPgb:0.0-262.0 (338 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:13:24 - PWorker] Processed 0 batches\n",
      "[16:13:24 - PWorker] All done, 1 remainder regions.\n",
      "[16:13:24 - Predict] Processing 1 short region(s).\n",
      "[16:13:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa2f1f6d420>\n",
      "[16:13:24 - MdlStrTF] loading weights from /tmp/tmpmb1pxi0y/model/variables/variables\n",
      "[16:13:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-263.\n",
      "[16:13:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:29 - Feature] Processed ParPgb:0.0-262.0 (median depth 125.0)\n",
      "[16:13:29 - Sampler] Took 4.43s to make features.\n",
      "[16:13:29 - PWorker] Processed 1 batches\n",
      "[16:13:29 - PWorker] All done, 0 remainder regions.\n",
      "[16:13:29 - Predict] Finished processing all regions.\n",
      "[16:13:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:33 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:13:33 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:13:33 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:13:33 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:13:33 - Predict] Found a GPU.\n",
      "[16:13:33 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:13:33 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:13:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f06afa8dae0>\n",
      "[16:13:34 - MdlStrTF] loading weights from /tmp/tmpv565ghvg/model/variables/variables\n",
      "[16:13:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:13:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:13:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:36 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-236.\n",
      "[16:13:36 - Feature] Processed ParPgb:0.0-236.0 (median depth 99.0)\n",
      "[16:13:36 - Sampler] Took 2.12s to make features.\n",
      "[16:13:36 - Sampler] Region ParPgb:0.0-236.0 (321 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:13:36 - PWorker] Processed 0 batches\n",
      "[16:13:36 - PWorker] All done, 1 remainder regions.\n",
      "[16:13:36 - Predict] Processing 1 short region(s).\n",
      "[16:13:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0610c16e90>\n",
      "[16:13:37 - MdlStrTF] loading weights from /tmp/tmpv565ghvg/model/variables/variables\n",
      "[16:13:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-237.\n",
      "[16:13:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:37 - Feature] Processed ParPgb:0.0-236.0 (median depth 99.0)\n",
      "[16:13:37 - Sampler] Took 0.08s to make features.\n",
      "[16:13:37 - PWorker] Processed 1 batches\n",
      "[16:13:37 - PWorker] All done, 0 remainder regions.\n",
      "[16:13:37 - Predict] Finished processing all regions.\n",
      "[16:13:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:13:41 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:13:41 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:13:41 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:13:41 - Predict] Found a GPU.\n",
      "[16:13:41 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:13:41 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:13:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f93bf201ae0>\n",
      "[16:13:42 - MdlStrTF] loading weights from /tmp/tmpt4_0z5et/model/variables/variables\n",
      "[16:13:42 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:13:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:13:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:42 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[16:13:42 - Feature] Processed ParPgb:0.0-253.0 (median depth 85.0)\n",
      "[16:13:42 - Sampler] Took 0.04s to make features.\n",
      "[16:13:42 - Sampler] Region ParPgb:0.0-253.0 (303 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:13:42 - PWorker] Processed 0 batches\n",
      "[16:13:42 - PWorker] All done, 1 remainder regions.\n",
      "[16:13:42 - Predict] Processing 1 short region(s).\n",
      "[16:13:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f932e445480>\n",
      "[16:13:43 - MdlStrTF] loading weights from /tmp/tmpt4_0z5et/model/variables/variables\n",
      "[16:13:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[16:13:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:43 - Feature] Processed ParPgb:0.0-253.0 (median depth 85.0)\n",
      "[16:13:43 - Sampler] Took 0.16s to make features.\n",
      "[16:13:43 - PWorker] Processed 1 batches\n",
      "[16:13:43 - PWorker] All done, 0 remainder regions.\n",
      "[16:13:43 - Predict] Finished processing all regions.\n",
      "[16:13:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:13:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:13:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:13:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:13:47 - Predict] Found a GPU.\n",
      "[16:13:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:13:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:13:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fca62be5ae0>\n",
      "[16:13:48 - MdlStrTF] loading weights from /tmp/tmp0lxm58_j/model/variables/variables\n",
      "[16:13:48 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:13:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:13:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:48 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-190.\n",
      "[16:13:48 - Feature] Processed ParPgb:0.0-190.0 (median depth 1.0)\n",
      "[16:13:48 - Sampler] Took 0.07s to make features.\n",
      "[16:13:48 - Sampler] Region ParPgb:0.0-190.0 (192 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:13:48 - PWorker] Processed 0 batches\n",
      "[16:13:48 - PWorker] All done, 1 remainder regions.\n",
      "[16:13:48 - Predict] Processing 1 short region(s).\n",
      "[16:13:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc9d1d55480>\n",
      "[16:13:49 - MdlStrTF] loading weights from /tmp/tmp0lxm58_j/model/variables/variables\n",
      "[16:13:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-191.\n",
      "[16:13:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:51 - Feature] Processed ParPgb:0.0-190.0 (median depth 1.0)\n",
      "[16:13:51 - Sampler] Took 2.03s to make features.\n",
      "[16:13:51 - PWorker] Processed 1 batches\n",
      "[16:13:51 - PWorker] All done, 0 remainder regions.\n",
      "[16:13:51 - Predict] Finished processing all regions.\n",
      "[16:13:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:13:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:13:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:13:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:13:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:13:55 - Predict] Found a GPU.\n",
      "[16:13:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:13:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:13:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7feee58a9ae0>\n",
      "[16:13:56 - MdlStrTF] loading weights from /tmp/tmp7zforx6s/model/variables/variables\n",
      "[16:13:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:13:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:13:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:58 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[16:13:58 - Feature] Processed ParPgb:0.0-245.0 (median depth 127.0)\n",
      "[16:13:58 - Sampler] Took 1.72s to make features.\n",
      "[16:13:58 - Sampler] Region ParPgb:0.0-245.0 (332 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:13:58 - PWorker] Processed 0 batches\n",
      "[16:13:58 - PWorker] All done, 1 remainder regions.\n",
      "[16:13:58 - Predict] Processing 1 short region(s).\n",
      "[16:13:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:13:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fee50291480>\n",
      "[16:13:58 - MdlStrTF] loading weights from /tmp/tmp7zforx6s/model/variables/variables\n",
      "[16:13:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[16:13:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:13:58 - Feature] Processed ParPgb:0.0-245.0 (median depth 127.0)\n",
      "[16:13:58 - Sampler] Took 0.07s to make features.\n",
      "[16:13:59 - PWorker] Processed 1 batches\n",
      "[16:13:59 - PWorker] All done, 0 remainder regions.\n",
      "[16:13:59 - Predict] Finished processing all regions.\n",
      "[16:14:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:14:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:14:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:14:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:14:02 - Predict] Found a GPU.\n",
      "[16:14:02 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:14:02 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:14:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ffa68fb5ae0>\n",
      "[16:14:04 - MdlStrTF] loading weights from /tmp/tmpl2zdldvc/model/variables/variables\n",
      "[16:14:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:14:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:14:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-239.\n",
      "[16:14:04 - Feature] Processed ParPgb:0.0-239.0 (median depth 106.0)\n",
      "[16:14:04 - Sampler] Took 0.03s to make features.\n",
      "[16:14:04 - Sampler] Region ParPgb:0.0-239.0 (287 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:14:04 - PWorker] Processed 0 batches\n",
      "[16:14:04 - PWorker] All done, 1 remainder regions.\n",
      "[16:14:04 - Predict] Processing 1 short region(s).\n",
      "[16:14:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff9d81c1480>\n",
      "[16:14:04 - MdlStrTF] loading weights from /tmp/tmpl2zdldvc/model/variables/variables\n",
      "[16:14:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-240.\n",
      "[16:14:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:04 - Feature] Processed ParPgb:0.0-239.0 (median depth 106.0)\n",
      "[16:14:04 - Sampler] Took 0.16s to make features.\n",
      "[16:14:05 - PWorker] Processed 1 batches\n",
      "[16:14:05 - PWorker] All done, 0 remainder regions.\n",
      "[16:14:05 - Predict] Finished processing all regions.\n",
      "[16:14:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:14:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:14:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:14:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:14:08 - Predict] Found a GPU.\n",
      "[16:14:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:14:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:14:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f155d309ae0>\n",
      "[16:14:10 - MdlStrTF] loading weights from /tmp/tmp9lmsfzii/model/variables/variables\n",
      "[16:14:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:14:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:14:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:10 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[16:14:10 - Feature] Processed ParPgb:0.0-251.0 (median depth 183.0)\n",
      "[16:14:10 - Sampler] Took 0.27s to make features.\n",
      "[16:14:10 - Sampler] Region ParPgb:0.0-251.0 (350 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:14:10 - PWorker] Processed 0 batches\n",
      "[16:14:10 - PWorker] All done, 1 remainder regions.\n",
      "[16:14:10 - Predict] Processing 1 short region(s).\n",
      "[16:14:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f14cc3a1b10>\n",
      "[16:14:10 - MdlStrTF] loading weights from /tmp/tmp9lmsfzii/model/variables/variables\n",
      "[16:14:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[16:14:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:10 - Feature] Processed ParPgb:0.0-251.0 (median depth 183.0)\n",
      "[16:14:10 - Sampler] Took 0.05s to make features.\n",
      "[16:14:11 - PWorker] Processed 1 batches\n",
      "[16:14:11 - PWorker] All done, 0 remainder regions.\n",
      "[16:14:11 - Predict] Finished processing all regions.\n",
      "[16:14:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:14:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:14:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:14:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:14:14 - Predict] Found a GPU.\n",
      "[16:14:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:14:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:14:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f44674a5a80>\n",
      "[16:14:16 - MdlStrTF] loading weights from /tmp/tmpsl4jkat1/model/variables/variables\n",
      "[16:14:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:14:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:14:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-241.\n",
      "[16:14:16 - Feature] Processed ParPgb:0.0-241.0 (median depth 170.0)\n",
      "[16:14:16 - Sampler] Took 0.08s to make features.\n",
      "[16:14:16 - Sampler] Region ParPgb:0.0-241.0 (314 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:14:16 - PWorker] Processed 0 batches\n",
      "[16:14:16 - PWorker] All done, 1 remainder regions.\n",
      "[16:14:16 - Predict] Processing 1 short region(s).\n",
      "[16:14:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f43c8672fb0>\n",
      "[16:14:16 - MdlStrTF] loading weights from /tmp/tmpsl4jkat1/model/variables/variables\n",
      "[16:14:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-242.\n",
      "[16:14:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:16 - Feature] Processed ParPgb:0.0-241.0 (median depth 170.0)\n",
      "[16:14:16 - Sampler] Took 0.07s to make features.\n",
      "[16:14:17 - PWorker] Processed 1 batches\n",
      "[16:14:17 - PWorker] All done, 0 remainder regions.\n",
      "[16:14:17 - Predict] Finished processing all regions.\n",
      "[16:14:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:14:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:14:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:14:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:14:20 - Predict] Found a GPU.\n",
      "[16:14:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:14:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:14:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd7e66f5ae0>\n",
      "[16:14:22 - MdlStrTF] loading weights from /tmp/tmp1_1yn_ft/model/variables/variables\n",
      "[16:14:22 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:14:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:14:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-260.\n",
      "[16:14:24 - Feature] Processed ParPgb:0.0-260.0 (median depth 94.0)\n",
      "[16:14:24 - Sampler] Took 2.17s to make features.\n",
      "[16:14:24 - Sampler] Region ParPgb:0.0-260.0 (318 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:14:24 - PWorker] Processed 0 batches\n",
      "[16:14:24 - PWorker] All done, 1 remainder regions.\n",
      "[16:14:24 - Predict] Processing 1 short region(s).\n",
      "[16:14:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd731771480>\n",
      "[16:14:24 - MdlStrTF] loading weights from /tmp/tmp1_1yn_ft/model/variables/variables\n",
      "[16:14:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-261.\n",
      "[16:14:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:24 - Feature] Processed ParPgb:0.0-260.0 (median depth 94.0)\n",
      "[16:14:24 - Sampler] Took 0.04s to make features.\n",
      "[16:14:25 - PWorker] Processed 1 batches\n",
      "[16:14:25 - PWorker] All done, 0 remainder regions.\n",
      "[16:14:25 - Predict] Finished processing all regions.\n",
      "[16:14:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:28 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:14:28 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:14:28 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:14:28 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:14:28 - Predict] Found a GPU.\n",
      "[16:14:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:14:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:14:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff833f3dae0>\n",
      "[16:14:30 - MdlStrTF] loading weights from /tmp/tmpdysu99ub/model/variables/variables\n",
      "[16:14:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:14:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:14:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:30 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-256.\n",
      "[16:14:30 - Feature] Processed ParPgb:0.0-256.0 (median depth 126.0)\n",
      "[16:14:30 - Sampler] Took 0.04s to make features.\n",
      "[16:14:30 - Sampler] Region ParPgb:0.0-256.0 (337 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:14:30 - PWorker] Processed 0 batches\n",
      "[16:14:30 - PWorker] All done, 1 remainder regions.\n",
      "[16:14:30 - Predict] Processing 1 short region(s).\n",
      "[16:14:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff80c29d480>\n",
      "[16:14:30 - MdlStrTF] loading weights from /tmp/tmpdysu99ub/model/variables/variables\n",
      "[16:14:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-257.\n",
      "[16:14:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:30 - Feature] Processed ParPgb:0.0-256.0 (median depth 126.0)\n",
      "[16:14:30 - Sampler] Took 0.04s to make features.\n",
      "[16:14:31 - PWorker] Processed 1 batches\n",
      "[16:14:31 - PWorker] All done, 0 remainder regions.\n",
      "[16:14:31 - Predict] Finished processing all regions.\n",
      "[16:14:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:34 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:14:34 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:14:34 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:14:34 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:14:34 - Predict] Found a GPU.\n",
      "[16:14:34 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:14:34 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:14:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f33cd2e9a80>\n",
      "[16:14:35 - MdlStrTF] loading weights from /tmp/tmp276vij1p/model/variables/variables\n",
      "[16:14:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:14:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:14:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:36 - Sampler] Took 0.13s to make features.\n",
      "[16:14:36 - PWorker] Processed 0 batches\n",
      "[16:14:36 - PWorker] All done, 0 remainder regions.\n",
      "[16:14:36 - Predict] Finished processing all regions.\n",
      "[16:14:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:37 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:14:39 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:14:39 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:14:39 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:14:39 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:14:39 - Predict] Found a GPU.\n",
      "[16:14:39 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:14:39 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:14:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb7ec145ae0>\n",
      "[16:14:40 - MdlStrTF] loading weights from /tmp/tmpofq5c_5o/model/variables/variables\n",
      "[16:14:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:14:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:14:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:40 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-218.\n",
      "[16:14:40 - Feature] Processed ParPgb:0.0-218.0 (median depth 140.0)\n",
      "[16:14:40 - Sampler] Took 0.05s to make features.\n",
      "[16:14:40 - Sampler] Region ParPgb:0.0-218.0 (311 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:14:40 - PWorker] Processed 0 batches\n",
      "[16:14:40 - PWorker] All done, 1 remainder regions.\n",
      "[16:14:40 - Predict] Processing 1 short region(s).\n",
      "[16:14:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb74d33e080>\n",
      "[16:14:41 - MdlStrTF] loading weights from /tmp/tmpofq5c_5o/model/variables/variables\n",
      "[16:14:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-219.\n",
      "[16:14:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:41 - Feature] Processed ParPgb:0.0-218.0 (median depth 140.0)\n",
      "[16:14:41 - Sampler] Took 0.03s to make features.\n",
      "[16:14:41 - PWorker] Processed 1 batches\n",
      "[16:14:41 - PWorker] All done, 0 remainder regions.\n",
      "[16:14:41 - Predict] Finished processing all regions.\n",
      "[16:14:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:45 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:14:45 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:14:45 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:14:45 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:14:45 - Predict] Found a GPU.\n",
      "[16:14:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:14:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:14:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6a58cb1ae0>\n",
      "[16:14:46 - MdlStrTF] loading weights from /tmp/tmppb6g_4pn/model/variables/variables\n",
      "[16:14:46 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:14:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:14:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:48 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:14:48 - Feature] Processed ParPgb:0.0-246.0 (median depth 145.0)\n",
      "[16:14:48 - Sampler] Took 1.96s to make features.\n",
      "[16:14:48 - Sampler] Region ParPgb:0.0-246.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:14:48 - PWorker] Processed 0 batches\n",
      "[16:14:48 - PWorker] All done, 1 remainder regions.\n",
      "[16:14:48 - Predict] Processing 1 short region(s).\n",
      "[16:14:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f69b9e6d480>\n",
      "[16:14:48 - MdlStrTF] loading weights from /tmp/tmppb6g_4pn/model/variables/variables\n",
      "[16:14:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:14:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:49 - Feature] Processed ParPgb:0.0-246.0 (median depth 145.0)\n",
      "[16:14:49 - Sampler] Took 0.12s to make features.\n",
      "[16:14:49 - PWorker] Processed 1 batches\n",
      "[16:14:49 - PWorker] All done, 0 remainder regions.\n",
      "[16:14:49 - Predict] Finished processing all regions.\n",
      "[16:14:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:51 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:14:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:14:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:14:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:14:53 - Predict] Found a GPU.\n",
      "[16:14:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:14:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:14:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa414601a80>\n",
      "[16:14:54 - MdlStrTF] loading weights from /tmp/tmptzizdmtd/model/variables/variables\n",
      "[16:14:54 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:14:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:14:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:54 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-225.\n",
      "[16:14:54 - Feature] Processed ParPgb:0.0-225.0 (median depth 86.0)\n",
      "[16:14:54 - Sampler] Took 0.03s to make features.\n",
      "[16:14:54 - Sampler] Region ParPgb:0.0-225.0 (285 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:14:54 - PWorker] Processed 0 batches\n",
      "[16:14:54 - PWorker] All done, 1 remainder regions.\n",
      "[16:14:54 - Predict] Processing 1 short region(s).\n",
      "[16:14:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:14:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa37af713f0>\n",
      "[16:14:54 - MdlStrTF] loading weights from /tmp/tmptzizdmtd/model/variables/variables\n",
      "[16:14:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-226.\n",
      "[16:14:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:14:54 - Feature] Processed ParPgb:0.0-225.0 (median depth 86.0)\n",
      "[16:14:54 - Sampler] Took 0.03s to make features.\n",
      "[16:14:55 - PWorker] Processed 1 batches\n",
      "[16:14:55 - PWorker] All done, 0 remainder regions.\n",
      "[16:14:55 - Predict] Finished processing all regions.\n",
      "[16:14:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:14:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:14:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:14:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:14:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:14:58 - Predict] Found a GPU.\n",
      "[16:14:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:14:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:14:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f94ea985ae0>\n",
      "[16:15:00 - MdlStrTF] loading weights from /tmp/tmpidax_cec/model/variables/variables\n",
      "[16:15:00 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:15:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:15:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:00 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[16:15:01 - Feature] Processed ParPgb:0.0-245.0 (median depth 188.0)\n",
      "[16:15:01 - Sampler] Took 1.18s to make features.\n",
      "[16:15:01 - Sampler] Region ParPgb:0.0-245.0 (359 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:15:01 - PWorker] Processed 0 batches\n",
      "[16:15:01 - PWorker] All done, 1 remainder regions.\n",
      "[16:15:01 - Predict] Processing 1 short region(s).\n",
      "[16:15:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9459b25480>\n",
      "[16:15:01 - MdlStrTF] loading weights from /tmp/tmpidax_cec/model/variables/variables\n",
      "[16:15:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[16:15:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:01 - Feature] Processed ParPgb:0.0-245.0 (median depth 188.0)\n",
      "[16:15:01 - Sampler] Took 0.05s to make features.\n",
      "[16:15:02 - PWorker] Processed 1 batches\n",
      "[16:15:02 - PWorker] All done, 0 remainder regions.\n",
      "[16:15:02 - Predict] Finished processing all regions.\n",
      "[16:15:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:15:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:15:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:15:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:15:05 - Predict] Found a GPU.\n",
      "[16:15:05 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:15:05 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:15:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2ca703dae0>\n",
      "[16:15:07 - MdlStrTF] loading weights from /tmp/tmppejk18hh/model/variables/variables\n",
      "[16:15:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:15:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:15:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[16:15:07 - Feature] Processed ParPgb:0.0-244.0 (median depth 115.0)\n",
      "[16:15:07 - Sampler] Took 0.19s to make features.\n",
      "[16:15:07 - Sampler] Region ParPgb:0.0-244.0 (302 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:15:07 - PWorker] Processed 0 batches\n",
      "[16:15:07 - PWorker] All done, 1 remainder regions.\n",
      "[16:15:07 - Predict] Processing 1 short region(s).\n",
      "[16:15:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2c0820db10>\n",
      "[16:15:07 - MdlStrTF] loading weights from /tmp/tmppejk18hh/model/variables/variables\n",
      "[16:15:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[16:15:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:07 - Feature] Processed ParPgb:0.0-244.0 (median depth 115.0)\n",
      "[16:15:07 - Sampler] Took 0.03s to make features.\n",
      "[16:15:08 - PWorker] Processed 1 batches\n",
      "[16:15:08 - PWorker] All done, 0 remainder regions.\n",
      "[16:15:08 - Predict] Finished processing all regions.\n",
      "[16:15:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:11 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:15:11 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:15:11 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:15:11 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:15:11 - Predict] Found a GPU.\n",
      "[16:15:11 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:15:11 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:15:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb303405a80>\n",
      "[16:15:13 - MdlStrTF] loading weights from /tmp/tmp_816ohfq/model/variables/variables\n",
      "[16:15:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:15:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:15:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[16:15:14 - Feature] Processed ParPgb:0.0-247.0 (median depth 123.0)\n",
      "[16:15:14 - Sampler] Took 1.44s to make features.\n",
      "[16:15:14 - Sampler] Region ParPgb:0.0-247.0 (315 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:15:14 - PWorker] Processed 0 batches\n",
      "[16:15:14 - PWorker] All done, 1 remainder regions.\n",
      "[16:15:14 - Predict] Processing 1 short region(s).\n",
      "[16:15:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb271d22140>\n",
      "[16:15:15 - MdlStrTF] loading weights from /tmp/tmp_816ohfq/model/variables/variables\n",
      "[16:15:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[16:15:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:15 - Feature] Processed ParPgb:0.0-247.0 (median depth 123.0)\n",
      "[16:15:15 - Sampler] Took 0.08s to make features.\n",
      "[16:15:15 - PWorker] Processed 1 batches\n",
      "[16:15:15 - PWorker] All done, 0 remainder regions.\n",
      "[16:15:15 - Predict] Finished processing all regions.\n",
      "[16:15:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:15:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:15:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:15:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:15:19 - Predict] Found a GPU.\n",
      "[16:15:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:15:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:15:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efff251dae0>\n",
      "[16:15:20 - MdlStrTF] loading weights from /tmp/tmpv76gillv/model/variables/variables\n",
      "[16:15:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:15:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:15:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-239.\n",
      "[16:15:20 - Feature] Processed ParPgb:0.0-239.0 (median depth 185.0)\n",
      "[16:15:20 - Sampler] Took 0.05s to make features.\n",
      "[16:15:20 - Sampler] Region ParPgb:0.0-239.0 (329 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:15:20 - PWorker] Processed 0 batches\n",
      "[16:15:20 - PWorker] All done, 1 remainder regions.\n",
      "[16:15:20 - Predict] Processing 1 short region(s).\n",
      "[16:15:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7eff616c55a0>\n",
      "[16:15:21 - MdlStrTF] loading weights from /tmp/tmpv76gillv/model/variables/variables\n",
      "[16:15:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-240.\n",
      "[16:15:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:21 - Feature] Processed ParPgb:0.0-239.0 (median depth 185.0)\n",
      "[16:15:21 - Sampler] Took 0.16s to make features.\n",
      "[16:15:21 - PWorker] Processed 1 batches\n",
      "[16:15:21 - PWorker] All done, 0 remainder regions.\n",
      "[16:15:21 - Predict] Finished processing all regions.\n",
      "[16:15:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:15:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:15:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:15:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:15:25 - Predict] Found a GPU.\n",
      "[16:15:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:15:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:15:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0078e9dae0>\n",
      "[16:15:26 - MdlStrTF] loading weights from /tmp/tmpnoeybsxr/model/variables/variables\n",
      "[16:15:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:15:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:15:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[16:15:26 - Feature] Processed ParPgb:0.0-251.0 (median depth 106.0)\n",
      "[16:15:26 - Sampler] Took 0.03s to make features.\n",
      "[16:15:26 - Sampler] Region ParPgb:0.0-251.0 (305 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:15:26 - PWorker] Processed 0 batches\n",
      "[16:15:26 - PWorker] All done, 1 remainder regions.\n",
      "[16:15:26 - Predict] Processing 1 short region(s).\n",
      "[16:15:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7effe80c1480>\n",
      "[16:15:27 - MdlStrTF] loading weights from /tmp/tmpnoeybsxr/model/variables/variables\n",
      "[16:15:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[16:15:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:27 - Feature] Processed ParPgb:0.0-251.0 (median depth 106.0)\n",
      "[16:15:27 - Sampler] Took 0.16s to make features.\n",
      "[16:15:27 - PWorker] Processed 1 batches\n",
      "[16:15:27 - PWorker] All done, 0 remainder regions.\n",
      "[16:15:27 - Predict] Finished processing all regions.\n",
      "[16:15:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:15:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:15:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:15:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:15:31 - Predict] Found a GPU.\n",
      "[16:15:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:15:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:15:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5a47d51ae0>\n",
      "[16:15:32 - MdlStrTF] loading weights from /tmp/tmpf6ldx1na/model/variables/variables\n",
      "[16:15:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:15:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:15:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:32 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-222.\n",
      "[16:15:32 - Feature] Processed ParPgb:0.0-222.0 (median depth 137.0)\n",
      "[16:15:32 - Sampler] Took 0.04s to make features.\n",
      "[16:15:32 - Sampler] Region ParPgb:0.0-222.0 (314 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:15:32 - PWorker] Processed 0 batches\n",
      "[16:15:32 - PWorker] All done, 1 remainder regions.\n",
      "[16:15:32 - Predict] Processing 1 short region(s).\n",
      "[16:15:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f59a8e71450>\n",
      "[16:15:33 - MdlStrTF] loading weights from /tmp/tmpf6ldx1na/model/variables/variables\n",
      "[16:15:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-223.\n",
      "[16:15:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:35 - Feature] Processed ParPgb:0.0-222.0 (median depth 137.0)\n",
      "[16:15:35 - Sampler] Took 2.09s to make features.\n",
      "[16:15:35 - PWorker] Processed 1 batches\n",
      "[16:15:35 - PWorker] All done, 0 remainder regions.\n",
      "[16:15:35 - Predict] Finished processing all regions.\n",
      "[16:15:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:39 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:15:39 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:15:39 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:15:39 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:15:39 - Predict] Found a GPU.\n",
      "[16:15:39 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:15:39 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:15:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd9c71f9a80>\n",
      "[16:15:40 - MdlStrTF] loading weights from /tmp/tmpqekcfwgd/model/variables/variables\n",
      "[16:15:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:15:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:15:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:40 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[16:15:40 - Feature] Processed ParPgb:0.0-238.0 (median depth 288.0)\n",
      "[16:15:40 - Sampler] Took 0.02s to make features.\n",
      "[16:15:40 - Sampler] Region ParPgb:0.0-238.0 (397 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:15:40 - PWorker] Processed 0 batches\n",
      "[16:15:40 - PWorker] All done, 1 remainder regions.\n",
      "[16:15:40 - Predict] Processing 1 short region(s).\n",
      "[16:15:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd928371420>\n",
      "[16:15:40 - MdlStrTF] loading weights from /tmp/tmpqekcfwgd/model/variables/variables\n",
      "[16:15:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[16:15:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:44 - Feature] Processed ParPgb:0.0-238.0 (median depth 288.0)\n",
      "[16:15:44 - Sampler] Took 3.04s to make features.\n",
      "[16:15:44 - PWorker] Processed 1 batches\n",
      "[16:15:44 - PWorker] All done, 0 remainder regions.\n",
      "[16:15:44 - Predict] Finished processing all regions.\n",
      "[16:15:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:15:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:15:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:15:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:15:48 - Predict] Found a GPU.\n",
      "[16:15:48 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:15:48 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:15:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc4a2661ae0>\n",
      "[16:15:49 - MdlStrTF] loading weights from /tmp/tmp8cn9ptzg/model/variables/variables\n",
      "[16:15:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:15:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:15:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-220.\n",
      "[16:15:49 - Feature] Processed ParPgb:0.0-220.0 (median depth 97.0)\n",
      "[16:15:49 - Sampler] Took 0.09s to make features.\n",
      "[16:15:49 - Sampler] Region ParPgb:0.0-220.0 (282 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:15:49 - PWorker] Processed 0 batches\n",
      "[16:15:49 - PWorker] All done, 1 remainder regions.\n",
      "[16:15:49 - Predict] Processing 1 short region(s).\n",
      "[16:15:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc4117f5b10>\n",
      "[16:15:49 - MdlStrTF] loading weights from /tmp/tmp8cn9ptzg/model/variables/variables\n",
      "[16:15:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-221.\n",
      "[16:15:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:49 - Feature] Processed ParPgb:0.0-220.0 (median depth 97.0)\n",
      "[16:15:49 - Sampler] Took 0.05s to make features.\n",
      "[16:15:50 - PWorker] Processed 1 batches\n",
      "[16:15:50 - PWorker] All done, 0 remainder regions.\n",
      "[16:15:50 - Predict] Finished processing all regions.\n",
      "[16:15:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:15:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:15:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:15:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:15:53 - Predict] Found a GPU.\n",
      "[16:15:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:15:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:15:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1541579ae0>\n",
      "[16:15:55 - MdlStrTF] loading weights from /tmp/tmph5orn46b/model/variables/variables\n",
      "[16:15:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:15:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:15:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-223.\n",
      "[16:15:55 - Feature] Processed ParPgb:0.0-223.0 (median depth 140.0)\n",
      "[16:15:55 - Sampler] Took 0.02s to make features.\n",
      "[16:15:55 - Sampler] Region ParPgb:0.0-223.0 (304 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:15:55 - PWorker] Processed 0 batches\n",
      "[16:15:55 - PWorker] All done, 1 remainder regions.\n",
      "[16:15:55 - Predict] Processing 1 short region(s).\n",
      "[16:15:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:15:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1489799480>\n",
      "[16:15:55 - MdlStrTF] loading weights from /tmp/tmph5orn46b/model/variables/variables\n",
      "[16:15:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-224.\n",
      "[16:15:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:15:55 - Feature] Processed ParPgb:0.0-223.0 (median depth 140.0)\n",
      "[16:15:55 - Sampler] Took 0.05s to make features.\n",
      "[16:15:56 - PWorker] Processed 1 batches\n",
      "[16:15:56 - PWorker] All done, 0 remainder regions.\n",
      "[16:15:56 - Predict] Finished processing all regions.\n",
      "[16:15:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:15:59 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:15:59 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:15:59 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:15:59 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:15:59 - Predict] Found a GPU.\n",
      "[16:15:59 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:15:59 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:15:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4f132fdae0>\n",
      "[16:16:01 - MdlStrTF] loading weights from /tmp/tmp82tfpvon/model/variables/variables\n",
      "[16:16:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:16:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:16:01 - Sampler] Took 0.01s to make features.\n",
      "[16:16:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:01 - PWorker] Processed 0 batches\n",
      "[16:16:01 - PWorker] All done, 0 remainder regions.\n",
      "[16:16:01 - Predict] Finished processing all regions.\n",
      "[16:16:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:02 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:16:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:16:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:16:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:16:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:16:04 - Predict] Found a GPU.\n",
      "[16:16:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:16:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:16:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faa426f5a80>\n",
      "[16:16:05 - MdlStrTF] loading weights from /tmp/tmp7jcw02xz/model/variables/variables\n",
      "[16:16:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:16:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:16:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:08 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-221.\n",
      "[16:16:08 - Feature] Processed ParPgb:0.0-221.0 (median depth 207.0)\n",
      "[16:16:08 - Sampler] Took 2.57s to make features.\n",
      "[16:16:08 - Sampler] Region ParPgb:0.0-221.0 (333 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:16:08 - PWorker] Processed 0 batches\n",
      "[16:16:08 - PWorker] All done, 1 remainder regions.\n",
      "[16:16:08 - Predict] Processing 1 short region(s).\n",
      "[16:16:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa9b18f6110>\n",
      "[16:16:08 - MdlStrTF] loading weights from /tmp/tmp7jcw02xz/model/variables/variables\n",
      "[16:16:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-222.\n",
      "[16:16:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:08 - Feature] Processed ParPgb:0.0-221.0 (median depth 207.0)\n",
      "[16:16:08 - Sampler] Took 0.10s to make features.\n",
      "[16:16:09 - PWorker] Processed 1 batches\n",
      "[16:16:09 - PWorker] All done, 0 remainder regions.\n",
      "[16:16:09 - Predict] Finished processing all regions.\n",
      "[16:16:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:16:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:16:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:16:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:16:12 - Predict] Found a GPU.\n",
      "[16:16:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:16:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:16:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2c2df25ae0>\n",
      "[16:16:14 - MdlStrTF] loading weights from /tmp/tmpj_qczjmy/model/variables/variables\n",
      "[16:16:14 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:16:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:16:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-220.\n",
      "[16:16:14 - Feature] Processed ParPgb:0.0-220.0 (median depth 136.0)\n",
      "[16:16:14 - Sampler] Took 0.09s to make features.\n",
      "[16:16:14 - Sampler] Region ParPgb:0.0-220.0 (289 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:16:14 - PWorker] Processed 0 batches\n",
      "[16:16:14 - PWorker] All done, 1 remainder regions.\n",
      "[16:16:14 - Predict] Processing 1 short region(s).\n",
      "[16:16:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2b9d0a2f20>\n",
      "[16:16:14 - MdlStrTF] loading weights from /tmp/tmpj_qczjmy/model/variables/variables\n",
      "[16:16:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-221.\n",
      "[16:16:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:14 - Feature] Processed ParPgb:0.0-220.0 (median depth 136.0)\n",
      "[16:16:14 - Sampler] Took 0.07s to make features.\n",
      "[16:16:15 - PWorker] Processed 1 batches\n",
      "[16:16:15 - PWorker] All done, 0 remainder regions.\n",
      "[16:16:15 - Predict] Finished processing all regions.\n",
      "[16:16:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:18 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:16:18 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:16:18 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:16:18 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:16:18 - Predict] Found a GPU.\n",
      "[16:16:18 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:16:18 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:16:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f51b9211ae0>\n",
      "[16:16:20 - MdlStrTF] loading weights from /tmp/tmp0ixk4en7/model/variables/variables\n",
      "[16:16:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:16:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:16:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[16:16:20 - Feature] Processed ParPgb:0.0-247.0 (median depth 271.0)\n",
      "[16:16:20 - Sampler] Took 0.80s to make features.\n",
      "[16:16:20 - Sampler] Region ParPgb:0.0-247.0 (385 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:16:20 - PWorker] Processed 0 batches\n",
      "[16:16:20 - PWorker] All done, 1 remainder regions.\n",
      "[16:16:20 - Predict] Processing 1 short region(s).\n",
      "[16:16:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5128365ff0>\n",
      "[16:16:21 - MdlStrTF] loading weights from /tmp/tmp0ixk4en7/model/variables/variables\n",
      "[16:16:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[16:16:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:21 - Feature] Processed ParPgb:0.0-247.0 (median depth 271.0)\n",
      "[16:16:21 - Sampler] Took 0.02s to make features.\n",
      "[16:16:21 - PWorker] Processed 1 batches\n",
      "[16:16:21 - PWorker] All done, 0 remainder regions.\n",
      "[16:16:21 - Predict] Finished processing all regions.\n",
      "[16:16:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:16:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:16:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:16:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:16:25 - Predict] Found a GPU.\n",
      "[16:16:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:16:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:16:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9c76ccdae0>\n",
      "[16:16:26 - MdlStrTF] loading weights from /tmp/tmpt2rqzwdk/model/variables/variables\n",
      "[16:16:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:16:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:16:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:16:33 - Feature] Processed ParPgb:0.0-246.0 (median depth 103.0)\n",
      "[16:16:33 - Sampler] Took 7.25s to make features.\n",
      "[16:16:33 - Sampler] Region ParPgb:0.0-246.0 (333 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:16:33 - PWorker] Processed 0 batches\n",
      "[16:16:33 - PWorker] All done, 1 remainder regions.\n",
      "[16:16:33 - Predict] Processing 1 short region(s).\n",
      "[16:16:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9bd8671420>\n",
      "[16:16:34 - MdlStrTF] loading weights from /tmp/tmpt2rqzwdk/model/variables/variables\n",
      "[16:16:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:16:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:34 - Feature] Processed ParPgb:0.0-246.0 (median depth 103.0)\n",
      "[16:16:34 - Sampler] Took 0.06s to make features.\n",
      "[16:16:35 - PWorker] Processed 1 batches\n",
      "[16:16:35 - PWorker] All done, 0 remainder regions.\n",
      "[16:16:35 - Predict] Finished processing all regions.\n",
      "[16:16:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:16:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:16:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:16:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:16:38 - Predict] Found a GPU.\n",
      "[16:16:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:16:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:16:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3691f61ae0>\n",
      "[16:16:39 - MdlStrTF] loading weights from /tmp/tmppho_ruk7/model/variables/variables\n",
      "[16:16:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:16:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:16:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:16:39 - Feature] Processed ParPgb:0.0-248.0 (median depth 118.0)\n",
      "[16:16:39 - Sampler] Took 0.02s to make features.\n",
      "[16:16:39 - Sampler] Region ParPgb:0.0-248.0 (328 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:16:39 - PWorker] Processed 0 batches\n",
      "[16:16:39 - PWorker] All done, 1 remainder regions.\n",
      "[16:16:39 - Predict] Processing 1 short region(s).\n",
      "[16:16:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f36010bd480>\n",
      "[16:16:40 - MdlStrTF] loading weights from /tmp/tmppho_ruk7/model/variables/variables\n",
      "[16:16:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:16:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:40 - Feature] Processed ParPgb:0.0-248.0 (median depth 118.0)\n",
      "[16:16:40 - Sampler] Took 0.05s to make features.\n",
      "[16:16:40 - PWorker] Processed 1 batches\n",
      "[16:16:40 - PWorker] All done, 0 remainder regions.\n",
      "[16:16:40 - Predict] Finished processing all regions.\n",
      "[16:16:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:44 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:16:44 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:16:44 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:16:44 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:16:44 - Predict] Found a GPU.\n",
      "[16:16:44 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:16:44 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:16:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f43f38d9ae0>\n",
      "[16:16:45 - MdlStrTF] loading weights from /tmp/tmp0zj0_sff/model/variables/variables\n",
      "[16:16:45 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:16:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:16:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-236.\n",
      "[16:16:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:45 - Feature] Processed ParPgb:0.0-236.0 (median depth 268.0)\n",
      "[16:16:45 - Sampler] Took 0.21s to make features.\n",
      "[16:16:45 - Sampler] Region ParPgb:0.0-236.0 (369 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:16:45 - PWorker] Processed 0 batches\n",
      "[16:16:45 - PWorker] All done, 1 remainder regions.\n",
      "[16:16:45 - Predict] Processing 1 short region(s).\n",
      "[16:16:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4362a22320>\n",
      "[16:16:46 - MdlStrTF] loading weights from /tmp/tmp0zj0_sff/model/variables/variables\n",
      "[16:16:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-237.\n",
      "[16:16:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:46 - Feature] Processed ParPgb:0.0-236.0 (median depth 268.0)\n",
      "[16:16:46 - Sampler] Took 0.05s to make features.\n",
      "[16:16:46 - PWorker] Processed 1 batches\n",
      "[16:16:46 - PWorker] All done, 0 remainder regions.\n",
      "[16:16:46 - Predict] Finished processing all regions.\n",
      "[16:16:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:16:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:16:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:16:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:16:50 - Predict] Found a GPU.\n",
      "[16:16:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:16:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:16:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f623c761ae0>\n",
      "[16:16:51 - MdlStrTF] loading weights from /tmp/tmpz1xzwpaa/model/variables/variables\n",
      "[16:16:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:16:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:16:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-205.\n",
      "[16:16:55 - Feature] Processed ParPgb:0.0-205.0 (median depth 9.0)\n",
      "[16:16:55 - Sampler] Took 3.42s to make features.\n",
      "[16:16:55 - Sampler] Region ParPgb:0.0-205.0 (211 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:16:55 - PWorker] Processed 0 batches\n",
      "[16:16:55 - PWorker] All done, 1 remainder regions.\n",
      "[16:16:55 - Predict] Processing 1 short region(s).\n",
      "[16:16:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:16:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f61ac09e1d0>\n",
      "[16:16:55 - MdlStrTF] loading weights from /tmp/tmpz1xzwpaa/model/variables/variables\n",
      "[16:16:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-206.\n",
      "[16:16:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:16:55 - Feature] Processed ParPgb:0.0-205.0 (median depth 9.0)\n",
      "[16:16:55 - Sampler] Took 0.04s to make features.\n",
      "[16:16:56 - PWorker] Processed 1 batches\n",
      "[16:16:56 - PWorker] All done, 0 remainder regions.\n",
      "[16:16:56 - Predict] Finished processing all regions.\n",
      "[16:16:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:57 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:16:59 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:16:59 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:16:59 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:16:59 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:16:59 - Predict] Found a GPU.\n",
      "[16:16:59 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:16:59 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:16:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3084545ae0>\n",
      "[16:17:00 - MdlStrTF] loading weights from /tmp/tmpfzeusc98/model/variables/variables\n",
      "[16:17:00 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:17:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:17:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[16:17:01 - Feature] Processed ParPgb:0.0-250.0 (median depth 91.0)\n",
      "[16:17:01 - Sampler] Took 0.12s to make features.\n",
      "[16:17:01 - Sampler] Region ParPgb:0.0-250.0 (306 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:17:01 - PWorker] Processed 0 batches\n",
      "[16:17:01 - PWorker] All done, 1 remainder regions.\n",
      "[16:17:01 - Predict] Processing 1 short region(s).\n",
      "[16:17:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2fc7675450>\n",
      "[16:17:01 - MdlStrTF] loading weights from /tmp/tmpfzeusc98/model/variables/variables\n",
      "[16:17:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[16:17:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:01 - Feature] Processed ParPgb:0.0-250.0 (median depth 91.0)\n",
      "[16:17:01 - Sampler] Took 0.04s to make features.\n",
      "[16:17:02 - PWorker] Processed 1 batches\n",
      "[16:17:02 - PWorker] All done, 0 remainder regions.\n",
      "[16:17:02 - Predict] Finished processing all regions.\n",
      "[16:17:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:17:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:17:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:17:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:17:05 - Predict] Found a GPU.\n",
      "[16:17:05 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:17:05 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:17:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff05bbe1ae0>\n",
      "[16:17:06 - MdlStrTF] loading weights from /tmp/tmpyglt0tm3/model/variables/variables\n",
      "[16:17:06 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:17:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:17:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-223.\n",
      "[16:17:08 - Feature] Processed ParPgb:0.0-223.0 (median depth 132.0)\n",
      "[16:17:08 - Sampler] Took 1.58s to make features.\n",
      "[16:17:08 - Sampler] Region ParPgb:0.0-223.0 (294 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:17:08 - PWorker] Processed 0 batches\n",
      "[16:17:08 - PWorker] All done, 1 remainder regions.\n",
      "[16:17:08 - Predict] Processing 1 short region(s).\n",
      "[16:17:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fefca551ff0>\n",
      "[16:17:08 - MdlStrTF] loading weights from /tmp/tmpyglt0tm3/model/variables/variables\n",
      "[16:17:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-224.\n",
      "[16:17:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:09 - Feature] Processed ParPgb:0.0-223.0 (median depth 132.0)\n",
      "[16:17:09 - Sampler] Took 0.08s to make features.\n",
      "[16:17:09 - PWorker] Processed 1 batches\n",
      "[16:17:09 - PWorker] All done, 0 remainder regions.\n",
      "[16:17:09 - Predict] Finished processing all regions.\n",
      "[16:17:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:17:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:17:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:17:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:17:13 - Predict] Found a GPU.\n",
      "[16:17:13 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:17:13 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:17:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fac5e93dae0>\n",
      "[16:17:14 - MdlStrTF] loading weights from /tmp/tmpc1cqr26n/model/variables/variables\n",
      "[16:17:14 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:17:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:17:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[16:17:16 - Feature] Processed ParPgb:0.0-251.0 (median depth 215.0)\n",
      "[16:17:16 - Sampler] Took 2.33s to make features.\n",
      "[16:17:16 - Sampler] Region ParPgb:0.0-251.0 (372 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:17:16 - PWorker] Processed 0 batches\n",
      "[16:17:16 - PWorker] All done, 1 remainder regions.\n",
      "[16:17:16 - Predict] Processing 1 short region(s).\n",
      "[16:17:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fabcc1b1ea0>\n",
      "[16:17:17 - MdlStrTF] loading weights from /tmp/tmpc1cqr26n/model/variables/variables\n",
      "[16:17:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[16:17:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:19 - Feature] Processed ParPgb:0.0-251.0 (median depth 215.0)\n",
      "[16:17:19 - Sampler] Took 2.04s to make features.\n",
      "[16:17:19 - PWorker] Processed 1 batches\n",
      "[16:17:19 - PWorker] All done, 0 remainder regions.\n",
      "[16:17:19 - Predict] Finished processing all regions.\n",
      "[16:17:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:23 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:17:23 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:17:23 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:17:23 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:17:23 - Predict] Found a GPU.\n",
      "[16:17:23 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:17:23 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:17:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f318ca05ae0>\n",
      "[16:17:24 - MdlStrTF] loading weights from /tmp/tmptgjocn0h/model/variables/variables\n",
      "[16:17:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:17:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:17:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:17:24 - Feature] Processed ParPgb:0.0-240.0 (median depth 138.0)\n",
      "[16:17:24 - Sampler] Took 0.04s to make features.\n",
      "[16:17:24 - Sampler] Region ParPgb:0.0-240.0 (309 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:17:24 - PWorker] Processed 0 batches\n",
      "[16:17:24 - PWorker] All done, 1 remainder regions.\n",
      "[16:17:24 - Predict] Processing 1 short region(s).\n",
      "[16:17:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f30fc33d450>\n",
      "[16:17:24 - MdlStrTF] loading weights from /tmp/tmptgjocn0h/model/variables/variables\n",
      "[16:17:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:17:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:25 - Feature] Processed ParPgb:0.0-240.0 (median depth 138.0)\n",
      "[16:17:25 - Sampler] Took 0.04s to make features.\n",
      "[16:17:25 - PWorker] Processed 1 batches\n",
      "[16:17:25 - PWorker] All done, 0 remainder regions.\n",
      "[16:17:25 - Predict] Finished processing all regions.\n",
      "[16:17:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:28 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:17:28 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:17:28 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:17:28 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:17:29 - Predict] Found a GPU.\n",
      "[16:17:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:17:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:17:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f72675e5a80>\n",
      "[16:17:30 - MdlStrTF] loading weights from /tmp/tmp9uwfadnz/model/variables/variables\n",
      "[16:17:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:17:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:17:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:30 - Sampler] Took 0.08s to make features.\n",
      "[16:17:30 - PWorker] Processed 0 batches\n",
      "[16:17:30 - PWorker] All done, 0 remainder regions.\n",
      "[16:17:30 - Predict] Finished processing all regions.\n",
      "[16:17:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:32 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:17:33 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:17:33 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:17:33 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:17:33 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:17:33 - Predict] Found a GPU.\n",
      "[16:17:33 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:17:33 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:17:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7feca7e1dae0>\n",
      "[16:17:35 - MdlStrTF] loading weights from /tmp/tmpm6_3dog8/model/variables/variables\n",
      "[16:17:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:17:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:17:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:35 - Sampler] Took 0.03s to make features.\n",
      "[16:17:35 - PWorker] Processed 0 batches\n",
      "[16:17:35 - PWorker] All done, 0 remainder regions.\n",
      "[16:17:35 - Predict] Finished processing all regions.\n",
      "[16:17:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:36 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:17:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:17:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:17:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:17:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:17:38 - Predict] Found a GPU.\n",
      "[16:17:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:17:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:17:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f28949d1ae0>\n",
      "[16:17:39 - MdlStrTF] loading weights from /tmp/tmpl2b4rark/model/variables/variables\n",
      "[16:17:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:17:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:17:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-262.\n",
      "[16:17:39 - Feature] Processed ParPgb:0.0-262.0 (median depth 124.0)\n",
      "[16:17:39 - Sampler] Took 0.16s to make features.\n",
      "[16:17:39 - Sampler] Region ParPgb:0.0-262.0 (338 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:17:39 - PWorker] Processed 0 batches\n",
      "[16:17:39 - PWorker] All done, 1 remainder regions.\n",
      "[16:17:39 - Predict] Processing 1 short region(s).\n",
      "[16:17:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2800391ae0>\n",
      "[16:17:40 - MdlStrTF] loading weights from /tmp/tmpl2b4rark/model/variables/variables\n",
      "[16:17:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-263.\n",
      "[16:17:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:40 - Feature] Processed ParPgb:0.0-262.0 (median depth 124.0)\n",
      "[16:17:40 - Sampler] Took 0.04s to make features.\n",
      "[16:17:40 - PWorker] Processed 1 batches\n",
      "[16:17:40 - PWorker] All done, 0 remainder regions.\n",
      "[16:17:40 - Predict] Finished processing all regions.\n",
      "[16:17:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:44 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:17:44 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:17:44 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:17:44 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:17:44 - Predict] Found a GPU.\n",
      "[16:17:44 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:17:44 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:17:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff07e4e9ae0>\n",
      "[16:17:45 - MdlStrTF] loading weights from /tmp/tmpmjh2xipb/model/variables/variables\n",
      "[16:17:45 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:17:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:17:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-234.\n",
      "[16:17:45 - Feature] Processed ParPgb:0.0-234.0 (median depth 1.0)\n",
      "[16:17:48 - Sampler] Took 3.05s to make features.\n",
      "[16:17:48 - Sampler] Region ParPgb:0.0-234.0 (237 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:17:48 - PWorker] Processed 0 batches\n",
      "[16:17:48 - PWorker] All done, 1 remainder regions.\n",
      "[16:17:48 - Predict] Processing 1 short region(s).\n",
      "[16:17:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fefec2e6320>\n",
      "[16:17:49 - MdlStrTF] loading weights from /tmp/tmpmjh2xipb/model/variables/variables\n",
      "[16:17:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-235.\n",
      "[16:17:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:51 - Feature] Processed ParPgb:0.0-234.0 (median depth 1.0)\n",
      "[16:17:51 - Sampler] Took 2.40s to make features.\n",
      "[16:17:52 - PWorker] Processed 1 batches\n",
      "[16:17:52 - PWorker] All done, 0 remainder regions.\n",
      "[16:17:52 - Predict] Finished processing all regions.\n",
      "[16:17:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:17:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:17:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:17:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:17:55 - Predict] Found a GPU.\n",
      "[16:17:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:17:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:17:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1a8c085ae0>\n",
      "[16:17:56 - MdlStrTF] loading weights from /tmp/tmp44_bhi72/model/variables/variables\n",
      "[16:17:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:17:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:17:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[16:17:56 - Feature] Processed ParPgb:0.0-244.0 (median depth 117.0)\n",
      "[16:17:56 - Sampler] Took 0.04s to make features.\n",
      "[16:17:56 - Sampler] Region ParPgb:0.0-244.0 (321 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:17:56 - PWorker] Processed 0 batches\n",
      "[16:17:56 - PWorker] All done, 1 remainder regions.\n",
      "[16:17:56 - Predict] Processing 1 short region(s).\n",
      "[16:17:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:17:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f19fc1d9480>\n",
      "[16:17:57 - MdlStrTF] loading weights from /tmp/tmp44_bhi72/model/variables/variables\n",
      "[16:17:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[16:17:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:17:57 - Feature] Processed ParPgb:0.0-244.0 (median depth 117.0)\n",
      "[16:17:57 - Sampler] Took 0.05s to make features.\n",
      "[16:17:57 - PWorker] Processed 1 batches\n",
      "[16:17:57 - PWorker] All done, 0 remainder regions.\n",
      "[16:17:57 - Predict] Finished processing all regions.\n",
      "[16:17:59 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:17:59 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:01 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:18:01 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:18:01 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:18:01 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:18:01 - Predict] Found a GPU.\n",
      "[16:18:01 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:18:01 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:18:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0e430d9a80>\n",
      "[16:18:02 - MdlStrTF] loading weights from /tmp/tmpze0jw9yq/model/variables/variables\n",
      "[16:18:02 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:18:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:18:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:02 - Sampler] Took 0.02s to make features.\n",
      "[16:18:02 - PWorker] Processed 0 batches\n",
      "[16:18:02 - PWorker] All done, 0 remainder regions.\n",
      "[16:18:02 - Predict] Finished processing all regions.\n",
      "[16:18:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:04 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:18:06 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:18:06 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:18:06 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:18:06 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:18:06 - Predict] Found a GPU.\n",
      "[16:18:06 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:18:06 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:18:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fac60991ae0>\n",
      "[16:18:07 - MdlStrTF] loading weights from /tmp/tmp8udvqmym/model/variables/variables\n",
      "[16:18:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:18:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:18:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[16:18:07 - Feature] Processed ParPgb:0.0-250.0 (median depth 140.0)\n",
      "[16:18:07 - Sampler] Took 0.03s to make features.\n",
      "[16:18:07 - Sampler] Region ParPgb:0.0-250.0 (330 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:18:07 - PWorker] Processed 0 batches\n",
      "[16:18:07 - PWorker] All done, 1 remainder regions.\n",
      "[16:18:07 - Predict] Processing 1 short region(s).\n",
      "[16:18:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fabd0365480>\n",
      "[16:18:07 - MdlStrTF] loading weights from /tmp/tmp8udvqmym/model/variables/variables\n",
      "[16:18:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[16:18:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:07 - Feature] Processed ParPgb:0.0-250.0 (median depth 140.0)\n",
      "[16:18:08 - Sampler] Took 0.05s to make features.\n",
      "[16:18:08 - PWorker] Processed 1 batches\n",
      "[16:18:08 - PWorker] All done, 0 remainder regions.\n",
      "[16:18:08 - Predict] Finished processing all regions.\n",
      "[16:18:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:11 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:18:11 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:18:11 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:18:11 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:18:12 - Predict] Found a GPU.\n",
      "[16:18:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:18:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:18:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe2d8205ae0>\n",
      "[16:18:13 - MdlStrTF] loading weights from /tmp/tmpk5eacmj6/model/variables/variables\n",
      "[16:18:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:18:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:18:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:13 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[16:18:13 - Feature] Processed ParPgb:0.0-242.0 (median depth 143.0)\n",
      "[16:18:13 - Sampler] Took 0.03s to make features.\n",
      "[16:18:13 - Sampler] Region ParPgb:0.0-242.0 (331 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:18:13 - PWorker] Processed 0 batches\n",
      "[16:18:13 - PWorker] All done, 1 remainder regions.\n",
      "[16:18:13 - Predict] Processing 1 short region(s).\n",
      "[16:18:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe23933d420>\n",
      "[16:18:13 - MdlStrTF] loading weights from /tmp/tmpk5eacmj6/model/variables/variables\n",
      "[16:18:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[16:18:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:13 - Feature] Processed ParPgb:0.0-242.0 (median depth 143.0)\n",
      "[16:18:13 - Sampler] Took 0.10s to make features.\n",
      "[16:18:14 - PWorker] Processed 1 batches\n",
      "[16:18:14 - PWorker] All done, 0 remainder regions.\n",
      "[16:18:14 - Predict] Finished processing all regions.\n",
      "[16:18:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:17 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:18:17 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:18:17 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:18:17 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:18:17 - Predict] Found a GPU.\n",
      "[16:18:17 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:18:17 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:18:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0014a61a80>\n",
      "[16:18:19 - MdlStrTF] loading weights from /tmp/tmpnif92bil/model/variables/variables\n",
      "[16:18:19 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:18:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:18:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:19 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-257.\n",
      "[16:18:19 - Feature] Processed ParPgb:0.0-257.0 (median depth 137.0)\n",
      "[16:18:19 - Sampler] Took 0.13s to make features.\n",
      "[16:18:19 - Sampler] Region ParPgb:0.0-257.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:18:19 - PWorker] Processed 0 batches\n",
      "[16:18:19 - PWorker] All done, 1 remainder regions.\n",
      "[16:18:19 - Predict] Processing 1 short region(s).\n",
      "[16:18:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7eff55b69ab0>\n",
      "[16:18:19 - MdlStrTF] loading weights from /tmp/tmpnif92bil/model/variables/variables\n",
      "[16:18:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-258.\n",
      "[16:18:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:22 - Feature] Processed ParPgb:0.0-257.0 (median depth 137.0)\n",
      "[16:18:22 - Sampler] Took 2.40s to make features.\n",
      "[16:18:22 - PWorker] Processed 1 batches\n",
      "[16:18:22 - PWorker] All done, 0 remainder regions.\n",
      "[16:18:22 - Predict] Finished processing all regions.\n",
      "[16:18:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:24 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:26 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:18:26 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:18:26 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:18:26 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:18:26 - Predict] Found a GPU.\n",
      "[16:18:26 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:18:26 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:18:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe43799dae0>\n",
      "[16:18:27 - MdlStrTF] loading weights from /tmp/tmp9e0tsdcu/model/variables/variables\n",
      "[16:18:27 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:18:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:18:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-266.\n",
      "[16:18:34 - Feature] Processed ParPgb:0.0-266.0 (median depth 222.0)\n",
      "[16:18:34 - Sampler] Took 6.79s to make features.\n",
      "[16:18:34 - Sampler] Region ParPgb:0.0-266.0 (392 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:18:34 - PWorker] Processed 0 batches\n",
      "[16:18:34 - PWorker] All done, 1 remainder regions.\n",
      "[16:18:34 - Predict] Processing 1 short region(s).\n",
      "[16:18:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe398b15ff0>\n",
      "[16:18:34 - MdlStrTF] loading weights from /tmp/tmp9e0tsdcu/model/variables/variables\n",
      "[16:18:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-267.\n",
      "[16:18:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:37 - Feature] Processed ParPgb:0.0-266.0 (median depth 222.0)\n",
      "[16:18:37 - Sampler] Took 2.37s to make features.\n",
      "[16:18:37 - PWorker] Processed 1 batches\n",
      "[16:18:37 - PWorker] All done, 0 remainder regions.\n",
      "[16:18:37 - Predict] Finished processing all regions.\n",
      "[16:18:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:39 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:18:41 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:18:41 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:18:41 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:18:41 - Predict] Found a GPU.\n",
      "[16:18:41 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:18:41 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:18:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faa2adf5ae0>\n",
      "[16:18:42 - MdlStrTF] loading weights from /tmp/tmpbezm709y/model/variables/variables\n",
      "[16:18:42 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:18:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:18:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:42 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:18:42 - Feature] Processed ParPgb:0.0-240.0 (median depth 98.0)\n",
      "[16:18:42 - Sampler] Took 0.08s to make features.\n",
      "[16:18:42 - Sampler] Region ParPgb:0.0-240.0 (283 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:18:42 - PWorker] Processed 0 batches\n",
      "[16:18:42 - PWorker] All done, 1 remainder regions.\n",
      "[16:18:42 - Predict] Processing 1 short region(s).\n",
      "[16:18:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa999fca230>\n",
      "[16:18:43 - MdlStrTF] loading weights from /tmp/tmpbezm709y/model/variables/variables\n",
      "[16:18:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:18:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:43 - Feature] Processed ParPgb:0.0-240.0 (median depth 98.0)\n",
      "[16:18:43 - Sampler] Took 0.03s to make features.\n",
      "[16:18:43 - PWorker] Processed 1 batches\n",
      "[16:18:43 - PWorker] All done, 0 remainder regions.\n",
      "[16:18:43 - Predict] Finished processing all regions.\n",
      "[16:18:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:45 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:18:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:18:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:18:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:18:47 - Predict] Found a GPU.\n",
      "[16:18:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:18:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:18:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f43b1c7dae0>\n",
      "[16:18:48 - MdlStrTF] loading weights from /tmp/tmpqckb1rol/model/variables/variables\n",
      "[16:18:48 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:18:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:18:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:48 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-220.\n",
      "[16:18:48 - Feature] Processed ParPgb:0.0-220.0 (median depth 94.0)\n",
      "[16:18:48 - Sampler] Took 0.07s to make features.\n",
      "[16:18:48 - Sampler] Region ParPgb:0.0-220.0 (276 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:18:48 - PWorker] Processed 0 batches\n",
      "[16:18:48 - PWorker] All done, 1 remainder regions.\n",
      "[16:18:48 - Predict] Processing 1 short region(s).\n",
      "[16:18:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4320ac5b10>\n",
      "[16:18:48 - MdlStrTF] loading weights from /tmp/tmpqckb1rol/model/variables/variables\n",
      "[16:18:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-221.\n",
      "[16:18:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:51 - Feature] Processed ParPgb:0.0-220.0 (median depth 94.0)\n",
      "[16:18:51 - Sampler] Took 2.39s to make features.\n",
      "[16:18:51 - PWorker] Processed 1 batches\n",
      "[16:18:51 - PWorker] All done, 0 remainder regions.\n",
      "[16:18:51 - Predict] Finished processing all regions.\n",
      "[16:18:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:18:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:18:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:18:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:18:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:18:55 - Predict] Found a GPU.\n",
      "[16:18:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:18:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:18:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f92352fdae0>\n",
      "[16:18:56 - MdlStrTF] loading weights from /tmp/tmpwsb4czen/model/variables/variables\n",
      "[16:18:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:18:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:18:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[16:18:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:18:58 - Feature] Processed ParPgb:0.0-244.0 (median depth 162.0)\n",
      "[16:18:58 - Sampler] Took 2.09s to make features.\n",
      "[16:18:58 - Sampler] Region ParPgb:0.0-244.0 (330 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:18:58 - PWorker] Processed 0 batches\n",
      "[16:18:58 - PWorker] All done, 1 remainder regions.\n",
      "[16:18:58 - Predict] Processing 1 short region(s).\n",
      "[16:18:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:18:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f916a47e3b0>\n",
      "[16:18:59 - MdlStrTF] loading weights from /tmp/tmpwsb4czen/model/variables/variables\n",
      "[16:18:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[16:18:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:00 - Feature] Processed ParPgb:0.0-244.0 (median depth 162.0)\n",
      "[16:19:00 - Sampler] Took 1.09s to make features.\n",
      "[16:19:00 - PWorker] Processed 1 batches\n",
      "[16:19:00 - PWorker] All done, 0 remainder regions.\n",
      "[16:19:00 - Predict] Finished processing all regions.\n",
      "[16:19:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:19:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:19:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:19:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:19:04 - Predict] Found a GPU.\n",
      "[16:19:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:19:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:19:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:19:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3e757d1ae0>\n",
      "[16:19:05 - MdlStrTF] loading weights from /tmp/tmpbo2y87vo/model/variables/variables\n",
      "[16:19:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:19:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:19:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-237.\n",
      "[16:19:05 - Feature] Processed ParPgb:0.0-237.0 (median depth 132.0)\n",
      "[16:19:05 - Sampler] Took 0.04s to make features.\n",
      "[16:19:05 - Sampler] Region ParPgb:0.0-237.0 (297 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:19:05 - PWorker] Processed 0 batches\n",
      "[16:19:05 - PWorker] All done, 1 remainder regions.\n",
      "[16:19:05 - Predict] Processing 1 short region(s).\n",
      "[16:19:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:19:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3de01261a0>\n",
      "[16:19:06 - MdlStrTF] loading weights from /tmp/tmpbo2y87vo/model/variables/variables\n",
      "[16:19:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-238.\n",
      "[16:19:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:08 - Feature] Processed ParPgb:0.0-237.0 (median depth 132.0)\n",
      "[16:19:08 - Sampler] Took 2.41s to make features.\n",
      "[16:19:09 - PWorker] Processed 1 batches\n",
      "[16:19:09 - PWorker] All done, 0 remainder regions.\n",
      "[16:19:09 - Predict] Finished processing all regions.\n",
      "[16:19:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:19:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:19:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:19:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:19:12 - Predict] Found a GPU.\n",
      "[16:19:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:19:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:19:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:19:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2d07b25ae0>\n",
      "[16:19:13 - MdlStrTF] loading weights from /tmp/tmpiohrykth/model/variables/variables\n",
      "[16:19:14 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:19:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:19:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:19:14 - Feature] Processed ParPgb:0.0-248.0 (median depth 118.0)\n",
      "[16:19:14 - Sampler] Took 0.11s to make features.\n",
      "[16:19:14 - Sampler] Region ParPgb:0.0-248.0 (302 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:19:14 - PWorker] Processed 0 batches\n",
      "[16:19:14 - PWorker] All done, 1 remainder regions.\n",
      "[16:19:14 - Predict] Processing 1 short region(s).\n",
      "[16:19:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:19:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2c68c75480>\n",
      "[16:19:14 - MdlStrTF] loading weights from /tmp/tmpiohrykth/model/variables/variables\n",
      "[16:19:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:19:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:14 - Feature] Processed ParPgb:0.0-248.0 (median depth 118.0)\n",
      "[16:19:14 - Sampler] Took 0.04s to make features.\n",
      "[16:19:15 - PWorker] Processed 1 batches\n",
      "[16:19:15 - PWorker] All done, 0 remainder regions.\n",
      "[16:19:15 - Predict] Finished processing all regions.\n",
      "[16:19:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:18 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:19:18 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:19:18 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:19:18 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:19:18 - Predict] Found a GPU.\n",
      "[16:19:18 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:19:18 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:19:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:19:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f06f0411ae0>\n",
      "[16:19:19 - MdlStrTF] loading weights from /tmp/tmpmqw41vhv/model/variables/variables\n",
      "[16:19:19 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:19:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:19:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:22 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[16:19:22 - Feature] Processed ParPgb:0.0-252.0 (median depth 213.0)\n",
      "[16:19:22 - Sampler] Took 2.72s to make features.\n",
      "[16:19:22 - Sampler] Region ParPgb:0.0-252.0 (358 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:19:22 - PWorker] Processed 0 batches\n",
      "[16:19:22 - PWorker] All done, 1 remainder regions.\n",
      "[16:19:22 - Predict] Processing 1 short region(s).\n",
      "[16:19:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:19:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f06515a2140>\n",
      "[16:19:23 - MdlStrTF] loading weights from /tmp/tmpmqw41vhv/model/variables/variables\n",
      "[16:19:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[16:19:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:25 - Feature] Processed ParPgb:0.0-252.0 (median depth 213.0)\n",
      "[16:19:25 - Sampler] Took 2.65s to make features.\n",
      "[16:19:26 - PWorker] Processed 1 batches\n",
      "[16:19:26 - PWorker] All done, 0 remainder regions.\n",
      "[16:19:26 - Predict] Finished processing all regions.\n",
      "[16:19:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:19:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:19:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:19:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:19:29 - Predict] Found a GPU.\n",
      "[16:19:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:19:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:19:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:19:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7f26151ae0>\n",
      "[16:19:31 - MdlStrTF] loading weights from /tmp/tmpoi8hm84p/model/variables/variables\n",
      "[16:19:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:19:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:19:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[16:19:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:31 - Feature] Processed ParPgb:0.0-238.0 (median depth 109.0)\n",
      "[16:19:31 - Sampler] Took 0.12s to make features.\n",
      "[16:19:31 - Sampler] Region ParPgb:0.0-238.0 (309 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:19:31 - PWorker] Processed 0 batches\n",
      "[16:19:31 - PWorker] All done, 1 remainder regions.\n",
      "[16:19:31 - Predict] Processing 1 short region(s).\n",
      "[16:19:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:19:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7e8930e320>\n",
      "[16:19:31 - MdlStrTF] loading weights from /tmp/tmpoi8hm84p/model/variables/variables\n",
      "[16:19:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[16:19:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:36 - Feature] Processed ParPgb:0.0-238.0 (median depth 109.0)\n",
      "[16:19:36 - Sampler] Took 4.69s to make features.\n",
      "[16:19:36 - PWorker] Batches in cache: 1.\n",
      "[16:19:36 - PWorker] Processed 1 batches\n",
      "[16:19:36 - PWorker] All done, 0 remainder regions.\n",
      "[16:19:36 - Predict] Finished processing all regions.\n",
      "[16:19:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:19:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:19:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:19:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:19:40 - Predict] Found a GPU.\n",
      "[16:19:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:19:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:19:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:19:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ffaec7a5ae0>\n",
      "[16:19:41 - MdlStrTF] loading weights from /tmp/tmpncbniymd/model/variables/variables\n",
      "[16:19:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:19:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:19:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:41 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-221.\n",
      "[16:19:41 - Feature] Processed ParPgb:0.0-221.0 (median depth 116.0)\n",
      "[16:19:41 - Sampler] Took 0.12s to make features.\n",
      "[16:19:41 - Sampler] Region ParPgb:0.0-221.0 (295 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:19:41 - PWorker] Processed 0 batches\n",
      "[16:19:41 - PWorker] All done, 1 remainder regions.\n",
      "[16:19:41 - Predict] Processing 1 short region(s).\n",
      "[16:19:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:19:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ffa5c19aef0>\n",
      "[16:19:42 - MdlStrTF] loading weights from /tmp/tmpncbniymd/model/variables/variables\n",
      "[16:19:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-222.\n",
      "[16:19:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:48 - Feature] Processed ParPgb:0.0-221.0 (median depth 116.0)\n",
      "[16:19:48 - Sampler] Took 6.34s to make features.\n",
      "[16:19:49 - PWorker] Batches in cache: 1.\n",
      "[16:19:49 - PWorker] Processed 1 batches\n",
      "[16:19:49 - PWorker] All done, 0 remainder regions.\n",
      "[16:19:49 - Predict] Finished processing all regions.\n",
      "[16:19:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:52 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:19:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:19:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:19:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:19:52 - Predict] Found a GPU.\n",
      "[16:19:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:19:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:19:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:19:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fed78d91ae0>\n",
      "[16:19:53 - MdlStrTF] loading weights from /tmp/tmp4spt_88h/model/variables/variables\n",
      "[16:19:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:19:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:19:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-262.\n",
      "[16:19:53 - Feature] Processed ParPgb:0.0-262.0 (median depth 149.0)\n",
      "[16:19:53 - Sampler] Took 0.05s to make features.\n",
      "[16:19:53 - Sampler] Region ParPgb:0.0-262.0 (372 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:19:53 - PWorker] Processed 0 batches\n",
      "[16:19:53 - PWorker] All done, 1 remainder regions.\n",
      "[16:19:53 - Predict] Processing 1 short region(s).\n",
      "[16:19:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:19:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fecd858d480>\n",
      "[16:19:54 - MdlStrTF] loading weights from /tmp/tmp4spt_88h/model/variables/variables\n",
      "[16:19:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-263.\n",
      "[16:19:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:19:55 - Feature] Processed ParPgb:0.0-262.0 (median depth 149.0)\n",
      "[16:19:55 - Sampler] Took 1.30s to make features.\n",
      "[16:19:56 - PWorker] Processed 1 batches\n",
      "[16:19:56 - PWorker] All done, 0 remainder regions.\n",
      "[16:19:56 - Predict] Finished processing all regions.\n",
      "[16:19:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:19:59 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:19:59 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:19:59 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:19:59 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:19:59 - Predict] Found a GPU.\n",
      "[16:19:59 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:19:59 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:19:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f32cfc2dae0>\n",
      "[16:20:01 - MdlStrTF] loading weights from /tmp/tmps1yc7o7n/model/variables/variables\n",
      "[16:20:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:20:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:20:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-199.\n",
      "[16:20:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:01 - Feature] Processed ParPgb:0.0-199.0 (median depth 9.0)\n",
      "[16:20:01 - Sampler] Took 0.17s to make features.\n",
      "[16:20:01 - Sampler] Region ParPgb:0.0-199.0 (207 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:20:01 - PWorker] Processed 0 batches\n",
      "[16:20:01 - PWorker] All done, 1 remainder regions.\n",
      "[16:20:01 - Predict] Processing 1 short region(s).\n",
      "[16:20:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3230d723b0>\n",
      "[16:20:01 - MdlStrTF] loading weights from /tmp/tmps1yc7o7n/model/variables/variables\n",
      "[16:20:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-200.\n",
      "[16:20:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:01 - Feature] Processed ParPgb:0.0-199.0 (median depth 9.0)\n",
      "[16:20:01 - Sampler] Took 0.10s to make features.\n",
      "[16:20:02 - PWorker] Processed 1 batches\n",
      "[16:20:02 - PWorker] All done, 0 remainder regions.\n",
      "[16:20:02 - Predict] Finished processing all regions.\n",
      "[16:20:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:04 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:20:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:20:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:20:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:20:05 - Predict] Found a GPU.\n",
      "[16:20:05 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:20:05 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:20:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4f563d5ae0>\n",
      "[16:20:07 - MdlStrTF] loading weights from /tmp/tmppk4patk_/model/variables/variables\n",
      "[16:20:07 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:20:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:20:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:07 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[16:20:07 - Feature] Processed ParPgb:0.0-242.0 (median depth 106.0)\n",
      "[16:20:07 - Sampler] Took 0.06s to make features.\n",
      "[16:20:07 - Sampler] Region ParPgb:0.0-242.0 (329 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:20:07 - PWorker] Processed 0 batches\n",
      "[16:20:07 - PWorker] All done, 1 remainder regions.\n",
      "[16:20:07 - Predict] Processing 1 short region(s).\n",
      "[16:20:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4eb8c6d480>\n",
      "[16:20:07 - MdlStrTF] loading weights from /tmp/tmppk4patk_/model/variables/variables\n",
      "[16:20:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[16:20:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:07 - Feature] Processed ParPgb:0.0-242.0 (median depth 106.0)\n",
      "[16:20:07 - Sampler] Took 0.06s to make features.\n",
      "[16:20:08 - PWorker] Processed 1 batches\n",
      "[16:20:08 - PWorker] All done, 0 remainder regions.\n",
      "[16:20:08 - Predict] Finished processing all regions.\n",
      "[16:20:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:11 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:20:11 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:20:11 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:20:11 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:20:11 - Predict] Found a GPU.\n",
      "[16:20:11 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:20:11 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:20:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe0df3cdae0>\n",
      "[16:20:13 - MdlStrTF] loading weights from /tmp/tmpesld6zju/model/variables/variables\n",
      "[16:20:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:20:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:20:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-223.\n",
      "[16:20:14 - Feature] Processed ParPgb:0.0-223.0 (median depth 135.0)\n",
      "[16:20:14 - Sampler] Took 1.66s to make features.\n",
      "[16:20:14 - Sampler] Region ParPgb:0.0-223.0 (313 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:20:14 - PWorker] Processed 0 batches\n",
      "[16:20:14 - PWorker] All done, 1 remainder regions.\n",
      "[16:20:14 - Predict] Processing 1 short region(s).\n",
      "[16:20:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe04e571480>\n",
      "[16:20:15 - MdlStrTF] loading weights from /tmp/tmpesld6zju/model/variables/variables\n",
      "[16:20:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-224.\n",
      "[16:20:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:15 - Feature] Processed ParPgb:0.0-223.0 (median depth 135.0)\n",
      "[16:20:15 - Sampler] Took 0.05s to make features.\n",
      "[16:20:15 - PWorker] Processed 1 batches\n",
      "[16:20:15 - PWorker] All done, 0 remainder regions.\n",
      "[16:20:15 - Predict] Finished processing all regions.\n",
      "[16:20:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:20:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:20:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:20:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:20:19 - Predict] Found a GPU.\n",
      "[16:20:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:20:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:20:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f68dd889ae0>\n",
      "[16:20:20 - MdlStrTF] loading weights from /tmp/tmpi023i_7x/model/variables/variables\n",
      "[16:20:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:20:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:20:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:20:20 - Feature] Processed ParPgb:0.0-240.0 (median depth 163.0)\n",
      "[16:20:20 - Sampler] Took 0.09s to make features.\n",
      "[16:20:20 - Sampler] Region ParPgb:0.0-240.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:20:20 - PWorker] Processed 0 batches\n",
      "[16:20:20 - PWorker] All done, 1 remainder regions.\n",
      "[16:20:20 - Predict] Processing 1 short region(s).\n",
      "[16:20:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f684c689b10>\n",
      "[16:20:21 - MdlStrTF] loading weights from /tmp/tmpi023i_7x/model/variables/variables\n",
      "[16:20:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:20:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:21 - Feature] Processed ParPgb:0.0-240.0 (median depth 163.0)\n",
      "[16:20:21 - Sampler] Took 0.05s to make features.\n",
      "[16:20:21 - PWorker] Processed 1 batches\n",
      "[16:20:21 - PWorker] All done, 0 remainder regions.\n",
      "[16:20:21 - Predict] Finished processing all regions.\n",
      "[16:20:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:20:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:20:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:20:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:20:25 - Predict] Found a GPU.\n",
      "[16:20:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:20:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:20:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f39676e9ae0>\n",
      "[16:20:26 - MdlStrTF] loading weights from /tmp/tmp11gao_mw/model/variables/variables\n",
      "[16:20:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:20:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:20:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-241.\n",
      "[16:20:26 - Feature] Processed ParPgb:0.0-241.0 (median depth 113.0)\n",
      "[16:20:26 - Sampler] Took 0.16s to make features.\n",
      "[16:20:26 - Sampler] Region ParPgb:0.0-241.0 (308 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:20:26 - PWorker] Processed 0 batches\n",
      "[16:20:26 - PWorker] All done, 1 remainder regions.\n",
      "[16:20:26 - Predict] Processing 1 short region(s).\n",
      "[16:20:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f38d80c1ff0>\n",
      "[16:20:27 - MdlStrTF] loading weights from /tmp/tmp11gao_mw/model/variables/variables\n",
      "[16:20:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-242.\n",
      "[16:20:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:28 - Feature] Processed ParPgb:0.0-241.0 (median depth 113.0)\n",
      "[16:20:28 - Sampler] Took 1.36s to make features.\n",
      "[16:20:28 - PWorker] Processed 1 batches\n",
      "[16:20:28 - PWorker] All done, 0 remainder regions.\n",
      "[16:20:28 - Predict] Finished processing all regions.\n",
      "[16:20:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:30 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:32 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:20:32 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:20:32 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:20:32 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:20:32 - Predict] Found a GPU.\n",
      "[16:20:32 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:20:32 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:20:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2dedc2dae0>\n",
      "[16:20:33 - MdlStrTF] loading weights from /tmp/tmpt3rrgxr7/model/variables/variables\n",
      "[16:20:33 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:20:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:20:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:33 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[16:20:33 - Feature] Processed ParPgb:0.0-255.0 (median depth 125.0)\n",
      "[16:20:33 - Sampler] Took 0.04s to make features.\n",
      "[16:20:33 - Sampler] Region ParPgb:0.0-255.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:20:33 - PWorker] Processed 0 batches\n",
      "[16:20:33 - PWorker] All done, 1 remainder regions.\n",
      "[16:20:33 - Predict] Processing 1 short region(s).\n",
      "[16:20:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2d5c539480>\n",
      "[16:20:34 - MdlStrTF] loading weights from /tmp/tmpt3rrgxr7/model/variables/variables\n",
      "[16:20:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[16:20:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:34 - Feature] Processed ParPgb:0.0-255.0 (median depth 125.0)\n",
      "[16:20:34 - Sampler] Took 0.03s to make features.\n",
      "[16:20:34 - PWorker] Processed 1 batches\n",
      "[16:20:34 - PWorker] All done, 0 remainder regions.\n",
      "[16:20:34 - Predict] Finished processing all regions.\n",
      "[16:20:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:20:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:20:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:20:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:20:38 - Predict] Found a GPU.\n",
      "[16:20:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:20:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:20:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f97aefbdae0>\n",
      "[16:20:39 - MdlStrTF] loading weights from /tmp/tmp17226477/model/variables/variables\n",
      "[16:20:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:20:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:20:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-259.\n",
      "[16:20:41 - Feature] Processed ParPgb:0.0-259.0 (median depth 109.0)\n",
      "[16:20:41 - Sampler] Took 2.17s to make features.\n",
      "[16:20:41 - Sampler] Region ParPgb:0.0-259.0 (315 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:20:41 - PWorker] Processed 0 batches\n",
      "[16:20:41 - PWorker] All done, 1 remainder regions.\n",
      "[16:20:41 - Predict] Processing 1 short region(s).\n",
      "[16:20:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:42 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9790299990>\n",
      "[16:20:42 - MdlStrTF] loading weights from /tmp/tmp17226477/model/variables/variables\n",
      "[16:20:42 - Sampler] Initializing sampler for consensus of region ParPgb:0-260.\n",
      "[16:20:42 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:42 - Feature] Processed ParPgb:0.0-259.0 (median depth 109.0)\n",
      "[16:20:42 - Sampler] Took 0.03s to make features.\n",
      "[16:20:42 - PWorker] Processed 1 batches\n",
      "[16:20:42 - PWorker] All done, 0 remainder regions.\n",
      "[16:20:42 - Predict] Finished processing all regions.\n",
      "[16:20:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:46 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:20:46 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:20:46 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:20:46 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:20:46 - Predict] Found a GPU.\n",
      "[16:20:46 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:20:46 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:20:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8e034c5ae0>\n",
      "[16:20:47 - MdlStrTF] loading weights from /tmp/tmpj26l3__m/model/variables/variables\n",
      "[16:20:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:20:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:20:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[16:20:47 - Feature] Processed ParPgb:0.0-243.0 (median depth 250.0)\n",
      "[16:20:47 - Sampler] Took 0.02s to make features.\n",
      "[16:20:47 - Sampler] Region ParPgb:0.0-243.0 (390 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:20:47 - PWorker] Processed 0 batches\n",
      "[16:20:47 - PWorker] All done, 1 remainder regions.\n",
      "[16:20:47 - Predict] Processing 1 short region(s).\n",
      "[16:20:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8d72619480>\n",
      "[16:20:48 - MdlStrTF] loading weights from /tmp/tmpj26l3__m/model/variables/variables\n",
      "[16:20:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[16:20:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:48 - Feature] Processed ParPgb:0.0-243.0 (median depth 250.0)\n",
      "[16:20:48 - Sampler] Took 0.06s to make features.\n",
      "[16:20:48 - PWorker] Processed 1 batches\n",
      "[16:20:48 - PWorker] All done, 0 remainder regions.\n",
      "[16:20:48 - Predict] Finished processing all regions.\n",
      "[16:20:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:52 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:20:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:20:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:20:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:20:52 - Predict] Found a GPU.\n",
      "[16:20:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:20:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:20:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6c2f21dae0>\n",
      "[16:20:53 - MdlStrTF] loading weights from /tmp/tmpr4vvh_0s/model/variables/variables\n",
      "[16:20:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:20:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:20:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-265.\n",
      "[16:20:53 - Feature] Processed ParPgb:0.0-265.0 (median depth 120.0)\n",
      "[16:20:53 - Sampler] Took 0.17s to make features.\n",
      "[16:20:53 - Sampler] Region ParPgb:0.0-265.0 (341 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:20:53 - PWorker] Processed 0 batches\n",
      "[16:20:53 - PWorker] All done, 1 remainder regions.\n",
      "[16:20:53 - Predict] Processing 1 short region(s).\n",
      "[16:20:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6b8c551b10>\n",
      "[16:20:54 - MdlStrTF] loading weights from /tmp/tmpr4vvh_0s/model/variables/variables\n",
      "[16:20:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-266.\n",
      "[16:20:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:54 - Feature] Processed ParPgb:0.0-265.0 (median depth 120.0)\n",
      "[16:20:54 - Sampler] Took 0.10s to make features.\n",
      "[16:20:54 - PWorker] Processed 1 batches\n",
      "[16:20:54 - PWorker] All done, 0 remainder regions.\n",
      "[16:20:54 - Predict] Finished processing all regions.\n",
      "[16:20:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:20:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:20:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:20:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:20:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:20:58 - Predict] Found a GPU.\n",
      "[16:20:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:20:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:20:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:20:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9d57841a80>\n",
      "[16:20:59 - MdlStrTF] loading weights from /tmp/tmphhn27ydq/model/variables/variables\n",
      "[16:20:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:20:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:20:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:20:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[16:20:59 - Feature] Processed ParPgb:0.0-252.0 (median depth 187.0)\n",
      "[16:20:59 - Sampler] Took 0.05s to make features.\n",
      "[16:20:59 - Sampler] Region ParPgb:0.0-252.0 (357 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:20:59 - PWorker] Processed 0 batches\n",
      "[16:20:59 - PWorker] All done, 1 remainder regions.\n",
      "[16:20:59 - Predict] Processing 1 short region(s).\n",
      "[16:20:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:00 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9cb8a16140>\n",
      "[16:21:00 - MdlStrTF] loading weights from /tmp/tmphhn27ydq/model/variables/variables\n",
      "[16:21:00 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[16:21:00 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:00 - Feature] Processed ParPgb:0.0-252.0 (median depth 187.0)\n",
      "[16:21:00 - Sampler] Took 0.05s to make features.\n",
      "[16:21:00 - PWorker] Processed 1 batches\n",
      "[16:21:00 - PWorker] All done, 0 remainder regions.\n",
      "[16:21:00 - Predict] Finished processing all regions.\n",
      "[16:21:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:21:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:21:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:21:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:21:04 - Predict] Found a GPU.\n",
      "[16:21:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:21:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:21:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcebf8c9ae0>\n",
      "[16:21:05 - MdlStrTF] loading weights from /tmp/tmpimtn8n_f/model/variables/variables\n",
      "[16:21:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:21:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:21:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-201.\n",
      "[16:21:05 - Feature] Processed ParPgb:0.0-201.0 (median depth 119.0)\n",
      "[16:21:05 - Sampler] Took 0.06s to make features.\n",
      "[16:21:05 - Sampler] Region ParPgb:0.0-201.0 (269 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:21:05 - PWorker] Processed 0 batches\n",
      "[16:21:05 - PWorker] All done, 1 remainder regions.\n",
      "[16:21:05 - Predict] Processing 1 short region(s).\n",
      "[16:21:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fce20a11ae0>\n",
      "[16:21:06 - MdlStrTF] loading weights from /tmp/tmpimtn8n_f/model/variables/variables\n",
      "[16:21:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-202.\n",
      "[16:21:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:06 - Feature] Processed ParPgb:0.0-201.0 (median depth 119.0)\n",
      "[16:21:06 - Sampler] Took 0.06s to make features.\n",
      "[16:21:06 - PWorker] Processed 1 batches\n",
      "[16:21:06 - PWorker] All done, 0 remainder regions.\n",
      "[16:21:06 - Predict] Finished processing all regions.\n",
      "[16:21:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:10 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:21:10 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:21:10 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:21:10 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:21:10 - Predict] Found a GPU.\n",
      "[16:21:10 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:21:10 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:21:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4fdffa1ae0>\n",
      "[16:21:11 - MdlStrTF] loading weights from /tmp/tmptadwn7du/model/variables/variables\n",
      "[16:21:11 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:21:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:21:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-237.\n",
      "[16:21:11 - Feature] Processed ParPgb:0.0-237.0 (median depth 240.0)\n",
      "[16:21:11 - Sampler] Took 0.04s to make features.\n",
      "[16:21:11 - Sampler] Region ParPgb:0.0-237.0 (370 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:21:11 - PWorker] Processed 0 batches\n",
      "[16:21:11 - PWorker] All done, 1 remainder regions.\n",
      "[16:21:11 - Predict] Processing 1 short region(s).\n",
      "[16:21:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4f500c1ff0>\n",
      "[16:21:11 - MdlStrTF] loading weights from /tmp/tmptadwn7du/model/variables/variables\n",
      "[16:21:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-238.\n",
      "[16:21:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:14 - Feature] Processed ParPgb:0.0-237.0 (median depth 240.0)\n",
      "[16:21:14 - Sampler] Took 2.53s to make features.\n",
      "[16:21:15 - PWorker] Processed 1 batches\n",
      "[16:21:15 - PWorker] All done, 0 remainder regions.\n",
      "[16:21:15 - Predict] Finished processing all regions.\n",
      "[16:21:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:18 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:21:18 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:21:18 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:21:18 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:21:18 - Predict] Found a GPU.\n",
      "[16:21:18 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:21:18 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:21:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4c0c131ae0>\n",
      "[16:21:19 - MdlStrTF] loading weights from /tmp/tmp1klp9i1i/model/variables/variables\n",
      "[16:21:19 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:21:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:21:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:19 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-223.\n",
      "[16:21:19 - Feature] Processed ParPgb:0.0-223.0 (median depth 139.0)\n",
      "[16:21:19 - Sampler] Took 0.03s to make features.\n",
      "[16:21:19 - Sampler] Region ParPgb:0.0-223.0 (308 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:21:19 - PWorker] Processed 0 batches\n",
      "[16:21:19 - PWorker] All done, 1 remainder regions.\n",
      "[16:21:19 - Predict] Processing 1 short region(s).\n",
      "[16:21:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4b6cff5450>\n",
      "[16:21:20 - MdlStrTF] loading weights from /tmp/tmp1klp9i1i/model/variables/variables\n",
      "[16:21:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-224.\n",
      "[16:21:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:20 - Feature] Processed ParPgb:0.0-223.0 (median depth 139.0)\n",
      "[16:21:20 - Sampler] Took 0.03s to make features.\n",
      "[16:21:20 - PWorker] Processed 1 batches\n",
      "[16:21:20 - PWorker] All done, 0 remainder regions.\n",
      "[16:21:20 - Predict] Finished processing all regions.\n",
      "[16:21:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:21:24 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:21:24 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:21:24 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:21:24 - Predict] Found a GPU.\n",
      "[16:21:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:21:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:21:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd7d3515ae0>\n",
      "[16:21:25 - MdlStrTF] loading weights from /tmp/tmpbu3sum7s/model/variables/variables\n",
      "[16:21:25 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:21:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:21:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:25 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[16:21:25 - Feature] Processed ParPgb:0.0-251.0 (median depth 128.0)\n",
      "[16:21:25 - Sampler] Took 0.04s to make features.\n",
      "[16:21:25 - Sampler] Region ParPgb:0.0-251.0 (333 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:21:25 - PWorker] Processed 0 batches\n",
      "[16:21:25 - PWorker] All done, 1 remainder regions.\n",
      "[16:21:25 - Predict] Processing 1 short region(s).\n",
      "[16:21:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd741e4d480>\n",
      "[16:21:26 - MdlStrTF] loading weights from /tmp/tmpbu3sum7s/model/variables/variables\n",
      "[16:21:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[16:21:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:26 - Feature] Processed ParPgb:0.0-251.0 (median depth 128.0)\n",
      "[16:21:26 - Sampler] Took 0.05s to make features.\n",
      "[16:21:26 - PWorker] Processed 1 batches\n",
      "[16:21:26 - PWorker] All done, 0 remainder regions.\n",
      "[16:21:26 - Predict] Finished processing all regions.\n",
      "[16:21:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:21:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:21:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:21:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:21:30 - Predict] Found a GPU.\n",
      "[16:21:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:21:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:21:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ffa2a3edae0>\n",
      "[16:21:31 - MdlStrTF] loading weights from /tmp/tmpmui1kk6r/model/variables/variables\n",
      "[16:21:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:21:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:21:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-189.\n",
      "[16:21:31 - Feature] Processed ParPgb:0.0-189.0 (median depth 1.0)\n",
      "[16:21:31 - Sampler] Took 0.30s to make features.\n",
      "[16:21:31 - Sampler] Region ParPgb:0.0-189.0 (191 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:21:31 - PWorker] Processed 0 batches\n",
      "[16:21:31 - PWorker] All done, 1 remainder regions.\n",
      "[16:21:31 - Predict] Processing 1 short region(s).\n",
      "[16:21:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff9981e61a0>\n",
      "[16:21:32 - MdlStrTF] loading weights from /tmp/tmpmui1kk6r/model/variables/variables\n",
      "[16:21:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-190.\n",
      "[16:21:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:32 - Feature] Processed ParPgb:0.0-189.0 (median depth 1.0)\n",
      "[16:21:32 - Sampler] Took 0.10s to make features.\n",
      "[16:21:32 - PWorker] Processed 1 batches\n",
      "[16:21:32 - PWorker] All done, 0 remainder regions.\n",
      "[16:21:32 - Predict] Finished processing all regions.\n",
      "[16:21:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:36 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:21:36 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:21:36 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:21:36 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:21:36 - Predict] Found a GPU.\n",
      "[16:21:36 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:21:36 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:21:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f05addf5ae0>\n",
      "[16:21:37 - MdlStrTF] loading weights from /tmp/tmpjvqa4c7o/model/variables/variables\n",
      "[16:21:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:21:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:21:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-188.\n",
      "[16:21:37 - Feature] Processed ParPgb:0.0-188.0 (median depth 1.0)\n",
      "[16:21:37 - Sampler] Took 0.03s to make features.\n",
      "[16:21:37 - Sampler] Region ParPgb:0.0-188.0 (189 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:21:37 - PWorker] Processed 0 batches\n",
      "[16:21:37 - PWorker] All done, 1 remainder regions.\n",
      "[16:21:37 - Predict] Processing 1 short region(s).\n",
      "[16:21:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f051cfa9450>\n",
      "[16:21:38 - MdlStrTF] loading weights from /tmp/tmpjvqa4c7o/model/variables/variables\n",
      "[16:21:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-189.\n",
      "[16:21:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:38 - Feature] Processed ParPgb:0.0-188.0 (median depth 1.0)\n",
      "[16:21:38 - Sampler] Took 0.76s to make features.\n",
      "[16:21:39 - PWorker] Processed 1 batches\n",
      "[16:21:39 - PWorker] All done, 0 remainder regions.\n",
      "[16:21:39 - Predict] Finished processing all regions.\n",
      "[16:21:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:42 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:21:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:21:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:21:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:21:43 - Predict] Found a GPU.\n",
      "[16:21:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:21:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:21:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7d8bcc9ae0>\n",
      "[16:21:44 - MdlStrTF] loading weights from /tmp/tmpxl0z0h7n/model/variables/variables\n",
      "[16:21:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:21:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:21:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:44 - Sampler] Took 0.06s to make features.\n",
      "[16:21:44 - PWorker] Processed 0 batches\n",
      "[16:21:44 - PWorker] All done, 0 remainder regions.\n",
      "[16:21:44 - Predict] Finished processing all regions.\n",
      "[16:21:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:46 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:21:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:21:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:21:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:21:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:21:47 - Predict] Found a GPU.\n",
      "[16:21:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:21:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:21:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4838989ae0>\n",
      "[16:21:49 - MdlStrTF] loading weights from /tmp/tmpgc2tu8m5/model/variables/variables\n",
      "[16:21:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:21:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:21:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-263.\n",
      "[16:21:49 - Feature] Processed ParPgb:0.0-263.0 (median depth 223.0)\n",
      "[16:21:49 - Sampler] Took 0.04s to make features.\n",
      "[16:21:49 - Sampler] Region ParPgb:0.0-263.0 (376 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:21:49 - PWorker] Processed 0 batches\n",
      "[16:21:49 - PWorker] All done, 1 remainder regions.\n",
      "[16:21:49 - Predict] Processing 1 short region(s).\n",
      "[16:21:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f47a8391480>\n",
      "[16:21:49 - MdlStrTF] loading weights from /tmp/tmpgc2tu8m5/model/variables/variables\n",
      "[16:21:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-264.\n",
      "[16:21:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:51 - Feature] Processed ParPgb:0.0-263.0 (median depth 223.0)\n",
      "[16:21:51 - Sampler] Took 2.18s to make features.\n",
      "[16:21:52 - PWorker] Processed 1 batches\n",
      "[16:21:52 - PWorker] All done, 0 remainder regions.\n",
      "[16:21:52 - Predict] Finished processing all regions.\n",
      "[16:21:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:21:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:21:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:21:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:21:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:21:55 - Predict] Found a GPU.\n",
      "[16:21:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:21:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:21:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f358f5e1ae0>\n",
      "[16:21:57 - MdlStrTF] loading weights from /tmp/tmpqhwkcpkg/model/variables/variables\n",
      "[16:21:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:21:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:21:57 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:21:57 - Feature] Processed ParPgb:0.0-248.0 (median depth 198.0)\n",
      "[16:21:57 - Sampler] Took 0.04s to make features.\n",
      "[16:21:57 - Sampler] Region ParPgb:0.0-248.0 (369 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:21:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:57 - PWorker] Processed 0 batches\n",
      "[16:21:57 - PWorker] All done, 1 remainder regions.\n",
      "[16:21:57 - Predict] Processing 1 short region(s).\n",
      "[16:21:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:21:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f34f079de10>\n",
      "[16:21:57 - MdlStrTF] loading weights from /tmp/tmpqhwkcpkg/model/variables/variables\n",
      "[16:21:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:21:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:21:57 - Feature] Processed ParPgb:0.0-248.0 (median depth 198.0)\n",
      "[16:21:57 - Sampler] Took 0.21s to make features.\n",
      "[16:21:58 - PWorker] Processed 1 batches\n",
      "[16:21:58 - PWorker] All done, 0 remainder regions.\n",
      "[16:21:58 - Predict] Finished processing all regions.\n",
      "[16:22:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:00 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:01 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:22:01 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:22:01 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:22:01 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:22:01 - Predict] Found a GPU.\n",
      "[16:22:01 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:22:01 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:22:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbda9131ae0>\n",
      "[16:22:03 - MdlStrTF] loading weights from /tmp/tmpnv3xrg7q/model/variables/variables\n",
      "[16:22:03 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:22:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:22:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:03 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-252.\n",
      "[16:22:03 - Feature] Processed ParPgb:0.0-252.0 (median depth 242.0)\n",
      "[16:22:03 - Sampler] Took 0.09s to make features.\n",
      "[16:22:03 - Sampler] Region ParPgb:0.0-252.0 (366 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:22:03 - PWorker] Processed 0 batches\n",
      "[16:22:03 - PWorker] All done, 1 remainder regions.\n",
      "[16:22:03 - Predict] Processing 1 short region(s).\n",
      "[16:22:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbd18329ff0>\n",
      "[16:22:03 - MdlStrTF] loading weights from /tmp/tmpnv3xrg7q/model/variables/variables\n",
      "[16:22:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-253.\n",
      "[16:22:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:03 - Feature] Processed ParPgb:0.0-252.0 (median depth 242.0)\n",
      "[16:22:03 - Sampler] Took 0.03s to make features.\n",
      "[16:22:04 - PWorker] Processed 1 batches\n",
      "[16:22:04 - PWorker] All done, 0 remainder regions.\n",
      "[16:22:04 - Predict] Finished processing all regions.\n",
      "[16:22:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:07 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:22:07 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:22:07 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:22:07 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:22:07 - Predict] Found a GPU.\n",
      "[16:22:07 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:22:07 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:22:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8affa41a80>\n",
      "[16:22:09 - MdlStrTF] loading weights from /tmp/tmpkpvxr0cc/model/variables/variables\n",
      "[16:22:09 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:22:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:22:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:09 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[16:22:09 - Feature] Processed ParPgb:0.0-244.0 (median depth 74.0)\n",
      "[16:22:09 - Sampler] Took 0.06s to make features.\n",
      "[16:22:09 - Sampler] Region ParPgb:0.0-244.0 (308 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:22:09 - PWorker] Processed 0 batches\n",
      "[16:22:09 - PWorker] All done, 1 remainder regions.\n",
      "[16:22:09 - Predict] Processing 1 short region(s).\n",
      "[16:22:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8a60c16e60>\n",
      "[16:22:09 - MdlStrTF] loading weights from /tmp/tmpkpvxr0cc/model/variables/variables\n",
      "[16:22:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[16:22:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:09 - Feature] Processed ParPgb:0.0-244.0 (median depth 74.0)\n",
      "[16:22:09 - Sampler] Took 0.05s to make features.\n",
      "[16:22:10 - PWorker] Processed 1 batches\n",
      "[16:22:10 - PWorker] All done, 0 remainder regions.\n",
      "[16:22:10 - Predict] Finished processing all regions.\n",
      "[16:22:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:13 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:22:13 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:22:13 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:22:13 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:22:13 - Predict] Found a GPU.\n",
      "[16:22:13 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:22:13 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:22:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7e76339ae0>\n",
      "[16:22:14 - MdlStrTF] loading weights from /tmp/tmpgoy7z36e/model/variables/variables\n",
      "[16:22:14 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:22:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:22:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-234.\n",
      "[16:22:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:15 - Feature] Processed ParPgb:0.0-234.0 (median depth 253.0)\n",
      "[16:22:15 - Sampler] Took 0.12s to make features.\n",
      "[16:22:15 - Sampler] Region ParPgb:0.0-234.0 (342 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:22:15 - PWorker] Processed 0 batches\n",
      "[16:22:15 - PWorker] All done, 1 remainder regions.\n",
      "[16:22:15 - Predict] Processing 1 short region(s).\n",
      "[16:22:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7dd946a3b0>\n",
      "[16:22:15 - MdlStrTF] loading weights from /tmp/tmpgoy7z36e/model/variables/variables\n",
      "[16:22:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-235.\n",
      "[16:22:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:15 - Feature] Processed ParPgb:0.0-234.0 (median depth 253.0)\n",
      "[16:22:15 - Sampler] Took 0.06s to make features.\n",
      "[16:22:16 - PWorker] Processed 1 batches\n",
      "[16:22:16 - PWorker] All done, 0 remainder regions.\n",
      "[16:22:16 - Predict] Finished processing all regions.\n",
      "[16:22:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:22:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:22:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:22:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:22:19 - Predict] Found a GPU.\n",
      "[16:22:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:22:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:22:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1f99d4dae0>\n",
      "[16:22:20 - MdlStrTF] loading weights from /tmp/tmpqzdxdjba/model/variables/variables\n",
      "[16:22:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:22:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:22:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:22:20 - Feature] Processed ParPgb:0.0-246.0 (median depth 131.0)\n",
      "[16:22:20 - Sampler] Took 0.03s to make features.\n",
      "[16:22:20 - Sampler] Region ParPgb:0.0-246.0 (306 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:22:20 - PWorker] Processed 0 batches\n",
      "[16:22:20 - PWorker] All done, 1 remainder regions.\n",
      "[16:22:20 - Predict] Processing 1 short region(s).\n",
      "[16:22:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1f08eed480>\n",
      "[16:22:21 - MdlStrTF] loading weights from /tmp/tmpqzdxdjba/model/variables/variables\n",
      "[16:22:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:22:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:21 - Feature] Processed ParPgb:0.0-246.0 (median depth 131.0)\n",
      "[16:22:21 - Sampler] Took 0.03s to make features.\n",
      "[16:22:21 - PWorker] Processed 1 batches\n",
      "[16:22:21 - PWorker] All done, 0 remainder regions.\n",
      "[16:22:21 - Predict] Finished processing all regions.\n",
      "[16:22:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:25 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:22:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:22:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:22:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:22:25 - Predict] Found a GPU.\n",
      "[16:22:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:22:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:22:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc8a87e1ae0>\n",
      "[16:22:26 - MdlStrTF] loading weights from /tmp/tmpo85mif6t/model/variables/variables\n",
      "[16:22:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:22:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:22:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-272.\n",
      "[16:22:26 - Feature] Processed ParPgb:0.0-272.0 (median depth 139.0)\n",
      "[16:22:26 - Sampler] Took 0.18s to make features.\n",
      "[16:22:26 - Sampler] Region ParPgb:0.0-272.0 (354 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:22:26 - PWorker] Processed 0 batches\n",
      "[16:22:26 - PWorker] All done, 1 remainder regions.\n",
      "[16:22:26 - Predict] Processing 1 short region(s).\n",
      "[16:22:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:27 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc8181c5b10>\n",
      "[16:22:27 - MdlStrTF] loading weights from /tmp/tmpo85mif6t/model/variables/variables\n",
      "[16:22:27 - Sampler] Initializing sampler for consensus of region ParPgb:0-273.\n",
      "[16:22:27 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:27 - Feature] Processed ParPgb:0.0-272.0 (median depth 139.0)\n",
      "[16:22:27 - Sampler] Took 0.06s to make features.\n",
      "[16:22:28 - PWorker] Processed 1 batches\n",
      "[16:22:28 - PWorker] All done, 0 remainder regions.\n",
      "[16:22:28 - Predict] Finished processing all regions.\n",
      "[16:22:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:22:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:22:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:22:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:22:31 - Predict] Found a GPU.\n",
      "[16:22:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:22:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:22:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7943c05a80>\n",
      "[16:22:32 - MdlStrTF] loading weights from /tmp/tmpu9um9wme/model/variables/variables\n",
      "[16:22:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:22:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:22:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:35 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[16:22:35 - Feature] Processed ParPgb:0.0-251.0 (median depth 86.0)\n",
      "[16:22:35 - Sampler] Took 2.79s to make features.\n",
      "[16:22:35 - Sampler] Region ParPgb:0.0-251.0 (296 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:22:35 - PWorker] Processed 0 batches\n",
      "[16:22:35 - PWorker] All done, 1 remainder regions.\n",
      "[16:22:35 - Predict] Processing 1 short region(s).\n",
      "[16:22:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f78b2d51f90>\n",
      "[16:22:36 - MdlStrTF] loading weights from /tmp/tmpu9um9wme/model/variables/variables\n",
      "[16:22:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[16:22:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:36 - Feature] Processed ParPgb:0.0-251.0 (median depth 86.0)\n",
      "[16:22:36 - Sampler] Took 0.05s to make features.\n",
      "[16:22:36 - PWorker] Processed 1 batches\n",
      "[16:22:36 - PWorker] All done, 0 remainder regions.\n",
      "[16:22:36 - Predict] Finished processing all regions.\n",
      "[16:22:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:22:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:22:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:22:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:22:40 - Predict] Found a GPU.\n",
      "[16:22:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:22:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:22:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2d4b849ae0>\n",
      "[16:22:41 - MdlStrTF] loading weights from /tmp/tmpblsdzyz2/model/variables/variables\n",
      "[16:22:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:22:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:22:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-268.\n",
      "[16:22:45 - Feature] Processed ParPgb:0.0-268.0 (median depth 136.0)\n",
      "[16:22:45 - Sampler] Took 3.86s to make features.\n",
      "[16:22:45 - Sampler] Region ParPgb:0.0-268.0 (354 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:22:45 - PWorker] Processed 0 batches\n",
      "[16:22:45 - PWorker] All done, 1 remainder regions.\n",
      "[16:22:45 - Predict] Processing 1 short region(s).\n",
      "[16:22:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2cbaa1d480>\n",
      "[16:22:45 - MdlStrTF] loading weights from /tmp/tmpblsdzyz2/model/variables/variables\n",
      "[16:22:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-269.\n",
      "[16:22:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:45 - Feature] Processed ParPgb:0.0-268.0 (median depth 136.0)\n",
      "[16:22:45 - Sampler] Took 0.03s to make features.\n",
      "[16:22:46 - PWorker] Processed 1 batches\n",
      "[16:22:46 - PWorker] All done, 0 remainder regions.\n",
      "[16:22:46 - Predict] Finished processing all regions.\n",
      "[16:22:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:49 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:22:49 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:22:49 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:22:49 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:22:49 - Predict] Found a GPU.\n",
      "[16:22:49 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:22:49 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:22:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb5d59ddae0>\n",
      "[16:22:51 - MdlStrTF] loading weights from /tmp/tmp_wdrtfyc/model/variables/variables\n",
      "[16:22:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:22:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:22:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-263.\n",
      "[16:22:51 - Feature] Processed ParPgb:0.0-263.0 (median depth 163.0)\n",
      "[16:22:51 - Sampler] Took 0.04s to make features.\n",
      "[16:22:51 - Sampler] Region ParPgb:0.0-263.0 (374 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:22:51 - PWorker] Processed 0 batches\n",
      "[16:22:51 - PWorker] All done, 1 remainder regions.\n",
      "[16:22:51 - Predict] Processing 1 short region(s).\n",
      "[16:22:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb540605480>\n",
      "[16:22:51 - MdlStrTF] loading weights from /tmp/tmp_wdrtfyc/model/variables/variables\n",
      "[16:22:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-264.\n",
      "[16:22:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:51 - Feature] Processed ParPgb:0.0-263.0 (median depth 163.0)\n",
      "[16:22:51 - Sampler] Took 0.19s to make features.\n",
      "[16:22:52 - PWorker] Processed 1 batches\n",
      "[16:22:52 - PWorker] All done, 0 remainder regions.\n",
      "[16:22:52 - Predict] Finished processing all regions.\n",
      "[16:22:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:54 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:22:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:22:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:22:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:22:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:22:55 - Predict] Found a GPU.\n",
      "[16:22:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:22:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:22:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdfd375dae0>\n",
      "[16:22:57 - MdlStrTF] loading weights from /tmp/tmpb475zwej/model/variables/variables\n",
      "[16:22:57 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:22:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:22:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:22:57 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:22:57 - Feature] Processed ParPgb:0.0-240.0 (median depth 102.0)\n",
      "[16:22:57 - Sampler] Took 0.05s to make features.\n",
      "[16:22:57 - Sampler] Region ParPgb:0.0-240.0 (313 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:22:57 - PWorker] Processed 0 batches\n",
      "[16:22:57 - PWorker] All done, 1 remainder regions.\n",
      "[16:22:57 - Predict] Processing 1 short region(s).\n",
      "[16:22:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:22:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fdf428f5480>\n",
      "[16:22:57 - MdlStrTF] loading weights from /tmp/tmpb475zwej/model/variables/variables\n",
      "[16:22:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:22:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:00 - Feature] Processed ParPgb:0.0-240.0 (median depth 102.0)\n",
      "[16:23:00 - Sampler] Took 2.74s to make features.\n",
      "[16:23:01 - PWorker] Processed 1 batches\n",
      "[16:23:01 - PWorker] All done, 0 remainder regions.\n",
      "[16:23:01 - Predict] Finished processing all regions.\n",
      "[16:23:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:04 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:23:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:23:04 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:23:04 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:23:04 - Predict] Found a GPU.\n",
      "[16:23:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:23:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:23:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb0c5a55ae0>\n",
      "[16:23:05 - MdlStrTF] loading weights from /tmp/tmprogtsilv/model/variables/variables\n",
      "[16:23:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:23:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:23:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:23:05 - Feature] Processed ParPgb:0.0-248.0 (median depth 136.0)\n",
      "[16:23:05 - Sampler] Took 0.02s to make features.\n",
      "[16:23:05 - Sampler] Region ParPgb:0.0-248.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:23:05 - PWorker] Processed 0 batches\n",
      "[16:23:05 - PWorker] All done, 1 remainder regions.\n",
      "[16:23:05 - Predict] Processing 1 short region(s).\n",
      "[16:23:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb02836dea0>\n",
      "[16:23:06 - MdlStrTF] loading weights from /tmp/tmprogtsilv/model/variables/variables\n",
      "[16:23:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:23:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:06 - Feature] Processed ParPgb:0.0-248.0 (median depth 136.0)\n",
      "[16:23:06 - Sampler] Took 0.05s to make features.\n",
      "[16:23:06 - PWorker] Processed 1 batches\n",
      "[16:23:06 - PWorker] All done, 0 remainder regions.\n",
      "[16:23:06 - Predict] Finished processing all regions.\n",
      "[16:23:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:10 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:23:10 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:23:10 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:23:10 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:23:10 - Predict] Found a GPU.\n",
      "[16:23:10 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:23:10 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:23:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2fdfe85ae0>\n",
      "[16:23:11 - MdlStrTF] loading weights from /tmp/tmpodi4je_i/model/variables/variables\n",
      "[16:23:11 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:23:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:23:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-230.\n",
      "[16:23:11 - Feature] Processed ParPgb:0.0-230.0 (median depth 131.0)\n",
      "[16:23:11 - Sampler] Took 0.03s to make features.\n",
      "[16:23:11 - Sampler] Region ParPgb:0.0-230.0 (326 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:23:11 - PWorker] Processed 0 batches\n",
      "[16:23:11 - PWorker] All done, 1 remainder regions.\n",
      "[16:23:11 - Predict] Processing 1 short region(s).\n",
      "[16:23:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:12 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2f40f79480>\n",
      "[16:23:12 - MdlStrTF] loading weights from /tmp/tmpodi4je_i/model/variables/variables\n",
      "[16:23:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-231.\n",
      "[16:23:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:16 - Feature] Processed ParPgb:0.0-230.0 (median depth 131.0)\n",
      "[16:23:16 - Sampler] Took 4.40s to make features.\n",
      "[16:23:17 - PWorker] Processed 1 batches\n",
      "[16:23:17 - PWorker] All done, 0 remainder regions.\n",
      "[16:23:17 - Predict] Finished processing all regions.\n",
      "[16:23:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:23:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:23:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:23:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:23:20 - Predict] Found a GPU.\n",
      "[16:23:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:23:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:23:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd22b7edae0>\n",
      "[16:23:21 - MdlStrTF] loading weights from /tmp/tmpvzezxl4c/model/variables/variables\n",
      "[16:23:21 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:23:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:23:21 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-234.\n",
      "[16:23:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:22 - Feature] Processed ParPgb:0.0-234.0 (median depth 96.0)\n",
      "[16:23:22 - Sampler] Took 0.11s to make features.\n",
      "[16:23:22 - Sampler] Region ParPgb:0.0-234.0 (287 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:23:22 - PWorker] Processed 0 batches\n",
      "[16:23:22 - PWorker] All done, 1 remainder regions.\n",
      "[16:23:22 - Predict] Processing 1 short region(s).\n",
      "[16:23:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd188e7a320>\n",
      "[16:23:22 - MdlStrTF] loading weights from /tmp/tmpvzezxl4c/model/variables/variables\n",
      "[16:23:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-235.\n",
      "[16:23:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:24 - Feature] Processed ParPgb:0.0-234.0 (median depth 96.0)\n",
      "[16:23:24 - Sampler] Took 1.67s to make features.\n",
      "[16:23:24 - PWorker] Processed 1 batches\n",
      "[16:23:24 - PWorker] All done, 0 remainder regions.\n",
      "[16:23:24 - Predict] Finished processing all regions.\n",
      "[16:23:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:26 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:28 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:23:28 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:23:28 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:23:28 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:23:28 - Predict] Found a GPU.\n",
      "[16:23:28 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:23:28 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:23:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f210cfe1ae0>\n",
      "[16:23:29 - MdlStrTF] loading weights from /tmp/tmp8lf9hbbt/model/variables/variables\n",
      "[16:23:29 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:23:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:23:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:29 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[16:23:29 - Feature] Processed ParPgb:0.0-247.0 (median depth 234.0)\n",
      "[16:23:29 - Sampler] Took 0.40s to make features.\n",
      "[16:23:29 - Sampler] Region ParPgb:0.0-247.0 (369 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:23:29 - PWorker] Processed 0 batches\n",
      "[16:23:29 - PWorker] All done, 1 remainder regions.\n",
      "[16:23:29 - Predict] Processing 1 short region(s).\n",
      "[16:23:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f207c199b10>\n",
      "[16:23:30 - MdlStrTF] loading weights from /tmp/tmp8lf9hbbt/model/variables/variables\n",
      "[16:23:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[16:23:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:30 - Feature] Processed ParPgb:0.0-247.0 (median depth 234.0)\n",
      "[16:23:30 - Sampler] Took 0.04s to make features.\n",
      "[16:23:30 - PWorker] Processed 1 batches\n",
      "[16:23:30 - PWorker] All done, 0 remainder regions.\n",
      "[16:23:30 - Predict] Finished processing all regions.\n",
      "[16:23:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:34 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:23:34 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:23:34 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:23:34 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:23:34 - Predict] Found a GPU.\n",
      "[16:23:34 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:23:34 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:23:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6cfb231ae0>\n",
      "[16:23:35 - MdlStrTF] loading weights from /tmp/tmpvorj6yec/model/variables/variables\n",
      "[16:23:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:23:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:23:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:35 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[16:23:35 - Feature] Processed ParPgb:0.0-251.0 (median depth 119.0)\n",
      "[16:23:35 - Sampler] Took 0.10s to make features.\n",
      "[16:23:35 - Sampler] Region ParPgb:0.0-251.0 (334 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:23:35 - PWorker] Processed 0 batches\n",
      "[16:23:35 - PWorker] All done, 1 remainder regions.\n",
      "[16:23:35 - Predict] Processing 1 short region(s).\n",
      "[16:23:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:36 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6c6a425450>\n",
      "[16:23:36 - MdlStrTF] loading weights from /tmp/tmpvorj6yec/model/variables/variables\n",
      "[16:23:36 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[16:23:36 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:36 - Feature] Processed ParPgb:0.0-251.0 (median depth 119.0)\n",
      "[16:23:36 - Sampler] Took 0.04s to make features.\n",
      "[16:23:36 - PWorker] Processed 1 batches\n",
      "[16:23:36 - PWorker] All done, 0 remainder regions.\n",
      "[16:23:36 - Predict] Finished processing all regions.\n",
      "[16:23:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:38 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:40 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:23:40 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:23:40 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:23:40 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:23:40 - Predict] Found a GPU.\n",
      "[16:23:40 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:23:40 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:23:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faf6091dae0>\n",
      "[16:23:41 - MdlStrTF] loading weights from /tmp/tmpsag2nh1j/model/variables/variables\n",
      "[16:23:41 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:23:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:23:41 - Sampler] Took 0.01s to make features.\n",
      "[16:23:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:41 - PWorker] Processed 0 batches\n",
      "[16:23:41 - PWorker] All done, 0 remainder regions.\n",
      "[16:23:41 - Predict] Finished processing all regions.\n",
      "[16:23:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:43 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:23:44 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:23:44 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:23:44 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:23:44 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:23:45 - Predict] Found a GPU.\n",
      "[16:23:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:23:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:23:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f061f549ae0>\n",
      "[16:23:46 - MdlStrTF] loading weights from /tmp/tmpz2h66bky/model/variables/variables\n",
      "[16:23:46 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:23:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:23:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:46 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[16:23:46 - Feature] Processed ParPgb:0.0-255.0 (median depth 74.0)\n",
      "[16:23:46 - Sampler] Took 0.05s to make features.\n",
      "[16:23:46 - Sampler] Region ParPgb:0.0-255.0 (306 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:23:46 - PWorker] Processed 0 batches\n",
      "[16:23:46 - PWorker] All done, 1 remainder regions.\n",
      "[16:23:46 - Predict] Processing 1 short region(s).\n",
      "[16:23:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f058069d480>\n",
      "[16:23:46 - MdlStrTF] loading weights from /tmp/tmpz2h66bky/model/variables/variables\n",
      "[16:23:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[16:23:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:47 - Feature] Processed ParPgb:0.0-255.0 (median depth 74.0)\n",
      "[16:23:47 - Sampler] Took 1.00s to make features.\n",
      "[16:23:48 - PWorker] Processed 1 batches\n",
      "[16:23:48 - PWorker] All done, 0 remainder regions.\n",
      "[16:23:48 - Predict] Finished processing all regions.\n",
      "[16:23:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:51 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:23:51 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:23:51 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:23:51 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:23:51 - Predict] Found a GPU.\n",
      "[16:23:51 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:23:51 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:23:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd1c1089a80>\n",
      "[16:23:53 - MdlStrTF] loading weights from /tmp/tmp762ken2f/model/variables/variables\n",
      "[16:23:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:23:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:23:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:53 - Sampler] Took 0.16s to make features.\n",
      "[16:23:53 - PWorker] Processed 0 batches\n",
      "[16:23:53 - PWorker] All done, 0 remainder regions.\n",
      "[16:23:53 - Predict] Finished processing all regions.\n",
      "[16:23:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:55 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:23:56 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:23:56 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:23:56 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:23:56 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:23:56 - Predict] Found a GPU.\n",
      "[16:23:56 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:23:56 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:23:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:23:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8cf42c9ae0>\n",
      "[16:23:58 - MdlStrTF] loading weights from /tmp/tmpziq6y81l/model/variables/variables\n",
      "[16:23:58 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:23:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:23:58 - Sampler] Took 0.01s to make features.\n",
      "[16:23:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:23:58 - PWorker] Processed 0 batches\n",
      "[16:23:58 - PWorker] All done, 0 remainder regions.\n",
      "[16:23:58 - Predict] Finished processing all regions.\n",
      "[16:23:59 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:23:59 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:24:01 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:24:01 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:24:01 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:24:01 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:24:01 - Predict] Found a GPU.\n",
      "[16:24:01 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:24:01 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:24:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6f91009a80>\n",
      "[16:24:02 - MdlStrTF] loading weights from /tmp/tmp7ps62zgm/model/variables/variables\n",
      "[16:24:02 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:24:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:24:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:02 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-235.\n",
      "[16:24:02 - Feature] Processed ParPgb:0.0-235.0 (median depth 247.0)\n",
      "[16:24:02 - Sampler] Took 0.10s to make features.\n",
      "[16:24:02 - Sampler] Region ParPgb:0.0-235.0 (350 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:24:02 - PWorker] Processed 0 batches\n",
      "[16:24:02 - PWorker] All done, 1 remainder regions.\n",
      "[16:24:02 - Predict] Processing 1 short region(s).\n",
      "[16:24:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6f00221a80>\n",
      "[16:24:03 - MdlStrTF] loading weights from /tmp/tmp7ps62zgm/model/variables/variables\n",
      "[16:24:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-236.\n",
      "[16:24:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:05 - Feature] Processed ParPgb:0.0-235.0 (median depth 247.0)\n",
      "[16:24:05 - Sampler] Took 1.95s to make features.\n",
      "[16:24:05 - PWorker] Processed 1 batches\n",
      "[16:24:05 - PWorker] All done, 0 remainder regions.\n",
      "[16:24:05 - Predict] Finished processing all regions.\n",
      "[16:24:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:24:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:24:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:24:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:24:09 - Predict] Found a GPU.\n",
      "[16:24:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:24:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:24:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7f487f5ae0>\n",
      "[16:24:10 - MdlStrTF] loading weights from /tmp/tmpev85fiwa/model/variables/variables\n",
      "[16:24:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:24:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:24:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:12 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[16:24:12 - Feature] Processed ParPgb:0.0-253.0 (median depth 117.0)\n",
      "[16:24:12 - Sampler] Took 2.22s to make features.\n",
      "[16:24:12 - Sampler] Region ParPgb:0.0-253.0 (307 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:24:12 - PWorker] Processed 0 batches\n",
      "[16:24:12 - PWorker] All done, 1 remainder regions.\n",
      "[16:24:12 - Predict] Processing 1 short region(s).\n",
      "[16:24:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7eb8221480>\n",
      "[16:24:13 - MdlStrTF] loading weights from /tmp/tmpev85fiwa/model/variables/variables\n",
      "[16:24:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[16:24:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:13 - Feature] Processed ParPgb:0.0-253.0 (median depth 117.0)\n",
      "[16:24:13 - Sampler] Took 0.05s to make features.\n",
      "[16:24:13 - PWorker] Processed 1 batches\n",
      "[16:24:13 - PWorker] All done, 0 remainder regions.\n",
      "[16:24:13 - Predict] Finished processing all regions.\n",
      "[16:24:15 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:15 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:17 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:24:17 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:24:17 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:24:17 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:24:17 - Predict] Found a GPU.\n",
      "[16:24:17 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:24:17 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:24:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb1deb01ae0>\n",
      "[16:24:18 - MdlStrTF] loading weights from /tmp/tmpiozjnpeu/model/variables/variables\n",
      "[16:24:18 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:24:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:24:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:18 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[16:24:18 - Feature] Processed ParPgb:0.0-254.0 (median depth 212.0)\n",
      "[16:24:18 - Sampler] Took 0.05s to make features.\n",
      "[16:24:18 - Sampler] Region ParPgb:0.0-254.0 (337 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:24:18 - PWorker] Processed 0 batches\n",
      "[16:24:18 - PWorker] All done, 1 remainder regions.\n",
      "[16:24:18 - Predict] Processing 1 short region(s).\n",
      "[16:24:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb1c0115420>\n",
      "[16:24:19 - MdlStrTF] loading weights from /tmp/tmpiozjnpeu/model/variables/variables\n",
      "[16:24:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[16:24:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:19 - Feature] Processed ParPgb:0.0-254.0 (median depth 212.0)\n",
      "[16:24:19 - Sampler] Took 0.32s to make features.\n",
      "[16:24:20 - PWorker] Processed 1 batches\n",
      "[16:24:20 - PWorker] All done, 0 remainder regions.\n",
      "[16:24:20 - Predict] Finished processing all regions.\n",
      "[16:24:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:23 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:24:23 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:24:23 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:24:23 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:24:23 - Predict] Found a GPU.\n",
      "[16:24:23 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:24:23 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:24:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2e3ed19ae0>\n",
      "[16:24:24 - MdlStrTF] loading weights from /tmp/tmpen8tijpk/model/variables/variables\n",
      "[16:24:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:24:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:24:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[16:24:24 - Feature] Processed ParPgb:0.0-251.0 (median depth 130.0)\n",
      "[16:24:24 - Sampler] Took 0.04s to make features.\n",
      "[16:24:24 - Sampler] Region ParPgb:0.0-251.0 (330 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:24:24 - PWorker] Processed 0 batches\n",
      "[16:24:24 - PWorker] All done, 1 remainder regions.\n",
      "[16:24:24 - Predict] Processing 1 short region(s).\n",
      "[16:24:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2e202dd480>\n",
      "[16:24:25 - MdlStrTF] loading weights from /tmp/tmpen8tijpk/model/variables/variables\n",
      "[16:24:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[16:24:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:25 - Feature] Processed ParPgb:0.0-251.0 (median depth 130.0)\n",
      "[16:24:25 - Sampler] Took 0.07s to make features.\n",
      "[16:24:25 - PWorker] Processed 1 batches\n",
      "[16:24:25 - PWorker] All done, 0 remainder regions.\n",
      "[16:24:25 - Predict] Finished processing all regions.\n",
      "[16:24:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:24:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:24:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:24:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:24:29 - Predict] Found a GPU.\n",
      "[16:24:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:24:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:24:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbe7aafdae0>\n",
      "[16:24:30 - MdlStrTF] loading weights from /tmp/tmpnalmae6x/model/variables/variables\n",
      "[16:24:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:24:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:24:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:32 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-260.\n",
      "[16:24:33 - Feature] Processed ParPgb:0.0-260.0 (median depth 120.0)\n",
      "[16:24:33 - Sampler] Took 2.34s to make features.\n",
      "[16:24:33 - Sampler] Region ParPgb:0.0-260.0 (353 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:24:33 - PWorker] Processed 0 batches\n",
      "[16:24:33 - PWorker] All done, 1 remainder regions.\n",
      "[16:24:33 - Predict] Processing 1 short region(s).\n",
      "[16:24:33 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbde84361a0>\n",
      "[16:24:33 - MdlStrTF] loading weights from /tmp/tmpnalmae6x/model/variables/variables\n",
      "[16:24:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-261.\n",
      "[16:24:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:33 - Feature] Processed ParPgb:0.0-260.0 (median depth 120.0)\n",
      "[16:24:33 - Sampler] Took 0.10s to make features.\n",
      "[16:24:34 - PWorker] Processed 1 batches\n",
      "[16:24:34 - PWorker] All done, 0 remainder regions.\n",
      "[16:24:34 - Predict] Finished processing all regions.\n",
      "[16:24:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:24:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:24:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:24:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:24:37 - Predict] Found a GPU.\n",
      "[16:24:37 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:24:37 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:24:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff83b449ae0>\n",
      "[16:24:38 - MdlStrTF] loading weights from /tmp/tmpm6wl5vga/model/variables/variables\n",
      "[16:24:39 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:24:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:24:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:24:39 - Feature] Processed ParPgb:0.0-246.0 (median depth 246.0)\n",
      "[16:24:39 - Sampler] Took 0.05s to make features.\n",
      "[16:24:39 - Sampler] Region ParPgb:0.0-246.0 (376 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:24:39 - PWorker] Processed 0 batches\n",
      "[16:24:39 - PWorker] All done, 1 remainder regions.\n",
      "[16:24:39 - Predict] Processing 1 short region(s).\n",
      "[16:24:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff7a9d21480>\n",
      "[16:24:39 - MdlStrTF] loading weights from /tmp/tmpm6wl5vga/model/variables/variables\n",
      "[16:24:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:24:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:39 - Feature] Processed ParPgb:0.0-246.0 (median depth 246.0)\n",
      "[16:24:39 - Sampler] Took 0.05s to make features.\n",
      "[16:24:40 - PWorker] Processed 1 batches\n",
      "[16:24:40 - PWorker] All done, 0 remainder regions.\n",
      "[16:24:40 - Predict] Finished processing all regions.\n",
      "[16:24:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:24:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:24:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:24:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:24:43 - Predict] Found a GPU.\n",
      "[16:24:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:24:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:24:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe9d2e09ae0>\n",
      "[16:24:44 - MdlStrTF] loading weights from /tmp/tmpf1xm8_04/model/variables/variables\n",
      "[16:24:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:24:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:24:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-214.\n",
      "[16:24:49 - Feature] Processed ParPgb:0.0-214.0 (median depth 68.0)\n",
      "[16:24:49 - Sampler] Took 5.00s to make features.\n",
      "[16:24:49 - Sampler] Region ParPgb:0.0-214.0 (267 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:24:49 - PWorker] Processed 0 batches\n",
      "[16:24:49 - PWorker] All done, 1 remainder regions.\n",
      "[16:24:49 - Predict] Processing 1 short region(s).\n",
      "[16:24:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe941fc9480>\n",
      "[16:24:50 - MdlStrTF] loading weights from /tmp/tmpf1xm8_04/model/variables/variables\n",
      "[16:24:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-215.\n",
      "[16:24:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:50 - Feature] Processed ParPgb:0.0-214.0 (median depth 68.0)\n",
      "[16:24:50 - Sampler] Took 0.04s to make features.\n",
      "[16:24:50 - PWorker] Processed 1 batches\n",
      "[16:24:50 - PWorker] All done, 0 remainder regions.\n",
      "[16:24:50 - Predict] Finished processing all regions.\n",
      "[16:24:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:24:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:24:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:24:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:24:54 - Predict] Found a GPU.\n",
      "[16:24:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:24:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:24:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7feb1c7edae0>\n",
      "[16:24:55 - MdlStrTF] loading weights from /tmp/tmppcegt8ir/model/variables/variables\n",
      "[16:24:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:24:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:24:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:55 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:24:55 - Feature] Processed ParPgb:0.0-246.0 (median depth 177.0)\n",
      "[16:24:55 - Sampler] Took 0.11s to make features.\n",
      "[16:24:55 - Sampler] Region ParPgb:0.0-246.0 (342 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:24:55 - PWorker] Processed 0 batches\n",
      "[16:24:55 - PWorker] All done, 1 remainder regions.\n",
      "[16:24:55 - Predict] Processing 1 short region(s).\n",
      "[16:24:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:24:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fea8c1c6f20>\n",
      "[16:24:56 - MdlStrTF] loading weights from /tmp/tmppcegt8ir/model/variables/variables\n",
      "[16:24:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:24:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:24:56 - Feature] Processed ParPgb:0.0-246.0 (median depth 177.0)\n",
      "[16:24:56 - Sampler] Took 0.04s to make features.\n",
      "[16:24:56 - PWorker] Processed 1 batches\n",
      "[16:24:56 - PWorker] All done, 0 remainder regions.\n",
      "[16:24:56 - Predict] Finished processing all regions.\n",
      "[16:24:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:24:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:00 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:25:00 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:25:00 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:25:00 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:25:00 - Predict] Found a GPU.\n",
      "[16:25:00 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:25:00 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:25:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f42da501ae0>\n",
      "[16:25:01 - MdlStrTF] loading weights from /tmp/tmpim_rmu85/model/variables/variables\n",
      "[16:25:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:25:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:25:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:01 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-221.\n",
      "[16:25:01 - Feature] Processed ParPgb:0.0-221.0 (median depth 129.0)\n",
      "[16:25:01 - Sampler] Took 0.04s to make features.\n",
      "[16:25:01 - Sampler] Region ParPgb:0.0-221.0 (300 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:25:01 - PWorker] Processed 0 batches\n",
      "[16:25:01 - PWorker] All done, 1 remainder regions.\n",
      "[16:25:01 - Predict] Processing 1 short region(s).\n",
      "[16:25:01 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:02 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f42496ca1a0>\n",
      "[16:25:02 - MdlStrTF] loading weights from /tmp/tmpim_rmu85/model/variables/variables\n",
      "[16:25:02 - Sampler] Initializing sampler for consensus of region ParPgb:0-222.\n",
      "[16:25:02 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:05 - Feature] Processed ParPgb:0.0-221.0 (median depth 129.0)\n",
      "[16:25:05 - Sampler] Took 2.89s to make features.\n",
      "[16:25:05 - PWorker] Processed 1 batches\n",
      "[16:25:05 - PWorker] All done, 0 remainder regions.\n",
      "[16:25:05 - Predict] Finished processing all regions.\n",
      "[16:25:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:25:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:25:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:25:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:25:09 - Predict] Found a GPU.\n",
      "[16:25:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:25:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:25:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3993f5dae0>\n",
      "[16:25:10 - MdlStrTF] loading weights from /tmp/tmpg39bgpog/model/variables/variables\n",
      "[16:25:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:25:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:25:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:10 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[16:25:10 - Feature] Processed ParPgb:0.0-253.0 (median depth 202.0)\n",
      "[16:25:10 - Sampler] Took 0.03s to make features.\n",
      "[16:25:10 - Sampler] Region ParPgb:0.0-253.0 (369 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:25:10 - PWorker] Processed 0 batches\n",
      "[16:25:10 - PWorker] All done, 1 remainder regions.\n",
      "[16:25:10 - Predict] Processing 1 short region(s).\n",
      "[16:25:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f396c271480>\n",
      "[16:25:10 - MdlStrTF] loading weights from /tmp/tmpg39bgpog/model/variables/variables\n",
      "[16:25:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[16:25:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:11 - Feature] Processed ParPgb:0.0-253.0 (median depth 202.0)\n",
      "[16:25:11 - Sampler] Took 0.10s to make features.\n",
      "[16:25:11 - PWorker] Processed 1 batches\n",
      "[16:25:11 - PWorker] All done, 0 remainder regions.\n",
      "[16:25:11 - Predict] Finished processing all regions.\n",
      "[16:25:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:13 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:25:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:25:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:25:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:25:15 - Predict] Found a GPU.\n",
      "[16:25:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:25:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:25:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4029b75ae0>\n",
      "[16:25:16 - MdlStrTF] loading weights from /tmp/tmp8ej4uo5j/model/variables/variables\n",
      "[16:25:16 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:25:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:25:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:16 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-239.\n",
      "[16:25:16 - Feature] Processed ParPgb:0.0-239.0 (median depth 166.0)\n",
      "[16:25:16 - Sampler] Took 0.05s to make features.\n",
      "[16:25:16 - Sampler] Region ParPgb:0.0-239.0 (345 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:25:16 - PWorker] Processed 0 batches\n",
      "[16:25:16 - PWorker] All done, 1 remainder regions.\n",
      "[16:25:16 - Predict] Processing 1 short region(s).\n",
      "[16:25:16 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3f98d8d450>\n",
      "[16:25:16 - MdlStrTF] loading weights from /tmp/tmp8ej4uo5j/model/variables/variables\n",
      "[16:25:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-240.\n",
      "[16:25:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:17 - Feature] Processed ParPgb:0.0-239.0 (median depth 166.0)\n",
      "[16:25:17 - Sampler] Took 0.53s to make features.\n",
      "[16:25:18 - PWorker] Processed 1 batches\n",
      "[16:25:18 - PWorker] All done, 0 remainder regions.\n",
      "[16:25:18 - Predict] Finished processing all regions.\n",
      "[16:25:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:19 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:21 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:25:21 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:25:21 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:25:21 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:25:21 - Predict] Found a GPU.\n",
      "[16:25:21 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:25:21 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:25:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:22 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd8ea169ae0>\n",
      "[16:25:22 - MdlStrTF] loading weights from /tmp/tmpvg46bjl3/model/variables/variables\n",
      "[16:25:22 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:25:22 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:25:22 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:22 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[16:25:22 - Feature] Processed ParPgb:0.0-243.0 (median depth 66.0)\n",
      "[16:25:22 - Sampler] Took 0.10s to make features.\n",
      "[16:25:22 - Sampler] Region ParPgb:0.0-243.0 (292 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:25:22 - PWorker] Processed 0 batches\n",
      "[16:25:22 - PWorker] All done, 1 remainder regions.\n",
      "[16:25:22 - Predict] Processing 1 short region(s).\n",
      "[16:25:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd859355ff0>\n",
      "[16:25:23 - MdlStrTF] loading weights from /tmp/tmpvg46bjl3/model/variables/variables\n",
      "[16:25:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[16:25:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:23 - Feature] Processed ParPgb:0.0-243.0 (median depth 66.0)\n",
      "[16:25:23 - Sampler] Took 0.05s to make features.\n",
      "[16:25:23 - PWorker] Processed 1 batches\n",
      "[16:25:23 - PWorker] All done, 0 remainder regions.\n",
      "[16:25:23 - Predict] Finished processing all regions.\n",
      "[16:25:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:27 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:25:27 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:25:27 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:25:27 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:25:27 - Predict] Found a GPU.\n",
      "[16:25:27 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:25:27 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:25:27 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f13c9e2dae0>\n",
      "[16:25:28 - MdlStrTF] loading weights from /tmp/tmpzxlpul00/model/variables/variables\n",
      "[16:25:28 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:25:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:25:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:28 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-234.\n",
      "[16:25:28 - Feature] Processed ParPgb:0.0-234.0 (median depth 90.0)\n",
      "[16:25:28 - Sampler] Took 0.12s to make features.\n",
      "[16:25:28 - Sampler] Region ParPgb:0.0-234.0 (298 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:25:28 - PWorker] Processed 0 batches\n",
      "[16:25:28 - PWorker] All done, 1 remainder regions.\n",
      "[16:25:28 - Predict] Processing 1 short region(s).\n",
      "[16:25:28 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:29 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1328559b10>\n",
      "[16:25:29 - MdlStrTF] loading weights from /tmp/tmpzxlpul00/model/variables/variables\n",
      "[16:25:29 - Sampler] Initializing sampler for consensus of region ParPgb:0-235.\n",
      "[16:25:29 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:31 - Feature] Processed ParPgb:0.0-234.0 (median depth 90.0)\n",
      "[16:25:31 - Sampler] Took 2.47s to make features.\n",
      "[16:25:32 - PWorker] Processed 1 batches\n",
      "[16:25:32 - PWorker] All done, 0 remainder regions.\n",
      "[16:25:32 - Predict] Finished processing all regions.\n",
      "[16:25:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:35 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:25:35 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:25:35 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:25:35 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:25:35 - Predict] Found a GPU.\n",
      "[16:25:35 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:25:35 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:25:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f106ee2dae0>\n",
      "[16:25:37 - MdlStrTF] loading weights from /tmp/tmpt1xat5_9/model/variables/variables\n",
      "[16:25:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:25:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:25:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:25:37 - Feature] Processed ParPgb:0.0-240.0 (median depth 61.0)\n",
      "[16:25:37 - Sampler] Took 0.07s to make features.\n",
      "[16:25:37 - Sampler] Region ParPgb:0.0-240.0 (276 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:25:37 - PWorker] Processed 0 batches\n",
      "[16:25:37 - PWorker] All done, 1 remainder regions.\n",
      "[16:25:37 - Predict] Processing 1 short region(s).\n",
      "[16:25:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f10503b5ff0>\n",
      "[16:25:37 - MdlStrTF] loading weights from /tmp/tmpt1xat5_9/model/variables/variables\n",
      "[16:25:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:25:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:37 - Feature] Processed ParPgb:0.0-240.0 (median depth 61.0)\n",
      "[16:25:37 - Sampler] Took 0.07s to make features.\n",
      "[16:25:38 - PWorker] Processed 1 batches\n",
      "[16:25:38 - PWorker] All done, 0 remainder regions.\n",
      "[16:25:38 - Predict] Finished processing all regions.\n",
      "[16:25:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:25:41 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:25:41 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:25:41 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:25:41 - Predict] Found a GPU.\n",
      "[16:25:41 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:25:41 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:25:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe6dda55ae0>\n",
      "[16:25:43 - MdlStrTF] loading weights from /tmp/tmp3mvnd9rh/model/variables/variables\n",
      "[16:25:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:25:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:25:43 - Sampler] Took 0.01s to make features.\n",
      "[16:25:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:43 - PWorker] Processed 0 batches\n",
      "[16:25:43 - PWorker] All done, 0 remainder regions.\n",
      "[16:25:43 - Predict] Finished processing all regions.\n",
      "[16:25:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:44 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:25:46 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:25:46 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:25:46 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:25:46 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:25:46 - Predict] Found a GPU.\n",
      "[16:25:46 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:25:46 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:25:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcb94da5ae0>\n",
      "[16:25:47 - MdlStrTF] loading weights from /tmp/tmpg2g70978/model/variables/variables\n",
      "[16:25:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:25:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:25:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-239.\n",
      "[16:25:47 - Feature] Processed ParPgb:0.0-239.0 (median depth 119.0)\n",
      "[16:25:47 - Sampler] Took 0.04s to make features.\n",
      "[16:25:47 - Sampler] Region ParPgb:0.0-239.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:25:47 - PWorker] Processed 0 batches\n",
      "[16:25:47 - PWorker] All done, 1 remainder regions.\n",
      "[16:25:47 - Predict] Processing 1 short region(s).\n",
      "[16:25:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fcad1f99b10>\n",
      "[16:25:48 - MdlStrTF] loading weights from /tmp/tmpg2g70978/model/variables/variables\n",
      "[16:25:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-240.\n",
      "[16:25:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:48 - Feature] Processed ParPgb:0.0-239.0 (median depth 119.0)\n",
      "[16:25:48 - Sampler] Took 0.05s to make features.\n",
      "[16:25:48 - PWorker] Processed 1 batches\n",
      "[16:25:48 - PWorker] All done, 0 remainder regions.\n",
      "[16:25:48 - Predict] Finished processing all regions.\n",
      "[16:25:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:52 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:25:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:25:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:25:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:25:52 - Predict] Found a GPU.\n",
      "[16:25:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:25:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:25:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4d2d7f5ae0>\n",
      "[16:25:53 - MdlStrTF] loading weights from /tmp/tmp0njii2vs/model/variables/variables\n",
      "[16:25:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:25:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:25:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-195.\n",
      "[16:25:53 - Feature] Processed ParPgb:0.0-195.0 (median depth 52.0)\n",
      "[16:25:53 - Sampler] Took 0.09s to make features.\n",
      "[16:25:53 - Sampler] Region ParPgb:0.0-195.0 (211 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:25:53 - PWorker] Processed 0 batches\n",
      "[16:25:53 - PWorker] All done, 1 remainder regions.\n",
      "[16:25:53 - Predict] Processing 1 short region(s).\n",
      "[16:25:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:54 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4c9c9d1480>\n",
      "[16:25:54 - MdlStrTF] loading weights from /tmp/tmp0njii2vs/model/variables/variables\n",
      "[16:25:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-196.\n",
      "[16:25:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:25:54 - Feature] Processed ParPgb:0.0-195.0 (median depth 52.0)\n",
      "[16:25:54 - Sampler] Took 0.10s to make features.\n",
      "[16:25:54 - PWorker] Processed 1 batches\n",
      "[16:25:54 - PWorker] All done, 0 remainder regions.\n",
      "[16:25:54 - Predict] Finished processing all regions.\n",
      "[16:25:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:25:58 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:25:58 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:25:58 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:25:58 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:25:58 - Predict] Found a GPU.\n",
      "[16:25:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:25:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:25:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:25:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8b4f6e5ae0>\n",
      "[16:25:59 - MdlStrTF] loading weights from /tmp/tmp40pqjlk6/model/variables/variables\n",
      "[16:25:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:25:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:25:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:00 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-259.\n",
      "[16:26:00 - Feature] Processed ParPgb:0.0-259.0 (median depth 102.0)\n",
      "[16:26:00 - Sampler] Took 1.45s to make features.\n",
      "[16:26:00 - Sampler] Region ParPgb:0.0-259.0 (347 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:26:00 - PWorker] Processed 0 batches\n",
      "[16:26:00 - PWorker] All done, 1 remainder regions.\n",
      "[16:26:00 - Predict] Processing 1 short region(s).\n",
      "[16:26:00 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8ac0111480>\n",
      "[16:26:01 - MdlStrTF] loading weights from /tmp/tmp40pqjlk6/model/variables/variables\n",
      "[16:26:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-260.\n",
      "[16:26:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:01 - Feature] Processed ParPgb:0.0-259.0 (median depth 102.0)\n",
      "[16:26:01 - Sampler] Took 0.06s to make features.\n",
      "[16:26:02 - PWorker] Processed 1 batches\n",
      "[16:26:02 - PWorker] All done, 0 remainder regions.\n",
      "[16:26:02 - Predict] Finished processing all regions.\n",
      "[16:26:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:03 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:05 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:26:05 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:26:05 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:26:05 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:26:05 - Predict] Found a GPU.\n",
      "[16:26:05 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:26:05 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:26:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:06 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f26f8795ae0>\n",
      "[16:26:06 - MdlStrTF] loading weights from /tmp/tmpyyqadlpf/model/variables/variables\n",
      "[16:26:06 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:26:06 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:26:06 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:06 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:26:06 - Feature] Processed ParPgb:0.0-248.0 (median depth 46.0)\n",
      "[16:26:06 - Sampler] Took 0.04s to make features.\n",
      "[16:26:06 - Sampler] Region ParPgb:0.0-248.0 (321 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:26:06 - PWorker] Processed 0 batches\n",
      "[16:26:06 - PWorker] All done, 1 remainder regions.\n",
      "[16:26:06 - Predict] Processing 1 short region(s).\n",
      "[16:26:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f26680ed480>\n",
      "[16:26:07 - MdlStrTF] loading weights from /tmp/tmpyyqadlpf/model/variables/variables\n",
      "[16:26:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:26:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:07 - Feature] Processed ParPgb:0.0-248.0 (median depth 46.0)\n",
      "[16:26:07 - Sampler] Took 0.06s to make features.\n",
      "[16:26:07 - PWorker] Processed 1 batches\n",
      "[16:26:07 - PWorker] All done, 0 remainder regions.\n",
      "[16:26:07 - Predict] Finished processing all regions.\n",
      "[16:26:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:09 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:11 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:26:11 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:26:11 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:26:11 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:26:11 - Predict] Found a GPU.\n",
      "[16:26:11 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:26:11 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:26:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:12 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7eff5c5e9ae0>\n",
      "[16:26:12 - MdlStrTF] loading weights from /tmp/tmpugcpzdu5/model/variables/variables\n",
      "[16:26:12 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:26:12 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:26:12 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:12 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[16:26:12 - Feature] Processed ParPgb:0.0-238.0 (median depth 125.0)\n",
      "[16:26:12 - Sampler] Took 0.10s to make features.\n",
      "[16:26:12 - Sampler] Region ParPgb:0.0-238.0 (303 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:26:12 - PWorker] Processed 0 batches\n",
      "[16:26:12 - PWorker] All done, 1 remainder regions.\n",
      "[16:26:12 - Predict] Processing 1 short region(s).\n",
      "[16:26:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efebd76ee90>\n",
      "[16:26:13 - MdlStrTF] loading weights from /tmp/tmpugcpzdu5/model/variables/variables\n",
      "[16:26:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[16:26:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:13 - Feature] Processed ParPgb:0.0-238.0 (median depth 125.0)\n",
      "[16:26:13 - Sampler] Took 0.04s to make features.\n",
      "[16:26:13 - PWorker] Processed 1 batches\n",
      "[16:26:13 - PWorker] All done, 0 remainder regions.\n",
      "[16:26:13 - Predict] Finished processing all regions.\n",
      "[16:26:15 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:15 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:17 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:26:17 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:26:17 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:26:17 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:26:17 - Predict] Found a GPU.\n",
      "[16:26:17 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:26:17 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:26:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f95ad389ae0>\n",
      "[16:26:18 - MdlStrTF] loading weights from /tmp/tmpy3d45ohz/model/variables/variables\n",
      "[16:26:18 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:26:18 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:26:18 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:18 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-258.\n",
      "[16:26:18 - Feature] Processed ParPgb:0.0-258.0 (median depth 94.0)\n",
      "[16:26:18 - Sampler] Took 0.19s to make features.\n",
      "[16:26:18 - Sampler] Region ParPgb:0.0-258.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:26:18 - PWorker] Processed 0 batches\n",
      "[16:26:18 - PWorker] All done, 1 remainder regions.\n",
      "[16:26:18 - Predict] Processing 1 short region(s).\n",
      "[16:26:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f951c223040>\n",
      "[16:26:19 - MdlStrTF] loading weights from /tmp/tmpy3d45ohz/model/variables/variables\n",
      "[16:26:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-259.\n",
      "[16:26:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:19 - Feature] Processed ParPgb:0.0-258.0 (median depth 94.0)\n",
      "[16:26:19 - Sampler] Took 0.08s to make features.\n",
      "[16:26:19 - PWorker] Processed 1 batches\n",
      "[16:26:19 - PWorker] All done, 0 remainder regions.\n",
      "[16:26:19 - Predict] Finished processing all regions.\n",
      "[16:26:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:23 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:26:23 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:26:23 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:26:23 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:26:23 - Predict] Found a GPU.\n",
      "[16:26:23 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:26:23 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:26:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f59915c5ae0>\n",
      "[16:26:24 - MdlStrTF] loading weights from /tmp/tmpa3tlp3yv/model/variables/variables\n",
      "[16:26:24 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:26:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:26:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:24 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-218.\n",
      "[16:26:24 - Feature] Processed ParPgb:0.0-218.0 (median depth 102.0)\n",
      "[16:26:24 - Sampler] Took 0.04s to make features.\n",
      "[16:26:24 - Sampler] Region ParPgb:0.0-218.0 (307 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:26:24 - PWorker] Processed 0 batches\n",
      "[16:26:24 - PWorker] All done, 1 remainder regions.\n",
      "[16:26:24 - Predict] Processing 1 short region(s).\n",
      "[16:26:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f59007c5ff0>\n",
      "[16:26:25 - MdlStrTF] loading weights from /tmp/tmpa3tlp3yv/model/variables/variables\n",
      "[16:26:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-219.\n",
      "[16:26:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:26 - Feature] Processed ParPgb:0.0-218.0 (median depth 102.0)\n",
      "[16:26:26 - Sampler] Took 0.98s to make features.\n",
      "[16:26:26 - PWorker] Processed 1 batches\n",
      "[16:26:26 - PWorker] All done, 0 remainder regions.\n",
      "[16:26:26 - Predict] Finished processing all regions.\n",
      "[16:26:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:26:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:26:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:26:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:26:29 - Predict] Found a GPU.\n",
      "[16:26:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:26:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:26:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb17c545ae0>\n",
      "[16:26:31 - MdlStrTF] loading weights from /tmp/tmpvzne893t/model/variables/variables\n",
      "[16:26:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:26:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:26:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-258.\n",
      "[16:26:31 - Feature] Processed ParPgb:0.0-258.0 (median depth 137.0)\n",
      "[16:26:31 - Sampler] Took 0.03s to make features.\n",
      "[16:26:31 - Sampler] Region ParPgb:0.0-258.0 (328 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:26:31 - PWorker] Processed 0 batches\n",
      "[16:26:31 - PWorker] All done, 1 remainder regions.\n",
      "[16:26:31 - Predict] Processing 1 short region(s).\n",
      "[16:26:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb0dd56db10>\n",
      "[16:26:31 - MdlStrTF] loading weights from /tmp/tmpvzne893t/model/variables/variables\n",
      "[16:26:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-259.\n",
      "[16:26:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:31 - Feature] Processed ParPgb:0.0-258.0 (median depth 137.0)\n",
      "[16:26:31 - Sampler] Took 0.05s to make features.\n",
      "[16:26:32 - PWorker] Processed 1 batches\n",
      "[16:26:32 - PWorker] All done, 0 remainder regions.\n",
      "[16:26:32 - Predict] Finished processing all regions.\n",
      "[16:26:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:35 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:26:35 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:26:35 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:26:35 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:26:35 - Predict] Found a GPU.\n",
      "[16:26:35 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:26:35 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:26:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbebb8ada80>\n",
      "[16:26:37 - MdlStrTF] loading weights from /tmp/tmpk4upo1uj/model/variables/variables\n",
      "[16:26:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:26:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:26:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:38 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-220.\n",
      "[16:26:38 - Feature] Processed ParPgb:0.0-220.0 (median depth 82.0)\n",
      "[16:26:38 - Sampler] Took 1.57s to make features.\n",
      "[16:26:38 - Sampler] Region ParPgb:0.0-220.0 (294 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:26:38 - PWorker] Processed 0 batches\n",
      "[16:26:38 - PWorker] All done, 1 remainder regions.\n",
      "[16:26:38 - Predict] Processing 1 short region(s).\n",
      "[16:26:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbe18f9e0e0>\n",
      "[16:26:39 - MdlStrTF] loading weights from /tmp/tmpk4upo1uj/model/variables/variables\n",
      "[16:26:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-221.\n",
      "[16:26:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:41 - Feature] Processed ParPgb:0.0-220.0 (median depth 82.0)\n",
      "[16:26:41 - Sampler] Took 2.02s to make features.\n",
      "[16:26:41 - PWorker] Processed 1 batches\n",
      "[16:26:41 - PWorker] All done, 0 remainder regions.\n",
      "[16:26:41 - Predict] Finished processing all regions.\n",
      "[16:26:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:45 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:26:45 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:26:45 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:26:45 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:26:45 - Predict] Found a GPU.\n",
      "[16:26:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:26:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:26:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7965eb1ae0>\n",
      "[16:26:46 - MdlStrTF] loading weights from /tmp/tmp4x0n3z6k/model/variables/variables\n",
      "[16:26:46 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:26:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:26:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:46 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-218.\n",
      "[16:26:46 - Feature] Processed ParPgb:0.0-218.0 (median depth 81.0)\n",
      "[16:26:46 - Sampler] Took 0.05s to make features.\n",
      "[16:26:46 - Sampler] Region ParPgb:0.0-218.0 (250 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:26:46 - PWorker] Processed 0 batches\n",
      "[16:26:46 - PWorker] All done, 1 remainder regions.\n",
      "[16:26:46 - Predict] Processing 1 short region(s).\n",
      "[16:26:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f789d676170>\n",
      "[16:26:46 - MdlStrTF] loading weights from /tmp/tmp4x0n3z6k/model/variables/variables\n",
      "[16:26:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-219.\n",
      "[16:26:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:47 - Feature] Processed ParPgb:0.0-218.0 (median depth 81.0)\n",
      "[16:26:47 - Sampler] Took 0.62s to make features.\n",
      "[16:26:48 - PWorker] Processed 1 batches\n",
      "[16:26:48 - PWorker] All done, 0 remainder regions.\n",
      "[16:26:48 - Predict] Finished processing all regions.\n",
      "[16:26:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:51 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:26:51 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:26:51 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:26:51 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:26:51 - Predict] Found a GPU.\n",
      "[16:26:51 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:26:51 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:26:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f125ba89ae0>\n",
      "[16:26:52 - MdlStrTF] loading weights from /tmp/tmp6cqkwbid/model/variables/variables\n",
      "[16:26:52 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:26:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:26:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[16:26:53 - Feature] Processed ParPgb:0.0-245.0 (median depth 122.0)\n",
      "[16:26:53 - Sampler] Took 0.12s to make features.\n",
      "[16:26:53 - Sampler] Region ParPgb:0.0-245.0 (336 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:26:53 - PWorker] Processed 0 batches\n",
      "[16:26:53 - PWorker] All done, 1 remainder regions.\n",
      "[16:26:53 - Predict] Processing 1 short region(s).\n",
      "[16:26:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f11ca8f5ff0>\n",
      "[16:26:53 - MdlStrTF] loading weights from /tmp/tmp6cqkwbid/model/variables/variables\n",
      "[16:26:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[16:26:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:53 - Feature] Processed ParPgb:0.0-245.0 (median depth 122.0)\n",
      "[16:26:53 - Sampler] Took 0.08s to make features.\n",
      "[16:26:54 - PWorker] Processed 1 batches\n",
      "[16:26:54 - PWorker] All done, 0 remainder regions.\n",
      "[16:26:54 - Predict] Finished processing all regions.\n",
      "[16:26:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:26:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:26:57 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:26:57 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:26:57 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:26:57 - Predict] Found a GPU.\n",
      "[16:26:57 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:26:57 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:26:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f15b9481ae0>\n",
      "[16:26:58 - MdlStrTF] loading weights from /tmp/tmpnok8lf_n/model/variables/variables\n",
      "[16:26:58 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:26:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:26:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:58 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[16:26:58 - Feature] Processed ParPgb:0.0-245.0 (median depth 107.0)\n",
      "[16:26:58 - Sampler] Took 0.05s to make features.\n",
      "[16:26:58 - Sampler] Region ParPgb:0.0-245.0 (327 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:26:58 - PWorker] Processed 0 batches\n",
      "[16:26:58 - PWorker] All done, 1 remainder regions.\n",
      "[16:26:58 - Predict] Processing 1 short region(s).\n",
      "[16:26:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:26:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1518555fc0>\n",
      "[16:26:59 - MdlStrTF] loading weights from /tmp/tmpnok8lf_n/model/variables/variables\n",
      "[16:26:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[16:26:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:26:59 - Feature] Processed ParPgb:0.0-245.0 (median depth 107.0)\n",
      "[16:26:59 - Sampler] Took 0.13s to make features.\n",
      "[16:27:00 - PWorker] Processed 1 batches\n",
      "[16:27:00 - PWorker] All done, 0 remainder regions.\n",
      "[16:27:00 - Predict] Finished processing all regions.\n",
      "[16:27:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:27:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:27:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:27:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:27:03 - Predict] Found a GPU.\n",
      "[16:27:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:27:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:27:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2f77499ae0>\n",
      "[16:27:04 - MdlStrTF] loading weights from /tmp/tmp58dolemg/model/variables/variables\n",
      "[16:27:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:27:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:27:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-219.\n",
      "[16:27:04 - Feature] Processed ParPgb:0.0-219.0 (median depth 98.0)\n",
      "[16:27:04 - Sampler] Took 0.05s to make features.\n",
      "[16:27:04 - Sampler] Region ParPgb:0.0-219.0 (286 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:27:04 - PWorker] Processed 0 batches\n",
      "[16:27:04 - PWorker] All done, 1 remainder regions.\n",
      "[16:27:04 - Predict] Processing 1 short region(s).\n",
      "[16:27:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2ed8671480>\n",
      "[16:27:05 - MdlStrTF] loading weights from /tmp/tmp58dolemg/model/variables/variables\n",
      "[16:27:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-220.\n",
      "[16:27:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:05 - Feature] Processed ParPgb:0.0-219.0 (median depth 98.0)\n",
      "[16:27:05 - Sampler] Took 0.07s to make features.\n",
      "[16:27:05 - PWorker] Processed 1 batches\n",
      "[16:27:05 - PWorker] All done, 0 remainder regions.\n",
      "[16:27:05 - Predict] Finished processing all regions.\n",
      "[16:27:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:27:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:27:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:27:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:27:09 - Predict] Found a GPU.\n",
      "[16:27:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:27:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:27:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faa82a9da80>\n",
      "[16:27:10 - MdlStrTF] loading weights from /tmp/tmpxavalz3d/model/variables/variables\n",
      "[16:27:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:27:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:27:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-249.\n",
      "[16:27:15 - Feature] Processed ParPgb:0.0-249.0 (median depth 98.0)\n",
      "[16:27:15 - Sampler] Took 4.67s to make features.\n",
      "[16:27:15 - Sampler] Region ParPgb:0.0-249.0 (315 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:27:15 - PWorker] Processed 0 batches\n",
      "[16:27:15 - PWorker] All done, 1 remainder regions.\n",
      "[16:27:15 - Predict] Processing 1 short region(s).\n",
      "[16:27:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa9f033d420>\n",
      "[16:27:15 - MdlStrTF] loading weights from /tmp/tmpxavalz3d/model/variables/variables\n",
      "[16:27:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-250.\n",
      "[16:27:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:18 - Feature] Processed ParPgb:0.0-249.0 (median depth 98.0)\n",
      "[16:27:18 - Sampler] Took 2.44s to make features.\n",
      "[16:27:18 - PWorker] Processed 1 batches\n",
      "[16:27:18 - PWorker] All done, 0 remainder regions.\n",
      "[16:27:18 - Predict] Finished processing all regions.\n",
      "[16:27:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:20 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:22 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:27:22 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:27:22 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:27:22 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:27:22 - Predict] Found a GPU.\n",
      "[16:27:22 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:27:22 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:27:22 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:23 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f35cc575a80>\n",
      "[16:27:23 - MdlStrTF] loading weights from /tmp/tmp19lpjfjq/model/variables/variables\n",
      "[16:27:23 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:27:23 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:27:23 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:23 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-202.\n",
      "[16:27:23 - Feature] Processed ParPgb:0.0-202.0 (median depth 108.0)\n",
      "[16:27:23 - Sampler] Took 0.05s to make features.\n",
      "[16:27:23 - Sampler] Region ParPgb:0.0-202.0 (255 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:27:23 - PWorker] Processed 0 batches\n",
      "[16:27:23 - PWorker] All done, 1 remainder regions.\n",
      "[16:27:23 - Predict] Processing 1 short region(s).\n",
      "[16:27:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f352d5a5420>\n",
      "[16:27:24 - MdlStrTF] loading weights from /tmp/tmp19lpjfjq/model/variables/variables\n",
      "[16:27:24 - Sampler] Initializing sampler for consensus of region ParPgb:0-203.\n",
      "[16:27:24 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:26 - Feature] Processed ParPgb:0.0-202.0 (median depth 108.0)\n",
      "[16:27:26 - Sampler] Took 2.25s to make features.\n",
      "[16:27:26 - PWorker] Processed 1 batches\n",
      "[16:27:26 - PWorker] All done, 0 remainder regions.\n",
      "[16:27:26 - Predict] Finished processing all regions.\n",
      "[16:27:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:27:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:27:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:27:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:27:30 - Predict] Found a GPU.\n",
      "[16:27:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:27:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:27:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f60e4205ae0>\n",
      "[16:27:31 - MdlStrTF] loading weights from /tmp/tmpfq5v1ia8/model/variables/variables\n",
      "[16:27:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:27:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:27:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-221.\n",
      "[16:27:31 - Feature] Processed ParPgb:0.0-221.0 (median depth 86.0)\n",
      "[16:27:31 - Sampler] Took 0.11s to make features.\n",
      "[16:27:31 - Sampler] Region ParPgb:0.0-221.0 (270 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:27:31 - PWorker] Processed 0 batches\n",
      "[16:27:31 - PWorker] All done, 1 remainder regions.\n",
      "[16:27:31 - Predict] Processing 1 short region(s).\n",
      "[16:27:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6027341ff0>\n",
      "[16:27:32 - MdlStrTF] loading weights from /tmp/tmpfq5v1ia8/model/variables/variables\n",
      "[16:27:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-222.\n",
      "[16:27:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:33 - Feature] Processed ParPgb:0.0-221.0 (median depth 86.0)\n",
      "[16:27:33 - Sampler] Took 1.40s to make features.\n",
      "[16:27:34 - PWorker] Processed 1 batches\n",
      "[16:27:34 - PWorker] All done, 0 remainder regions.\n",
      "[16:27:34 - Predict] Finished processing all regions.\n",
      "[16:27:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:27:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:27:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:27:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:27:37 - Predict] Found a GPU.\n",
      "[16:27:37 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:27:37 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:27:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff473be9ae0>\n",
      "[16:27:38 - MdlStrTF] loading weights from /tmp/tmp7pxqdpv8/model/variables/variables\n",
      "[16:27:38 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:27:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:27:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-244.\n",
      "[16:27:39 - Feature] Processed ParPgb:0.0-244.0 (median depth 24.0)\n",
      "[16:27:39 - Sampler] Took 0.29s to make features.\n",
      "[16:27:39 - Sampler] Region ParPgb:0.0-244.0 (265 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:27:39 - PWorker] Processed 0 batches\n",
      "[16:27:39 - PWorker] All done, 1 remainder regions.\n",
      "[16:27:39 - Predict] Processing 1 short region(s).\n",
      "[16:27:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff3e2d1de70>\n",
      "[16:27:39 - MdlStrTF] loading weights from /tmp/tmp7pxqdpv8/model/variables/variables\n",
      "[16:27:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-245.\n",
      "[16:27:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:39 - Feature] Processed ParPgb:0.0-244.0 (median depth 24.0)\n",
      "[16:27:39 - Sampler] Took 0.04s to make features.\n",
      "[16:27:40 - PWorker] Processed 1 batches\n",
      "[16:27:40 - PWorker] All done, 0 remainder regions.\n",
      "[16:27:40 - Predict] Finished processing all regions.\n",
      "[16:27:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:27:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:27:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:27:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:27:43 - Predict] Found a GPU.\n",
      "[16:27:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:27:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:27:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f26d8955ae0>\n",
      "[16:27:45 - MdlStrTF] loading weights from /tmp/tmpmwzws2oc/model/variables/variables\n",
      "[16:27:45 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:27:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:27:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-263.\n",
      "[16:27:45 - Feature] Processed ParPgb:0.0-263.0 (median depth 66.0)\n",
      "[16:27:45 - Sampler] Took 0.03s to make features.\n",
      "[16:27:45 - Sampler] Region ParPgb:0.0-263.0 (314 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:27:45 - PWorker] Processed 0 batches\n",
      "[16:27:45 - PWorker] All done, 1 remainder regions.\n",
      "[16:27:45 - Predict] Processing 1 short region(s).\n",
      "[16:27:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2648369480>\n",
      "[16:27:45 - MdlStrTF] loading weights from /tmp/tmpmwzws2oc/model/variables/variables\n",
      "[16:27:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-264.\n",
      "[16:27:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:45 - Feature] Processed ParPgb:0.0-263.0 (median depth 66.0)\n",
      "[16:27:45 - Sampler] Took 0.17s to make features.\n",
      "[16:27:46 - PWorker] Processed 1 batches\n",
      "[16:27:46 - PWorker] All done, 0 remainder regions.\n",
      "[16:27:46 - Predict] Finished processing all regions.\n",
      "[16:27:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:49 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:27:49 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:27:49 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:27:49 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:27:49 - Predict] Found a GPU.\n",
      "[16:27:49 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:27:49 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:27:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fca3e8eda80>\n",
      "[16:27:51 - MdlStrTF] loading weights from /tmp/tmpivfli479/model/variables/variables\n",
      "[16:27:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:27:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:27:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:27:51 - Feature] Processed ParPgb:0.0-240.0 (median depth 84.0)\n",
      "[16:27:51 - Sampler] Took 0.07s to make features.\n",
      "[16:27:51 - Sampler] Region ParPgb:0.0-240.0 (284 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:27:51 - PWorker] Processed 0 batches\n",
      "[16:27:51 - PWorker] All done, 1 remainder regions.\n",
      "[16:27:51 - Predict] Processing 1 short region(s).\n",
      "[16:27:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fc9ad9d5420>\n",
      "[16:27:51 - MdlStrTF] loading weights from /tmp/tmpivfli479/model/variables/variables\n",
      "[16:27:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:27:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:51 - Feature] Processed ParPgb:0.0-240.0 (median depth 84.0)\n",
      "[16:27:51 - Sampler] Took 0.04s to make features.\n",
      "[16:27:52 - PWorker] Processed 1 batches\n",
      "[16:27:52 - PWorker] All done, 0 remainder regions.\n",
      "[16:27:52 - Predict] Finished processing all regions.\n",
      "[16:27:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:27:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:27:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:27:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:27:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:27:55 - Predict] Found a GPU.\n",
      "[16:27:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:27:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:27:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe1f4139ae0>\n",
      "[16:27:56 - MdlStrTF] loading weights from /tmp/tmp6i9m6xt0/model/variables/variables\n",
      "[16:27:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:27:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:27:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[16:27:56 - Feature] Processed ParPgb:0.0-238.0 (median depth 83.0)\n",
      "[16:27:56 - Sampler] Took 0.05s to make features.\n",
      "[16:27:56 - Sampler] Region ParPgb:0.0-238.0 (278 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:27:57 - PWorker] Processed 0 batches\n",
      "[16:27:57 - PWorker] All done, 1 remainder regions.\n",
      "[16:27:57 - Predict] Processing 1 short region(s).\n",
      "[16:27:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:27:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe160361420>\n",
      "[16:27:57 - MdlStrTF] loading weights from /tmp/tmp6i9m6xt0/model/variables/variables\n",
      "[16:27:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[16:27:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:27:59 - Feature] Processed ParPgb:0.0-238.0 (median depth 83.0)\n",
      "[16:27:59 - Sampler] Took 1.91s to make features.\n",
      "[16:27:59 - PWorker] Processed 1 batches\n",
      "[16:27:59 - PWorker] All done, 0 remainder regions.\n",
      "[16:27:59 - Predict] Finished processing all regions.\n",
      "[16:28:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:28:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:28:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:28:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:28:03 - Predict] Found a GPU.\n",
      "[16:28:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:28:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:28:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fa3fdb21ae0>\n",
      "[16:28:04 - MdlStrTF] loading weights from /tmp/tmp2a7v9ft3/model/variables/variables\n",
      "[16:28:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:28:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:28:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:04 - Sampler] Took 0.13s to make features.\n",
      "[16:28:04 - PWorker] Processed 0 batches\n",
      "[16:28:04 - PWorker] All done, 0 remainder regions.\n",
      "[16:28:04 - Predict] Finished processing all regions.\n",
      "[16:28:06 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:06 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:28:07 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:28:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:28:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:28:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:28:08 - Predict] Found a GPU.\n",
      "[16:28:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:28:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:28:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f38e9921ae0>\n",
      "[16:28:09 - MdlStrTF] loading weights from /tmp/tmpn2icn2j0/model/variables/variables\n",
      "[16:28:09 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:28:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:28:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:10 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[16:28:10 - Feature] Processed ParPgb:0.0-242.0 (median depth 86.0)\n",
      "[16:28:10 - Sampler] Took 0.63s to make features.\n",
      "[16:28:10 - Sampler] Region ParPgb:0.0-242.0 (300 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:28:10 - PWorker] Processed 0 batches\n",
      "[16:28:10 - PWorker] All done, 1 remainder regions.\n",
      "[16:28:10 - Predict] Processing 1 short region(s).\n",
      "[16:28:10 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f385831e1a0>\n",
      "[16:28:10 - MdlStrTF] loading weights from /tmp/tmpn2icn2j0/model/variables/variables\n",
      "[16:28:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[16:28:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:10 - Feature] Processed ParPgb:0.0-242.0 (median depth 86.0)\n",
      "[16:28:10 - Sampler] Took 0.09s to make features.\n",
      "[16:28:11 - PWorker] Processed 1 batches\n",
      "[16:28:11 - PWorker] All done, 0 remainder regions.\n",
      "[16:28:11 - Predict] Finished processing all regions.\n",
      "[16:28:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:28:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:28:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:28:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:28:14 - Predict] Found a GPU.\n",
      "[16:28:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:28:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:28:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4c83285ae0>\n",
      "[16:28:15 - MdlStrTF] loading weights from /tmp/tmppo83q4pk/model/variables/variables\n",
      "[16:28:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:28:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:28:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-219.\n",
      "[16:28:15 - Feature] Processed ParPgb:0.0-219.0 (median depth 106.0)\n",
      "[16:28:15 - Sampler] Took 0.04s to make features.\n",
      "[16:28:15 - Sampler] Region ParPgb:0.0-219.0 (258 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:28:15 - PWorker] Processed 0 batches\n",
      "[16:28:15 - PWorker] All done, 1 remainder regions.\n",
      "[16:28:15 - Predict] Processing 1 short region(s).\n",
      "[16:28:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4bf2429450>\n",
      "[16:28:16 - MdlStrTF] loading weights from /tmp/tmppo83q4pk/model/variables/variables\n",
      "[16:28:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-220.\n",
      "[16:28:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:16 - Feature] Processed ParPgb:0.0-219.0 (median depth 106.0)\n",
      "[16:28:16 - Sampler] Took 0.08s to make features.\n",
      "[16:28:17 - PWorker] Processed 1 batches\n",
      "[16:28:17 - PWorker] All done, 0 remainder regions.\n",
      "[16:28:17 - Predict] Finished processing all regions.\n",
      "[16:28:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:18 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:20 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:28:20 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:28:20 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:28:20 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:28:20 - Predict] Found a GPU.\n",
      "[16:28:20 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:28:20 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:28:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb90f4ddae0>\n",
      "[16:28:21 - MdlStrTF] loading weights from /tmp/tmpga1i5w_m/model/variables/variables\n",
      "[16:28:21 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:28:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:28:21 - Sampler] Took 0.01s to make features.\n",
      "[16:28:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:21 - PWorker] Processed 0 batches\n",
      "[16:28:21 - PWorker] All done, 0 remainder regions.\n",
      "[16:28:21 - Predict] Finished processing all regions.\n",
      "[16:28:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:23 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:28:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:28:25 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:28:25 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:28:25 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:28:25 - Predict] Found a GPU.\n",
      "[16:28:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:28:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:28:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff41dff1ae0>\n",
      "[16:28:26 - MdlStrTF] loading weights from /tmp/tmpscknwamt/model/variables/variables\n",
      "[16:28:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:28:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:28:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-258.\n",
      "[16:28:26 - Feature] Processed ParPgb:0.0-258.0 (median depth 107.0)\n",
      "[16:28:26 - Sampler] Took 0.03s to make features.\n",
      "[16:28:26 - Sampler] Region ParPgb:0.0-258.0 (333 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:28:26 - PWorker] Processed 0 batches\n",
      "[16:28:26 - PWorker] All done, 1 remainder regions.\n",
      "[16:28:26 - Predict] Processing 1 short region(s).\n",
      "[16:28:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff38cea9480>\n",
      "[16:28:26 - MdlStrTF] loading weights from /tmp/tmpscknwamt/model/variables/variables\n",
      "[16:28:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-259.\n",
      "[16:28:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:26 - Feature] Processed ParPgb:0.0-258.0 (median depth 107.0)\n",
      "[16:28:26 - Sampler] Took 0.11s to make features.\n",
      "[16:28:27 - PWorker] Processed 1 batches\n",
      "[16:28:27 - PWorker] All done, 0 remainder regions.\n",
      "[16:28:27 - Predict] Finished processing all regions.\n",
      "[16:28:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:28:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:28:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:28:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:28:30 - Predict] Found a GPU.\n",
      "[16:28:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:28:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:28:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe59a8a5a80>\n",
      "[16:28:32 - MdlStrTF] loading weights from /tmp/tmpt3_fd4zs/model/variables/variables\n",
      "[16:28:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:28:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:28:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:32 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-255.\n",
      "[16:28:32 - Feature] Processed ParPgb:0.0-255.0 (median depth 114.0)\n",
      "[16:28:32 - Sampler] Took 0.04s to make features.\n",
      "[16:28:32 - Sampler] Region ParPgb:0.0-255.0 (310 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:28:32 - PWorker] Processed 0 batches\n",
      "[16:28:32 - PWorker] All done, 1 remainder regions.\n",
      "[16:28:32 - Predict] Processing 1 short region(s).\n",
      "[16:28:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe509a26140>\n",
      "[16:28:32 - MdlStrTF] loading weights from /tmp/tmpt3_fd4zs/model/variables/variables\n",
      "[16:28:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-256.\n",
      "[16:28:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:32 - Feature] Processed ParPgb:0.0-255.0 (median depth 114.0)\n",
      "[16:28:32 - Sampler] Took 0.04s to make features.\n",
      "[16:28:33 - PWorker] Processed 1 batches\n",
      "[16:28:33 - PWorker] All done, 0 remainder regions.\n",
      "[16:28:33 - Predict] Finished processing all regions.\n",
      "[16:28:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:36 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:28:36 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:28:36 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:28:36 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:28:36 - Predict] Found a GPU.\n",
      "[16:28:36 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:28:36 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:28:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff8cd1b9ae0>\n",
      "[16:28:38 - MdlStrTF] loading weights from /tmp/tmpioju7yha/model/variables/variables\n",
      "[16:28:38 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:28:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:28:38 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:28:39 - Feature] Processed ParPgb:0.0-240.0 (median depth 118.0)\n",
      "[16:28:39 - Sampler] Took 1.39s to make features.\n",
      "[16:28:39 - Sampler] Region ParPgb:0.0-240.0 (303 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:28:39 - PWorker] Processed 0 batches\n",
      "[16:28:39 - PWorker] All done, 1 remainder regions.\n",
      "[16:28:39 - Predict] Processing 1 short region(s).\n",
      "[16:28:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff83c2a1960>\n",
      "[16:28:39 - MdlStrTF] loading weights from /tmp/tmpioju7yha/model/variables/variables\n",
      "[16:28:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:28:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:41 - Feature] Processed ParPgb:0.0-240.0 (median depth 118.0)\n",
      "[16:28:41 - Sampler] Took 2.04s to make features.\n",
      "[16:28:42 - PWorker] Processed 1 batches\n",
      "[16:28:42 - PWorker] All done, 0 remainder regions.\n",
      "[16:28:42 - Predict] Finished processing all regions.\n",
      "[16:28:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:45 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:28:45 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:28:45 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:28:45 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:28:45 - Predict] Found a GPU.\n",
      "[16:28:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:28:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:28:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f731f369ae0>\n",
      "[16:28:47 - MdlStrTF] loading weights from /tmp/tmp15xlkpda/model/variables/variables\n",
      "[16:28:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:28:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:28:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:47 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[16:28:47 - Feature] Processed ParPgb:0.0-254.0 (median depth 92.0)\n",
      "[16:28:47 - Sampler] Took 0.21s to make features.\n",
      "[16:28:47 - Sampler] Region ParPgb:0.0-254.0 (329 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:28:47 - PWorker] Processed 0 batches\n",
      "[16:28:47 - PWorker] All done, 1 remainder regions.\n",
      "[16:28:47 - Predict] Processing 1 short region(s).\n",
      "[16:28:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f728e53dfc0>\n",
      "[16:28:47 - MdlStrTF] loading weights from /tmp/tmp15xlkpda/model/variables/variables\n",
      "[16:28:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[16:28:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:48 - Feature] Processed ParPgb:0.0-254.0 (median depth 92.0)\n",
      "[16:28:48 - Sampler] Took 0.21s to make features.\n",
      "[16:28:48 - PWorker] Processed 1 batches\n",
      "[16:28:48 - PWorker] All done, 0 remainder regions.\n",
      "[16:28:48 - Predict] Finished processing all regions.\n",
      "[16:28:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:50 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:52 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:28:52 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:28:52 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:28:52 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:28:52 - Predict] Found a GPU.\n",
      "[16:28:52 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:28:52 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:28:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbb561d1ae0>\n",
      "[16:28:53 - MdlStrTF] loading weights from /tmp/tmp_zjx1fl_/model/variables/variables\n",
      "[16:28:53 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:28:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:28:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-259.\n",
      "[16:28:53 - Feature] Processed ParPgb:0.0-259.0 (median depth 90.0)\n",
      "[16:28:53 - Sampler] Took 0.07s to make features.\n",
      "[16:28:53 - Sampler] Region ParPgb:0.0-259.0 (296 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:28:53 - PWorker] Processed 0 batches\n",
      "[16:28:53 - PWorker] All done, 1 remainder regions.\n",
      "[16:28:53 - Predict] Processing 1 short region(s).\n",
      "[16:28:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fbab9311480>\n",
      "[16:28:53 - MdlStrTF] loading weights from /tmp/tmp_zjx1fl_/model/variables/variables\n",
      "[16:28:54 - Sampler] Initializing sampler for consensus of region ParPgb:0-260.\n",
      "[16:28:54 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:54 - Feature] Processed ParPgb:0.0-259.0 (median depth 90.0)\n",
      "[16:28:54 - Sampler] Took 0.05s to make features.\n",
      "[16:28:54 - PWorker] Processed 1 batches\n",
      "[16:28:54 - PWorker] All done, 0 remainder regions.\n",
      "[16:28:54 - Predict] Finished processing all regions.\n",
      "[16:28:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:56 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:28:57 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:28:57 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:28:57 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:28:57 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:28:58 - Predict] Found a GPU.\n",
      "[16:28:58 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:28:58 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:28:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8947761ae0>\n",
      "[16:28:59 - MdlStrTF] loading weights from /tmp/tmp8pfkl7hv/model/variables/variables\n",
      "[16:28:59 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:28:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:28:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:28:59 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-222.\n",
      "[16:28:59 - Feature] Processed ParPgb:0.0-222.0 (median depth 113.0)\n",
      "[16:28:59 - Sampler] Took 0.07s to make features.\n",
      "[16:28:59 - Sampler] Region ParPgb:0.0-222.0 (308 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:28:59 - PWorker] Processed 0 batches\n",
      "[16:28:59 - PWorker] All done, 1 remainder regions.\n",
      "[16:28:59 - Predict] Processing 1 short region(s).\n",
      "[16:28:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:28:59 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f88b80b9480>\n",
      "[16:28:59 - MdlStrTF] loading weights from /tmp/tmp8pfkl7hv/model/variables/variables\n",
      "[16:28:59 - Sampler] Initializing sampler for consensus of region ParPgb:0-223.\n",
      "[16:28:59 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:00 - Feature] Processed ParPgb:0.0-222.0 (median depth 113.0)\n",
      "[16:29:00 - Sampler] Took 0.12s to make features.\n",
      "[16:29:00 - PWorker] Processed 1 batches\n",
      "[16:29:00 - PWorker] All done, 0 remainder regions.\n",
      "[16:29:00 - Predict] Finished processing all regions.\n",
      "[16:29:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:02 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:29:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:29:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:29:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:29:04 - Predict] Found a GPU.\n",
      "[16:29:04 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:29:04 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:29:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f200bec1ae0>\n",
      "[16:29:05 - MdlStrTF] loading weights from /tmp/tmp_5hswgvs/model/variables/variables\n",
      "[16:29:05 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:29:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:29:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:05 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-241.\n",
      "[16:29:05 - Feature] Processed ParPgb:0.0-241.0 (median depth 97.0)\n",
      "[16:29:05 - Sampler] Took 0.03s to make features.\n",
      "[16:29:05 - Sampler] Region ParPgb:0.0-241.0 (293 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:29:05 - PWorker] Processed 0 batches\n",
      "[16:29:05 - PWorker] All done, 1 remainder regions.\n",
      "[16:29:05 - Predict] Processing 1 short region(s).\n",
      "[16:29:05 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1f7c095b10>\n",
      "[16:29:05 - MdlStrTF] loading weights from /tmp/tmp_5hswgvs/model/variables/variables\n",
      "[16:29:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-242.\n",
      "[16:29:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:08 - Feature] Processed ParPgb:0.0-241.0 (median depth 97.0)\n",
      "[16:29:08 - Sampler] Took 2.40s to make features.\n",
      "[16:29:08 - PWorker] Processed 1 batches\n",
      "[16:29:08 - PWorker] All done, 0 remainder regions.\n",
      "[16:29:08 - Predict] Finished processing all regions.\n",
      "[16:29:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:12 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:29:12 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:29:12 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:29:12 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:29:12 - Predict] Found a GPU.\n",
      "[16:29:12 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:29:12 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:29:12 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f66e23b5ae0>\n",
      "[16:29:13 - MdlStrTF] loading weights from /tmp/tmp2nbdfjzy/model/variables/variables\n",
      "[16:29:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:29:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:29:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:13 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-199.\n",
      "[16:29:13 - Feature] Processed ParPgb:0.0-199.0 (median depth 104.0)\n",
      "[16:29:13 - Sampler] Took 0.13s to make features.\n",
      "[16:29:13 - Sampler] Region ParPgb:0.0-199.0 (259 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:29:13 - PWorker] Processed 0 batches\n",
      "[16:29:13 - PWorker] All done, 1 remainder regions.\n",
      "[16:29:13 - Predict] Processing 1 short region(s).\n",
      "[16:29:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f66515cde70>\n",
      "[16:29:14 - MdlStrTF] loading weights from /tmp/tmp2nbdfjzy/model/variables/variables\n",
      "[16:29:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-200.\n",
      "[16:29:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:14 - Feature] Processed ParPgb:0.0-199.0 (median depth 104.0)\n",
      "[16:29:14 - Sampler] Took 0.05s to make features.\n",
      "[16:29:14 - PWorker] Processed 1 batches\n",
      "[16:29:14 - PWorker] All done, 0 remainder regions.\n",
      "[16:29:14 - Predict] Finished processing all regions.\n",
      "[16:29:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:18 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:29:18 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:29:18 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:29:18 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:29:18 - Predict] Found a GPU.\n",
      "[16:29:18 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:29:18 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:29:18 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f19925e1a80>\n",
      "[16:29:19 - MdlStrTF] loading weights from /tmp/tmpb65_8l_8/model/variables/variables\n",
      "[16:29:19 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:29:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:29:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:19 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-232.\n",
      "[16:29:19 - Feature] Processed ParPgb:0.0-232.0 (median depth 78.0)\n",
      "[16:29:19 - Sampler] Took 0.16s to make features.\n",
      "[16:29:19 - Sampler] Region ParPgb:0.0-232.0 (274 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:29:19 - PWorker] Processed 0 batches\n",
      "[16:29:19 - PWorker] All done, 1 remainder regions.\n",
      "[16:29:19 - Predict] Processing 1 short region(s).\n",
      "[16:29:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f19017ca140>\n",
      "[16:29:20 - MdlStrTF] loading weights from /tmp/tmpb65_8l_8/model/variables/variables\n",
      "[16:29:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-233.\n",
      "[16:29:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:20 - Feature] Processed ParPgb:0.0-232.0 (median depth 78.0)\n",
      "[16:29:20 - Sampler] Took 0.03s to make features.\n",
      "[16:29:20 - PWorker] Processed 1 batches\n",
      "[16:29:20 - PWorker] All done, 0 remainder regions.\n",
      "[16:29:20 - Predict] Finished processing all regions.\n",
      "[16:29:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:29:24 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:29:24 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:29:24 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:29:24 - Predict] Found a GPU.\n",
      "[16:29:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:29:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:29:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f32d696dae0>\n",
      "[16:29:25 - MdlStrTF] loading weights from /tmp/tmptj2zhgd3/model/variables/variables\n",
      "[16:29:25 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:29:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:29:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:25 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-258.\n",
      "[16:29:25 - Feature] Processed ParPgb:0.0-258.0 (median depth 125.0)\n",
      "[16:29:25 - Sampler] Took 0.07s to make features.\n",
      "[16:29:25 - Sampler] Region ParPgb:0.0-258.0 (345 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:29:25 - PWorker] Processed 0 batches\n",
      "[16:29:25 - PWorker] All done, 1 remainder regions.\n",
      "[16:29:25 - Predict] Processing 1 short region(s).\n",
      "[16:29:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3238311480>\n",
      "[16:29:26 - MdlStrTF] loading weights from /tmp/tmptj2zhgd3/model/variables/variables\n",
      "[16:29:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-259.\n",
      "[16:29:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:26 - Feature] Processed ParPgb:0.0-258.0 (median depth 125.0)\n",
      "[16:29:26 - Sampler] Took 0.19s to make features.\n",
      "[16:29:26 - PWorker] Processed 1 batches\n",
      "[16:29:26 - PWorker] All done, 0 remainder regions.\n",
      "[16:29:26 - Predict] Finished processing all regions.\n",
      "[16:29:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:29:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:29:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:29:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:29:30 - Predict] Found a GPU.\n",
      "[16:29:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:29:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:29:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5511955ae0>\n",
      "[16:29:31 - MdlStrTF] loading weights from /tmp/tmpydrt7r_w/model/variables/variables\n",
      "[16:29:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:29:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:29:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-199.\n",
      "[16:29:31 - Feature] Processed ParPgb:0.0-199.0 (median depth 33.0)\n",
      "[16:29:31 - Sampler] Took 0.03s to make features.\n",
      "[16:29:31 - Sampler] Region ParPgb:0.0-199.0 (214 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:29:31 - PWorker] Processed 0 batches\n",
      "[16:29:31 - PWorker] All done, 1 remainder regions.\n",
      "[16:29:31 - Predict] Processing 1 short region(s).\n",
      "[16:29:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5480389b10>\n",
      "[16:29:32 - MdlStrTF] loading weights from /tmp/tmpydrt7r_w/model/variables/variables\n",
      "[16:29:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-200.\n",
      "[16:29:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:32 - Feature] Processed ParPgb:0.0-199.0 (median depth 33.0)\n",
      "[16:29:32 - Sampler] Took 0.04s to make features.\n",
      "[16:29:32 - PWorker] Processed 1 batches\n",
      "[16:29:32 - PWorker] All done, 0 remainder regions.\n",
      "[16:29:32 - Predict] Finished processing all regions.\n",
      "[16:29:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:35 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:29:36 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:29:36 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:29:36 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:29:36 - Predict] Found a GPU.\n",
      "[16:29:36 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:29:36 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:29:36 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f90943f9ae0>\n",
      "[16:29:37 - MdlStrTF] loading weights from /tmp/tmpd7kbtx3j/model/variables/variables\n",
      "[16:29:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:29:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:29:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[16:29:37 - Feature] Processed ParPgb:0.0-254.0 (median depth 98.0)\n",
      "[16:29:37 - Sampler] Took 0.06s to make features.\n",
      "[16:29:37 - Sampler] Region ParPgb:0.0-254.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:29:37 - PWorker] Processed 0 batches\n",
      "[16:29:37 - PWorker] All done, 1 remainder regions.\n",
      "[16:29:37 - Predict] Processing 1 short region(s).\n",
      "[16:29:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8ffbd6d480>\n",
      "[16:29:37 - MdlStrTF] loading weights from /tmp/tmpd7kbtx3j/model/variables/variables\n",
      "[16:29:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[16:29:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:38 - Feature] Processed ParPgb:0.0-254.0 (median depth 98.0)\n",
      "[16:29:38 - Sampler] Took 0.06s to make features.\n",
      "[16:29:38 - PWorker] Processed 1 batches\n",
      "[16:29:38 - PWorker] All done, 0 remainder regions.\n",
      "[16:29:38 - Predict] Finished processing all regions.\n",
      "[16:29:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:29:42 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:29:42 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:29:42 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:29:42 - Predict] Found a GPU.\n",
      "[16:29:42 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:29:42 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:29:42 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efd20025ae0>\n",
      "[16:29:43 - MdlStrTF] loading weights from /tmp/tmp05xx_lgk/model/variables/variables\n",
      "[16:29:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:29:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:29:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:43 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-247.\n",
      "[16:29:43 - Feature] Processed ParPgb:0.0-247.0 (median depth 93.0)\n",
      "[16:29:43 - Sampler] Took 0.03s to make features.\n",
      "[16:29:43 - Sampler] Region ParPgb:0.0-247.0 (297 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:29:43 - PWorker] Processed 0 batches\n",
      "[16:29:43 - PWorker] All done, 1 remainder regions.\n",
      "[16:29:43 - Predict] Processing 1 short region(s).\n",
      "[16:29:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7efc901c1450>\n",
      "[16:29:43 - MdlStrTF] loading weights from /tmp/tmp05xx_lgk/model/variables/variables\n",
      "[16:29:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-248.\n",
      "[16:29:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:43 - Feature] Processed ParPgb:0.0-247.0 (median depth 93.0)\n",
      "[16:29:43 - Sampler] Took 0.04s to make features.\n",
      "[16:29:44 - PWorker] Processed 1 batches\n",
      "[16:29:44 - PWorker] All done, 0 remainder regions.\n",
      "[16:29:44 - Predict] Finished processing all regions.\n",
      "[16:29:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:46 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:47 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:29:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:29:47 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:29:47 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:29:47 - Predict] Found a GPU.\n",
      "[16:29:47 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:29:47 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:29:47 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff6a9635ae0>\n",
      "[16:29:49 - MdlStrTF] loading weights from /tmp/tmpd1o_7hxw/model/variables/variables\n",
      "[16:29:49 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:29:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:29:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:49 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-245.\n",
      "[16:29:49 - Feature] Processed ParPgb:0.0-245.0 (median depth 92.0)\n",
      "[16:29:49 - Sampler] Took 0.05s to make features.\n",
      "[16:29:49 - Sampler] Region ParPgb:0.0-245.0 (306 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:29:49 - PWorker] Processed 0 batches\n",
      "[16:29:49 - PWorker] All done, 1 remainder regions.\n",
      "[16:29:49 - Predict] Processing 1 short region(s).\n",
      "[16:29:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:49 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff6187c1b10>\n",
      "[16:29:49 - MdlStrTF] loading weights from /tmp/tmpd1o_7hxw/model/variables/variables\n",
      "[16:29:49 - Sampler] Initializing sampler for consensus of region ParPgb:0-246.\n",
      "[16:29:49 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:49 - Feature] Processed ParPgb:0.0-245.0 (median depth 92.0)\n",
      "[16:29:49 - Sampler] Took 0.05s to make features.\n",
      "[16:29:50 - PWorker] Processed 1 batches\n",
      "[16:29:50 - PWorker] All done, 0 remainder regions.\n",
      "[16:29:50 - Predict] Finished processing all regions.\n",
      "[16:29:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:52 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:29:53 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:29:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:29:53 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:29:53 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:29:53 - Predict] Found a GPU.\n",
      "[16:29:53 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:29:53 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:29:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:55 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1970599ae0>\n",
      "[16:29:55 - MdlStrTF] loading weights from /tmp/tmpjsqf8b6f/model/variables/variables\n",
      "[16:29:55 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:29:55 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:29:55 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:29:57 - Feature] Processed ParPgb:0.0-246.0 (median depth 92.0)\n",
      "[16:29:57 - Sampler] Took 1.89s to make features.\n",
      "[16:29:57 - Sampler] Region ParPgb:0.0-246.0 (306 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:29:57 - PWorker] Processed 0 batches\n",
      "[16:29:57 - PWorker] All done, 1 remainder regions.\n",
      "[16:29:57 - Predict] Processing 1 short region(s).\n",
      "[16:29:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:29:57 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f18d169e230>\n",
      "[16:29:57 - MdlStrTF] loading weights from /tmp/tmpjsqf8b6f/model/variables/variables\n",
      "[16:29:57 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:29:57 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:29:59 - Feature] Processed ParPgb:0.0-246.0 (median depth 92.0)\n",
      "[16:29:59 - Sampler] Took 1.82s to make features.\n",
      "[16:29:59 - PWorker] Processed 1 batches\n",
      "[16:29:59 - PWorker] All done, 0 remainder regions.\n",
      "[16:29:59 - Predict] Finished processing all regions.\n",
      "[16:30:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:03 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:30:03 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:30:03 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:30:03 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:30:03 - Predict] Found a GPU.\n",
      "[16:30:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:30:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:30:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f39e1ef5a80>\n",
      "[16:30:04 - MdlStrTF] loading weights from /tmp/tmpn6kp6wen/model/variables/variables\n",
      "[16:30:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:30:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:30:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-242.\n",
      "[16:30:04 - Feature] Processed ParPgb:0.0-242.0 (median depth 148.0)\n",
      "[16:30:04 - Sampler] Took 0.04s to make features.\n",
      "[16:30:04 - Sampler] Region ParPgb:0.0-242.0 (311 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:30:04 - PWorker] Processed 0 batches\n",
      "[16:30:04 - PWorker] All done, 1 remainder regions.\n",
      "[16:30:04 - Predict] Processing 1 short region(s).\n",
      "[16:30:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:05 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f39510c5420>\n",
      "[16:30:05 - MdlStrTF] loading weights from /tmp/tmpn6kp6wen/model/variables/variables\n",
      "[16:30:05 - Sampler] Initializing sampler for consensus of region ParPgb:0-243.\n",
      "[16:30:05 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:07 - Feature] Processed ParPgb:0.0-242.0 (median depth 148.0)\n",
      "[16:30:07 - Sampler] Took 2.79s to make features.\n",
      "[16:30:08 - PWorker] Processed 1 batches\n",
      "[16:30:08 - PWorker] All done, 0 remainder regions.\n",
      "[16:30:08 - Predict] Finished processing all regions.\n",
      "[16:30:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:10 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:11 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:30:11 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:30:11 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:30:11 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:30:11 - Predict] Found a GPU.\n",
      "[16:30:11 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:30:11 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:30:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5a0a029ae0>\n",
      "[16:30:13 - MdlStrTF] loading weights from /tmp/tmpnzpuhelo/model/variables/variables\n",
      "[16:30:13 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:30:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:30:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:13 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-221.\n",
      "[16:30:13 - Feature] Processed ParPgb:0.0-221.0 (median depth 83.0)\n",
      "[16:30:13 - Sampler] Took 0.04s to make features.\n",
      "[16:30:13 - Sampler] Region ParPgb:0.0-221.0 (274 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:30:13 - PWorker] Processed 0 batches\n",
      "[16:30:13 - PWorker] All done, 1 remainder regions.\n",
      "[16:30:13 - Predict] Processing 1 short region(s).\n",
      "[16:30:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:13 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f596876dae0>\n",
      "[16:30:13 - MdlStrTF] loading weights from /tmp/tmpnzpuhelo/model/variables/variables\n",
      "[16:30:13 - Sampler] Initializing sampler for consensus of region ParPgb:0-222.\n",
      "[16:30:13 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:13 - Feature] Processed ParPgb:0.0-221.0 (median depth 83.0)\n",
      "[16:30:13 - Sampler] Took 0.05s to make features.\n",
      "[16:30:14 - PWorker] Processed 1 batches\n",
      "[16:30:14 - PWorker] All done, 0 remainder regions.\n",
      "[16:30:14 - Predict] Finished processing all regions.\n",
      "[16:30:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:17 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:30:17 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:30:17 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:30:17 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:30:17 - Predict] Found a GPU.\n",
      "[16:30:17 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:30:17 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:30:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1c2437dae0>\n",
      "[16:30:18 - MdlStrTF] loading weights from /tmp/tmpkwdgzm8m/model/variables/variables\n",
      "[16:30:19 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:30:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:30:19 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-200.\n",
      "[16:30:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:21 - Feature] Processed ParPgb:0.0-200.0 (median depth 39.0)\n",
      "[16:30:21 - Sampler] Took 2.25s to make features.\n",
      "[16:30:21 - Sampler] Region ParPgb:0.0-200.0 (223 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:30:21 - PWorker] Processed 0 batches\n",
      "[16:30:21 - PWorker] All done, 1 remainder regions.\n",
      "[16:30:21 - Predict] Processing 1 short region(s).\n",
      "[16:30:21 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1b674a2320>\n",
      "[16:30:21 - MdlStrTF] loading weights from /tmp/tmpkwdgzm8m/model/variables/variables\n",
      "[16:30:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-201.\n",
      "[16:30:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:26 - Feature] Processed ParPgb:0.0-200.0 (median depth 39.0)\n",
      "[16:30:26 - Sampler] Took 4.39s to make features.\n",
      "[16:30:26 - PWorker] Processed 1 batches\n",
      "[16:30:26 - PWorker] All done, 0 remainder regions.\n",
      "[16:30:26 - Predict] Finished processing all regions.\n",
      "[16:30:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:28 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:30:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:30:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:30:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:30:30 - Predict] Found a GPU.\n",
      "[16:30:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:30:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:30:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb61b5e1ae0>\n",
      "[16:30:31 - MdlStrTF] loading weights from /tmp/tmpcuk2w9n9/model/variables/variables\n",
      "[16:30:31 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:30:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:30:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:31 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-262.\n",
      "[16:30:31 - Feature] Processed ParPgb:0.0-262.0 (median depth 93.0)\n",
      "[16:30:31 - Sampler] Took 0.04s to make features.\n",
      "[16:30:31 - Sampler] Region ParPgb:0.0-262.0 (320 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:30:31 - PWorker] Processed 0 batches\n",
      "[16:30:31 - PWorker] All done, 1 remainder regions.\n",
      "[16:30:31 - Predict] Processing 1 short region(s).\n",
      "[16:30:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb58a7f1480>\n",
      "[16:30:31 - MdlStrTF] loading weights from /tmp/tmpcuk2w9n9/model/variables/variables\n",
      "[16:30:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-263.\n",
      "[16:30:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:31 - Feature] Processed ParPgb:0.0-262.0 (median depth 93.0)\n",
      "[16:30:31 - Sampler] Took 0.06s to make features.\n",
      "[16:30:32 - PWorker] Processed 1 batches\n",
      "[16:30:32 - PWorker] All done, 0 remainder regions.\n",
      "[16:30:32 - Predict] Finished processing all regions.\n",
      "[16:30:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:34 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:35 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:30:35 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:30:35 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:30:35 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:30:35 - Predict] Found a GPU.\n",
      "[16:30:35 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:30:35 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:30:35 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fec96d31ae0>\n",
      "[16:30:37 - MdlStrTF] loading weights from /tmp/tmpyrfout66/model/variables/variables\n",
      "[16:30:37 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:30:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:30:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:37 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:30:37 - Feature] Processed ParPgb:0.0-248.0 (median depth 27.0)\n",
      "[16:30:37 - Sampler] Took 0.05s to make features.\n",
      "[16:30:37 - Sampler] Region ParPgb:0.0-248.0 (268 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:30:37 - PWorker] Processed 0 batches\n",
      "[16:30:37 - PWorker] All done, 1 remainder regions.\n",
      "[16:30:37 - Predict] Processing 1 short region(s).\n",
      "[16:30:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:37 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7febf8675450>\n",
      "[16:30:37 - MdlStrTF] loading weights from /tmp/tmpyrfout66/model/variables/variables\n",
      "[16:30:37 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:30:37 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:37 - Feature] Processed ParPgb:0.0-248.0 (median depth 27.0)\n",
      "[16:30:37 - Sampler] Took 0.10s to make features.\n",
      "[16:30:38 - PWorker] Processed 1 batches\n",
      "[16:30:38 - PWorker] All done, 0 remainder regions.\n",
      "[16:30:38 - Predict] Finished processing all regions.\n",
      "[16:30:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:40 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:41 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:30:41 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:30:41 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:30:41 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:30:41 - Predict] Found a GPU.\n",
      "[16:30:41 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:30:41 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:30:41 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:43 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe2beea9ae0>\n",
      "[16:30:43 - MdlStrTF] loading weights from /tmp/tmp8erjz1wh/model/variables/variables\n",
      "[16:30:43 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:30:43 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:30:43 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:43 - Sampler] Took 0.05s to make features.\n",
      "[16:30:43 - PWorker] Processed 0 batches\n",
      "[16:30:43 - PWorker] All done, 0 remainder regions.\n",
      "[16:30:43 - Predict] Finished processing all regions.\n",
      "[16:30:44 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:44 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:30:46 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:30:46 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:30:46 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:30:46 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:30:46 - Predict] Found a GPU.\n",
      "[16:30:46 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:30:46 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:30:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:47 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f054493dae0>\n",
      "[16:30:47 - MdlStrTF] loading weights from /tmp/tmphcp60blj/model/variables/variables\n",
      "[16:30:47 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:30:47 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:30:47 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:48 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-223.\n",
      "[16:30:48 - Feature] Processed ParPgb:0.0-223.0 (median depth 110.0)\n",
      "[16:30:48 - Sampler] Took 0.18s to make features.\n",
      "[16:30:48 - Sampler] Region ParPgb:0.0-223.0 (264 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:30:48 - PWorker] Processed 0 batches\n",
      "[16:30:48 - PWorker] All done, 1 remainder regions.\n",
      "[16:30:48 - Predict] Processing 1 short region(s).\n",
      "[16:30:48 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f04b0365ff0>\n",
      "[16:30:48 - MdlStrTF] loading weights from /tmp/tmphcp60blj/model/variables/variables\n",
      "[16:30:48 - Sampler] Initializing sampler for consensus of region ParPgb:0-224.\n",
      "[16:30:48 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:50 - Feature] Processed ParPgb:0.0-223.0 (median depth 110.0)\n",
      "[16:30:50 - Sampler] Took 2.51s to make features.\n",
      "[16:30:51 - PWorker] Processed 1 batches\n",
      "[16:30:51 - PWorker] All done, 0 remainder regions.\n",
      "[16:30:51 - Predict] Finished processing all regions.\n",
      "[16:30:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:30:54 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:30:54 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:30:54 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:30:54 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:30:54 - Predict] Found a GPU.\n",
      "[16:30:54 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:30:54 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:30:54 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff3fe661ae0>\n",
      "[16:30:56 - MdlStrTF] loading weights from /tmp/tmp31o_obib/model/variables/variables\n",
      "[16:30:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:30:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:30:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:58 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-214.\n",
      "[16:30:58 - Feature] Processed ParPgb:0.0-214.0 (median depth 114.0)\n",
      "[16:30:58 - Sampler] Took 2.04s to make features.\n",
      "[16:30:58 - Sampler] Region ParPgb:0.0-214.0 (274 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:30:58 - PWorker] Processed 0 batches\n",
      "[16:30:58 - PWorker] All done, 1 remainder regions.\n",
      "[16:30:58 - Predict] Processing 1 short region(s).\n",
      "[16:30:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:30:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff36d4be170>\n",
      "[16:30:58 - MdlStrTF] loading weights from /tmp/tmp31o_obib/model/variables/variables\n",
      "[16:30:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-215.\n",
      "[16:30:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:30:58 - Feature] Processed ParPgb:0.0-214.0 (median depth 114.0)\n",
      "[16:30:58 - Sampler] Took 0.09s to make features.\n",
      "[16:30:59 - PWorker] Processed 1 batches\n",
      "[16:30:59 - PWorker] All done, 0 remainder regions.\n",
      "[16:30:59 - Predict] Finished processing all regions.\n",
      "[16:31:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:31:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:31:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:31:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:31:02 - Predict] Found a GPU.\n",
      "[16:31:02 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:31:02 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:31:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8c4637dae0>\n",
      "[16:31:04 - MdlStrTF] loading weights from /tmp/tmpomx7ob_a/model/variables/variables\n",
      "[16:31:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:31:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:31:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:06 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:31:06 - Feature] Processed ParPgb:0.0-246.0 (median depth 69.0)\n",
      "[16:31:06 - Sampler] Took 2.78s to make features.\n",
      "[16:31:06 - Sampler] Region ParPgb:0.0-246.0 (283 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:31:06 - PWorker] Processed 0 batches\n",
      "[16:31:06 - PWorker] All done, 1 remainder regions.\n",
      "[16:31:06 - Predict] Processing 1 short region(s).\n",
      "[16:31:06 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:07 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f8ba838af20>\n",
      "[16:31:07 - MdlStrTF] loading weights from /tmp/tmpomx7ob_a/model/variables/variables\n",
      "[16:31:07 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:31:07 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:10 - Feature] Processed ParPgb:0.0-246.0 (median depth 69.0)\n",
      "[16:31:10 - Sampler] Took 2.83s to make features.\n",
      "[16:31:10 - PWorker] Processed 1 batches\n",
      "[16:31:10 - PWorker] All done, 0 remainder regions.\n",
      "[16:31:10 - Predict] Finished processing all regions.\n",
      "[16:31:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:14 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:31:14 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:31:14 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:31:14 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:31:14 - Predict] Found a GPU.\n",
      "[16:31:14 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:31:14 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:31:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff86086dae0>\n",
      "[16:31:15 - MdlStrTF] loading weights from /tmp/tmpnjas5691/model/variables/variables\n",
      "[16:31:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:31:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:31:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-239.\n",
      "[16:31:15 - Feature] Processed ParPgb:0.0-239.0 (median depth 80.0)\n",
      "[16:31:15 - Sampler] Took 0.07s to make features.\n",
      "[16:31:15 - Sampler] Region ParPgb:0.0-239.0 (303 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:31:15 - PWorker] Processed 0 batches\n",
      "[16:31:15 - PWorker] All done, 1 remainder regions.\n",
      "[16:31:15 - Predict] Processing 1 short region(s).\n",
      "[16:31:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:16 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff7d0221480>\n",
      "[16:31:16 - MdlStrTF] loading weights from /tmp/tmpnjas5691/model/variables/variables\n",
      "[16:31:16 - Sampler] Initializing sampler for consensus of region ParPgb:0-240.\n",
      "[16:31:16 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:20 - Feature] Processed ParPgb:0.0-239.0 (median depth 80.0)\n",
      "[16:31:20 - Sampler] Took 4.67s to make features.\n",
      "[16:31:21 - PWorker] Batches in cache: 1.\n",
      "[16:31:21 - PWorker] Processed 1 batches\n",
      "[16:31:21 - PWorker] All done, 0 remainder regions.\n",
      "[16:31:21 - Predict] Finished processing all regions.\n",
      "[16:31:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:31:24 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:31:24 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:31:24 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:31:24 - Predict] Found a GPU.\n",
      "[16:31:24 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:31:24 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:31:24 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f83a704dae0>\n",
      "[16:31:26 - MdlStrTF] loading weights from /tmp/tmp04lcm56y/model/variables/variables\n",
      "[16:31:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:31:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:31:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[16:31:26 - Feature] Processed ParPgb:0.0-250.0 (median depth 79.0)\n",
      "[16:31:26 - Sampler] Took 0.11s to make features.\n",
      "[16:31:26 - Sampler] Region ParPgb:0.0-250.0 (305 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:31:26 - PWorker] Processed 0 batches\n",
      "[16:31:26 - PWorker] All done, 1 remainder regions.\n",
      "[16:31:26 - Predict] Processing 1 short region(s).\n",
      "[16:31:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f830820d450>\n",
      "[16:31:26 - MdlStrTF] loading weights from /tmp/tmp04lcm56y/model/variables/variables\n",
      "[16:31:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[16:31:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:28 - Feature] Processed ParPgb:0.0-250.0 (median depth 79.0)\n",
      "[16:31:28 - Sampler] Took 2.10s to make features.\n",
      "[16:31:29 - PWorker] Processed 1 batches\n",
      "[16:31:29 - PWorker] All done, 0 remainder regions.\n",
      "[16:31:29 - Predict] Finished processing all regions.\n",
      "[16:31:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:31 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:32 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:31:32 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:31:32 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:31:32 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:31:32 - Predict] Found a GPU.\n",
      "[16:31:32 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:31:32 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:31:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fee6ffe1ae0>\n",
      "[16:31:34 - MdlStrTF] loading weights from /tmp/tmpisyjep0h/model/variables/variables\n",
      "[16:31:34 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:31:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:31:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-205.\n",
      "[16:31:34 - Feature] Processed ParPgb:0.0-205.0 (median depth 110.0)\n",
      "[16:31:34 - Sampler] Took 0.08s to make features.\n",
      "[16:31:34 - Sampler] Region ParPgb:0.0-205.0 (277 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:31:34 - PWorker] Processed 0 batches\n",
      "[16:31:34 - PWorker] All done, 1 remainder regions.\n",
      "[16:31:34 - Predict] Processing 1 short region(s).\n",
      "[16:31:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:34 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fede01c5ff0>\n",
      "[16:31:34 - MdlStrTF] loading weights from /tmp/tmpisyjep0h/model/variables/variables\n",
      "[16:31:34 - Sampler] Initializing sampler for consensus of region ParPgb:0-206.\n",
      "[16:31:34 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:34 - Feature] Processed ParPgb:0.0-205.0 (median depth 110.0)\n",
      "[16:31:34 - Sampler] Took 0.06s to make features.\n",
      "[16:31:35 - PWorker] Processed 1 batches\n",
      "[16:31:35 - PWorker] All done, 0 remainder regions.\n",
      "[16:31:35 - Predict] Finished processing all regions.\n",
      "[16:31:36 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:31:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:31:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:31:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:31:38 - Predict] Found a GPU.\n",
      "[16:31:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:31:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:31:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9530435ae0>\n",
      "[16:31:39 - MdlStrTF] loading weights from /tmp/tmpc_am8dlv/model/variables/variables\n",
      "[16:31:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:31:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:31:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:40 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-253.\n",
      "[16:31:40 - Feature] Processed ParPgb:0.0-253.0 (median depth 120.0)\n",
      "[16:31:40 - Sampler] Took 0.03s to make features.\n",
      "[16:31:40 - Sampler] Region ParPgb:0.0-253.0 (315 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:31:40 - PWorker] Processed 0 batches\n",
      "[16:31:40 - PWorker] All done, 1 remainder regions.\n",
      "[16:31:40 - Predict] Processing 1 short region(s).\n",
      "[16:31:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9490489480>\n",
      "[16:31:40 - MdlStrTF] loading weights from /tmp/tmpc_am8dlv/model/variables/variables\n",
      "[16:31:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-254.\n",
      "[16:31:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:40 - Feature] Processed ParPgb:0.0-253.0 (median depth 120.0)\n",
      "[16:31:40 - Sampler] Took 0.09s to make features.\n",
      "[16:31:41 - PWorker] Processed 1 batches\n",
      "[16:31:41 - PWorker] All done, 0 remainder regions.\n",
      "[16:31:41 - Predict] Finished processing all regions.\n",
      "[16:31:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:44 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:31:44 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:31:44 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:31:44 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:31:44 - Predict] Found a GPU.\n",
      "[16:31:44 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:31:44 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:31:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0964ba9ae0>\n",
      "[16:31:45 - MdlStrTF] loading weights from /tmp/tmpzlq5mz17/model/variables/variables\n",
      "[16:31:45 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:31:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:31:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-240.\n",
      "[16:31:45 - Feature] Processed ParPgb:0.0-240.0 (median depth 46.0)\n",
      "[16:31:45 - Sampler] Took 0.04s to make features.\n",
      "[16:31:45 - Sampler] Region ParPgb:0.0-240.0 (277 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:31:45 - PWorker] Processed 0 batches\n",
      "[16:31:45 - PWorker] All done, 1 remainder regions.\n",
      "[16:31:45 - Predict] Processing 1 short region(s).\n",
      "[16:31:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f08a1d95b10>\n",
      "[16:31:46 - MdlStrTF] loading weights from /tmp/tmpzlq5mz17/model/variables/variables\n",
      "[16:31:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-241.\n",
      "[16:31:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:46 - Feature] Processed ParPgb:0.0-240.0 (median depth 46.0)\n",
      "[16:31:46 - Sampler] Took 0.14s to make features.\n",
      "[16:31:47 - PWorker] Processed 1 batches\n",
      "[16:31:47 - PWorker] All done, 0 remainder regions.\n",
      "[16:31:47 - Predict] Finished processing all regions.\n",
      "[16:31:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:31:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:31:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:31:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:31:50 - Predict] Found a GPU.\n",
      "[16:31:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:31:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:31:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f413b7c1ae0>\n",
      "[16:31:51 - MdlStrTF] loading weights from /tmp/tmpmrk_0q0x/model/variables/variables\n",
      "[16:31:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:31:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:31:51 - Sampler] Took 0.01s to make features.\n",
      "[16:31:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:51 - PWorker] Processed 0 batches\n",
      "[16:31:51 - PWorker] All done, 0 remainder regions.\n",
      "[16:31:51 - Predict] Finished processing all regions.\n",
      "[16:31:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:31:53 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:31:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:31:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:31:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:31:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:31:55 - Predict] Found a GPU.\n",
      "[16:31:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:31:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:31:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0b6c5e5ae0>\n",
      "[16:31:56 - MdlStrTF] loading weights from /tmp/tmptr_fpyiw/model/variables/variables\n",
      "[16:31:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:31:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:31:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:56 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-222.\n",
      "[16:31:56 - Feature] Processed ParPgb:0.0-222.0 (median depth 112.0)\n",
      "[16:31:56 - Sampler] Took 0.04s to make features.\n",
      "[16:31:56 - Sampler] Region ParPgb:0.0-222.0 (286 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:31:56 - PWorker] Processed 0 batches\n",
      "[16:31:56 - PWorker] All done, 1 remainder regions.\n",
      "[16:31:56 - Predict] Processing 1 short region(s).\n",
      "[16:31:56 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:31:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f0acd795450>\n",
      "[16:31:56 - MdlStrTF] loading weights from /tmp/tmptr_fpyiw/model/variables/variables\n",
      "[16:31:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-223.\n",
      "[16:31:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:31:59 - Feature] Processed ParPgb:0.0-222.0 (median depth 112.0)\n",
      "[16:31:59 - Sampler] Took 2.09s to make features.\n",
      "[16:31:59 - PWorker] Processed 1 batches\n",
      "[16:31:59 - PWorker] All done, 0 remainder regions.\n",
      "[16:31:59 - Predict] Finished processing all regions.\n",
      "[16:32:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:32:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:32:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:32:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:32:03 - Predict] Found a GPU.\n",
      "[16:32:03 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:32:03 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:32:03 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff26b541ae0>\n",
      "[16:32:04 - MdlStrTF] loading weights from /tmp/tmpwp__1h3p/model/variables/variables\n",
      "[16:32:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:32:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:32:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-217.\n",
      "[16:32:04 - Feature] Processed ParPgb:0.0-217.0 (median depth 86.0)\n",
      "[16:32:04 - Sampler] Took 0.04s to make features.\n",
      "[16:32:04 - Sampler] Region ParPgb:0.0-217.0 (253 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:32:04 - PWorker] Processed 0 batches\n",
      "[16:32:04 - PWorker] All done, 1 remainder regions.\n",
      "[16:32:04 - Predict] Processing 1 short region(s).\n",
      "[16:32:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff1da61d450>\n",
      "[16:32:04 - MdlStrTF] loading weights from /tmp/tmpwp__1h3p/model/variables/variables\n",
      "[16:32:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-218.\n",
      "[16:32:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:04 - Feature] Processed ParPgb:0.0-217.0 (median depth 86.0)\n",
      "[16:32:04 - Sampler] Took 0.06s to make features.\n",
      "[16:32:05 - PWorker] Processed 1 batches\n",
      "[16:32:05 - PWorker] All done, 0 remainder regions.\n",
      "[16:32:05 - Predict] Finished processing all regions.\n",
      "[16:32:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:07 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:08 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:32:08 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:32:08 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:32:08 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:32:08 - Predict] Found a GPU.\n",
      "[16:32:08 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:32:08 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:32:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:10 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1d37f35ae0>\n",
      "[16:32:10 - MdlStrTF] loading weights from /tmp/tmp8c6ee4kh/model/variables/variables\n",
      "[16:32:10 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:32:10 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:32:10 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[16:32:11 - Feature] Processed ParPgb:0.0-250.0 (median depth 82.0)\n",
      "[16:32:11 - Sampler] Took 1.20s to make features.\n",
      "[16:32:11 - Sampler] Region ParPgb:0.0-250.0 (302 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:32:11 - PWorker] Processed 0 batches\n",
      "[16:32:11 - PWorker] All done, 1 remainder regions.\n",
      "[16:32:11 - Predict] Processing 1 short region(s).\n",
      "[16:32:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1ca80ca1a0>\n",
      "[16:32:11 - MdlStrTF] loading weights from /tmp/tmp8c6ee4kh/model/variables/variables\n",
      "[16:32:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[16:32:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:13 - Feature] Processed ParPgb:0.0-250.0 (median depth 82.0)\n",
      "[16:32:13 - Sampler] Took 1.73s to make features.\n",
      "[16:32:14 - PWorker] Processed 1 batches\n",
      "[16:32:14 - PWorker] All done, 0 remainder regions.\n",
      "[16:32:14 - Predict] Finished processing all regions.\n",
      "[16:32:15 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:16 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:17 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:32:17 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:32:17 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:32:17 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:32:17 - Predict] Found a GPU.\n",
      "[16:32:17 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:32:17 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:32:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:18 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f67511cda80>\n",
      "[16:32:18 - MdlStrTF] loading weights from /tmp/tmp4gpn3fpz/model/variables/variables\n",
      "[16:32:19 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:32:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:32:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:19 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-251.\n",
      "[16:32:19 - Feature] Processed ParPgb:0.0-251.0 (median depth 39.0)\n",
      "[16:32:19 - Sampler] Took 0.14s to make features.\n",
      "[16:32:19 - Sampler] Region ParPgb:0.0-251.0 (303 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:32:19 - PWorker] Processed 0 batches\n",
      "[16:32:19 - PWorker] All done, 1 remainder regions.\n",
      "[16:32:19 - Predict] Processing 1 short region(s).\n",
      "[16:32:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:19 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f66c0365f90>\n",
      "[16:32:19 - MdlStrTF] loading weights from /tmp/tmp4gpn3fpz/model/variables/variables\n",
      "[16:32:19 - Sampler] Initializing sampler for consensus of region ParPgb:0-252.\n",
      "[16:32:19 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:19 - Feature] Processed ParPgb:0.0-251.0 (median depth 39.0)\n",
      "[16:32:19 - Sampler] Took 0.09s to make features.\n",
      "[16:32:20 - PWorker] Processed 1 batches\n",
      "[16:32:20 - PWorker] All done, 0 remainder regions.\n",
      "[16:32:20 - Predict] Finished processing all regions.\n",
      "[16:32:21 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:22 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:23 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:32:23 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:32:23 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:32:23 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:32:23 - Predict] Found a GPU.\n",
      "[16:32:23 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:32:23 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:32:23 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:24 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f84cd981ae0>\n",
      "[16:32:24 - MdlStrTF] loading weights from /tmp/tmpze2ez6ny/model/variables/variables\n",
      "[16:32:25 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:32:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:32:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:25 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:32:25 - Feature] Processed ParPgb:0.0-246.0 (median depth 139.0)\n",
      "[16:32:25 - Sampler] Took 0.05s to make features.\n",
      "[16:32:25 - Sampler] Region ParPgb:0.0-246.0 (329 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:32:25 - PWorker] Processed 0 batches\n",
      "[16:32:25 - PWorker] All done, 1 remainder regions.\n",
      "[16:32:25 - Predict] Processing 1 short region(s).\n",
      "[16:32:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:25 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f842cf02350>\n",
      "[16:32:25 - MdlStrTF] loading weights from /tmp/tmpze2ez6ny/model/variables/variables\n",
      "[16:32:25 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:32:25 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:25 - Feature] Processed ParPgb:0.0-246.0 (median depth 139.0)\n",
      "[16:32:25 - Sampler] Took 0.04s to make features.\n",
      "[16:32:26 - PWorker] Processed 1 batches\n",
      "[16:32:26 - PWorker] All done, 0 remainder regions.\n",
      "[16:32:26 - Predict] Finished processing all regions.\n",
      "[16:32:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:27 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:29 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:32:29 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:32:29 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:32:29 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:32:29 - Predict] Found a GPU.\n",
      "[16:32:29 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:32:29 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:32:29 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fde5fd8dae0>\n",
      "[16:32:30 - MdlStrTF] loading weights from /tmp/tmp47xrul_c/model/variables/variables\n",
      "[16:32:30 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:32:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:32:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:30 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-233.\n",
      "[16:32:30 - Feature] Processed ParPgb:0.0-233.0 (median depth 84.0)\n",
      "[16:32:30 - Sampler] Took 0.09s to make features.\n",
      "[16:32:30 - Sampler] Region ParPgb:0.0-233.0 (288 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:32:30 - PWorker] Processed 0 batches\n",
      "[16:32:30 - PWorker] All done, 1 remainder regions.\n",
      "[16:32:30 - Predict] Processing 1 short region(s).\n",
      "[16:32:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:31 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fddc0e79480>\n",
      "[16:32:31 - MdlStrTF] loading weights from /tmp/tmp47xrul_c/model/variables/variables\n",
      "[16:32:31 - Sampler] Initializing sampler for consensus of region ParPgb:0-234.\n",
      "[16:32:31 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:33 - Feature] Processed ParPgb:0.0-233.0 (median depth 84.0)\n",
      "[16:32:33 - Sampler] Took 2.22s to make features.\n",
      "[16:32:34 - PWorker] Processed 1 batches\n",
      "[16:32:34 - PWorker] All done, 0 remainder regions.\n",
      "[16:32:34 - Predict] Finished processing all regions.\n",
      "[16:32:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:35 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:37 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:32:37 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:32:37 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:32:37 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:32:37 - Predict] Found a GPU.\n",
      "[16:32:37 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:32:37 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:32:37 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:38 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9ef8555ae0>\n",
      "[16:32:38 - MdlStrTF] loading weights from /tmp/tmpx5ebrutg/model/variables/variables\n",
      "[16:32:38 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:32:38 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:32:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:39 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[16:32:39 - Feature] Processed ParPgb:0.0-254.0 (median depth 96.0)\n",
      "[16:32:39 - Sampler] Took 0.18s to make features.\n",
      "[16:32:39 - Sampler] Region ParPgb:0.0-254.0 (323 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:32:39 - PWorker] Processed 0 batches\n",
      "[16:32:39 - PWorker] All done, 1 remainder regions.\n",
      "[16:32:39 - Predict] Processing 1 short region(s).\n",
      "[16:32:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9e59679ae0>\n",
      "[16:32:39 - MdlStrTF] loading weights from /tmp/tmpx5ebrutg/model/variables/variables\n",
      "[16:32:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[16:32:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:39 - Feature] Processed ParPgb:0.0-254.0 (median depth 96.0)\n",
      "[16:32:39 - Sampler] Took 0.20s to make features.\n",
      "[16:32:40 - PWorker] Processed 1 batches\n",
      "[16:32:40 - PWorker] All done, 0 remainder regions.\n",
      "[16:32:40 - Predict] Finished processing all regions.\n",
      "[16:32:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:42 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:32:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:32:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:32:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:32:43 - Predict] Found a GPU.\n",
      "[16:32:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:32:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:32:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fad99efdae0>\n",
      "[16:32:45 - MdlStrTF] loading weights from /tmp/tmp07w8zta1/model/variables/variables\n",
      "[16:32:45 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:32:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:32:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:45 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-256.\n",
      "[16:32:45 - Feature] Processed ParPgb:0.0-256.0 (median depth 139.0)\n",
      "[16:32:45 - Sampler] Took 0.07s to make features.\n",
      "[16:32:45 - Sampler] Region ParPgb:0.0-256.0 (329 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:32:45 - PWorker] Processed 0 batches\n",
      "[16:32:45 - PWorker] All done, 1 remainder regions.\n",
      "[16:32:45 - Predict] Processing 1 short region(s).\n",
      "[16:32:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fad080f1450>\n",
      "[16:32:45 - MdlStrTF] loading weights from /tmp/tmp07w8zta1/model/variables/variables\n",
      "[16:32:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-257.\n",
      "[16:32:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:46 - Feature] Processed ParPgb:0.0-256.0 (median depth 139.0)\n",
      "[16:32:46 - Sampler] Took 0.53s to make features.\n",
      "[16:32:46 - PWorker] Processed 1 batches\n",
      "[16:32:46 - PWorker] All done, 0 remainder regions.\n",
      "[16:32:46 - Predict] Finished processing all regions.\n",
      "[16:32:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:48 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:32:50 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:32:50 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:32:50 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:32:50 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:32:50 - Predict] Found a GPU.\n",
      "[16:32:50 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:32:50 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:32:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2f591fda80>\n",
      "[16:32:51 - MdlStrTF] loading weights from /tmp/tmp54pmhflh/model/variables/variables\n",
      "[16:32:51 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:32:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:32:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:53 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[16:32:53 - Feature] Processed ParPgb:0.0-250.0 (median depth 107.0)\n",
      "[16:32:53 - Sampler] Took 1.87s to make features.\n",
      "[16:32:53 - Sampler] Region ParPgb:0.0-250.0 (315 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:32:53 - PWorker] Processed 0 batches\n",
      "[16:32:53 - PWorker] All done, 1 remainder regions.\n",
      "[16:32:53 - Predict] Processing 1 short region(s).\n",
      "[16:32:53 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:32:53 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f2eb9f753f0>\n",
      "[16:32:53 - MdlStrTF] loading weights from /tmp/tmp54pmhflh/model/variables/variables\n",
      "[16:32:53 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[16:32:53 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:32:58 - Feature] Processed ParPgb:0.0-250.0 (median depth 107.0)\n",
      "[16:32:58 - Sampler] Took 5.08s to make features.\n",
      "[16:32:59 - PWorker] Batches in cache: 1.\n",
      "[16:32:59 - PWorker] Processed 1 batches\n",
      "[16:32:59 - PWorker] All done, 0 remainder regions.\n",
      "[16:32:59 - Predict] Finished processing all regions.\n",
      "[16:33:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:33:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:33:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:33:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:33:02 - Predict] Found a GPU.\n",
      "[16:33:02 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:33:02 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:33:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5e8f385ae0>\n",
      "[16:33:04 - MdlStrTF] loading weights from /tmp/tmp9ufj8blc/model/variables/variables\n",
      "[16:33:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:33:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:33:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:04 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-243.\n",
      "[16:33:04 - Feature] Processed ParPgb:0.0-243.0 (median depth 61.0)\n",
      "[16:33:04 - Sampler] Took 0.05s to make features.\n",
      "[16:33:04 - Sampler] Region ParPgb:0.0-243.0 (293 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:33:04 - PWorker] Processed 0 batches\n",
      "[16:33:04 - PWorker] All done, 1 remainder regions.\n",
      "[16:33:04 - Predict] Processing 1 short region(s).\n",
      "[16:33:04 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5dfe546f20>\n",
      "[16:33:04 - MdlStrTF] loading weights from /tmp/tmp9ufj8blc/model/variables/variables\n",
      "[16:33:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-244.\n",
      "[16:33:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:05 - Feature] Processed ParPgb:0.0-243.0 (median depth 61.0)\n",
      "[16:33:05 - Sampler] Took 1.11s to make features.\n",
      "[16:33:06 - PWorker] Processed 1 batches\n",
      "[16:33:06 - PWorker] All done, 0 remainder regions.\n",
      "[16:33:06 - Predict] Finished processing all regions.\n",
      "[16:33:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:08 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:09 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:33:09 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:33:09 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:33:09 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:33:09 - Predict] Found a GPU.\n",
      "[16:33:09 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:33:09 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:33:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7be6c7dae0>\n",
      "[16:33:11 - MdlStrTF] loading weights from /tmp/tmpp1fepoox/model/variables/variables\n",
      "[16:33:11 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:33:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:33:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:11 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-201.\n",
      "[16:33:11 - Feature] Processed ParPgb:0.0-201.0 (median depth 128.0)\n",
      "[16:33:11 - Sampler] Took 0.02s to make features.\n",
      "[16:33:11 - Sampler] Region ParPgb:0.0-201.0 (286 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:33:11 - PWorker] Processed 0 batches\n",
      "[16:33:11 - PWorker] All done, 1 remainder regions.\n",
      "[16:33:11 - Predict] Processing 1 short region(s).\n",
      "[16:33:11 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:11 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7b4869d480>\n",
      "[16:33:11 - MdlStrTF] loading weights from /tmp/tmpp1fepoox/model/variables/variables\n",
      "[16:33:11 - Sampler] Initializing sampler for consensus of region ParPgb:0-202.\n",
      "[16:33:11 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:11 - Feature] Processed ParPgb:0.0-201.0 (median depth 128.0)\n",
      "[16:33:11 - Sampler] Took 0.13s to make features.\n",
      "[16:33:12 - PWorker] Processed 1 batches\n",
      "[16:33:12 - PWorker] All done, 0 remainder regions.\n",
      "[16:33:12 - Predict] Finished processing all regions.\n",
      "[16:33:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:14 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:15 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:33:15 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:33:15 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:33:15 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:33:15 - Predict] Found a GPU.\n",
      "[16:33:15 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:33:15 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:33:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f596bb0dae0>\n",
      "[16:33:17 - MdlStrTF] loading weights from /tmp/tmpwcmfqq4y/model/variables/variables\n",
      "[16:33:17 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:33:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:33:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:17 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-241.\n",
      "[16:33:17 - Feature] Processed ParPgb:0.0-241.0 (median depth 86.0)\n",
      "[16:33:17 - Sampler] Took 0.04s to make features.\n",
      "[16:33:17 - Sampler] Region ParPgb:0.0-241.0 (304 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:33:17 - PWorker] Processed 0 batches\n",
      "[16:33:17 - PWorker] All done, 1 remainder regions.\n",
      "[16:33:17 - Predict] Processing 1 short region(s).\n",
      "[16:33:17 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:17 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f58da909480>\n",
      "[16:33:17 - MdlStrTF] loading weights from /tmp/tmpwcmfqq4y/model/variables/variables\n",
      "[16:33:17 - Sampler] Initializing sampler for consensus of region ParPgb:0-242.\n",
      "[16:33:17 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:22 - Feature] Processed ParPgb:0.0-241.0 (median depth 86.0)\n",
      "[16:33:22 - Sampler] Took 5.25s to make features.\n",
      "[16:33:23 - PWorker] Batches in cache: 1.\n",
      "[16:33:23 - PWorker] Processed 1 batches\n",
      "[16:33:23 - PWorker] All done, 0 remainder regions.\n",
      "[16:33:23 - Predict] Finished processing all regions.\n",
      "[16:33:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:25 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:26 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:33:26 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:33:26 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:33:26 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:33:26 - Predict] Found a GPU.\n",
      "[16:33:26 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:33:26 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:33:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:28 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff202bd5ae0>\n",
      "[16:33:28 - MdlStrTF] loading weights from /tmp/tmp1vj6wf2p/model/variables/variables\n",
      "[16:33:28 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:33:28 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:33:28 - Sampler] Took 0.00s to make features.\n",
      "[16:33:28 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:28 - PWorker] Processed 0 batches\n",
      "[16:33:28 - PWorker] All done, 0 remainder regions.\n",
      "[16:33:28 - Predict] Finished processing all regions.\n",
      "[16:33:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:29 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:33:31 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:33:31 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:33:31 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:33:31 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:33:31 - Predict] Found a GPU.\n",
      "[16:33:31 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:33:31 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:33:31 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7f5f529ae0>\n",
      "[16:33:32 - MdlStrTF] loading weights from /tmp/tmp2uswciid/model/variables/variables\n",
      "[16:33:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:33:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:33:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:32 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-260.\n",
      "[16:33:32 - Feature] Processed ParPgb:0.0-260.0 (median depth 81.0)\n",
      "[16:33:32 - Sampler] Took 0.10s to make features.\n",
      "[16:33:32 - Sampler] Region ParPgb:0.0-260.0 (325 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:33:32 - PWorker] Processed 0 batches\n",
      "[16:33:32 - PWorker] All done, 1 remainder regions.\n",
      "[16:33:32 - Predict] Processing 1 short region(s).\n",
      "[16:33:32 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:33 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7ec069d480>\n",
      "[16:33:33 - MdlStrTF] loading weights from /tmp/tmp2uswciid/model/variables/variables\n",
      "[16:33:33 - Sampler] Initializing sampler for consensus of region ParPgb:0-261.\n",
      "[16:33:33 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:34 - Feature] Processed ParPgb:0.0-260.0 (median depth 81.0)\n",
      "[16:33:34 - Sampler] Took 1.40s to make features.\n",
      "[16:33:35 - PWorker] Processed 1 batches\n",
      "[16:33:35 - PWorker] All done, 0 remainder regions.\n",
      "[16:33:35 - Predict] Finished processing all regions.\n",
      "[16:33:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:38 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:33:38 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:33:38 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:33:38 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:33:38 - Predict] Found a GPU.\n",
      "[16:33:38 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:33:38 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:33:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f340951dae0>\n",
      "[16:33:40 - MdlStrTF] loading weights from /tmp/tmpp5t3zn7c/model/variables/variables\n",
      "[16:33:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:33:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:33:40 - Sampler] Took 0.01s to make features.\n",
      "[16:33:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:40 - PWorker] Processed 0 batches\n",
      "[16:33:40 - PWorker] All done, 0 remainder regions.\n",
      "[16:33:40 - Predict] Finished processing all regions.\n",
      "[16:33:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:41 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:33:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:33:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:33:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:33:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:33:43 - Predict] Found a GPU.\n",
      "[16:33:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:33:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:33:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4e13509ae0>\n",
      "[16:33:44 - MdlStrTF] loading weights from /tmp/tmpni070leh/model/variables/variables\n",
      "[16:33:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:33:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:33:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:44 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-254.\n",
      "[16:33:44 - Feature] Processed ParPgb:0.0-254.0 (median depth 121.0)\n",
      "[16:33:44 - Sampler] Took 0.05s to make features.\n",
      "[16:33:44 - Sampler] Region ParPgb:0.0-254.0 (341 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:33:44 - PWorker] Processed 0 batches\n",
      "[16:33:44 - PWorker] All done, 1 remainder regions.\n",
      "[16:33:44 - Predict] Processing 1 short region(s).\n",
      "[16:33:44 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f4d8261d480>\n",
      "[16:33:45 - MdlStrTF] loading weights from /tmp/tmpni070leh/model/variables/variables\n",
      "[16:33:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-255.\n",
      "[16:33:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:45 - Feature] Processed ParPgb:0.0-254.0 (median depth 121.0)\n",
      "[16:33:45 - Sampler] Took 0.05s to make features.\n",
      "[16:33:45 - PWorker] Processed 1 batches\n",
      "[16:33:45 - PWorker] All done, 0 remainder regions.\n",
      "[16:33:45 - Predict] Finished processing all regions.\n",
      "[16:33:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:49 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:33:49 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:33:49 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:33:49 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:33:49 - Predict] Found a GPU.\n",
      "[16:33:49 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:33:49 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:33:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb510621ae0>\n",
      "[16:33:50 - MdlStrTF] loading weights from /tmp/tmpdwe_p4sb/model/variables/variables\n",
      "[16:33:50 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:33:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:33:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:50 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:33:50 - Feature] Processed ParPgb:0.0-248.0 (median depth 53.0)\n",
      "[16:33:50 - Sampler] Took 0.02s to make features.\n",
      "[16:33:50 - Sampler] Region ParPgb:0.0-248.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:33:50 - PWorker] Processed 0 batches\n",
      "[16:33:50 - PWorker] All done, 1 remainder regions.\n",
      "[16:33:50 - Predict] Processing 1 short region(s).\n",
      "[16:33:50 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb471771480>\n",
      "[16:33:51 - MdlStrTF] loading weights from /tmp/tmpdwe_p4sb/model/variables/variables\n",
      "[16:33:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:33:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:51 - Feature] Processed ParPgb:0.0-248.0 (median depth 53.0)\n",
      "[16:33:51 - Sampler] Took 0.06s to make features.\n",
      "[16:33:51 - PWorker] Processed 1 batches\n",
      "[16:33:51 - PWorker] All done, 0 remainder regions.\n",
      "[16:33:51 - Predict] Finished processing all regions.\n",
      "[16:33:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:55 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:33:55 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:33:55 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:33:55 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:33:55 - Predict] Found a GPU.\n",
      "[16:33:55 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:33:55 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:33:55 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:33:56 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f28f7735ae0>\n",
      "[16:33:56 - MdlStrTF] loading weights from /tmp/tmpc6fm_yi_/model/variables/variables\n",
      "[16:33:56 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:33:56 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:33:56 - Sampler] Took 0.01s to make features.\n",
      "[16:33:56 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:33:56 - PWorker] Processed 0 batches\n",
      "[16:33:56 - PWorker] All done, 0 remainder regions.\n",
      "[16:33:56 - Predict] Finished processing all regions.\n",
      "[16:33:58 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:33:58 - Stitcher] Copying contig 'ParPgb' verbatim from input.\n",
      "[16:33:59 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:33:59 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:33:59 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:33:59 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:33:59 - Predict] Found a GPU.\n",
      "[16:33:59 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:33:59 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:33:59 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:01 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd6bdbc9ae0>\n",
      "[16:34:01 - MdlStrTF] loading weights from /tmp/tmpt4khn95q/model/variables/variables\n",
      "[16:34:01 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:34:01 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:34:01 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:02 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-217.\n",
      "[16:34:02 - Feature] Processed ParPgb:0.0-217.0 (median depth 91.0)\n",
      "[16:34:02 - Sampler] Took 1.72s to make features.\n",
      "[16:34:02 - Sampler] Region ParPgb:0.0-217.0 (295 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:34:02 - PWorker] Processed 0 batches\n",
      "[16:34:02 - PWorker] All done, 1 remainder regions.\n",
      "[16:34:02 - Predict] Processing 1 short region(s).\n",
      "[16:34:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:03 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd62c539480>\n",
      "[16:34:03 - MdlStrTF] loading weights from /tmp/tmpt4khn95q/model/variables/variables\n",
      "[16:34:03 - Sampler] Initializing sampler for consensus of region ParPgb:0-218.\n",
      "[16:34:03 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:03 - Feature] Processed ParPgb:0.0-217.0 (median depth 91.0)\n",
      "[16:34:03 - Sampler] Took 0.11s to make features.\n",
      "[16:34:03 - PWorker] Processed 1 batches\n",
      "[16:34:03 - PWorker] All done, 0 remainder regions.\n",
      "[16:34:03 - Predict] Finished processing all regions.\n",
      "[16:34:05 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:05 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:07 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:34:07 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:34:07 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:34:07 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:34:07 - Predict] Found a GPU.\n",
      "[16:34:07 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:34:07 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:34:07 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:08 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5c8236dae0>\n",
      "[16:34:08 - MdlStrTF] loading weights from /tmp/tmprypz3kmb/model/variables/variables\n",
      "[16:34:08 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:34:08 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:34:08 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:08 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-261.\n",
      "[16:34:08 - Feature] Processed ParPgb:0.0-261.0 (median depth 76.0)\n",
      "[16:34:08 - Sampler] Took 0.03s to make features.\n",
      "[16:34:08 - Sampler] Region ParPgb:0.0-261.0 (308 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:34:08 - PWorker] Processed 0 batches\n",
      "[16:34:08 - PWorker] All done, 1 remainder regions.\n",
      "[16:34:08 - Predict] Processing 1 short region(s).\n",
      "[16:34:08 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f5bf1525b10>\n",
      "[16:34:09 - MdlStrTF] loading weights from /tmp/tmprypz3kmb/model/variables/variables\n",
      "[16:34:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-262.\n",
      "[16:34:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:09 - Feature] Processed ParPgb:0.0-261.0 (median depth 76.0)\n",
      "[16:34:09 - Sampler] Took 0.05s to make features.\n",
      "[16:34:09 - PWorker] Processed 1 batches\n",
      "[16:34:09 - PWorker] All done, 0 remainder regions.\n",
      "[16:34:09 - Predict] Finished processing all regions.\n",
      "[16:34:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:11 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:13 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:34:13 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:34:13 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:34:13 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:34:13 - Predict] Found a GPU.\n",
      "[16:34:13 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:34:13 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:34:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:14 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd14fcb1ae0>\n",
      "[16:34:14 - MdlStrTF] loading weights from /tmp/tmpaj6qty8a/model/variables/variables\n",
      "[16:34:14 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:34:14 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:34:14 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:14 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-241.\n",
      "[16:34:14 - Feature] Processed ParPgb:0.0-241.0 (median depth 121.0)\n",
      "[16:34:14 - Sampler] Took 0.14s to make features.\n",
      "[16:34:14 - Sampler] Region ParPgb:0.0-241.0 (307 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:34:14 - PWorker] Processed 0 batches\n",
      "[16:34:14 - PWorker] All done, 1 remainder regions.\n",
      "[16:34:14 - Predict] Processing 1 short region(s).\n",
      "[16:34:14 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fd0b0e6dff0>\n",
      "[16:34:15 - MdlStrTF] loading weights from /tmp/tmpaj6qty8a/model/variables/variables\n",
      "[16:34:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-242.\n",
      "[16:34:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:15 - Feature] Processed ParPgb:0.0-241.0 (median depth 121.0)\n",
      "[16:34:15 - Sampler] Took 0.04s to make features.\n",
      "[16:34:15 - PWorker] Processed 1 batches\n",
      "[16:34:15 - PWorker] All done, 0 remainder regions.\n",
      "[16:34:15 - Predict] Finished processing all regions.\n",
      "[16:34:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:34:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:34:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:34:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:34:19 - Predict] Found a GPU.\n",
      "[16:34:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:34:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:34:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f00146e1ae0>\n",
      "[16:34:20 - MdlStrTF] loading weights from /tmp/tmp0lo94ia8/model/variables/variables\n",
      "[16:34:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:34:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:34:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:20 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:34:20 - Feature] Processed ParPgb:0.0-246.0 (median depth 108.0)\n",
      "[16:34:20 - Sampler] Took 0.10s to make features.\n",
      "[16:34:20 - Sampler] Region ParPgb:0.0-246.0 (333 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:34:20 - PWorker] Processed 0 batches\n",
      "[16:34:20 - PWorker] All done, 1 remainder regions.\n",
      "[16:34:20 - Predict] Processing 1 short region(s).\n",
      "[16:34:20 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:21 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7eff80121270>\n",
      "[16:34:21 - MdlStrTF] loading weights from /tmp/tmp0lo94ia8/model/variables/variables\n",
      "[16:34:21 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:34:21 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:21 - Feature] Processed ParPgb:0.0-246.0 (median depth 108.0)\n",
      "[16:34:21 - Sampler] Took 0.05s to make features.\n",
      "[16:34:21 - PWorker] Processed 1 batches\n",
      "[16:34:21 - PWorker] All done, 0 remainder regions.\n",
      "[16:34:21 - Predict] Finished processing all regions.\n",
      "[16:34:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:23 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:24 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:34:24 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:34:24 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:34:24 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:34:25 - Predict] Found a GPU.\n",
      "[16:34:25 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:34:25 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:34:25 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fab2e20dae0>\n",
      "[16:34:26 - MdlStrTF] loading weights from /tmp/tmpcesf44td/model/variables/variables\n",
      "[16:34:26 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:34:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:34:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:26 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-206.\n",
      "[16:34:26 - Feature] Processed ParPgb:0.0-206.0 (median depth 74.0)\n",
      "[16:34:26 - Sampler] Took 0.06s to make features.\n",
      "[16:34:26 - Sampler] Region ParPgb:0.0-206.0 (254 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:34:26 - PWorker] Processed 0 batches\n",
      "[16:34:26 - PWorker] All done, 1 remainder regions.\n",
      "[16:34:26 - Predict] Processing 1 short region(s).\n",
      "[16:34:26 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:26 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7faa9d2a5990>\n",
      "[16:34:26 - MdlStrTF] loading weights from /tmp/tmpcesf44td/model/variables/variables\n",
      "[16:34:26 - Sampler] Initializing sampler for consensus of region ParPgb:0-207.\n",
      "[16:34:26 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:26 - Feature] Processed ParPgb:0.0-206.0 (median depth 74.0)\n",
      "[16:34:26 - Sampler] Took 0.04s to make features.\n",
      "[16:34:27 - PWorker] Processed 1 batches\n",
      "[16:34:27 - PWorker] All done, 0 remainder regions.\n",
      "[16:34:27 - Predict] Finished processing all regions.\n",
      "[16:34:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:29 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:30 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:34:30 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:34:30 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:34:30 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:34:30 - Predict] Found a GPU.\n",
      "[16:34:30 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:34:30 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:34:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:32 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f1a76509ae0>\n",
      "[16:34:32 - MdlStrTF] loading weights from /tmp/tmpixotqftk/model/variables/variables\n",
      "[16:34:32 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:34:32 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:34:32 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:34 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:34:34 - Feature] Processed ParPgb:0.0-248.0 (median depth 123.0)\n",
      "[16:34:34 - Sampler] Took 2.53s to make features.\n",
      "[16:34:34 - Sampler] Region ParPgb:0.0-248.0 (324 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:34:34 - PWorker] Processed 0 batches\n",
      "[16:34:34 - PWorker] All done, 1 remainder regions.\n",
      "[16:34:34 - Predict] Processing 1 short region(s).\n",
      "[16:34:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f19d969d480>\n",
      "[16:34:35 - MdlStrTF] loading weights from /tmp/tmpixotqftk/model/variables/variables\n",
      "[16:34:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:34:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:35 - Feature] Processed ParPgb:0.0-248.0 (median depth 123.0)\n",
      "[16:34:35 - Sampler] Took 0.04s to make features.\n",
      "[16:34:35 - PWorker] Processed 1 batches\n",
      "[16:34:35 - PWorker] All done, 0 remainder regions.\n",
      "[16:34:35 - Predict] Finished processing all regions.\n",
      "[16:34:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:37 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:39 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:34:39 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:34:39 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:34:39 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:34:39 - Predict] Found a GPU.\n",
      "[16:34:39 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:34:39 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:34:39 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:40 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6e7b631ae0>\n",
      "[16:34:40 - MdlStrTF] loading weights from /tmp/tmp_dkrzwnx/model/variables/variables\n",
      "[16:34:40 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:34:40 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:34:40 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:40 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-217.\n",
      "[16:34:40 - Feature] Processed ParPgb:0.0-217.0 (median depth 89.0)\n",
      "[16:34:40 - Sampler] Took 0.04s to make features.\n",
      "[16:34:40 - Sampler] Region ParPgb:0.0-217.0 (261 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:34:40 - PWorker] Processed 0 batches\n",
      "[16:34:40 - PWorker] All done, 1 remainder regions.\n",
      "[16:34:40 - Predict] Processing 1 short region(s).\n",
      "[16:34:40 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:41 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f6dea7c5480>\n",
      "[16:34:41 - MdlStrTF] loading weights from /tmp/tmp_dkrzwnx/model/variables/variables\n",
      "[16:34:41 - Sampler] Initializing sampler for consensus of region ParPgb:0-218.\n",
      "[16:34:41 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:41 - Feature] Processed ParPgb:0.0-217.0 (median depth 89.0)\n",
      "[16:34:41 - Sampler] Took 0.05s to make features.\n",
      "[16:34:41 - PWorker] Processed 1 batches\n",
      "[16:34:41 - PWorker] All done, 0 remainder regions.\n",
      "[16:34:41 - Predict] Finished processing all regions.\n",
      "[16:34:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:43 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:45 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:34:45 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:34:45 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:34:45 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:34:45 - Predict] Found a GPU.\n",
      "[16:34:45 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:34:45 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:34:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3ef8745ae0>\n",
      "[16:34:46 - MdlStrTF] loading weights from /tmp/tmpy6h38al7/model/variables/variables\n",
      "[16:34:46 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:34:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:34:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:46 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-256.\n",
      "[16:34:46 - Feature] Processed ParPgb:0.0-256.0 (median depth 107.0)\n",
      "[16:34:46 - Sampler] Took 0.04s to make features.\n",
      "[16:34:46 - Sampler] Region ParPgb:0.0-256.0 (322 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:34:46 - PWorker] Processed 0 batches\n",
      "[16:34:46 - PWorker] All done, 1 remainder regions.\n",
      "[16:34:46 - Predict] Processing 1 short region(s).\n",
      "[16:34:46 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:46 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3e680c5480>\n",
      "[16:34:46 - MdlStrTF] loading weights from /tmp/tmpy6h38al7/model/variables/variables\n",
      "[16:34:46 - Sampler] Initializing sampler for consensus of region ParPgb:0-257.\n",
      "[16:34:46 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:47 - Feature] Processed ParPgb:0.0-256.0 (median depth 107.0)\n",
      "[16:34:47 - Sampler] Took 0.15s to make features.\n",
      "[16:34:47 - PWorker] Processed 1 batches\n",
      "[16:34:47 - PWorker] All done, 0 remainder regions.\n",
      "[16:34:47 - Predict] Finished processing all regions.\n",
      "[16:34:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:49 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:51 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:34:51 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:34:51 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:34:51 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:34:51 - Predict] Found a GPU.\n",
      "[16:34:51 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:34:51 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:34:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb7d6059ae0>\n",
      "[16:34:52 - MdlStrTF] loading weights from /tmp/tmpqpanf8fn/model/variables/variables\n",
      "[16:34:52 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:34:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:34:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:52 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-238.\n",
      "[16:34:52 - Feature] Processed ParPgb:0.0-238.0 (median depth 111.0)\n",
      "[16:34:52 - Sampler] Took 0.04s to make features.\n",
      "[16:34:52 - Sampler] Region ParPgb:0.0-238.0 (319 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:34:52 - PWorker] Processed 0 batches\n",
      "[16:34:52 - PWorker] All done, 1 remainder regions.\n",
      "[16:34:52 - Predict] Processing 1 short region(s).\n",
      "[16:34:52 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:52 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fb739211990>\n",
      "[16:34:52 - MdlStrTF] loading weights from /tmp/tmpqpanf8fn/model/variables/variables\n",
      "[16:34:52 - Sampler] Initializing sampler for consensus of region ParPgb:0-239.\n",
      "[16:34:52 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:53 - Feature] Processed ParPgb:0.0-238.0 (median depth 111.0)\n",
      "[16:34:53 - Sampler] Took 0.04s to make features.\n",
      "[16:34:53 - PWorker] Processed 1 batches\n",
      "[16:34:53 - PWorker] All done, 0 remainder regions.\n",
      "[16:34:53 - Predict] Finished processing all regions.\n",
      "[16:34:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:55 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:34:56 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:34:56 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:34:56 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:34:56 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:34:57 - Predict] Found a GPU.\n",
      "[16:34:57 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:34:57 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:34:57 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9ee5a51ae0>\n",
      "[16:34:58 - MdlStrTF] loading weights from /tmp/tmpnc8885hc/model/variables/variables\n",
      "[16:34:58 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:34:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:34:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:58 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-248.\n",
      "[16:34:58 - Feature] Processed ParPgb:0.0-248.0 (median depth 84.0)\n",
      "[16:34:58 - Sampler] Took 0.03s to make features.\n",
      "[16:34:58 - Sampler] Region ParPgb:0.0-248.0 (284 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:34:58 - PWorker] Processed 0 batches\n",
      "[16:34:58 - PWorker] All done, 1 remainder regions.\n",
      "[16:34:58 - Predict] Processing 1 short region(s).\n",
      "[16:34:58 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:34:58 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f9e50371ea0>\n",
      "[16:34:58 - MdlStrTF] loading weights from /tmp/tmpnc8885hc/model/variables/variables\n",
      "[16:34:58 - Sampler] Initializing sampler for consensus of region ParPgb:0-249.\n",
      "[16:34:58 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:34:58 - Feature] Processed ParPgb:0.0-248.0 (median depth 84.0)\n",
      "[16:34:58 - Sampler] Took 0.05s to make features.\n",
      "[16:34:59 - PWorker] Processed 1 batches\n",
      "[16:34:59 - PWorker] All done, 0 remainder regions.\n",
      "[16:34:59 - Predict] Finished processing all regions.\n",
      "[16:35:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:01 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:02 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:35:02 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:35:02 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:35:02 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:35:02 - Predict] Found a GPU.\n",
      "[16:35:02 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:35:02 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:35:02 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:35:04 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff4b7599ae0>\n",
      "[16:35:04 - MdlStrTF] loading weights from /tmp/tmp0gkuxne4/model/variables/variables\n",
      "[16:35:04 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:35:04 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:35:04 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:35:09 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-246.\n",
      "[16:35:09 - Feature] Processed ParPgb:0.0-246.0 (median depth 152.0)\n",
      "[16:35:09 - Sampler] Took 5.00s to make features.\n",
      "[16:35:09 - Sampler] Region ParPgb:0.0-246.0 (330 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:35:09 - PWorker] Processed 0 batches\n",
      "[16:35:09 - PWorker] All done, 1 remainder regions.\n",
      "[16:35:09 - Predict] Processing 1 short region(s).\n",
      "[16:35:09 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:35:09 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7ff41879d480>\n",
      "[16:35:09 - MdlStrTF] loading weights from /tmp/tmp0gkuxne4/model/variables/variables\n",
      "[16:35:09 - Sampler] Initializing sampler for consensus of region ParPgb:0-247.\n",
      "[16:35:09 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:35:09 - Feature] Processed ParPgb:0.0-246.0 (median depth 152.0)\n",
      "[16:35:09 - Sampler] Took 0.13s to make features.\n",
      "[16:35:10 - PWorker] Processed 1 batches\n",
      "[16:35:10 - PWorker] All done, 0 remainder regions.\n",
      "[16:35:10 - Predict] Finished processing all regions.\n",
      "[16:35:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:12 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:13 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:35:13 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:35:13 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:35:13 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:35:13 - Predict] Found a GPU.\n",
      "[16:35:13 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:35:13 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:35:13 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:35:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe0a3361ae0>\n",
      "[16:35:15 - MdlStrTF] loading weights from /tmp/tmp5t3o943u/model/variables/variables\n",
      "[16:35:15 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:35:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:35:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:35:15 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-222.\n",
      "[16:35:15 - Feature] Processed ParPgb:0.0-222.0 (median depth 128.0)\n",
      "[16:35:15 - Sampler] Took 0.02s to make features.\n",
      "[16:35:15 - Sampler] Region ParPgb:0.0-222.0 (288 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:35:15 - PWorker] Processed 0 batches\n",
      "[16:35:15 - PWorker] All done, 1 remainder regions.\n",
      "[16:35:15 - Predict] Processing 1 short region(s).\n",
      "[16:35:15 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:35:15 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fe012525ea0>\n",
      "[16:35:15 - MdlStrTF] loading weights from /tmp/tmp5t3o943u/model/variables/variables\n",
      "[16:35:15 - Sampler] Initializing sampler for consensus of region ParPgb:0-223.\n",
      "[16:35:15 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:35:15 - Feature] Processed ParPgb:0.0-222.0 (median depth 128.0)\n",
      "[16:35:15 - Sampler] Took 0.03s to make features.\n",
      "[16:35:16 - PWorker] Processed 1 batches\n",
      "[16:35:16 - PWorker] All done, 0 remainder regions.\n",
      "[16:35:16 - Predict] Finished processing all regions.\n",
      "[16:35:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:17 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:19 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:35:19 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:35:19 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:35:19 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:35:19 - Predict] Found a GPU.\n",
      "[16:35:19 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:35:19 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:35:19 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:35:20 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7feee9981a80>\n",
      "[16:35:20 - MdlStrTF] loading weights from /tmp/tmpx_vryqeo/model/variables/variables\n",
      "[16:35:20 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:35:20 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:35:20 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:35:25 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-256.\n",
      "[16:35:30 - Feature] Processed ParPgb:0.0-256.0 (median depth 123.0)\n",
      "[16:35:30 - Sampler] Took 9.14s to make features.\n",
      "[16:35:30 - Sampler] Region ParPgb:0.0-256.0 (343 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:35:30 - PWorker] Processed 0 batches\n",
      "[16:35:30 - PWorker] All done, 1 remainder regions.\n",
      "[16:35:30 - Predict] Processing 1 short region(s).\n",
      "[16:35:30 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:35:30 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7fee5835df60>\n",
      "[16:35:30 - MdlStrTF] loading weights from /tmp/tmpx_vryqeo/model/variables/variables\n",
      "[16:35:30 - Sampler] Initializing sampler for consensus of region ParPgb:0-257.\n",
      "[16:35:30 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:35:30 - Feature] Processed ParPgb:0.0-256.0 (median depth 123.0)\n",
      "[16:35:30 - Sampler] Took 0.05s to make features.\n",
      "[16:35:31 - PWorker] Processed 1 batches\n",
      "[16:35:31 - PWorker] All done, 0 remainder regions.\n",
      "[16:35:31 - Predict] Finished processing all regions.\n",
      "[16:35:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:32 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:34 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:35:34 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:35:34 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:35:34 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:35:34 - Predict] Found a GPU.\n",
      "[16:35:34 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:35:34 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:35:34 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:35:35 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7c377e5ae0>\n",
      "[16:35:35 - MdlStrTF] loading weights from /tmp/tmpnzbss7ee/model/variables/variables\n",
      "[16:35:35 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:35:35 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:35:35 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:35:38 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-228.\n",
      "[16:35:38 - Feature] Processed ParPgb:0.0-228.0 (median depth 86.0)\n",
      "[16:35:38 - Sampler] Took 2.85s to make features.\n",
      "[16:35:38 - Sampler] Region ParPgb:0.0-228.0 (282 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:35:38 - PWorker] Processed 0 batches\n",
      "[16:35:38 - PWorker] All done, 1 remainder regions.\n",
      "[16:35:38 - Predict] Processing 1 short region(s).\n",
      "[16:35:38 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:35:39 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f7b98132f20>\n",
      "[16:35:39 - MdlStrTF] loading weights from /tmp/tmpnzbss7ee/model/variables/variables\n",
      "[16:35:39 - Sampler] Initializing sampler for consensus of region ParPgb:0-229.\n",
      "[16:35:39 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:35:39 - Feature] Processed ParPgb:0.0-228.0 (median depth 86.0)\n",
      "[16:35:39 - Sampler] Took 0.12s to make features.\n",
      "[16:35:39 - PWorker] Processed 1 batches\n",
      "[16:35:39 - PWorker] All done, 0 remainder regions.\n",
      "[16:35:39 - Predict] Finished processing all regions.\n",
      "[16:35:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:41 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:43 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:35:43 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:35:43 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:35:43 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:35:43 - Predict] Found a GPU.\n",
      "[16:35:43 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:35:43 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:35:43 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:35:44 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3e1f16dae0>\n",
      "[16:35:44 - MdlStrTF] loading weights from /tmp/tmpwqh0wcta/model/variables/variables\n",
      "[16:35:44 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:35:44 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:35:44 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:35:44 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-267.\n",
      "[16:35:45 - Feature] Processed ParPgb:0.0-267.0 (median depth 95.0)\n",
      "[16:35:45 - Sampler] Took 0.14s to make features.\n",
      "[16:35:45 - Sampler] Region ParPgb:0.0-267.0 (332 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:35:45 - PWorker] Processed 0 batches\n",
      "[16:35:45 - PWorker] All done, 1 remainder regions.\n",
      "[16:35:45 - Predict] Processing 1 short region(s).\n",
      "[16:35:45 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:35:45 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f3d8e2e1b10>\n",
      "[16:35:45 - MdlStrTF] loading weights from /tmp/tmpwqh0wcta/model/variables/variables\n",
      "[16:35:45 - Sampler] Initializing sampler for consensus of region ParPgb:0-268.\n",
      "[16:35:45 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:35:45 - Feature] Processed ParPgb:0.0-267.0 (median depth 95.0)\n",
      "[16:35:45 - Sampler] Took 0.04s to make features.\n",
      "[16:35:46 - PWorker] Processed 1 batches\n",
      "[16:35:46 - PWorker] All done, 0 remainder regions.\n",
      "[16:35:46 - Predict] Finished processing all regions.\n",
      "[16:35:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:47 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:49 - Predict] Reducing threads to 2, anymore is a waste.\n",
      "[16:35:49 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n",
      "[16:35:49 - Predict] Processing region(s): ParPgb:0-317\n",
      "[16:35:49 - Predict] Using model: /home/emre/miniconda3/envs/medaka/lib/python3.10/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.\n",
      "[16:35:49 - Predict] Found a GPU.\n",
      "[16:35:49 - Predict] If cuDNN errors are observed, try setting the environment variable `TF_FORCE_GPU_ALLOW_GROWTH=true`. To explicitely disable use of cuDNN use the commandline option `--disable_cudnn. If OOM (out of memory) errors are found please reduce batch size.\n",
      "[16:35:49 - Predict] Processing 1 long region(s) with batching.\n",
      "[16:35:49 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:35:50 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f98bc71dae0>\n",
      "[16:35:50 - MdlStrTF] loading weights from /tmp/tmpwuhosesb/model/variables/variables\n",
      "[16:35:50 - BAMFile] Creating pool of 16 BAM file sets.\n",
      "[16:35:50 - Sampler] Initializing sampler for consensus of region ParPgb:0-317.\n",
      "[16:35:50 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:35:51 - Feature] Pileup counts do not span requested region, requested ParPgb:0-317, received 0-250.\n",
      "[16:35:51 - Feature] Processed ParPgb:0.0-250.0 (median depth 101.0)\n",
      "[16:35:51 - Sampler] Took 0.14s to make features.\n",
      "[16:35:51 - Sampler] Region ParPgb:0.0-250.0 (301 positions) is smaller than inference chunk length 10000, quarantining.\n",
      "[16:35:51 - PWorker] Processed 0 batches\n",
      "[16:35:51 - PWorker] All done, 1 remainder regions.\n",
      "[16:35:51 - Predict] Processing 1 short region(s).\n",
      "[16:35:51 - ModelLoad] GPU available: building model with cudnn optimization\n",
      "[16:35:51 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0x7f982c096230>\n",
      "[16:35:51 - MdlStrTF] loading weights from /tmp/tmpwuhosesb/model/variables/variables\n",
      "[16:35:51 - Sampler] Initializing sampler for consensus of region ParPgb:0-251.\n",
      "[16:35:51 - PWorker] Running inference for 0.0M draft bases.\n",
      "[16:35:51 - Feature] Processed ParPgb:0.0-250.0 (median depth 101.0)\n",
      "[16:35:51 - Sampler] Took 0.11s to make features.\n",
      "[16:35:52 - PWorker] Processed 1 batches\n",
      "[16:35:52 - PWorker] All done, 0 remainder regions.\n",
      "[16:35:52 - Predict] Finished processing all regions.\n",
      "[16:35:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n",
      "[16:35:53 - DataIndx] Loaded 1/1 (100.00%) sample files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# analyser.get_variant_df(demultiplex_folder, ref_seq, barcode_dict, consensus_folder_name = \"consensus\" , sequences = False)\n",
    "\n",
    "for barcode_id, barcode_dict in barcode_dicts.items():\n",
    "\n",
    "    rbc = os.path.basename(barcode_id)\n",
    "\n",
    "    for front_barcode in barcode_dict:\n",
    "\n",
    "        fbc = os.path.basename(front_barcode)\n",
    "\n",
    "        consensus.get_consensus(front_barcode, ref_seq, output_name = \"consensus.fastq\", qualities = True, consensus_folder = \"consensus\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medaka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
