{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b3b02d3-630a-4720-8e6c-e1189357ac38",
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import holoviews as hv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import ninetysix as ns\n",
    "import numpy as np\n",
    "hv.extension('bokeh')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6edc6f6b-8af0-4e25-986f-a1d42dea24f6",
   "metadata": {},
   "source": [
    "def work_up_lcms(\n",
    "    file,\n",
    "    products,\n",
    "    substrates=None,\n",
    "    drop_string=None,\n",
    "):\n",
    "    \"\"\"Works up a standard csv file from Revali.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    file: string\n",
    "        Path to the csv file\n",
    "    products: list of strings\n",
    "        Name of the peaks that correspond to the product\n",
    "    substrates: list of strings\n",
    "        Name of the peaks that correspond to the substrate\n",
    "    drop_string: string, default 'burn_in'\n",
    "        Name of the wells to drop, e.g., for the wash/burn-in period that are not samples.\n",
    "    Returns:\n",
    "    --------\n",
    "    plate: ns.Plate object (DataFrame-like)\n",
    "    \"\"\"\n",
    "    # Read in the data\n",
    "    df = pd.read_csv(file, header=[1])\n",
    "    # Convert nans to 0\n",
    "    df = df.fillna(0)\n",
    "    # Only grab the Sample Acq Order No.s that have a numeric value\n",
    "    index = [True for _ in df['Sample Acq Order No']]\n",
    "    for i, value in enumerate(df['Sample Acq Order No']):\n",
    "        try:\n",
    "            int(value)\n",
    "        except ValueError:\n",
    "            index[i] = False\n",
    "    # Index on this\n",
    "    df = df[index]\n",
    "    def fill_vial_number(series):\n",
    "        for i, row in enumerate(series):\n",
    "            if pd.isna(row):\n",
    "                series[i] = series[i-1]\n",
    "        return series\n",
    "    df['Sample Vial Number'] = fill_vial_number(df['Sample Vial Number'].copy())\n",
    "    # Remove unwanted wells\n",
    "    df = df[df['Sample Name'] != drop_string]\n",
    "    # Get wells\n",
    "    df.insert(0, 'Well', df['Sample Vial Number'].apply(lambda x: x.split('-')[-1]))\n",
    "    # Rename\n",
    "    df = df.rename({'Sample Name': 'Plate'}, axis='columns')\n",
    "    # Create minimal DataFrame\n",
    "    df = df[['Well', 'Plate', 'Compound Name', 'Area']].reset_index(drop=True)\n",
    "    # Pivot table; drop redundant values by only taking 'max' with aggfunc\n",
    "    # (i.e., a row is (value, NaN, NaN) and df is 1728 rows long;\n",
    "    # taking max to aggregate duplicates gives only (value) and 576 rows long)\n",
    "    df = df.pivot_table(\n",
    "        index=['Well', 'Plate'],\n",
    "        columns='Compound Name',\n",
    "        values='Area',\n",
    "        aggfunc='max'\n",
    "    ).reset_index()\n",
    "    # Get rows and columns\n",
    "    df.insert(1, 'Column', df['Well'].apply(lambda x: int(x[1:])))\n",
    "    df.insert(1, 'Row', df['Well'].apply(lambda x: x[0]))\n",
    "    # Set values as floats\n",
    "    cols = products+substrates if substrates is not None else products\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(float)\n",
    "    plate = ns.Plate(df, value_name=products[-1]).set_as_location('Plate', idx=3)\n",
    "    plate.values = products\n",
    "    return plate"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836bc04a-d754-4d87-9739-c50e385e5d13",
   "metadata": {},
   "source": [
    "# Function to process the plate files\n",
    "def process_plate_files(product):\n",
    "    # Load the provided CSV file\n",
    "    results_df = pd.read_csv('HMC0225_HMC0226.csv')\n",
    "\n",
    "    # Extract the required columns: Plate, Well, Mutations, and nc_variant, and remove rows with '#N.A.#' and NaN values\n",
    "    filtered_df = results_df[['Plate', 'Well', 'Mutations', 'nc_variant', 'aa_variant']]\n",
    "    filtered_df = filtered_df[(filtered_df['Mutations'] != '#N.A.#')].dropna()\n",
    "\n",
    "    # Extract the unique entries of Plate\n",
    "    unique_plates = filtered_df['Plate'].unique()\n",
    "\n",
    "    # Create an empty list to store the processed plate data\n",
    "    processed_data = []\n",
    "\n",
    "    # Iterate over unique Plates and search for corresponding CSV files in the current directory\n",
    "    for plate in unique_plates:\n",
    "        # Construct the expected filename based on the Plate value\n",
    "        filename = f\"{plate}.csv\"\n",
    "        \n",
    "        # Check if the file exists in the current directory\n",
    "        if os.path.isfile(filename):\n",
    "            # Work up data to plate object\n",
    "            plate_object = work_up_lcms(filename, product)\n",
    "            \n",
    "            # Extract attributes from plate_object as needed for downstream processes\n",
    "            if hasattr(plate_object, 'df'):\n",
    "                # Assuming plate_object has a dataframe-like attribute 'df' that we can work with\n",
    "                plate_df = plate_object.df\n",
    "                plate_df['Plate'] = plate  # Add the plate identifier for reference\n",
    "                \n",
    "                # Merge filtered_df with plate_df to retain Mutations and nc_variant columns\n",
    "                merged_df = pd.merge(plate_df, filtered_df, on=['Plate', 'Well'], how='left')\n",
    "                columns_order = ['Plate', 'Well', 'Row', 'Column', 'Mutations'] + product + ['nc_variant', 'aa_variant']\n",
    "                merged_df = merged_df[columns_order]\n",
    "                processed_data.append(merged_df)\n",
    "\n",
    "    # Concatenate all dataframes if available\n",
    "    if processed_data:\n",
    "        processed_df = pd.concat(processed_data, ignore_index=True)\n",
    "    else:\n",
    "        processed_df = pd.DataFrame(columns=['Plate', 'Well', 'Row', 'Column', 'Mutations'] + product + ['nc_variant', 'aa_variant'])\n",
    "\n",
    "    # Ensure all entries in 'Mutations' are treated as strings\n",
    "    processed_df['Mutations'] = processed_df['Mutations'].astype(str)\n",
    "\n",
    "    # Remove any rows with empty values\n",
    "    processed_df = processed_df.dropna()\n",
    "\n",
    "    # Optionally, save the processed DataFrame to a CSV file\n",
    "    processed_df.to_csv('processed_plate_data.csv', index=False)\n",
    "\n",
    "    # Create a subset of the processed DataFrame where only '#PARENT#' and variants are kept\n",
    "    # parent_and_variant_df = processed_df[processed_df['Mutations'].isin(['#PARENT#']) | (processed_df['Mutations'] != '#N.A.#')]\n",
    "    # parent_and_variant_df.to_csv('/group_files/levseq-sequence-function/HMC0225_HMC0226/Results/parent_and_variant_data.csv', index=False)\n",
    "\n",
    "    # Return the processed DataFrame for downstream processes\n",
    "    return processed_df\n",
    "\n",
    "# Function to identify SSM experiments\n",
    "def identify_ssm_experiments(df):\n",
    "    # Function to identify if a mutation is part of an SSM experiment\n",
    "    def is_ssm(mutation):\n",
    "        # Define a regex pattern for detecting SSM: a single position with varying amino acids\n",
    "        return bool(re.match(r\"^[A-Z]\\d+[A-Z]$\", str(mutation)))\n",
    "\n",
    "    # Add a new column indicating whether each mutation is part of an SSM experiment\n",
    "    df['is_ssm'] = df['Mutations'].apply(is_ssm)\n",
    "    return df\n",
    "\n",
    "# Example usage of the function\n",
    "processed_plate_df = process_plate_files(product=[\"pdt\"])\n",
    "#processed_plate_df = identify_ssm_experiments(processed_plate_df)\n",
    "processed_plate_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d861a1e",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LevSeq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
