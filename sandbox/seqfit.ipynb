{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "%cd ~/LevSeq"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "%load_ext blackcellmagic"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "import re\n",
    "import os\n",
    "import html\n",
    "\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from glob import glob\n",
    "\n",
    "from ast import literal_eval\n",
    "import urllib.parse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import biopandas as Bio\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from chai_lab.chai1 import run_inference\n",
    "\n",
    "# Enable Bokeh to display plots in the notebook\n",
    "hv.extension('bokeh')\n",
    "pn.extension()\n",
    "output_notebook()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "# Amino acid code conversion\n",
    "AA_DICT = {\n",
    "    \"Ala\": \"A\",\n",
    "    \"Cys\": \"C\",\n",
    "    \"Asp\": \"D\",\n",
    "    \"Glu\": \"E\",\n",
    "    \"Phe\": \"F\",\n",
    "    \"Gly\": \"G\",\n",
    "    \"His\": \"H\",\n",
    "    \"Ile\": \"I\",\n",
    "    \"Lys\": \"K\",\n",
    "    \"Leu\": \"L\",\n",
    "    \"Met\": \"M\",\n",
    "    \"Asn\": \"N\",\n",
    "    \"Pro\": \"P\",\n",
    "    \"Gln\": \"Q\",\n",
    "    \"Arg\": \"R\",\n",
    "    \"Ser\": \"S\",\n",
    "    \"Thr\": \"T\",\n",
    "    \"Val\": \"V\",\n",
    "    \"Trp\": \"W\",\n",
    "    \"Tyr\": \"Y\",\n",
    "    \"Ter\": \"*\",\n",
    "}\n",
    "\n",
    "def checkNgen_folder(folder_path: str) -> str:\n",
    "\n",
    "    \"\"\"\n",
    "    Check if the folder and its subfolder exists\n",
    "    create a new directory if not\n",
    "    Args:\n",
    "    - folder_path: str, the folder path\n",
    "    \"\"\"\n",
    "    # get rid of the very first / if it exists\n",
    "    if folder_path[0] == \"/\":\n",
    "        folder_path = folder_path[1:]\n",
    "\n",
    "    # if input path is file\n",
    "    if bool(os.path.splitext(folder_path)[1]):\n",
    "        folder_path = os.path.dirname(folder_path)\n",
    "\n",
    "    split_list = os.path.normpath(folder_path).split(\"/\")\n",
    "    for p, _ in enumerate(split_list):\n",
    "        subfolder_path = \"/\".join(split_list[: p + 1])\n",
    "        if not os.path.exists(subfolder_path):\n",
    "            print(f\"Making {subfolder_path} ...\")\n",
    "            os.mkdir(subfolder_path)\n",
    "    return folder_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "def match_plate2parent(df: pd.DataFrame, parent_dict: dict | None = None) -> dict:\n",
    "\n",
    "    \"\"\"\n",
    "    Find plate names correpsonding to each parent sequence.\n",
    "\n",
    "    Args:\n",
    "    - df : pd.DataFrame\n",
    "        A pandas DataFrame containing the data for a single plate.\n",
    "        The DataFrame should have the following columns:\n",
    "        - \"Plate\" : str\n",
    "            The plate identifier.\n",
    "        - \"Well\" : str\n",
    "            The well identifier.\n",
    "        - \"Mutations\" : str\n",
    "            The mutations in the well.\n",
    "    - parent_dict : dict\n",
    "        A dictionary containing the parent name for each aa_varient.\n",
    "\n",
    "    Returns:\n",
    "    - dict\n",
    "        A dictionary containing the plate names for each parent sequence.\n",
    "    \"\"\"\n",
    "\n",
    "    if parent_dict is None:\n",
    "\n",
    "        # add aa_variant column if not present by translating from the nc_variant column\n",
    "        if \"aa_variant\" not in df.columns:\n",
    "            df[\"aa_variant\"] = df[\"nc_variant\"].apply(\n",
    "                Bio.sequence.Sequence(df[\"nc_variant\"]).translate\n",
    "            )\n",
    "\n",
    "        # get all the parents from the df\n",
    "        parents = df[df[\"Mutations\"] == \"#PARENT#\"].reset_index(drop=True).copy()\n",
    "\n",
    "        # get the parent nc_variant\n",
    "        parent_aas = (\n",
    "            df[df[\"Mutations\"] == \"#PARENT#\"][[\"Mutations\", \"aa_variant\"]]\n",
    "            .drop_duplicates()[\"aa_variant\"]\n",
    "            .tolist()\n",
    "        )\n",
    "\n",
    "        parent_dict = {f\"Parent-{i+1}\": parent for i, parent in enumerate(parent_aas)}\n",
    "\n",
    "    # get the plate names for each parent\n",
    "    parent2plate = {\n",
    "        p_name: df[df[\"aa_variant\"] == p_seq][\"Plate\"].unique().tolist()\n",
    "        for p_name, p_seq in parent_dict.items()\n",
    "    }\n",
    "\n",
    "    # reverse the dictionary to have plate names as keys and rasie flag if there are multiple parents for a plate\n",
    "    plate2parent = {}\n",
    "    for parent, plates in parent2plate.items():\n",
    "        for plate in plates:\n",
    "            if plate in plate2parent:\n",
    "                raise ValueError(f\"Multiple parents found for plate {plate}\")\n",
    "            else:\n",
    "                plate2parent[plate] = parent\n",
    "\n",
    "    return parent_dict, plate2parent\n",
    "\n",
    "\n",
    "def detect_outliers_iqr(series: pd.Series) -> pd.Index:\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the Interquartile Range (IQR) and\n",
    "    determine the lower and upper bounds for outlier detection.\n",
    "\n",
    "    The IQR is a measure of statistical dispersion and\n",
    "    is calculated as the difference between the third quartile (Q3)\n",
    "    and the first quartile (Q1) of the data\n",
    "\n",
    "    Args:\n",
    "    - series : pandas.Series\n",
    "        A pandas Series containing the data for which the IQR and bounds are to be calculated.\n",
    "\n",
    "    Returns:\n",
    "    - tuple\n",
    "        A tuple containing the lower bound and upper bound for outlier detection.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> data = pd.Series([10, 12, 14, 15, 18, 20, 22, 23, 24, 25, 100])\n",
    "    >>> calculate_iqr_bounds(data)\n",
    "    (-1.0, 39.0)\n",
    "    \"\"\"\n",
    "\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    return series[(series < lower_bound) | (series > upper_bound)].index\n",
    "\n",
    "\n",
    "def norm2parent(plate_df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    For each given plate,\n",
    "    normalize the pdt values of a plate to the mean of the parent\n",
    "    without the outliers.\n",
    "\n",
    "    Args:\n",
    "    - plate_df : pd.DataFrame\n",
    "        A pandas DataFrame containing the data for a single plate.\n",
    "        The DataFrame should have the following columns:\n",
    "        - \"Plate\" : str\n",
    "            The plate identifier.\n",
    "        - \"Mutations\" : str\n",
    "            The mutations in the well.\n",
    "        - \"pdt\" : float\n",
    "            The pdt value for the well.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame\n",
    "        A pandas DataFrame containing the normalized pdt values.\n",
    "    \"\"\"\n",
    "\n",
    "    # get all the parents from the df\n",
    "    parents = (\n",
    "        plate_df[plate_df[\"Mutations\"] == \"#PARENT#\"].reset_index(drop=True).copy()\n",
    "    )\n",
    "    filtered_parents = (\n",
    "        parents.drop(index=detect_outliers_iqr(parents[\"pdt\"]))\n",
    "        .reset_index(drop=True)\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "    # normalize the whole plate to the mean of the filtered parent\n",
    "    plate_df[\"pdt_norm\"] = plate_df[\"pdt\"] / filtered_parents[\"pdt\"].mean()\n",
    "\n",
    "    return plate_df\n",
    "\n",
    "\n",
    "def process_mutation(mutation: str) -> pd.Series:\n",
    "    # Check if mutation is #PARENT#\n",
    "    if mutation == \"#PARENT#\":\n",
    "        return pd.Series([0, [(None, None, None)]])  # Return 0 sites and NaN details\n",
    "\n",
    "    # Split by \"_\" to get number of sites\n",
    "    sites = mutation.split(\"_\")\n",
    "    num_sites = len(sites)\n",
    "\n",
    "    # Extract details if it matches the pattern\n",
    "    details = []\n",
    "    for site in sites:\n",
    "        match = re.match(r\"^([A-Z])(\\d+)([A-Z*])$\", site)\n",
    "        if match:\n",
    "            parent_aa, site_number, mutated_aa = match.groups()\n",
    "            details.append((parent_aa, site_number, mutated_aa))\n",
    "        else:\n",
    "            details.append((None, None, None))\n",
    "\n",
    "    return pd.Series([num_sites, details])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "def prep_single_ssm(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare the data for a single sitessm summary plot.\n",
    "\n",
    "    Args:\n",
    "    - df: pd.DataFrame, input full dataframe\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame, output dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # slice out single site SSM and add in parentAA, site, and mutAA columns\n",
    "    single_ssm_df = df[df[\"num_sites\"] <= 1].copy()\n",
    "\n",
    "    # Expand the single entry in Details for these rows into three columns\n",
    "    single_ssm_df[[\"parent_aa\", \"site_numb\", \"mut_aa\"]] = pd.DataFrame(\n",
    "        single_ssm_df[\"mut_dets\"].apply(lambda x: x[0]).tolist(),\n",
    "        index=single_ssm_df.index,\n",
    "    )\n",
    "\n",
    "    single_ssm_df[\"parent_aa_loc\"] = (\n",
    "        single_ssm_df[\"parent_aa\"] + single_ssm_df[\"site_numb\"]\n",
    "    )\n",
    "\n",
    "    # fill nan site numbers with 0 and convert to int\n",
    "    single_ssm_df[\"site_numb\"] = single_ssm_df[\"site_numb\"].fillna(0).astype(int)\n",
    "\n",
    "    return single_ssm_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "def get_single_ssm_site_df(single_ssm_df: pd.DataFrame, parent: str, site: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get the single site SSM data for a given site with appended parent data.\n",
    "\n",
    "    Args:\n",
    "    - single_ssm_df: pd.DataFrame, input single site SSM dataframe\n",
    "    - parent: str, parent to filter the data on\n",
    "    - site: str, site to filter the data on\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame, output dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # get the site data\n",
    "    site_df = single_ssm_df[\n",
    "        (single_ssm_df[\"Parent_Name\"] == parent)\n",
    "        & (single_ssm_df[\"parent_aa_loc\"] == site)\n",
    "    ].copy()\n",
    "\n",
    "    # get parents from those plates\n",
    "    site_parent_df = single_ssm_df[\n",
    "        (single_ssm_df[\"Mutations\"] == \"#PARENT#\")\n",
    "        & (single_ssm_df[\"Plate\"].isin(site_df[\"Plate\"].unique()))\n",
    "    ].copy()\n",
    "\n",
    "    # rename those site_numb, mut_aa, parent_aa_loc None or NaN to corresponding parent values\n",
    "    site_parent_df[\"mut_aa\"] = site_parent_df[\"mut_aa\"].fillna(\n",
    "        site_df[\"parent_aa\"].values[0]\n",
    "    )\n",
    "    site_parent_df[\"site_numb\"] = site_parent_df[\"site_numb\"].fillna(\n",
    "        site_df[\"site_numb\"].values[0]\n",
    "    )\n",
    "    site_parent_df[\"parent_aa_loc\"] = site_parent_df[\"parent_aa_loc\"].fillna(\n",
    "        site_df[\"parent_aa_loc\"].values[0]\n",
    "    )\n",
    "\n",
    "    # now merge the two dataframes\n",
    "    return pd.concat([site_parent_df, site_df]).reset_index(drop=True).copy()\n",
    "\n",
    "def prep_aa_order(df: pd.DataFrame, add_na: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare the data for a single sitessm summary plot.\n",
    "\n",
    "    Args:\n",
    "    - df: pd.DataFrame, input full dataframe\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame, output dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the order of x-axis categories\n",
    "    x_order = list(AA_DICT.values())\n",
    "    \n",
    "    if add_na:\n",
    "        x_order += [\"#N.A.#\"]\n",
    "\n",
    "    # Convert `Mutations` to a categorical column with specified order\n",
    "    df[\"mut_aa\"] = pd.Categorical(\n",
    "        df[\"mut_aa\"], categories=x_order, ordered=True\n",
    "    )\n",
    "\n",
    "    # Sort by the `x_order`, filling missing values\n",
    "    return (\n",
    "        df.sort_values(\"mut_aa\", key=lambda x: x.cat.codes)\n",
    "        .reset_index(drop=True)\n",
    "        .copy()\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "def get_parent2sitedict(df: pd.DataFrame) -> dict:\n",
    "\n",
    "    \"\"\"\n",
    "    Get a dictionary of parent to site mapping for single site mutants.\n",
    "\n",
    "    Args:\n",
    "    - df : pd.DataFrame\n",
    "\n",
    "    Returns:\n",
    "    - dict\n",
    "        A dictionary containing the parent sequence and site number for each parent.\n",
    "    \"\"\"\n",
    "\n",
    "    site_dict = deepcopy(\n",
    "        df[[\"Parent_Name\", \"parent_aa_loc\"]]\n",
    "        .drop_duplicates().dropna()\n",
    "        .groupby(\"Parent_Name\")[\"parent_aa_loc\"]\n",
    "        .apply(list)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    # Sort the site list for each parent as an integer\n",
    "    for parent, sites in site_dict.items():\n",
    "        # Ensure each site is processed as a string and sorted by the integer part\n",
    "        site_dict[parent] = sorted(sites, key=lambda site: int(str(site)[1:]))\n",
    "\n",
    "    return site_dict"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "def get_y_label(y: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to return the y-axis label based on the input string.\n",
    "    \"\"\"\n",
    "    clean_y = \"\"\n",
    "    if \"pdt\" in y.lower():\n",
    "        clean_y = \"Product\"\n",
    "    elif \"area\" in y.lower():\n",
    "        clean_y = \"Yield\"\n",
    "    elif y == \"fitness_ee2/(ee1+ee2)\":\n",
    "        clean_y = \"ee2/(ee1+ee2)\"\n",
    "    elif y == \"fitness_ee1/(ee1+ee2)\":\n",
    "        clean_y = \"ee1/(ee1+ee2)\"\n",
    "    else:\n",
    "        clean_y=  y\n",
    "\n",
    "    # normalize the y label\n",
    "    if \"norm\" in y.lower():\n",
    "        clean_y = f\"Normalized {clean_y.lower()}\"\n",
    "    return clean_y\n",
    "\n",
    "\n",
    "def plot_bar_point(\n",
    "    df: pd.DataFrame,\n",
    "    x: str,\n",
    "    y: str,\n",
    "    y_label: str = None,\n",
    "    title: str = None,\n",
    "    if_max: bool = False,\n",
    ") -> hv.Layout:\n",
    "\n",
    "    # Create Bars plot\n",
    "    bars = hv.Bars(\n",
    "        df[[y, x]].sort_values(x).groupby(x).mean(),\n",
    "        kdims=x,\n",
    "        vdims=y,\n",
    "    )\n",
    "\n",
    "    # Display the plot\n",
    "    bars.opts(\n",
    "        title=title,\n",
    "        ylabel=y_label or get_y_label(y),\n",
    "        color=y,\n",
    "        cmap=\"coolwarm\",\n",
    "        width=600,\n",
    "        height=400,\n",
    "        xrotation=45,\n",
    "    )\n",
    "\n",
    "    # Create Scatter chart\n",
    "    points = hv.Scatter(df, x, [y, \"Plate\", \"Well\"]).opts(\n",
    "        color=y, cmap=\"gray\", size=8, alpha=0.5, tools=[\"hover\"]\n",
    "    )\n",
    "\n",
    "    # create another scatter plot to highlight the max value\n",
    "    if if_max:\n",
    "        max_points = hv.Scatter(\n",
    "            df.loc[df.groupby(x)[y].idxmax()],\n",
    "            x,\n",
    "            [y, \"Plate\", \"Well\"],\n",
    "        ).opts(color=\"orange\", size=10, alpha=1, tools=[\"hover\"])\n",
    "        return bars * points * max_points\n",
    "    \n",
    "    else:\n",
    "        return bars * points"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "def get_parent_plot(df: pd.DataFrame, y: str = \"pdt_norm\") -> hv.Bars:\n",
    "\n",
    "    \"\"\"\n",
    "    Function to plot the max value by parent.\n",
    "\n",
    "    Args:\n",
    "    - df : pd.DataFrame\n",
    "        A pandas DataFrame containing the data for all parents.\n",
    "        The DataFrame should have the Parent_Name columns\n",
    "    - y : str\n",
    "        The column name for which the max value is to be calculated.\n",
    "\n",
    "    Returns:\n",
    "    - hv.Bars\n",
    "        A holoviews Bars object containing the plot.\n",
    "    \"\"\"\n",
    "\n",
    "    parent_summary = df.groupby(\"Parent_Name\")[y].max().reset_index()\n",
    "    return hv.Bars(parent_summary, kdims=\"Parent_Name\", vdims=y).opts(\n",
    "        title=\"Max Value by Parent\", width=600, height=400\n",
    "    )\n",
    "\n",
    "\n",
    "def agg_parent_plot(df: pd.DataFrame, ys: list = [\"pdt_norm\"]) -> pn.Row:\n",
    "\n",
    "    \"\"\"\n",
    "    Function to plot the max value by parent for different y metrics.\n",
    "\n",
    "    Args:\n",
    "    - df : pd.DataFrame\n",
    "        A pandas DataFrame containing the data for all parents.\n",
    "        The DataFrame should have the Parent_Name columns\n",
    "    - ys : list\n",
    "        The list of column name for which the max value is to be calculated.\n",
    "\n",
    "    Returns:\n",
    "    - hv.Bars\n",
    "    \"\"\"\n",
    "\n",
    "    # find single site mutations\n",
    "    # avg_parnet_plots = [get_parent_plot(y=y) for y in ys if y in df.columns]\n",
    "    avg_parnet_plots = [\n",
    "        plot_bar_point(\n",
    "            df,\n",
    "            x=\"Parent_Name\",\n",
    "            y=y,\n",
    "            title=f\"{get_y_label(y)} across parents\",\n",
    "            if_max=True,\n",
    "        )\n",
    "        for y in ys\n",
    "        if y in df.columns\n",
    "    ]\n",
    "\n",
    "    if len(avg_parnet_plots) == 0:\n",
    "        return None\n",
    "    # elif len(avg_ssm_plots) == 1:\n",
    "    #     return avg_ssm_plots[0]\n",
    "    else:\n",
    "        return pn.Row(*avg_parnet_plots)\n",
    "\n",
    "\n",
    "def plot_single_ssm_avg(\n",
    "    single_ssm_df: pd.DataFrame,\n",
    "    parent_name: str,\n",
    "    y: str = \"pdt_norm\",\n",
    "    width: int = 600,\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to plot single site mutations with average values.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing mutation data.\n",
    "    \"\"\"\n",
    "\n",
    "    sliced_df = prep_aa_order(single_ssm_df[single_ssm_df[\"Parent_Name\"] == parent_name].copy())\n",
    "\n",
    "    height = max(30 * sliced_df[\"site_numb\"].nunique(), 160)\n",
    "\n",
    "    return hv.HeatMap(\n",
    "        data=sliced_df[[\"parent_aa_loc\", \"mut_aa\", y]]\n",
    "        .dropna()\n",
    "        .groupby(by=[\"parent_aa_loc\", \"mut_aa\"])\n",
    "        .mean()\n",
    "        .sort_values(\n",
    "            [\"parent_aa_loc\", \"mut_aa\"],\n",
    "            key=lambda col: col.str.extract(r\"(\\d+)$\").fillna(0).astype(int).iloc[:, 0]\n",
    "            if col.name == \"parent_aa_loc\"\n",
    "            else col\n",
    "            # key=lambda col: col[1:].astype(int)\n",
    "            # if col.name == \"single_mutated_sites_w_parent\"\n",
    "            # else col,\n",
    "        )\n",
    "        .reset_index(),\n",
    "        kdims=[\"mut_aa\", \"parent_aa_loc\"],\n",
    "        vdims=[y],\n",
    "    ).opts(\n",
    "        height=height,\n",
    "        width=width,\n",
    "        cmap=\"coolwarm\",\n",
    "        # color_levels=color_levels,\n",
    "        colorbar=True,\n",
    "        colorbar_opts=dict(title=y, width=8),\n",
    "        xrotation=45,\n",
    "        title=f\"Average single site mutations for {parent_name}\",\n",
    "        xlabel=\"Residue\",\n",
    "        ylabel=\"Position\",\n",
    "        invert_yaxis=True,\n",
    "        tools=[\"hover\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def agg_single_ssm_exp_avg(\n",
    "    single_ssm_df: pd.DataFrame,\n",
    "    parent_name: str,\n",
    "    ys: list = [\"pdt_norm\"],\n",
    "):\n",
    "\n",
    "    # find single site mutations\n",
    "    avg_ssm_plots = [\n",
    "        plot_single_ssm_avg(single_ssm_df=single_ssm_df, parent_name=parent_name, y=y)\n",
    "        for y in ys\n",
    "        if y in df.columns\n",
    "    ]\n",
    "\n",
    "    if len(avg_ssm_plots) == 0:\n",
    "        return None\n",
    "    # elif len(avg_ssm_plots) == 1:\n",
    "    #     return avg_ssm_plots[0]\n",
    "    else:\n",
    "        return pn.Row(*avg_ssm_plots)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "def canonicalize_smiles(smiles_string: str) -> str:\n",
    "\n",
    "    \"\"\"\n",
    "    A function to canonicalize a SMILES string.\n",
    "\n",
    "    Args:\n",
    "    - smiles_string (str): The input SMILES string.\n",
    "\n",
    "    Returns:\n",
    "    - str: The canonicalized SMILES string.\n",
    "    \"\"\"\n",
    "\n",
    "    molecule = Chem.MolFromSmiles(smiles_string)\n",
    "    if molecule:\n",
    "        canonical_smiles = Chem.MolToSmiles(molecule, canonical=True)\n",
    "        return canonical_smiles\n",
    "\n",
    "\n",
    "def get_chaistructure(\n",
    "    chai_dir: str,\n",
    "    seq: str,\n",
    "    seq_name: str,\n",
    "    smiles: str = \"\",\n",
    "    smiles_name: str = \"\",\n",
    "    cofactor_smiles: list | str = \"\",\n",
    "    cofactor_name: str = \"\",\n",
    "    joinsubcofactor: bool = True,\n",
    "    torch_device: str = \"cuda\",\n",
    "    ifrerun: bool = False,\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    A function for getting chai structure for a gvien sequence.\n",
    "\n",
    "    Args:\n",
    "    - seq (str): sequence of the protein\n",
    "    - seq_name (str): label for the protein-ligand pair\n",
    "    - smiles (str): SMILES string of the ligand\n",
    "    - smiles_name (str): label for the ligand\n",
    "    - cofactor_smiles (list or str): list of SMILES strings of cofactors, default is \"\"\n",
    "    - cofactor_name (str): label for the cofactor, default is \"\"\n",
    "    - joinsubcofactor (bool): whether to join the substrate and cofactor in the same fasta file, default is True\n",
    "\n",
    "    Returns:\n",
    "    - list: list of the output files\n",
    "    \"\"\"\n",
    "\n",
    "    chai_dir = checkNgen_folder(os.path.normpath(chai_dir))\n",
    "\n",
    "    # make sure output dir is dir\n",
    "    output_subdir = os.path.join(chai_dir, seq_name)\n",
    "\n",
    "    # Need to clean up the sequence\n",
    "    seq = seq.strip().replace(\"*\", \"\").replace(\" \", \"\").upper()\n",
    "\n",
    "    input_fasta = f\">protein|{seq_name}\\n{seq}\\n\"\n",
    "\n",
    "    if cofactor_smiles != \"\":\n",
    "        # convert cofactor_smiles to a list if it is a string\n",
    "        if isinstance(cofactor_smiles, str):\n",
    "            # use ast.literal_eval to convert string to list\n",
    "            try:\n",
    "                cofactor_smiles = literal_eval(cofactor_smiles)\n",
    "            except:\n",
    "                cofactor_smiles = [cofactor_smiles]\n",
    "\n",
    "        # add cofactor SMILES to the fasta\n",
    "        for cofactor_smile in cofactor_smiles:\n",
    "            input_fasta += f\">ligand|{seq_name}-cofactor\\n{cofactor_smile}\\n\"\n",
    "\n",
    "    if smiles:\n",
    "        smiles = canonicalize_smiles(smiles)\n",
    "        # now add substrate\n",
    "        input_fasta += f\">ligand|{seq_name}-substrate\\n{smiles}\\n\"\n",
    "\n",
    "    # only rerun if the flag is set and the output folder doies not exists\n",
    "    if ifrerun or not os.path.exists(output_subdir):\n",
    "        \n",
    "        output_subdir = Path(checkNgen_folder(output_subdir))\n",
    "            \n",
    "        fasta_path = Path(f\"{output_subdir}/{seq_name}.fasta\")\n",
    "        fasta_path.write_text(input_fasta)\n",
    "\n",
    "        output_paths = run_inference(\n",
    "            fasta_file=fasta_path,\n",
    "            output_dir=output_subdir,\n",
    "            # 'default' setup\n",
    "            num_trunk_recycles=3,\n",
    "            num_diffn_timesteps=200,\n",
    "            seed=42,\n",
    "            device=torch.device(torch_device),\n",
    "            use_esm_embeddings=True,\n",
    "        )\n",
    "\n",
    "        renamed_output_files = []\n",
    "\n",
    "        # get name of the output cif or pdb files\n",
    "        output_strcut_files = sorted(glob(f\"{output_subdir}/*.cif\") + glob(\n",
    "            f\"{output_subdir}/*.pdb\"\n",
    "        ))\n",
    "\n",
    "        # rename the output files cif or pdb files\n",
    "        for output_strcut_file in output_strcut_files:\n",
    "            renamed_output_file = output_strcut_file.replace(\n",
    "                \"pred.model_idx\", seq_name\n",
    "            )\n",
    "            os.rename(\n",
    "                output_strcut_file, renamed_output_file # output_strcut_file.replace(\"pred.model_idx\", seq_name)\n",
    "            )\n",
    "            renamed_output_files.append(renamed_output_file)\n",
    "\n",
    "        renamed_scores_files = []\n",
    "\n",
    "        # for npz files do the same\n",
    "        output_scores_files = sorted(glob(f\"{output_subdir}/*.npz\"))\n",
    "\n",
    "        for output_scores_file in output_scores_files:\n",
    "            renamed_output_file = output_scores_file.replace(\n",
    "                \"scores.model_idx\", seq_name\n",
    "            )\n",
    "            os.rename(\n",
    "                output_scores_file, renamed_output_file # output_scores_file.replace(\"scores.model_idx\", seq_name)\n",
    "            )\n",
    "            renamed_scores_files.append(renamed_output_file)\n",
    "    \n",
    "    else:\n",
    "        renamed_output_files = glob(f\"{output_subdir}/*.cif\") + glob(\n",
    "            f\"{output_subdir}/*.pdb\"\n",
    "        )\n",
    "        renamed_scores_files = glob(f\"{output_subdir}/*.npz\")\n",
    "\n",
    "    return renamed_output_files, renamed_scores_files\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "def export_structure_as_html(\n",
    "    parent_name, file_path, output_dir=\"\", highlight_residues=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Exports the 3D structure as an interactive HTML file with highlighted residues.\n",
    "\n",
    "    Parameters:\n",
    "    - parent_name: str, the title/name for the viewer.\n",
    "    - file_path: str, path to the PDB or CIF structure file.\n",
    "    - output_dir: str, directory to save the HTML file (creates the directory if it doesn't exist).\n",
    "    - highlight_residues: list of dicts, each with 'chain' and 'resi' keys to specify residues to highlight.\n",
    "    \"\"\"\n",
    "\n",
    "    output_filename = f\"{parent_name}_structure.html\"\n",
    "\n",
    "    # Read the structure file content\n",
    "    with open(file_path, \"r\") as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    # Determine the output path\n",
    "    if output_dir:\n",
    "        os.makedirs(\n",
    "            output_dir, exist_ok=True\n",
    "        )  # Create the directory if it doesn't exist\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "    else:\n",
    "        output_path = output_filename  # Save in the current directory by default\n",
    "\n",
    "    # Convert highlight_residues list to JavaScript array format\n",
    "    residues_js = (\n",
    "        \", \".join(\n",
    "            f\"{{chain: '{res['chain']}', resi: {res['resi']}}}\"\n",
    "            for res in highlight_residues\n",
    "        )\n",
    "        if highlight_residues\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "    # Define the HTML content\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>3Dmol Structure Viewer</title>\n",
    "        <script src=\"https://3Dmol.org/build/3Dmol-min.js\"></script>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div id=\"viewer\" style=\"width: 600px; height: 360px; position: relative;\"></div>\n",
    "        <script>\n",
    "            function loadStructure(content, format) {{\n",
    "                var viewer = $3Dmol.createViewer(\"viewer\", {{ backgroundColor: \"white\" }});\n",
    "                viewer.addModel(content, format);\n",
    "                viewer.setStyle({{}}, {{ stick: {{}} }});\n",
    "                viewer.setStyle({{ chain: 'A' }}, {{ cartoon: {{}} }});\n",
    "                \n",
    "                // Highlight specified residues\n",
    "                const residuesToHighlight = [{residues_js}];\n",
    "                residuesToHighlight.forEach(res => {{\n",
    "                    viewer.addStyle(\n",
    "                        {{chain: res.chain, resi: res.resi, atom: \"CA\"}}, \n",
    "                        {{sphere: {{radius: 1.5, color: \"orange\"}}}}\n",
    "                    );\n",
    "                }});\n",
    "\n",
    "                viewer.zoomTo();\n",
    "                viewer.render();\n",
    "            }}\n",
    "\n",
    "            const structureContent = `{file_content}`;\n",
    "            const modelType = \"{'pdb' if file_path.endswith('.pdb') else 'cif'}\";\n",
    "            loadStructure(structureContent, modelType);\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # Write the HTML content to the file\n",
    "    with open(output_path, \"w\") as output_file:\n",
    "        output_file.write(html_content)\n",
    "\n",
    "    print(f\"Exported structure view to {output_path}\")\n",
    "    return output_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "# normalized per plate to parent\n",
    "seqfit_path = \"sandbox/processed_plate_data.csv\"\n",
    "protein_chain = \"A\"\n",
    "\n",
    "df = pd.read_csv(seqfit_path)\n",
    "# ignore deletion meaning \"Mutations\" == \"-\"\n",
    "df = df[df[\"Mutations\"] != \"-\"].copy()\n",
    "# count number of sites mutated and append mutation details\n",
    "# df[\"num_sites\"] = df['Mutations'].apply(lambda x: 0 if x == \"#PARENT#\" else len(x.split(\"_\")))\n",
    "\n",
    "# Apply function to the column\n",
    "df[[\"num_sites\", \"mut_dets\"]] = df[\"Mutations\"].apply(process_mutation)\n",
    "\n",
    "# apply the norm function to all plates\n",
    "df = df.groupby(\"Plate\").apply(norm2parent).reset_index(drop=True).copy()\n",
    "\n",
    "# add a new column called parent name to the df\n",
    "# using the dict out put from match_plate2parent\n",
    "# that matches the plate to the parent\n",
    "parent_dict, plate2parent = match_plate2parent(df, parent_dict=None)\n",
    "df[\"Parent_Name\"] = df[\"Plate\"].map(plate2parent)\n",
    "\n",
    "parents = df[\"Parent_Name\"].unique().tolist()\n",
    "single_ssm_df = prep_single_ssm(df)\n",
    "sites_dict = get_parent2sitedict(single_ssm_df)\n",
    "\n",
    "chai_meta_data = {\n",
    "    \"smiles\": \"\",\n",
    "    \"smiles_name\": \"\",\n",
    "    \"cofactor_smiles\": \"\",\n",
    "    \"cofactor_name\": \"\",\n",
    "    \"joinsubcofactor\": True,\n",
    "    \"torch_device\": \"cuda\",\n",
    "    \"ifrerun\": False,\n",
    "}\n",
    "\n",
    "struct_dict = {}\n",
    "\n",
    "# get structures for all parents\n",
    "for parent_name, parent_seq in parent_dict.items():\n",
    "# get parent chai structure\n",
    "    chai_files, chai_scores_files = get_chaistructure(\n",
    "        chai_dir=os.path.join(os.path.dirname(seqfit_path), \"chai\"),\n",
    "        seq=parent_seq,\n",
    "        seq_name=parent_name,\n",
    "        **chai_meta_data,\n",
    "    )\n",
    "\n",
    "    # Export the 3D structure as an interactive HTML file\n",
    "    html_path = export_structure_as_html(\n",
    "        parent_name=parent_name,\n",
    "        file_path=chai_files[0],\n",
    "        output_dir=os.path.dirname(seqfit_path),\n",
    "        highlight_residues=[\n",
    "            {\"chain\": protein_chain, \"resi\": int(i[1:])} for i in sites_dict.get(parent_name, [])\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    struct_dict[parent_name] = html_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "\n",
    "def get_subplots(\n",
    "    parent,\n",
    "):\n",
    "\n",
    "    # Load HTML content from a file\n",
    "    with open(struct_dict[parent], \"r\") as file:\n",
    "        html_content = file.read()\n",
    "    \n",
    "    # URL-encode the HTML content\n",
    "    data_url = \"data:text/html;charset=utf-8,\" + urllib.parse.quote(html_content)\n",
    "\n",
    "    # Embed in an iframe\n",
    "    iframe_code = f'<iframe id=\"viewerFrame\" width=\"600\" height=\"400\" src=\"{data_url}\"></iframe>'\n",
    "\n",
    "    # Create an HTML pane with the loaded content\n",
    "    html_pane = pn.pane.HTML(iframe_code)\n",
    "\n",
    "    site_dropdown = pn.widgets.Select(name=\"Sites\", options=sites_dict.get(parent, []))\n",
    "\n",
    "    def update_site_plot(site):\n",
    "\n",
    "        site_df = prep_aa_order(\n",
    "            get_single_ssm_site_df(single_ssm_df, parent=parent, site=site)\n",
    "        )\n",
    "\n",
    "        if site_df.empty:\n",
    "            return pn.pane.Markdown(\"### No data available for the selected site\")\n",
    "\n",
    "        site_info = (\n",
    "            site_df[\"parent_aa_loc\"].unique()[0] if not site_df.empty else \"Unknown\"\n",
    "        )\n",
    "\n",
    "        return plot_bar_point(\n",
    "            df=site_df,\n",
    "            x=\"mut_aa\",\n",
    "            y=\"pdt_norm\",\n",
    "            # y_label: str = None,\n",
    "            title=f\"{site_info} for {parent}\",\n",
    "            if_max=False,\n",
    "        )\n",
    "\n",
    "    site_plot = pn.Column(pn.bind(update_site_plot, site=site_dropdown))\n",
    "\n",
    "    return pn.Column(\n",
    "        html_pane,\n",
    "        agg_single_ssm_exp_avg(\n",
    "            single_ssm_df=single_ssm_df,\n",
    "            parent_name=parent,\n",
    "            # ys: list,\n",
    "        ),\n",
    "        site_dropdown,\n",
    "        site_plot,\n",
    "    )\n",
    "\n",
    "\n",
    "# Dropdown for parent selection\n",
    "parent_dropdown = pn.widgets.Select(name=\"Parent\", options=parents)\n",
    "\n",
    "# Initial parent plots\n",
    "initial_subplots = get_subplots(parents[0])\n",
    "\n",
    "# Panel layout\n",
    "dashboard = pn.Column(\n",
    "    agg_parent_plot(df),\n",
    "    parent_dropdown,\n",
    "    pn.Column(pn.bind(get_subplots, parent=parent_dropdown)),\n",
    ")\n",
    "\n",
    "\n",
    "# dashboard.save(\"/home/fli/LevSeq/sandbox/HMC.html\", embed=True)\n",
    "# dashboard.servable()\n",
    "pn.serve(dashboard, open=True, browser=\"chrome\")\n",
    "\n",
    "\n",
    "# Serve the dashboard\n",
    "port = 8000  # Specify the port you want to use\n",
    "server = pn.serve(dashboard, port=port, show=False, start=False)\n",
    "\n",
    "# Generate HTML wrapper file with iframe pointing to the served Panel app\n",
    "wrapper_html_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Interactive Panel Dashboard</title>\n",
    "</head>\n",
    "<body>\n",
    "    <iframe src=\"http://localhost:{port}\" style=\"width: 100%; height: 100vh; border: none;\"></iframe>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Define the path where you want to save the HTML file\n",
    "output_path = Path(\"sandbox/interactive_dashboard_wrapper.html\")\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(wrapper_html_content)\n",
    "\n",
    "print(f\"Wrapper HTML saved at {output_path}\")\n",
    "print(f\"Access the interactive dashboard via: http://localhost:{port}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LevSeq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
